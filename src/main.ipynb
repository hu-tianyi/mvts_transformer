{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a9d884a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:57:14,091 | INFO : Loading packages ...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Loading packages ...\")\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# 3rd party packages\n",
    "\n",
    "#from tqdm import tqdm\n",
    "# since we are using it in jupyter notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Project modules\n",
    "from options import Options\n",
    "from running import setup, pipeline_factory, validate, check_progress, NEG_METRICS\n",
    "from utils import utils\n",
    "from datasets.data import data_factory, Normalizer\n",
    "from datasets.datasplit import split_dataset\n",
    "from models.ts_transformer import model_factory\n",
    "from models.loss import get_loss_module\n",
    "from optimizers import get_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "56d5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(config):\n",
    "\n",
    "    total_epoch_time = 0\n",
    "    total_eval_time = 0\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Add file logging besides stdout\n",
    "    file_handler = logging.FileHandler(os.path.join(config['output_dir'], 'output.log'))\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    logger.info('Running:\\n{}\\n'.format(' '.join(sys.argv)))  # command used to run\n",
    "\n",
    "    if config['seed'] is not None:\n",
    "        torch.manual_seed(config['seed'])\n",
    "\n",
    "    device = torch.device('cuda' if (torch.cuda.is_available() and config['gpu'] != '-1') else 'cpu')\n",
    "    logger.info(\"Using device: {}\".format(device))\n",
    "    if device == 'cuda':\n",
    "        logger.info(\"Device index: {}\".format(torch.cuda.current_device()))\n",
    "\n",
    "    # Build data\n",
    "    logger.info(\"Loading and preprocessing data ...\")\n",
    "    data_class = data_factory[config['data_class']]\n",
    "    my_data = data_class(config['data_dir'], pattern=config['pattern'], n_proc=config['n_proc'], limit_size=config['limit_size'], config=config)\n",
    "    feat_dim = my_data.feature_df.shape[1]  # dimensionality of data features\n",
    "    if config['task'] == 'classification':\n",
    "        validation_method = 'StratifiedShuffleSplit'\n",
    "        labels = my_data.labels_df.values.flatten()\n",
    "    else:\n",
    "        validation_method = 'ShuffleSplit'\n",
    "        labels = None\n",
    "\n",
    "    # Split dataset\n",
    "    test_data = my_data\n",
    "    test_indices = None  # will be converted to empty list in `split_dataset`, if also test_set_ratio == 0\n",
    "    val_data = my_data\n",
    "    val_indices = []\n",
    "    if config['test_pattern']:  # used if test data come from different files / file patterns\n",
    "        test_data = data_class(config['data_dir'], pattern=config['test_pattern'], n_proc=-1, config=config)\n",
    "        test_indices = test_data.all_IDs\n",
    "    if config['test_from']:  # load test IDs directly from file, if available, otherwise use `test_set_ratio`. Can work together with `test_pattern`\n",
    "        test_indices = list(set([line.rstrip() for line in open(config['test_from']).readlines()]))\n",
    "        try:\n",
    "            test_indices = [int(ind) for ind in test_indices]  # integer indices\n",
    "        except ValueError:\n",
    "            pass  # in case indices are non-integers\n",
    "        logger.info(\"Loaded {} test IDs from file: '{}'\".format(len(test_indices), config['test_from']))\n",
    "    if config['val_pattern']:  # used if val data come from different files / file patterns\n",
    "        val_data = data_class(config['data_dir'], pattern=config['val_pattern'], n_proc=-1, config=config)\n",
    "        val_indices = val_data.all_IDs\n",
    "\n",
    "    # Note: currently a validation set must exist, either with `val_pattern` or `val_ratio`\n",
    "    # Using a `val_pattern` means that `val_ratio` == 0 and `test_ratio` == 0\n",
    "    if config['val_ratio'] > 0:\n",
    "        train_indices, val_indices, test_indices = split_dataset(data_indices=my_data.all_IDs,\n",
    "                                                                 validation_method=validation_method,\n",
    "                                                                 n_splits=1,\n",
    "                                                                 validation_ratio=config['val_ratio'],\n",
    "                                                                 test_set_ratio=config['test_ratio'],  # used only if test_indices not explicitly specified\n",
    "                                                                 test_indices=test_indices,\n",
    "                                                                 random_seed=1337,\n",
    "                                                                 labels=labels)\n",
    "        train_indices = train_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "        val_indices = val_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "    else:\n",
    "        train_indices = my_data.all_IDs\n",
    "        if test_indices is None:\n",
    "            test_indices = []\n",
    "\n",
    "    logger.info(\"{} samples may be used for training\".format(len(train_indices)))\n",
    "    logger.info(\"{} samples will be used for validation\".format(len(val_indices)))\n",
    "    logger.info(\"{} samples will be used for testing\".format(len(test_indices)))\n",
    "\n",
    "    with open(os.path.join(config['output_dir'], 'data_indices.json'), 'w') as f:\n",
    "        try:\n",
    "            json.dump({'train_indices': list(map(int, train_indices)),\n",
    "                       'val_indices': list(map(int, val_indices)),\n",
    "                       'test_indices': list(map(int, test_indices))}, f, indent=4)\n",
    "        except ValueError:  # in case indices are non-integers\n",
    "            json.dump({'train_indices': list(train_indices),\n",
    "                       'val_indices': list(val_indices),\n",
    "                       'test_indices': list(test_indices)}, f, indent=4)\n",
    "\n",
    "    # Pre-process features\n",
    "    normalizer = None\n",
    "    if config['norm_from']:\n",
    "        with open(config['norm_from'], 'rb') as f:\n",
    "            norm_dict = pickle.load(f)\n",
    "        normalizer = Normalizer(**norm_dict)\n",
    "    elif config['normalization'] is not None:\n",
    "        normalizer = Normalizer(config['normalization'])\n",
    "        my_data.feature_df.loc[train_indices] = normalizer.normalize(my_data.feature_df.loc[train_indices])\n",
    "        if not config['normalization'].startswith('per_sample'):\n",
    "            # get normalizing values from training set and store for future use\n",
    "            norm_dict = normalizer.__dict__\n",
    "            with open(os.path.join(config['output_dir'], 'normalization.pickle'), 'wb') as f:\n",
    "                pickle.dump(norm_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "    if normalizer is not None:\n",
    "        if len(val_indices):\n",
    "            val_data.feature_df.loc[val_indices] = normalizer.normalize(val_data.feature_df.loc[val_indices])\n",
    "        if len(test_indices):\n",
    "            test_data.feature_df.loc[test_indices] = normalizer.normalize(test_data.feature_df.loc[test_indices])\n",
    "\n",
    "    # Create model\n",
    "    logger.info(\"Creating model ...\")\n",
    "    model = model_factory(config, my_data)\n",
    "\n",
    "    if config['freeze']:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith('output_layer'):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    logger.info(\"Model:\\n{}\".format(model))\n",
    "    logger.info(\"Total number of parameters: {}\".format(utils.count_parameters(model)))\n",
    "    logger.info(\"Trainable parameters: {}\".format(utils.count_parameters(model, trainable=True)))\n",
    "\n",
    "\n",
    "    # Initialize optimizer\n",
    "\n",
    "    if config['global_reg']:\n",
    "        weight_decay = config['l2_reg']\n",
    "        output_reg = None\n",
    "    else:\n",
    "        weight_decay = 0\n",
    "        output_reg = config['l2_reg']\n",
    "\n",
    "    optim_class = get_optimizer(config['optimizer'])\n",
    "    optimizer = optim_class(model.parameters(), lr=config['lr'], weight_decay=weight_decay)\n",
    "\n",
    "    start_epoch = 0\n",
    "    lr_step = 0  # current step index of `lr_step`\n",
    "    lr = config['lr']  # current learning step\n",
    "    # Load model and optimizer state\n",
    "    if args.load_model:\n",
    "        model, optimizer, start_epoch = utils.load_model(model, config['load_model'], optimizer, config['resume'],\n",
    "                                                         config['change_output'],\n",
    "                                                         config['lr'],\n",
    "                                                         config['lr_step'],\n",
    "                                                         config['lr_factor'])\n",
    "    model.to(device)\n",
    "\n",
    "    loss_module = get_loss_module(config)\n",
    "\n",
    "    if config['test_only'] == 'testset':  # Only evaluate and skip training\n",
    "        dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "        test_dataset = dataset_class(test_data, test_indices)\n",
    "\n",
    "        test_loader = DataLoader(dataset=test_dataset,\n",
    "                                 batch_size=config['batch_size'],\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config['num_workers'],\n",
    "                                 pin_memory=True,\n",
    "                                 collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "        test_evaluator = runner_class(model, test_loader, device, loss_module,\n",
    "                                            print_interval=config['print_interval'], console=config['console'])\n",
    "        aggr_metrics_test, per_batch_test = test_evaluator.evaluate(keep_all=True)\n",
    "        print_str = 'Test Summary: '\n",
    "        for k, v in aggr_metrics_test.items():\n",
    "            print_str += '{}: {:8f} | '.format(k, v)\n",
    "        logger.info(print_str)\n",
    "        return\n",
    "    \n",
    "    # Initialize data generators\n",
    "    dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "    val_dataset = dataset_class(val_data, val_indices)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            shuffle=False,\n",
    "                            num_workers=config['num_workers'],\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    train_dataset = dataset_class(my_data, train_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=config['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=config['num_workers'],\n",
    "                              pin_memory=True,\n",
    "                              collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    trainer = runner_class(model, train_loader, device, loss_module, optimizer, l2_reg=output_reg,\n",
    "                                 print_interval=config['print_interval'], console=config['console'])\n",
    "    val_evaluator = runner_class(model, val_loader, device, loss_module,\n",
    "                                       print_interval=config['print_interval'], console=config['console'])\n",
    "\n",
    "    tensorboard_writer = SummaryWriter(config['tensorboard_dir'])\n",
    "\n",
    "    best_value = 1e16 if config['key_metric'] in NEG_METRICS else -1e16  # initialize with +inf or -inf depending on key metric\n",
    "    metrics = []  # (for validation) list of lists: for each epoch, stores metrics like loss, ...\n",
    "    best_metrics = {}\n",
    "\n",
    "    # Evaluate on validation before training\n",
    "    aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config, best_metrics,\n",
    "                                                          best_value, epoch=0)\n",
    "    metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "    metrics.append(list(metrics_values))\n",
    "\n",
    "    logger.info('Starting training...')\n",
    "    for epoch in tqdm(range(start_epoch + 1, config[\"epochs\"] + 1), desc='Training Epoch', leave=False):\n",
    "        mark = epoch if config['save_all'] else 'last'\n",
    "        epoch_start_time = time.time()\n",
    "        aggr_metrics_train = trainer.train_epoch(epoch)  # dictionary of aggregate epoch metrics\n",
    "        epoch_runtime = time.time() - epoch_start_time\n",
    "        print()\n",
    "        print_str = 'Epoch {} Training Summary: '.format(epoch)\n",
    "        for k, v in aggr_metrics_train.items():\n",
    "            tensorboard_writer.add_scalar('{}/train'.format(k), v, epoch)\n",
    "            print_str += '{}: {:8f} | '.format(k, v)\n",
    "        logger.info(print_str)\n",
    "        logger.info(\"Epoch runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(epoch_runtime)))\n",
    "        total_epoch_time += epoch_runtime\n",
    "        avg_epoch_time = total_epoch_time / (epoch - start_epoch)\n",
    "        avg_batch_time = avg_epoch_time / len(train_loader)\n",
    "        avg_sample_time = avg_epoch_time / len(train_dataset)\n",
    "        logger.info(\"Avg epoch train. time: {} hours, {} minutes, {} seconds\".format(*utils.readable_time(avg_epoch_time)))\n",
    "        logger.info(\"Avg batch train. time: {} seconds\".format(avg_batch_time))\n",
    "        logger.info(\"Avg sample train. time: {} seconds\".format(avg_sample_time))\n",
    "\n",
    "        # evaluate if first or last epoch or at specified interval\n",
    "        if (epoch == config[\"epochs\"]) or (epoch == start_epoch + 1) or (epoch % config['val_interval'] == 0):\n",
    "            aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config,\n",
    "                                                                  best_metrics, best_value, epoch)\n",
    "            metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "            metrics.append(list(metrics_values))\n",
    "\n",
    "        utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(mark)), epoch, model, optimizer)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        if epoch == config['lr_step'][lr_step]:\n",
    "            utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(epoch)), epoch, model, optimizer)\n",
    "            lr = lr * config['lr_factor'][lr_step]\n",
    "            if lr_step < len(config['lr_step']) - 1:  # so that this index does not get out of bounds\n",
    "                lr_step += 1\n",
    "            logger.info('Learning rate updated to: ', lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        # Difficulty scheduling\n",
    "        if config['harden'] and check_progress(epoch):\n",
    "            train_loader.dataset.update()\n",
    "            val_loader.dataset.update()\n",
    "\n",
    "    # Export evolution of metrics over epochs\n",
    "    header = metrics_names\n",
    "    metrics_filepath = os.path.join(config[\"output_dir\"], \"metrics_\" + config[\"experiment_name\"] + \".xls\")\n",
    "    book = utils.export_performance_metrics(metrics_filepath, metrics, header, sheet_name=\"metrics\")\n",
    "\n",
    "    # Export record metrics to a file accumulating records from all experiments\n",
    "    utils.register_record(config[\"records_file\"], config[\"initial_timestamp\"], config[\"experiment_name\"],\n",
    "                          best_metrics, aggr_metrics_val, comment=config['comment'])\n",
    "\n",
    "    logger.info('Best {} was {}. Other metrics: {}'.format(config['key_metric'], best_value, best_metrics))\n",
    "    logger.info('All Done!')\n",
    "\n",
    "    total_runtime = time.time() - total_start_time\n",
    "    logger.info(\"Total runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(total_runtime)))\n",
    "\n",
    "    return best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e17d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"--output_dir ../experiments/ --comment 'regression_from_Scratch' \\\n",
    "        --name pm25_fromScratch_Regression --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --task regression\"\n",
    "\n",
    "text = \"--output_dir ../experiments/ --comment 'regression_from_Scratch' \\\n",
    "        --name pm25_fromScratch_Regression_test --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --task regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d020d0",
   "metadata": {},
   "source": [
    "### Pretrain\n",
    "python src/main.py --output_dir experiments --comment \"pretraining through imputation\" --name $1_pretrained \n",
    "--records_file Imputation_records.xls --data_dir /path/to/$1/ --data_class tsra --pattern TRAIN --val_ratio 0.2 --epochs 700 --lr 0.001 --optimizer RAdam --batch_size 32 --pos_encoding learnable --d_model 128\n",
    "\n",
    "### Finetune\n",
    "python src/main.py --output_dir experiments --comment \"finetune for regression\" --name BeijingPM25Quality_finetuned --records_file Regression_records.xls --data_dir /path/to/Datasets/Regression/BeijingPM25Quality/ --data_class tsra --pattern TRAIN --val_pattern TEST  --epochs 200 --lr 0.001 --optimizer RAdam --pos_encoding learnable --d_model 128 --load_model path/to/BeijingPM25Quality_pretrained/checkpoints/model_best.pth --task regression --change_output --batch_size 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "036bf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain\n",
    "'''\n",
    "text = \"--output_dir ../experiments/ --comment 'pretraining_through_imputation' \\\n",
    "        --name pm25_pretrained --records_file Imputation_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_ratio 0.2 --epochs 20 --lr 0.001 --optimizer RAdam \\\n",
    "        --batch_size 32 --pos_encoding learnable --d_model 128\"\n",
    "'''\n",
    "\n",
    "\n",
    "# Finetune\n",
    "text = \"--output_dir ../experiments --comment 'finetune_for_regression' \\\n",
    "        --name BeijingPM25Quality_finetuned --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST  --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --d_model 128 \\\n",
    "        --load_model ../experiments/pm25_pretrained_2023-05-04_11-01-18_AhP/checkpoints/model_best.pth \\\n",
    "        --task regression --change_output --batch_size 128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e99d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = text.split()\n",
    "#input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "587e7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Options().parse(input_text)  # `argsparse` object\n",
    "#config = setup(args)  # configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3062ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f600101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_defaults = {}\n",
    "#for key in vars(args):\n",
    "#    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7d457b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:57:42,472 | INFO : Stored configuration file in '../experiments/BeijingPM25Quality_finetuned_2023-05-04_16-57-42_wdT'\n"
     ]
    }
   ],
   "source": [
    "config = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f1f4def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:57:43,523 | INFO : Running:\n",
      "/home/tianyi/anaconda3/envs/transformer/lib/python3.8/site-packages/ipykernel_launcher.py -f /home/tianyi/.local/share/jupyter/runtime/kernel-796aefab-8958-4f7c-bb18-fec8d264f221.json\n",
      "\n",
      "2023-05-04 16:57:43,524 | INFO : Using device: cuda\n",
      "2023-05-04 16:57:43,525 | INFO : Loading and preprocessing data ...\n",
      "11942it [00:24, 488.60it/s]\n",
      "5072it [00:10, 487.22it/s]\n",
      "2023-05-04 16:58:50,473 | INFO : 11918 samples may be used for training\n",
      "2023-05-04 16:58:50,474 | INFO : 5048 samples will be used for validation\n",
      "2023-05-04 16:58:50,474 | INFO : 0 samples will be used for testing\n",
      "2023-05-04 16:58:50,689 | INFO : Creating model ...\n",
      "2023-05-04 16:58:50,694 | INFO : Model:\n",
      "TSTransformerEncoderClassiregressor(\n",
      "  (project_inp): Linear(in_features=9, out_features=128, bias=True)\n",
      "  (pos_enc): LearnablePositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=3072, out_features=1, bias=True)\n",
      ")\n",
      "2023-05-04 16:58:50,695 | INFO : Total number of parameters: 404865\n",
      "2023-05-04 16:58:50,696 | INFO : Trainable parameters: 404865\n",
      "2023-05-04 16:58:50,834 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../experiments/pm25_pretrained_2023-05-04_11-01-18_AhP/checkpoints/model_best.pth. Epoch: 20\n",
      "Evaluating Epoch 0   0.0% | batch:         0 of        40\t|\tloss: 34523.5\n",
      "Evaluating Epoch 0   2.5% | batch:         1 of        40\t|\tloss: 10962\n",
      "Evaluating Epoch 0   5.0% | batch:         2 of        40\t|\tloss: 49514\n",
      "Evaluating Epoch 0   7.5% | batch:         3 of        40\t|\tloss: 30578.3\n",
      "Evaluating Epoch 0  10.0% | batch:         4 of        40\t|\tloss: 11949.3\n",
      "Evaluating Epoch 0  12.5% | batch:         5 of        40\t|\tloss: 17943.6\n",
      "Evaluating Epoch 0  15.0% | batch:         6 of        40\t|\tloss: 44269.7\n",
      "Evaluating Epoch 0  17.5% | batch:         7 of        40\t|\tloss: 18911.3\n",
      "Evaluating Epoch 0  20.0% | batch:         8 of        40\t|\tloss: 13043.2\n",
      "Evaluating Epoch 0  22.5% | batch:         9 of        40\t|\tloss: 33830.7\n",
      "Evaluating Epoch 0  25.0% | batch:        10 of        40\t|\tloss: 28445.7\n",
      "Evaluating Epoch 0  27.5% | batch:        11 of        40\t|\tloss: 15385.7\n",
      "Evaluating Epoch 0  30.0% | batch:        12 of        40\t|\tloss: 67594\n",
      "Evaluating Epoch 0  32.5% | batch:        13 of        40\t|\tloss: 28918.3\n",
      "Evaluating Epoch 0  35.0% | batch:        14 of        40\t|\tloss: 15273.9\n",
      "Evaluating Epoch 0  37.5% | batch:        15 of        40\t|\tloss: 50060\n",
      "Evaluating Epoch 0  40.0% | batch:        16 of        40\t|\tloss: 33086.7\n",
      "Evaluating Epoch 0  42.5% | batch:        17 of        40\t|\tloss: 21320\n",
      "Evaluating Epoch 0  45.0% | batch:        18 of        40\t|\tloss: 24582.7\n",
      "Evaluating Epoch 0  47.5% | batch:        19 of        40\t|\tloss: 55409\n",
      "Evaluating Epoch 0  50.0% | batch:        20 of        40\t|\tloss: 21953.5\n",
      "Evaluating Epoch 0  52.5% | batch:        21 of        40\t|\tloss: 11485.2\n",
      "Evaluating Epoch 0  55.0% | batch:        22 of        40\t|\tloss: 36981.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:51,290 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4556422233581543 seconds\n",
      "\n",
      "2023-05-04 16:58:51,290 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5502525597442816 seconds\n",
      "2023-05-04 16:58:51,291 | INFO : Avg batch val. time: 0.01375631399360704 seconds\n",
      "2023-05-04 16:58:51,292 | INFO : Avg sample val. time: 0.0001090040728495011 seconds\n",
      "2023-05-04 16:58:51,292 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 31395.954487 | \n",
      "/home/tianyi/anaconda3/envs/transformer/lib/python3.8/site-packages/numpy/lib/npyio.py:713: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n",
      "2023-05-04 16:58:51,304 | INFO : Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 0  57.5% | batch:        23 of        40\t|\tloss: 30231.1\n",
      "Evaluating Epoch 0  60.0% | batch:        24 of        40\t|\tloss: 12199\n",
      "Evaluating Epoch 0  62.5% | batch:        25 of        40\t|\tloss: 54077.7\n",
      "Evaluating Epoch 0  65.0% | batch:        26 of        40\t|\tloss: 50364.5\n",
      "Evaluating Epoch 0  67.5% | batch:        27 of        40\t|\tloss: 17486.7\n",
      "Evaluating Epoch 0  70.0% | batch:        28 of        40\t|\tloss: 38107.6\n",
      "Evaluating Epoch 0  72.5% | batch:        29 of        40\t|\tloss: 54040\n",
      "Evaluating Epoch 0  75.0% | batch:        30 of        40\t|\tloss: 17143.6\n",
      "Evaluating Epoch 0  77.5% | batch:        31 of        40\t|\tloss: 17641.4\n",
      "Evaluating Epoch 0  80.0% | batch:        32 of        40\t|\tloss: 54738\n",
      "Evaluating Epoch 0  82.5% | batch:        33 of        40\t|\tloss: 26178\n",
      "Evaluating Epoch 0  85.0% | batch:        34 of        40\t|\tloss: 12782.8\n",
      "Evaluating Epoch 0  87.5% | batch:        35 of        40\t|\tloss: 51777.4\n",
      "Evaluating Epoch 0  90.0% | batch:        36 of        40\t|\tloss: 34442.2\n",
      "Evaluating Epoch 0  92.5% | batch:        37 of        40\t|\tloss: 16541.9\n",
      "Evaluating Epoch 0  95.0% | batch:        38 of        40\t|\tloss: 48512.1\n",
      "Evaluating Epoch 0  97.5% | batch:        39 of        40\t|\tloss: 59181.7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1   0.0% | batch:         0 of        94\t|\tloss: 28550.1\n",
      "Training Epoch 1   1.1% | batch:         1 of        94\t|\tloss: 22703.3\n",
      "Training Epoch 1   2.1% | batch:         2 of        94\t|\tloss: 26831.7\n",
      "Training Epoch 1   3.2% | batch:         3 of        94\t|\tloss: 34254.3\n",
      "Training Epoch 1   4.3% | batch:         4 of        94\t|\tloss: 30830.4\n",
      "Training Epoch 1   5.3% | batch:         5 of        94\t|\tloss: 30773.5\n",
      "Training Epoch 1   6.4% | batch:         6 of        94\t|\tloss: 30826.2\n",
      "Training Epoch 1   7.4% | batch:         7 of        94\t|\tloss: 42041\n",
      "Training Epoch 1   8.5% | batch:         8 of        94\t|\tloss: 32573.3\n",
      "Training Epoch 1   9.6% | batch:         9 of        94\t|\tloss: 40816.9\n",
      "Training Epoch 1  10.6% | batch:        10 of        94\t|\tloss: 26788.2\n",
      "Training Epoch 1  11.7% | batch:        11 of        94\t|\tloss: 33396\n",
      "Training Epoch 1  12.8% | batch:        12 of        94\t|\tloss: 32683.3\n",
      "Training Epoch 1  13.8% | batch:        13 of        94\t|\tloss: 32145.8\n",
      "Training Epoch 1  14.9% | batch:        14 of        94\t|\tloss: 29402.9\n",
      "Training Epoch 1  16.0% | batch:        15 of        94\t|\tloss: 27679.8\n",
      "Training Epoch 1  17.0% | batch:        16 of        94\t|\tloss: 36117.4\n",
      "Training Epoch 1  18.1% | batch:        17 of        94\t|\tloss: 28790.7\n",
      "Training Epoch 1  19.1% | batch:        18 of        94\t|\tloss: 27829.6\n",
      "Training Epoch 1  20.2% | batch:        19 of        94\t|\tloss: 31800.7\n",
      "Training Epoch 1  21.3% | batch:        20 of        94\t|\tloss: 30529.1\n",
      "Training Epoch 1  22.3% | batch:        21 of        94\t|\tloss: 39965.7\n",
      "Training Epoch 1  23.4% | batch:        22 of        94\t|\tloss: 26137.6\n",
      "Training Epoch 1  24.5% | batch:        23 of        94\t|\tloss: 25915\n",
      "Training Epoch 1  25.5% | batch:        24 of        94\t|\tloss: 34028.3\n",
      "Training Epoch 1  26.6% | batch:        25 of        94\t|\tloss: 49248.3\n",
      "Training Epoch 1  27.7% | batch:        26 of        94\t|\tloss: 29047.3\n",
      "Training Epoch 1  28.7% | batch:        27 of        94\t|\tloss: 33683.1\n",
      "Training Epoch 1  29.8% | batch:        28 of        94\t|\tloss: 29621.2\n",
      "Training Epoch 1  30.9% | batch:        29 of        94\t|\tloss: 25648.5\n",
      "Training Epoch 1  31.9% | batch:        30 of        94\t|\tloss: 33145.5\n",
      "Training Epoch 1  33.0% | batch:        31 of        94\t|\tloss: 38499.6\n",
      "Training Epoch 1  34.0% | batch:        32 of        94\t|\tloss: 23634\n",
      "Training Epoch 1  35.1% | batch:        33 of        94\t|\tloss: 27692\n",
      "Training Epoch 1  36.2% | batch:        34 of        94\t|\tloss: 30469.3\n",
      "Training Epoch 1  37.2% | batch:        35 of        94\t|\tloss: 33976.8\n",
      "Training Epoch 1  38.3% | batch:        36 of        94\t|\tloss: 33342.2\n",
      "Training Epoch 1  39.4% | batch:        37 of        94\t|\tloss: 27984.1\n",
      "Training Epoch 1  40.4% | batch:        38 of        94\t|\tloss: 32343.5\n",
      "Training Epoch 1  41.5% | batch:        39 of        94\t|\tloss: 33349\n",
      "Training Epoch 1  42.6% | batch:        40 of        94\t|\tloss: 33091.2\n",
      "Training Epoch 1  43.6% | batch:        41 of        94\t|\tloss: 34366.2\n",
      "Training Epoch 1  44.7% | batch:        42 of        94\t|\tloss: 22905.4\n",
      "Training Epoch 1  45.7% | batch:        43 of        94\t|\tloss: 30167.7\n",
      "Training Epoch 1  46.8% | batch:        44 of        94\t|\tloss: 23340.2\n",
      "Training Epoch 1  47.9% | batch:        45 of        94\t|\tloss: 27945.2\n",
      "Training Epoch 1  48.9% | batch:        46 of        94\t|\tloss: 30017.8\n",
      "Training Epoch 1  50.0% | batch:        47 of        94\t|\tloss: 26340.1\n",
      "Training Epoch 1  51.1% | batch:        48 of        94\t|\tloss: 36063\n",
      "Training Epoch 1  52.1% | batch:        49 of        94\t|\tloss: 28804.9\n",
      "Training Epoch 1  53.2% | batch:        50 of        94\t|\tloss: 27042.8\n",
      "Training Epoch 1  54.3% | batch:        51 of        94\t|\tloss: 30737.7\n",
      "Training Epoch 1  55.3% | batch:        52 of        94\t|\tloss: 31317.3\n",
      "Training Epoch 1  56.4% | batch:        53 of        94\t|\tloss: 31794.2\n",
      "Training Epoch 1  57.4% | batch:        54 of        94\t|\tloss: 25979.5\n",
      "Training Epoch 1  58.5% | batch:        55 of        94\t|\tloss: 29381.6\n",
      "Training Epoch 1  59.6% | batch:        56 of        94\t|\tloss: 29233.5\n",
      "Training Epoch 1  60.6% | batch:        57 of        94\t|\tloss: 27660.4\n",
      "Training Epoch 1  61.7% | batch:        58 of        94\t|\tloss: 26475.6\n",
      "Training Epoch 1  62.8% | batch:        59 of        94\t|\tloss: 23313.5\n",
      "Training Epoch 1  63.8% | batch:        60 of        94\t|\tloss: 32588.6\n",
      "Training Epoch 1  64.9% | batch:        61 of        94\t|\tloss: 26698\n",
      "Training Epoch 1  66.0% | batch:        62 of        94\t|\tloss: 35857.9\n",
      "Training Epoch 1  67.0% | batch:        63 of        94\t|\tloss: 30482.7\n",
      "Training Epoch 1  68.1% | batch:        64 of        94\t|\tloss: 29036.6\n",
      "Training Epoch 1  69.1% | batch:        65 of        94\t|\tloss: 32815.5\n",
      "Training Epoch 1  70.2% | batch:        66 of        94\t|\tloss: 23816.3\n",
      "Training Epoch 1  71.3% | batch:        67 of        94\t|\tloss: 33952.5\n",
      "Training Epoch 1  72.3% | batch:        68 of        94\t|\tloss: 28868.8\n",
      "Training Epoch 1  73.4% | batch:        69 of        94\t|\tloss: 25811.8\n",
      "Training Epoch 1  74.5% | batch:        70 of        94\t|\tloss: 27073.9\n",
      "Training Epoch 1  75.5% | batch:        71 of        94\t|\tloss: 32801.3\n",
      "Training Epoch 1  76.6% | batch:        72 of        94\t|\tloss: 32795.6\n",
      "Training Epoch 1  77.7% | batch:        73 of        94\t|\tloss: 30323.5\n",
      "Training Epoch 1  78.7% | batch:        74 of        94\t|\tloss: 27426.3\n",
      "Training Epoch 1  79.8% | batch:        75 of        94\t|\tloss: 27980.1\n",
      "Training Epoch 1  80.9% | batch:        76 of        94\t|\tloss: 27815.7\n",
      "Training Epoch 1  81.9% | batch:        77 of        94\t|\tloss: 30338.4\n",
      "Training Epoch 1  83.0% | batch:        78 of        94\t|\tloss: 28352.8\n",
      "Training Epoch 1  84.0% | batch:        79 of        94\t|\tloss: 24546.1\n",
      "Training Epoch 1  85.1% | batch:        80 of        94\t|\tloss: 25869.2\n",
      "Training Epoch 1  86.2% | batch:        81 of        94\t|\tloss: 31759.6\n",
      "Training Epoch 1  87.2% | batch:        82 of        94\t|\tloss: 27392.2\n",
      "Training Epoch 1  88.3% | batch:        83 of        94\t|\tloss: 24225.5\n",
      "Training Epoch 1  89.4% | batch:        84 of        94\t|\tloss: 39576.1\n",
      "Training Epoch 1  90.4% | batch:        85 of        94\t|\tloss: 25302.2\n",
      "Training Epoch 1  91.5% | batch:        86 of        94\t|\tloss: 33835\n",
      "Training Epoch 1  92.6% | batch:        87 of        94\t|\tloss: 31545\n",
      "Training Epoch 1  93.6% | batch:        88 of        94\t|\tloss: 27107.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:53,088 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 30204.993607 | \n",
      "2023-05-04 16:58:53,089 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7765676975250244 seconds\n",
      "\n",
      "2023-05-04 16:58:53,090 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7765676975250244 seconds\n",
      "2023-05-04 16:58:53,091 | INFO : Avg batch train. time: 0.018899656356649197 seconds\n",
      "2023-05-04 16:58:53,092 | INFO : Avg sample train. time: 0.00014906592528318716 seconds\n",
      "2023-05-04 16:58:53,093 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1  94.7% | batch:        89 of        94\t|\tloss: 28936.6\n",
      "Training Epoch 1  95.7% | batch:        90 of        94\t|\tloss: 29497.9\n",
      "Training Epoch 1  96.8% | batch:        91 of        94\t|\tloss: 26470.3\n",
      "Training Epoch 1  97.9% | batch:        92 of        94\t|\tloss: 28973\n",
      "Training Epoch 1  98.9% | batch:        93 of        94\t|\tloss: 13007.9\n",
      "\n",
      "Evaluating Epoch 1   0.0% | batch:         0 of        40\t|\tloss: 28635.8\n",
      "Evaluating Epoch 1   2.5% | batch:         1 of        40\t|\tloss: 10899.4\n",
      "Evaluating Epoch 1   5.0% | batch:         2 of        40\t|\tloss: 35919\n",
      "Evaluating Epoch 1   7.5% | batch:         3 of        40\t|\tloss: 24633.8\n",
      "Evaluating Epoch 1  10.0% | batch:         4 of        40\t|\tloss: 11533.4\n",
      "Evaluating Epoch 1  12.5% | batch:         5 of        40\t|\tloss: 14281.4\n",
      "Evaluating Epoch 1  15.0% | batch:         6 of        40\t|\tloss: 34110.5\n",
      "Evaluating Epoch 1  17.5% | batch:         7 of        40\t|\tloss: 17594.2\n",
      "Evaluating Epoch 1  20.0% | batch:         8 of        40\t|\tloss: 12599.4\n",
      "Evaluating Epoch 1  22.5% | batch:         9 of        40\t|\tloss: 26069.3\n",
      "Evaluating Epoch 1  25.0% | batch:        10 of        40\t|\tloss: 24891.2\n",
      "Evaluating Epoch 1  27.5% | batch:        11 of        40\t|\tloss: 14353.9\n",
      "Evaluating Epoch 1  30.0% | batch:        12 of        40\t|\tloss: 51041.4\n",
      "Evaluating Epoch 1  32.5% | batch:        13 of        40\t|\tloss: 23580.7\n",
      "Evaluating Epoch 1  35.0% | batch:        14 of        40\t|\tloss: 14600.3\n",
      "Evaluating Epoch 1  37.5% | batch:        15 of        40\t|\tloss: 37376.3\n",
      "Evaluating Epoch 1  40.0% | batch:        16 of        40\t|\tloss: 27120\n",
      "Evaluating Epoch 1  42.5% | batch:        17 of        40\t|\tloss: 19742.5\n",
      "Evaluating Epoch 1  45.0% | batch:        18 of        40\t|\tloss: 20763.4\n",
      "Evaluating Epoch 1  47.5% | batch:        19 of        40\t|\tloss: 41885.9\n",
      "Evaluating Epoch 1  50.0% | batch:        20 of        40\t|\tloss: 20445.8\n",
      "Evaluating Epoch 1  52.5% | batch:        21 of        40\t|\tloss: 11337\n",
      "Evaluating Epoch 1  55.0% | batch:        22 of        40\t|\tloss: 29482.1\n",
      "Evaluating Epoch 1  57.5% | batch:        23 of        40\t|\tloss: 24042.7\n",
      "Evaluating Epoch 1  60.0% | batch:        24 of        40\t|\tloss: 11798.1\n",
      "Evaluating Epoch 1  62.5% | batch:        25 of        40\t|\tloss: 40016.2\n",
      "Evaluating Epoch 1  65.0% | batch:        26 of        40\t|\tloss: 42807.3\n",
      "Evaluating Epoch 1  67.5% | batch:        27 of        40\t|\tloss: 16922.4\n",
      "Evaluating Epoch 1  70.0% | batch:        28 of        40\t|\tloss: 29749.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:53,541 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4474906921386719 seconds\n",
      "\n",
      "2023-05-04 16:58:53,542 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5496221188387257 seconds\n",
      "2023-05-04 16:58:53,542 | INFO : Avg batch val. time: 0.013740552970968142 seconds\n",
      "2023-05-04 16:58:53,543 | INFO : Avg sample val. time: 0.00010887918360513584 seconds\n",
      "2023-05-04 16:58:53,544 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 25505.224222 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 1  72.5% | batch:        29 of        40\t|\tloss: 42600.6\n",
      "Evaluating Epoch 1  75.0% | batch:        30 of        40\t|\tloss: 15772.1\n",
      "Evaluating Epoch 1  77.5% | batch:        31 of        40\t|\tloss: 15405.9\n",
      "Evaluating Epoch 1  80.0% | batch:        32 of        40\t|\tloss: 40427.5\n",
      "Evaluating Epoch 1  82.5% | batch:        33 of        40\t|\tloss: 22397.6\n",
      "Evaluating Epoch 1  85.0% | batch:        34 of        40\t|\tloss: 12156.3\n",
      "Evaluating Epoch 1  87.5% | batch:        35 of        40\t|\tloss: 36765.7\n",
      "Evaluating Epoch 1  90.0% | batch:        36 of        40\t|\tloss: 28763.3\n",
      "Evaluating Epoch 1  92.5% | batch:        37 of        40\t|\tloss: 15884.1\n",
      "Evaluating Epoch 1  95.0% | batch:        38 of        40\t|\tloss: 36618.7\n",
      "Evaluating Epoch 1  97.5% | batch:        39 of        40\t|\tloss: 47629.4\n",
      "\n",
      "Training Epoch 2   0.0% | batch:         0 of        94\t|\tloss: 28055.5\n",
      "Training Epoch 2   1.1% | batch:         1 of        94\t|\tloss: 25165.8\n",
      "Training Epoch 2   2.1% | batch:         2 of        94\t|\tloss: 31906.8\n",
      "Training Epoch 2   3.2% | batch:         3 of        94\t|\tloss: 30386.5\n",
      "Training Epoch 2   4.3% | batch:         4 of        94\t|\tloss: 23515.8\n",
      "Training Epoch 2   5.3% | batch:         5 of        94\t|\tloss: 21194.3\n",
      "Training Epoch 2   6.4% | batch:         6 of        94\t|\tloss: 24852.2\n",
      "Training Epoch 2   7.4% | batch:         7 of        94\t|\tloss: 21896\n",
      "Training Epoch 2   8.5% | batch:         8 of        94\t|\tloss: 31302.8\n",
      "Training Epoch 2   9.6% | batch:         9 of        94\t|\tloss: 32698.3\n",
      "Training Epoch 2  10.6% | batch:        10 of        94\t|\tloss: 32216.8\n",
      "Training Epoch 2  11.7% | batch:        11 of        94\t|\tloss: 20124\n",
      "Training Epoch 2  12.8% | batch:        12 of        94\t|\tloss: 32356.5\n",
      "Training Epoch 2  13.8% | batch:        13 of        94\t|\tloss: 25133.5\n",
      "Training Epoch 2  14.9% | batch:        14 of        94\t|\tloss: 23998.1\n",
      "Training Epoch 2  16.0% | batch:        15 of        94\t|\tloss: 23248.4\n",
      "Training Epoch 2  17.0% | batch:        16 of        94\t|\tloss: 25087.2\n",
      "Training Epoch 2  18.1% | batch:        17 of        94\t|\tloss: 29854.5\n",
      "Training Epoch 2  19.1% | batch:        18 of        94\t|\tloss: 18676.3\n",
      "Training Epoch 2  20.2% | batch:        19 of        94\t|\tloss: 27750.7\n",
      "Training Epoch 2  21.3% | batch:        20 of        94\t|\tloss: 21308.5\n",
      "Training Epoch 2  22.3% | batch:        21 of        94\t|\tloss: 28903.6\n",
      "Training Epoch 2  23.4% | batch:        22 of        94\t|\tloss: 27871.4\n",
      "Training Epoch 2  24.5% | batch:        23 of        94\t|\tloss: 24312.4\n",
      "Training Epoch 2  25.5% | batch:        24 of        94\t|\tloss: 21438.6\n",
      "Training Epoch 2  26.6% | batch:        25 of        94\t|\tloss: 32048.8\n",
      "Training Epoch 2  27.7% | batch:        26 of        94\t|\tloss: 22173.6\n",
      "Training Epoch 2  28.7% | batch:        27 of        94\t|\tloss: 16338.5\n",
      "Training Epoch 2  29.8% | batch:        28 of        94\t|\tloss: 26432.2\n",
      "Training Epoch 2  30.9% | batch:        29 of        94\t|\tloss: 27003.9\n",
      "Training Epoch 2  31.9% | batch:        30 of        94\t|\tloss: 18311.9\n",
      "Training Epoch 2  33.0% | batch:        31 of        94\t|\tloss: 24212\n",
      "Training Epoch 2  34.0% | batch:        32 of        94\t|\tloss: 29092.9\n",
      "Training Epoch 2  35.1% | batch:        33 of        94\t|\tloss: 21360.3\n",
      "Training Epoch 2  36.2% | batch:        34 of        94\t|\tloss: 28583.1\n",
      "Training Epoch 2  37.2% | batch:        35 of        94\t|\tloss: 18468.3\n",
      "Training Epoch 2  38.3% | batch:        36 of        94\t|\tloss: 22234.8\n",
      "Training Epoch 2  39.4% | batch:        37 of        94\t|\tloss: 25160\n",
      "Training Epoch 2  40.4% | batch:        38 of        94\t|\tloss: 22572.3\n",
      "Training Epoch 2  41.5% | batch:        39 of        94\t|\tloss: 23685\n",
      "Training Epoch 2  42.6% | batch:        40 of        94\t|\tloss: 23632.2\n",
      "Training Epoch 2  43.6% | batch:        41 of        94\t|\tloss: 22512.1\n",
      "Training Epoch 2  44.7% | batch:        42 of        94\t|\tloss: 21837.1\n",
      "Training Epoch 2  45.7% | batch:        43 of        94\t|\tloss: 20334.8\n",
      "Training Epoch 2  46.8% | batch:        44 of        94\t|\tloss: 19325.4\n",
      "Training Epoch 2  47.9% | batch:        45 of        94\t|\tloss: 21616.7\n",
      "Training Epoch 2  48.9% | batch:        46 of        94\t|\tloss: 13352.9\n",
      "Training Epoch 2  50.0% | batch:        47 of        94\t|\tloss: 16392.4\n",
      "Training Epoch 2  51.1% | batch:        48 of        94\t|\tloss: 17698.3\n",
      "Training Epoch 2  52.1% | batch:        49 of        94\t|\tloss: 25756\n",
      "Training Epoch 2  53.2% | batch:        50 of        94\t|\tloss: 19241.7\n",
      "Training Epoch 2  54.3% | batch:        51 of        94\t|\tloss: 16140.9\n",
      "Training Epoch 2  55.3% | batch:        52 of        94\t|\tloss: 22494.4\n",
      "Training Epoch 2  56.4% | batch:        53 of        94\t|\tloss: 27549.1\n",
      "Training Epoch 2  57.4% | batch:        54 of        94\t|\tloss: 16640.2\n",
      "Training Epoch 2  58.5% | batch:        55 of        94\t|\tloss: 17079.8\n",
      "Training Epoch 2  59.6% | batch:        56 of        94\t|\tloss: 22712.1\n",
      "Training Epoch 2  60.6% | batch:        57 of        94\t|\tloss: 19317.8\n",
      "Training Epoch 2  61.7% | batch:        58 of        94\t|\tloss: 21555.2\n",
      "Training Epoch 2  62.8% | batch:        59 of        94\t|\tloss: 18420\n",
      "Training Epoch 2  63.8% | batch:        60 of        94\t|\tloss: 20699.8\n",
      "Training Epoch 2  64.9% | batch:        61 of        94\t|\tloss: 25309.1\n",
      "Training Epoch 2  66.0% | batch:        62 of        94\t|\tloss: 17480.2\n",
      "Training Epoch 2  67.0% | batch:        63 of        94\t|\tloss: 15593.4\n",
      "Training Epoch 2  68.1% | batch:        64 of        94\t|\tloss: 22568.4\n",
      "Training Epoch 2  69.1% | batch:        65 of        94\t|\tloss: 22980.1\n",
      "Training Epoch 2  70.2% | batch:        66 of        94\t|\tloss: 21622\n",
      "Training Epoch 2  71.3% | batch:        67 of        94\t|\tloss: 22096.9\n",
      "Training Epoch 2  72.3% | batch:        68 of        94\t|\tloss: 19617.5\n",
      "Training Epoch 2  73.4% | batch:        69 of        94\t|\tloss: 22223.9\n",
      "Training Epoch 2  74.5% | batch:        70 of        94\t|\tloss: 23072.4\n",
      "Training Epoch 2  75.5% | batch:        71 of        94\t|\tloss: 18259.5\n",
      "Training Epoch 2  76.6% | batch:        72 of        94\t|\tloss: 25133.3\n",
      "Training Epoch 2  77.7% | batch:        73 of        94\t|\tloss: 24129.4\n",
      "Training Epoch 2  78.7% | batch:        74 of        94\t|\tloss: 15550.2\n",
      "Training Epoch 2  79.8% | batch:        75 of        94\t|\tloss: 19052.7\n",
      "Training Epoch 2  80.9% | batch:        76 of        94\t|\tloss: 18397.2\n",
      "Training Epoch 2  81.9% | batch:        77 of        94\t|\tloss: 18310.6\n",
      "Training Epoch 2  83.0% | batch:        78 of        94\t|\tloss: 18151.4\n",
      "Training Epoch 2  84.0% | batch:        79 of        94\t|\tloss: 17078.6\n",
      "Training Epoch 2  85.1% | batch:        80 of        94\t|\tloss: 20213.4\n",
      "Training Epoch 2  86.2% | batch:        81 of        94\t|\tloss: 16884.8\n",
      "Training Epoch 2  87.2% | batch:        82 of        94\t|\tloss: 15683.2\n",
      "Training Epoch 2  88.3% | batch:        83 of        94\t|\tloss: 17897\n",
      "Training Epoch 2  89.4% | batch:        84 of        94\t|\tloss: 22738.9\n",
      "Training Epoch 2  90.4% | batch:        85 of        94\t|\tloss: 12968.4\n",
      "Training Epoch 2  91.5% | batch:        86 of        94\t|\tloss: 18011.2\n",
      "Training Epoch 2  92.6% | batch:        87 of        94\t|\tloss: 20868.6\n",
      "Training Epoch 2  93.6% | batch:        88 of        94\t|\tloss: 16197.5\n",
      "Training Epoch 2  94.7% | batch:        89 of        94\t|\tloss: 21278.5\n",
      "Training Epoch 2  95.7% | batch:        90 of        94\t|\tloss: 15231.2\n",
      "Training Epoch 2  96.8% | batch:        91 of        94\t|\tloss: 21995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:55,343 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 22129.874089 | \n",
      "2023-05-04 16:58:55,344 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7765204906463623 seconds\n",
      "\n",
      "2023-05-04 16:58:55,344 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7765440940856934 seconds\n",
      "2023-05-04 16:58:55,344 | INFO : Avg batch train. time: 0.01889940525623078 seconds\n",
      "2023-05-04 16:58:55,345 | INFO : Avg sample train. time: 0.00014906394479658445 seconds\n",
      "2023-05-04 16:58:55,345 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2  97.9% | batch:        92 of        94\t|\tloss: 17398.5\n",
      "Training Epoch 2  98.9% | batch:        93 of        94\t|\tloss: 11563.5\n",
      "\n",
      "Evaluating Epoch 2   0.0% | batch:         0 of        40\t|\tloss: 21675.6\n",
      "Evaluating Epoch 2   2.5% | batch:         1 of        40\t|\tloss: 8369.05\n",
      "Evaluating Epoch 2   5.0% | batch:         2 of        40\t|\tloss: 21805.2\n",
      "Evaluating Epoch 2   7.5% | batch:         3 of        40\t|\tloss: 18905.6\n",
      "Evaluating Epoch 2  10.0% | batch:         4 of        40\t|\tloss: 8544.75\n",
      "Evaluating Epoch 2  12.5% | batch:         5 of        40\t|\tloss: 9064.5\n",
      "Evaluating Epoch 2  15.0% | batch:         6 of        40\t|\tloss: 25693.8\n",
      "Evaluating Epoch 2  17.5% | batch:         7 of        40\t|\tloss: 14074.8\n",
      "Evaluating Epoch 2  20.0% | batch:         8 of        40\t|\tloss: 10317.2\n",
      "Evaluating Epoch 2  22.5% | batch:         9 of        40\t|\tloss: 18171.3\n",
      "Evaluating Epoch 2  25.0% | batch:        10 of        40\t|\tloss: 18997.7\n",
      "Evaluating Epoch 2  27.5% | batch:        11 of        40\t|\tloss: 9800.6\n",
      "Evaluating Epoch 2  30.0% | batch:        12 of        40\t|\tloss: 34692.2\n",
      "Evaluating Epoch 2  32.5% | batch:        13 of        40\t|\tloss: 17106.2\n",
      "Evaluating Epoch 2  35.0% | batch:        14 of        40\t|\tloss: 10830.8\n",
      "Evaluating Epoch 2  37.5% | batch:        15 of        40\t|\tloss: 24181.9\n",
      "Evaluating Epoch 2  40.0% | batch:        16 of        40\t|\tloss: 20668.6\n",
      "Evaluating Epoch 2  42.5% | batch:        17 of        40\t|\tloss: 14926.2\n",
      "Evaluating Epoch 2  45.0% | batch:        18 of        40\t|\tloss: 14027.4\n",
      "Evaluating Epoch 2  47.5% | batch:        19 of        40\t|\tloss: 29389.2\n",
      "Evaluating Epoch 2  50.0% | batch:        20 of        40\t|\tloss: 16877\n",
      "Evaluating Epoch 2  52.5% | batch:        21 of        40\t|\tloss: 8605.45\n",
      "Evaluating Epoch 2  55.0% | batch:        22 of        40\t|\tloss: 21067.9\n",
      "Evaluating Epoch 2  57.5% | batch:        23 of        40\t|\tloss: 16141.9\n",
      "Evaluating Epoch 2  60.0% | batch:        24 of        40\t|\tloss: 8739.42\n",
      "Evaluating Epoch 2  62.5% | batch:        25 of        40\t|\tloss: 26472\n",
      "Evaluating Epoch 2  65.0% | batch:        26 of        40\t|\tloss: 34368.4\n",
      "Evaluating Epoch 2  67.5% | batch:        27 of        40\t|\tloss: 13840.7\n",
      "Evaluating Epoch 2  70.0% | batch:        28 of        40\t|\tloss: 19568.8\n",
      "Evaluating Epoch 2  72.5% | batch:        29 of        40\t|\tloss: 31768.1\n",
      "Evaluating Epoch 2  75.0% | batch:        30 of        40\t|\tloss: 11861.8\n",
      "Evaluating Epoch 2  77.5% | batch:        31 of        40\t|\tloss: 10708.7\n",
      "Evaluating Epoch 2  80.0% | batch:        32 of        40\t|\tloss: 28716.1\n",
      "Evaluating Epoch 2  82.5% | batch:        33 of        40\t|\tloss: 17577.7\n",
      "Evaluating Epoch 2  85.0% | batch:        34 of        40\t|\tloss: 9238.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:55,794 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.448972225189209 seconds\n",
      "\n",
      "2023-05-04 16:58:55,795 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.549008399975009 seconds\n",
      "2023-05-04 16:58:55,796 | INFO : Avg batch val. time: 0.013725209999375227 seconds\n",
      "2023-05-04 16:58:55,797 | INFO : Avg sample val. time: 0.00010875760696810798 seconds\n",
      "2023-05-04 16:58:55,798 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 18366.448717 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 2  87.5% | batch:        35 of        40\t|\tloss: 23634.7\n",
      "Evaluating Epoch 2  90.0% | batch:        36 of        40\t|\tloss: 22137.6\n",
      "Evaluating Epoch 2  92.5% | batch:        37 of        40\t|\tloss: 11715\n",
      "Evaluating Epoch 2  95.0% | batch:        38 of        40\t|\tloss: 23993\n",
      "Evaluating Epoch 2  97.5% | batch:        39 of        40\t|\tloss: 36688.7\n",
      "\n",
      "Training Epoch 3   0.0% | batch:         0 of        94\t|\tloss: 19346.2\n",
      "Training Epoch 3   1.1% | batch:         1 of        94\t|\tloss: 13219.1\n",
      "Training Epoch 3   2.1% | batch:         2 of        94\t|\tloss: 14632.6\n",
      "Training Epoch 3   3.2% | batch:         3 of        94\t|\tloss: 16092.7\n",
      "Training Epoch 3   4.3% | batch:         4 of        94\t|\tloss: 19269.7\n",
      "Training Epoch 3   5.3% | batch:         5 of        94\t|\tloss: 17537.6\n",
      "Training Epoch 3   6.4% | batch:         6 of        94\t|\tloss: 15916\n",
      "Training Epoch 3   7.4% | batch:         7 of        94\t|\tloss: 21114\n",
      "Training Epoch 3   8.5% | batch:         8 of        94\t|\tloss: 19687.5\n",
      "Training Epoch 3   9.6% | batch:         9 of        94\t|\tloss: 17482.6\n",
      "Training Epoch 3  10.6% | batch:        10 of        94\t|\tloss: 10051.2\n",
      "Training Epoch 3  11.7% | batch:        11 of        94\t|\tloss: 18041.6\n",
      "Training Epoch 3  12.8% | batch:        12 of        94\t|\tloss: 15079.4\n",
      "Training Epoch 3  13.8% | batch:        13 of        94\t|\tloss: 17932.3\n",
      "Training Epoch 3  14.9% | batch:        14 of        94\t|\tloss: 12297.2\n",
      "Training Epoch 3  16.0% | batch:        15 of        94\t|\tloss: 16469.7\n",
      "Training Epoch 3  17.0% | batch:        16 of        94\t|\tloss: 14599.7\n",
      "Training Epoch 3  18.1% | batch:        17 of        94\t|\tloss: 19021.8\n",
      "Training Epoch 3  19.1% | batch:        18 of        94\t|\tloss: 16932.1\n",
      "Training Epoch 3  20.2% | batch:        19 of        94\t|\tloss: 22902.1\n",
      "Training Epoch 3  21.3% | batch:        20 of        94\t|\tloss: 24136.3\n",
      "Training Epoch 3  22.3% | batch:        21 of        94\t|\tloss: 18597.8\n",
      "Training Epoch 3  23.4% | batch:        22 of        94\t|\tloss: 15899.3\n",
      "Training Epoch 3  24.5% | batch:        23 of        94\t|\tloss: 15773.9\n",
      "Training Epoch 3  25.5% | batch:        24 of        94\t|\tloss: 15060.8\n",
      "Training Epoch 3  26.6% | batch:        25 of        94\t|\tloss: 18286.3\n",
      "Training Epoch 3  27.7% | batch:        26 of        94\t|\tloss: 15902.3\n",
      "Training Epoch 3  28.7% | batch:        27 of        94\t|\tloss: 17325.3\n",
      "Training Epoch 3  29.8% | batch:        28 of        94\t|\tloss: 12567.4\n",
      "Training Epoch 3  30.9% | batch:        29 of        94\t|\tloss: 10970.9\n",
      "Training Epoch 3  31.9% | batch:        30 of        94\t|\tloss: 12898.9\n",
      "Training Epoch 3  33.0% | batch:        31 of        94\t|\tloss: 11583.8\n",
      "Training Epoch 3  34.0% | batch:        32 of        94\t|\tloss: 14775.8\n",
      "Training Epoch 3  35.1% | batch:        33 of        94\t|\tloss: 11352.5\n",
      "Training Epoch 3  36.2% | batch:        34 of        94\t|\tloss: 20385.2\n",
      "Training Epoch 3  37.2% | batch:        35 of        94\t|\tloss: 10011\n",
      "Training Epoch 3  38.3% | batch:        36 of        94\t|\tloss: 16451.2\n",
      "Training Epoch 3  39.4% | batch:        37 of        94\t|\tloss: 13219.9\n",
      "Training Epoch 3  40.4% | batch:        38 of        94\t|\tloss: 11940.6\n",
      "Training Epoch 3  41.5% | batch:        39 of        94\t|\tloss: 18881.8\n",
      "Training Epoch 3  42.6% | batch:        40 of        94\t|\tloss: 14334.3\n",
      "Training Epoch 3  43.6% | batch:        41 of        94\t|\tloss: 13615.2\n",
      "Training Epoch 3  44.7% | batch:        42 of        94\t|\tloss: 13296.9\n",
      "Training Epoch 3  45.7% | batch:        43 of        94\t|\tloss: 11911\n",
      "Training Epoch 3  46.8% | batch:        44 of        94\t|\tloss: 8761.49\n",
      "Training Epoch 3  47.9% | batch:        45 of        94\t|\tloss: 16092.5\n",
      "Training Epoch 3  48.9% | batch:        46 of        94\t|\tloss: 11742.7\n",
      "Training Epoch 3  50.0% | batch:        47 of        94\t|\tloss: 14412.1\n",
      "Training Epoch 3  51.1% | batch:        48 of        94\t|\tloss: 8404.09\n",
      "Training Epoch 3  52.1% | batch:        49 of        94\t|\tloss: 7784.76\n",
      "Training Epoch 3  53.2% | batch:        50 of        94\t|\tloss: 7051.85\n",
      "Training Epoch 3  54.3% | batch:        51 of        94\t|\tloss: 12398.4\n",
      "Training Epoch 3  55.3% | batch:        52 of        94\t|\tloss: 14719.3\n",
      "Training Epoch 3  56.4% | batch:        53 of        94\t|\tloss: 10451.8\n",
      "Training Epoch 3  57.4% | batch:        54 of        94\t|\tloss: 15857.1\n",
      "Training Epoch 3  58.5% | batch:        55 of        94\t|\tloss: 13866.5\n",
      "Training Epoch 3  59.6% | batch:        56 of        94\t|\tloss: 17222.8\n",
      "Training Epoch 3  60.6% | batch:        57 of        94\t|\tloss: 13970.2\n",
      "Training Epoch 3  61.7% | batch:        58 of        94\t|\tloss: 12315.2\n",
      "Training Epoch 3  62.8% | batch:        59 of        94\t|\tloss: 12099.6\n",
      "Training Epoch 3  63.8% | batch:        60 of        94\t|\tloss: 10015\n",
      "Training Epoch 3  64.9% | batch:        61 of        94\t|\tloss: 10376.6\n",
      "Training Epoch 3  66.0% | batch:        62 of        94\t|\tloss: 10088.5\n",
      "Training Epoch 3  67.0% | batch:        63 of        94\t|\tloss: 9201.53\n",
      "Training Epoch 3  68.1% | batch:        64 of        94\t|\tloss: 11974.5\n",
      "Training Epoch 3  69.1% | batch:        65 of        94\t|\tloss: 8080.26\n",
      "Training Epoch 3  70.2% | batch:        66 of        94\t|\tloss: 14465.6\n",
      "Training Epoch 3  71.3% | batch:        67 of        94\t|\tloss: 11886.1\n",
      "Training Epoch 3  72.3% | batch:        68 of        94\t|\tloss: 11342.8\n",
      "Training Epoch 3  73.4% | batch:        69 of        94\t|\tloss: 9158.76\n",
      "Training Epoch 3  74.5% | batch:        70 of        94\t|\tloss: 11566.9\n",
      "Training Epoch 3  75.5% | batch:        71 of        94\t|\tloss: 11284.9\n",
      "Training Epoch 3  76.6% | batch:        72 of        94\t|\tloss: 9706.86\n",
      "Training Epoch 3  77.7% | batch:        73 of        94\t|\tloss: 9625.29\n",
      "Training Epoch 3  78.7% | batch:        74 of        94\t|\tloss: 9005.75\n",
      "Training Epoch 3  79.8% | batch:        75 of        94\t|\tloss: 11225\n",
      "Training Epoch 3  80.9% | batch:        76 of        94\t|\tloss: 13585.8\n",
      "Training Epoch 3  81.9% | batch:        77 of        94\t|\tloss: 12505.6\n",
      "Training Epoch 3  83.0% | batch:        78 of        94\t|\tloss: 8489.97\n",
      "Training Epoch 3  84.0% | batch:        79 of        94\t|\tloss: 13885.6\n",
      "Training Epoch 3  85.1% | batch:        80 of        94\t|\tloss: 7840.36\n",
      "Training Epoch 3  86.2% | batch:        81 of        94\t|\tloss: 6197.26\n",
      "Training Epoch 3  87.2% | batch:        82 of        94\t|\tloss: 12852.3\n",
      "Training Epoch 3  88.3% | batch:        83 of        94\t|\tloss: 7777.9\n",
      "Training Epoch 3  89.4% | batch:        84 of        94\t|\tloss: 7705.21\n",
      "Training Epoch 3  90.4% | batch:        85 of        94\t|\tloss: 13105.8\n",
      "Training Epoch 3  91.5% | batch:        86 of        94\t|\tloss: 9992.52\n",
      "Training Epoch 3  92.6% | batch:        87 of        94\t|\tloss: 12721\n",
      "Training Epoch 3  93.6% | batch:        88 of        94\t|\tloss: 11001.7\n",
      "Training Epoch 3  94.7% | batch:        89 of        94\t|\tloss: 7945.41\n",
      "Training Epoch 3  95.7% | batch:        90 of        94\t|\tloss: 6876.56\n",
      "Training Epoch 3  96.8% | batch:        91 of        94\t|\tloss: 7442.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:57,480 | INFO : Epoch 3 Training Summary: epoch: 3.000000 | loss: 13235.902120 | \n",
      "2023-05-04 16:58:57,481 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6504583358764648 seconds\n",
      "\n",
      "2023-05-04 16:58:57,482 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7345155080159504 seconds\n",
      "2023-05-04 16:58:57,483 | INFO : Avg batch train. time: 0.01845229263846756 seconds\n",
      "2023-05-04 16:58:57,483 | INFO : Avg sample train. time: 0.0001455374650122462 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 3  97.9% | batch:        92 of        94\t|\tloss: 8244.72\n",
      "Training Epoch 3  98.9% | batch:        93 of        94\t|\tloss: 11500.5\n",
      "\n",
      "Training Epoch 4   0.0% | batch:         0 of        94\t|\tloss: 11528\n",
      "Training Epoch 4   1.1% | batch:         1 of        94\t|\tloss: 11292.7\n",
      "Training Epoch 4   2.1% | batch:         2 of        94\t|\tloss: 6653.18\n",
      "Training Epoch 4   3.2% | batch:         3 of        94\t|\tloss: 7593.09\n",
      "Training Epoch 4   4.3% | batch:         4 of        94\t|\tloss: 6739.47\n",
      "Training Epoch 4   5.3% | batch:         5 of        94\t|\tloss: 7283.51\n",
      "Training Epoch 4   6.4% | batch:         6 of        94\t|\tloss: 6779.96\n",
      "Training Epoch 4   7.4% | batch:         7 of        94\t|\tloss: 7892.99\n",
      "Training Epoch 4   8.5% | batch:         8 of        94\t|\tloss: 8776.34\n",
      "Training Epoch 4   9.6% | batch:         9 of        94\t|\tloss: 8298.86\n",
      "Training Epoch 4  10.6% | batch:        10 of        94\t|\tloss: 11632.5\n",
      "Training Epoch 4  11.7% | batch:        11 of        94\t|\tloss: 9992.96\n",
      "Training Epoch 4  12.8% | batch:        12 of        94\t|\tloss: 6429.71\n",
      "Training Epoch 4  13.8% | batch:        13 of        94\t|\tloss: 10624.8\n",
      "Training Epoch 4  14.9% | batch:        14 of        94\t|\tloss: 8739.1\n",
      "Training Epoch 4  16.0% | batch:        15 of        94\t|\tloss: 7116.66\n",
      "Training Epoch 4  17.0% | batch:        16 of        94\t|\tloss: 5804.5\n",
      "Training Epoch 4  18.1% | batch:        17 of        94\t|\tloss: 7917.28\n",
      "Training Epoch 4  19.1% | batch:        18 of        94\t|\tloss: 4810.69\n",
      "Training Epoch 4  20.2% | batch:        19 of        94\t|\tloss: 6090.71\n",
      "Training Epoch 4  21.3% | batch:        20 of        94\t|\tloss: 10604.7\n",
      "Training Epoch 4  22.3% | batch:        21 of        94\t|\tloss: 4835.1\n",
      "Training Epoch 4  23.4% | batch:        22 of        94\t|\tloss: 11970.8\n",
      "Training Epoch 4  24.5% | batch:        23 of        94\t|\tloss: 6424.03\n",
      "Training Epoch 4  25.5% | batch:        24 of        94\t|\tloss: 6303.48\n",
      "Training Epoch 4  26.6% | batch:        25 of        94\t|\tloss: 4948.61\n",
      "Training Epoch 4  27.7% | batch:        26 of        94\t|\tloss: 7034.42\n",
      "Training Epoch 4  28.7% | batch:        27 of        94\t|\tloss: 8277.4\n",
      "Training Epoch 4  29.8% | batch:        28 of        94\t|\tloss: 6159.72\n",
      "Training Epoch 4  30.9% | batch:        29 of        94\t|\tloss: 6797.59\n",
      "Training Epoch 4  31.9% | batch:        30 of        94\t|\tloss: 3955.78\n",
      "Training Epoch 4  33.0% | batch:        31 of        94\t|\tloss: 8842.76\n",
      "Training Epoch 4  34.0% | batch:        32 of        94\t|\tloss: 5393.45\n",
      "Training Epoch 4  35.1% | batch:        33 of        94\t|\tloss: 4798.26\n",
      "Training Epoch 4  36.2% | batch:        34 of        94\t|\tloss: 5583.29\n",
      "Training Epoch 4  37.2% | batch:        35 of        94\t|\tloss: 10058.4\n",
      "Training Epoch 4  38.3% | batch:        36 of        94\t|\tloss: 6162.04\n",
      "Training Epoch 4  39.4% | batch:        37 of        94\t|\tloss: 11400.6\n",
      "Training Epoch 4  40.4% | batch:        38 of        94\t|\tloss: 6116.32\n",
      "Training Epoch 4  41.5% | batch:        39 of        94\t|\tloss: 8555.56\n",
      "Training Epoch 4  42.6% | batch:        40 of        94\t|\tloss: 7672.73\n",
      "Training Epoch 4  43.6% | batch:        41 of        94\t|\tloss: 8426.14\n",
      "Training Epoch 4  44.7% | batch:        42 of        94\t|\tloss: 4683.85\n",
      "Training Epoch 4  45.7% | batch:        43 of        94\t|\tloss: 6725.26\n",
      "Training Epoch 4  46.8% | batch:        44 of        94\t|\tloss: 6941.51\n",
      "Training Epoch 4  47.9% | batch:        45 of        94\t|\tloss: 6588.52\n",
      "Training Epoch 4  48.9% | batch:        46 of        94\t|\tloss: 6011.4\n",
      "Training Epoch 4  50.0% | batch:        47 of        94\t|\tloss: 6879.8\n",
      "Training Epoch 4  51.1% | batch:        48 of        94\t|\tloss: 4449.81\n",
      "Training Epoch 4  52.1% | batch:        49 of        94\t|\tloss: 6515.08\n",
      "Training Epoch 4  53.2% | batch:        50 of        94\t|\tloss: 6300.77\n",
      "Training Epoch 4  54.3% | batch:        51 of        94\t|\tloss: 6097.34\n",
      "Training Epoch 4  55.3% | batch:        52 of        94\t|\tloss: 5918.36\n",
      "Training Epoch 4  56.4% | batch:        53 of        94\t|\tloss: 7370.66\n",
      "Training Epoch 4  57.4% | batch:        54 of        94\t|\tloss: 3298.18\n",
      "Training Epoch 4  58.5% | batch:        55 of        94\t|\tloss: 9082.57\n",
      "Training Epoch 4  59.6% | batch:        56 of        94\t|\tloss: 6275.74\n",
      "Training Epoch 4  60.6% | batch:        57 of        94\t|\tloss: 5353.33\n",
      "Training Epoch 4  61.7% | batch:        58 of        94\t|\tloss: 3734.21\n",
      "Training Epoch 4  62.8% | batch:        59 of        94\t|\tloss: 3831.11\n",
      "Training Epoch 4  63.8% | batch:        60 of        94\t|\tloss: 8461.26\n",
      "Training Epoch 4  64.9% | batch:        61 of        94\t|\tloss: 3771.52\n",
      "Training Epoch 4  66.0% | batch:        62 of        94\t|\tloss: 4977.72\n",
      "Training Epoch 4  67.0% | batch:        63 of        94\t|\tloss: 2802.52\n",
      "Training Epoch 4  68.1% | batch:        64 of        94\t|\tloss: 6141.14\n",
      "Training Epoch 4  69.1% | batch:        65 of        94\t|\tloss: 6257.17\n",
      "Training Epoch 4  70.2% | batch:        66 of        94\t|\tloss: 5513.38\n",
      "Training Epoch 4  71.3% | batch:        67 of        94\t|\tloss: 4332.31\n",
      "Training Epoch 4  72.3% | batch:        68 of        94\t|\tloss: 5222.16\n",
      "Training Epoch 4  73.4% | batch:        69 of        94\t|\tloss: 6767.21\n",
      "Training Epoch 4  74.5% | batch:        70 of        94\t|\tloss: 4743.92\n",
      "Training Epoch 4  75.5% | batch:        71 of        94\t|\tloss: 5109.15\n",
      "Training Epoch 4  76.6% | batch:        72 of        94\t|\tloss: 6491.37\n",
      "Training Epoch 4  77.7% | batch:        73 of        94\t|\tloss: 4183.91\n",
      "Training Epoch 4  78.7% | batch:        74 of        94\t|\tloss: 3660.32\n",
      "Training Epoch 4  79.8% | batch:        75 of        94\t|\tloss: 7231.59\n",
      "Training Epoch 4  80.9% | batch:        76 of        94\t|\tloss: 4740.25\n",
      "Training Epoch 4  81.9% | batch:        77 of        94\t|\tloss: 5500.97\n",
      "Training Epoch 4  83.0% | batch:        78 of        94\t|\tloss: 4732.88\n",
      "Training Epoch 4  84.0% | batch:        79 of        94\t|\tloss: 8838.59\n",
      "Training Epoch 4  85.1% | batch:        80 of        94\t|\tloss: 7162.75\n",
      "Training Epoch 4  86.2% | batch:        81 of        94\t|\tloss: 3664.68\n",
      "Training Epoch 4  87.2% | batch:        82 of        94\t|\tloss: 4354.56\n",
      "Training Epoch 4  88.3% | batch:        83 of        94\t|\tloss: 7672.84\n",
      "Training Epoch 4  89.4% | batch:        84 of        94\t|\tloss: 2240.08\n",
      "Training Epoch 4  90.4% | batch:        85 of        94\t|\tloss: 6469.71\n",
      "Training Epoch 4  91.5% | batch:        86 of        94\t|\tloss: 7877.37\n",
      "Training Epoch 4  92.6% | batch:        87 of        94\t|\tloss: 5760.97\n",
      "Training Epoch 4  93.6% | batch:        88 of        94\t|\tloss: 3714.95\n",
      "Training Epoch 4  94.7% | batch:        89 of        94\t|\tloss: 5180.29\n",
      "Training Epoch 4  95.7% | batch:        90 of        94\t|\tloss: 4955.55\n",
      "Training Epoch 4  96.8% | batch:        91 of        94\t|\tloss: 6832.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:59,178 | INFO : Epoch 4 Training Summary: epoch: 4.000000 | loss: 6536.127667 | \n",
      "2023-05-04 16:58:59,179 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6748006343841553 seconds\n",
      "\n",
      "2023-05-04 16:58:59,180 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7195867896080017 seconds\n",
      "2023-05-04 16:58:59,180 | INFO : Avg batch train. time: 0.018293476485191508 seconds\n",
      "2023-05-04 16:58:59,181 | INFO : Avg sample train. time: 0.00014428484557878852 seconds\n",
      "2023-05-04 16:58:59,182 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 4  97.9% | batch:        92 of        94\t|\tloss: 3698.06\n",
      "Training Epoch 4  98.9% | batch:        93 of        94\t|\tloss: 10378.6\n",
      "\n",
      "Evaluating Epoch 4   0.0% | batch:         0 of        40\t|\tloss: 10076.9\n",
      "Evaluating Epoch 4   2.5% | batch:         1 of        40\t|\tloss: 2198.53\n",
      "Evaluating Epoch 4   5.0% | batch:         2 of        40\t|\tloss: 4281.61\n",
      "Evaluating Epoch 4   7.5% | batch:         3 of        40\t|\tloss: 9740.81\n",
      "Evaluating Epoch 4  10.0% | batch:         4 of        40\t|\tloss: 2199.89\n",
      "Evaluating Epoch 4  12.5% | batch:         5 of        40\t|\tloss: 1809.77\n",
      "Evaluating Epoch 4  15.0% | batch:         6 of        40\t|\tloss: 10753.1\n",
      "Evaluating Epoch 4  17.5% | batch:         7 of        40\t|\tloss: 5238.38\n",
      "Evaluating Epoch 4  20.0% | batch:         8 of        40\t|\tloss: 4376.94\n",
      "Evaluating Epoch 4  22.5% | batch:         9 of        40\t|\tloss: 4158.57\n",
      "Evaluating Epoch 4  25.0% | batch:        10 of        40\t|\tloss: 8428.59\n",
      "Evaluating Epoch 4  27.5% | batch:        11 of        40\t|\tloss: 2560.36\n",
      "Evaluating Epoch 4  30.0% | batch:        12 of        40\t|\tloss: 10875.8\n",
      "Evaluating Epoch 4  32.5% | batch:        13 of        40\t|\tloss: 6377.91\n",
      "Evaluating Epoch 4  35.0% | batch:        14 of        40\t|\tloss: 3265.73\n",
      "Evaluating Epoch 4  37.5% | batch:        15 of        40\t|\tloss: 6568.59\n",
      "Evaluating Epoch 4  40.0% | batch:        16 of        40\t|\tloss: 8907.81\n",
      "Evaluating Epoch 4  42.5% | batch:        17 of        40\t|\tloss: 4732.87\n",
      "Evaluating Epoch 4  45.0% | batch:        18 of        40\t|\tloss: 3938.54\n",
      "Evaluating Epoch 4  47.5% | batch:        19 of        40\t|\tloss: 8804.7\n",
      "Evaluating Epoch 4  50.0% | batch:        20 of        40\t|\tloss: 7892.48\n",
      "Evaluating Epoch 4  52.5% | batch:        21 of        40\t|\tloss: 2576.84\n",
      "Evaluating Epoch 4  55.0% | batch:        22 of        40\t|\tloss: 5552.97\n",
      "Evaluating Epoch 4  57.5% | batch:        23 of        40\t|\tloss: 5082.31\n",
      "Evaluating Epoch 4  60.0% | batch:        24 of        40\t|\tloss: 2519.98\n",
      "Evaluating Epoch 4  62.5% | batch:        25 of        40\t|\tloss: 5886.89\n",
      "Evaluating Epoch 4  65.0% | batch:        26 of        40\t|\tloss: 17817.3\n",
      "Evaluating Epoch 4  67.5% | batch:        27 of        40\t|\tloss: 4846.33\n",
      "Evaluating Epoch 4  70.0% | batch:        28 of        40\t|\tloss: 4332.34\n",
      "Evaluating Epoch 4  72.5% | batch:        29 of        40\t|\tloss: 13346\n",
      "Evaluating Epoch 4  75.0% | batch:        30 of        40\t|\tloss: 3369.43\n",
      "Evaluating Epoch 4  77.5% | batch:        31 of        40\t|\tloss: 2645.01\n",
      "Evaluating Epoch 4  80.0% | batch:        32 of        40\t|\tloss: 9776.12\n",
      "Evaluating Epoch 4  82.5% | batch:        33 of        40\t|\tloss: 9115.73\n",
      "Evaluating Epoch 4  85.0% | batch:        34 of        40\t|\tloss: 2502.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:58:59,630 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4471147060394287 seconds\n",
      "\n",
      "2023-05-04 16:58:59,630 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5483908624360055 seconds\n",
      "2023-05-04 16:58:59,631 | INFO : Avg batch val. time: 0.013709771560900138 seconds\n",
      "2023-05-04 16:58:59,631 | INFO : Avg sample val. time: 0.00010863527385816274 seconds\n",
      "2023-05-04 16:58:59,632 | INFO : Epoch 4 Validation Summary: epoch: 4.000000 | loss: 6348.218663 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 4  87.5% | batch:        35 of        40\t|\tloss: 6123.18\n",
      "Evaluating Epoch 4  90.0% | batch:        36 of        40\t|\tloss: 10043.9\n",
      "Evaluating Epoch 4  92.5% | batch:        37 of        40\t|\tloss: 3896.23\n",
      "Evaluating Epoch 4  95.0% | batch:        38 of        40\t|\tloss: 5991.62\n",
      "Evaluating Epoch 4  97.5% | batch:        39 of        40\t|\tloss: 17704.4\n",
      "\n",
      "Training Epoch 5   0.0% | batch:         0 of        94\t|\tloss: 2621.46\n",
      "Training Epoch 5   1.1% | batch:         1 of        94\t|\tloss: 4068.12\n",
      "Training Epoch 5   2.1% | batch:         2 of        94\t|\tloss: 3772.69\n",
      "Training Epoch 5   3.2% | batch:         3 of        94\t|\tloss: 4863.43\n",
      "Training Epoch 5   4.3% | batch:         4 of        94\t|\tloss: 6090.42\n",
      "Training Epoch 5   5.3% | batch:         5 of        94\t|\tloss: 4605.9\n",
      "Training Epoch 5   6.4% | batch:         6 of        94\t|\tloss: 4718.98\n",
      "Training Epoch 5   7.4% | batch:         7 of        94\t|\tloss: 4474.76\n",
      "Training Epoch 5   8.5% | batch:         8 of        94\t|\tloss: 4099.6\n",
      "Training Epoch 5   9.6% | batch:         9 of        94\t|\tloss: 4380.13\n",
      "Training Epoch 5  10.6% | batch:        10 of        94\t|\tloss: 4106.09\n",
      "Training Epoch 5  11.7% | batch:        11 of        94\t|\tloss: 3587.75\n",
      "Training Epoch 5  12.8% | batch:        12 of        94\t|\tloss: 3046.98\n",
      "Training Epoch 5  13.8% | batch:        13 of        94\t|\tloss: 3018.43\n",
      "Training Epoch 5  14.9% | batch:        14 of        94\t|\tloss: 3009.9\n",
      "Training Epoch 5  16.0% | batch:        15 of        94\t|\tloss: 3811.15\n",
      "Training Epoch 5  17.0% | batch:        16 of        94\t|\tloss: 4183.14\n",
      "Training Epoch 5  18.1% | batch:        17 of        94\t|\tloss: 1700.16\n",
      "Training Epoch 5  19.1% | batch:        18 of        94\t|\tloss: 5385.09\n",
      "Training Epoch 5  20.2% | batch:        19 of        94\t|\tloss: 4938.48\n",
      "Training Epoch 5  21.3% | batch:        20 of        94\t|\tloss: 2251.62\n",
      "Training Epoch 5  22.3% | batch:        21 of        94\t|\tloss: 2583.54\n",
      "Training Epoch 5  23.4% | batch:        22 of        94\t|\tloss: 3480.58\n",
      "Training Epoch 5  24.5% | batch:        23 of        94\t|\tloss: 2715.51\n",
      "Training Epoch 5  25.5% | batch:        24 of        94\t|\tloss: 3663.43\n",
      "Training Epoch 5  26.6% | batch:        25 of        94\t|\tloss: 2024.44\n",
      "Training Epoch 5  27.7% | batch:        26 of        94\t|\tloss: 2851.05\n",
      "Training Epoch 5  28.7% | batch:        27 of        94\t|\tloss: 5429.9\n",
      "Training Epoch 5  29.8% | batch:        28 of        94\t|\tloss: 4353.76\n",
      "Training Epoch 5  30.9% | batch:        29 of        94\t|\tloss: 3068.6\n",
      "Training Epoch 5  31.9% | batch:        30 of        94\t|\tloss: 3598.91\n",
      "Training Epoch 5  33.0% | batch:        31 of        94\t|\tloss: 2944.13\n",
      "Training Epoch 5  34.0% | batch:        32 of        94\t|\tloss: 2638.95\n",
      "Training Epoch 5  35.1% | batch:        33 of        94\t|\tloss: 2842.75\n",
      "Training Epoch 5  36.2% | batch:        34 of        94\t|\tloss: 2272.11\n",
      "Training Epoch 5  37.2% | batch:        35 of        94\t|\tloss: 3126.65\n",
      "Training Epoch 5  38.3% | batch:        36 of        94\t|\tloss: 2434.57\n",
      "Training Epoch 5  39.4% | batch:        37 of        94\t|\tloss: 8017.17\n",
      "Training Epoch 5  40.4% | batch:        38 of        94\t|\tloss: 2530.94\n",
      "Training Epoch 5  41.5% | batch:        39 of        94\t|\tloss: 6648.53\n",
      "Training Epoch 5  42.6% | batch:        40 of        94\t|\tloss: 5209.18\n",
      "Training Epoch 5  43.6% | batch:        41 of        94\t|\tloss: 6190.53\n",
      "Training Epoch 5  44.7% | batch:        42 of        94\t|\tloss: 3222.45\n",
      "Training Epoch 5  45.7% | batch:        43 of        94\t|\tloss: 3206.14\n",
      "Training Epoch 5  46.8% | batch:        44 of        94\t|\tloss: 3472.27\n",
      "Training Epoch 5  47.9% | batch:        45 of        94\t|\tloss: 3227.35\n",
      "Training Epoch 5  48.9% | batch:        46 of        94\t|\tloss: 2034.03\n",
      "Training Epoch 5  50.0% | batch:        47 of        94\t|\tloss: 2344.92\n",
      "Training Epoch 5  51.1% | batch:        48 of        94\t|\tloss: 4633.81\n",
      "Training Epoch 5  52.1% | batch:        49 of        94\t|\tloss: 1504.28\n",
      "Training Epoch 5  53.2% | batch:        50 of        94\t|\tloss: 6245.54\n",
      "Training Epoch 5  54.3% | batch:        51 of        94\t|\tloss: 4525.41\n",
      "Training Epoch 5  55.3% | batch:        52 of        94\t|\tloss: 2703.05\n",
      "Training Epoch 5  56.4% | batch:        53 of        94\t|\tloss: 1729.39\n",
      "Training Epoch 5  57.4% | batch:        54 of        94\t|\tloss: 3572.62\n",
      "Training Epoch 5  58.5% | batch:        55 of        94\t|\tloss: 7295.88\n",
      "Training Epoch 5  59.6% | batch:        56 of        94\t|\tloss: 3462.69\n",
      "Training Epoch 5  60.6% | batch:        57 of        94\t|\tloss: 2218.84\n",
      "Training Epoch 5  61.7% | batch:        58 of        94\t|\tloss: 2738.44\n",
      "Training Epoch 5  62.8% | batch:        59 of        94\t|\tloss: 2447.24\n",
      "Training Epoch 5  63.8% | batch:        60 of        94\t|\tloss: 2342.27\n",
      "Training Epoch 5  64.9% | batch:        61 of        94\t|\tloss: 4010.03\n",
      "Training Epoch 5  66.0% | batch:        62 of        94\t|\tloss: 2255.02\n",
      "Training Epoch 5  67.0% | batch:        63 of        94\t|\tloss: 2687.36\n",
      "Training Epoch 5  68.1% | batch:        64 of        94\t|\tloss: 2476.31\n",
      "Training Epoch 5  69.1% | batch:        65 of        94\t|\tloss: 3367.48\n",
      "Training Epoch 5  70.2% | batch:        66 of        94\t|\tloss: 3860.16\n",
      "Training Epoch 5  71.3% | batch:        67 of        94\t|\tloss: 2073.63\n",
      "Training Epoch 5  72.3% | batch:        68 of        94\t|\tloss: 2593.7\n",
      "Training Epoch 5  73.4% | batch:        69 of        94\t|\tloss: 4270.74\n",
      "Training Epoch 5  74.5% | batch:        70 of        94\t|\tloss: 2522.02\n",
      "Training Epoch 5  75.5% | batch:        71 of        94\t|\tloss: 2923.08\n",
      "Training Epoch 5  76.6% | batch:        72 of        94\t|\tloss: 2107.78\n",
      "Training Epoch 5  77.7% | batch:        73 of        94\t|\tloss: 3316.65\n",
      "Training Epoch 5  78.7% | batch:        74 of        94\t|\tloss: 1865.19\n",
      "Training Epoch 5  79.8% | batch:        75 of        94\t|\tloss: 1452.67\n",
      "Training Epoch 5  80.9% | batch:        76 of        94\t|\tloss: 2351.98\n",
      "Training Epoch 5  81.9% | batch:        77 of        94\t|\tloss: 2161.39\n",
      "Training Epoch 5  83.0% | batch:        78 of        94\t|\tloss: 1411.37\n",
      "Training Epoch 5  84.0% | batch:        79 of        94\t|\tloss: 2477.79\n",
      "Training Epoch 5  85.1% | batch:        80 of        94\t|\tloss: 2498.02\n",
      "Training Epoch 5  86.2% | batch:        81 of        94\t|\tloss: 3597.79\n",
      "Training Epoch 5  87.2% | batch:        82 of        94\t|\tloss: 2714.02\n",
      "Training Epoch 5  88.3% | batch:        83 of        94\t|\tloss: 3143.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:01,491 | INFO : Epoch 5 Training Summary: epoch: 5.000000 | loss: 3338.883964 | \n",
      "2023-05-04 16:59:01,492 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8274996280670166 seconds\n",
      "\n",
      "2023-05-04 16:59:01,493 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7411693572998046 seconds\n",
      "2023-05-04 16:59:01,493 | INFO : Avg batch train. time: 0.018523078269146856 seconds\n",
      "2023-05-04 16:59:01,494 | INFO : Avg sample train. time: 0.0001460957675197017 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 5  89.4% | batch:        84 of        94\t|\tloss: 3128.16\n",
      "Training Epoch 5  90.4% | batch:        85 of        94\t|\tloss: 3177.36\n",
      "Training Epoch 5  91.5% | batch:        86 of        94\t|\tloss: 2121.21\n",
      "Training Epoch 5  92.6% | batch:        87 of        94\t|\tloss: 1673.74\n",
      "Training Epoch 5  93.6% | batch:        88 of        94\t|\tloss: 2870.4\n",
      "Training Epoch 5  94.7% | batch:        89 of        94\t|\tloss: 4999.25\n",
      "Training Epoch 5  95.7% | batch:        90 of        94\t|\tloss: 3073.12\n",
      "Training Epoch 5  96.8% | batch:        91 of        94\t|\tloss: 1351.46\n",
      "Training Epoch 5  97.9% | batch:        92 of        94\t|\tloss: 1886.16\n",
      "Training Epoch 5  98.9% | batch:        93 of        94\t|\tloss: 1612.26\n",
      "\n",
      "Training Epoch 6   0.0% | batch:         0 of        94\t|\tloss: 2192\n",
      "Training Epoch 6   1.1% | batch:         1 of        94\t|\tloss: 1806.72\n",
      "Training Epoch 6   2.1% | batch:         2 of        94\t|\tloss: 1826.08\n",
      "Training Epoch 6   3.2% | batch:         3 of        94\t|\tloss: 1565.91\n",
      "Training Epoch 6   4.3% | batch:         4 of        94\t|\tloss: 2722.6\n",
      "Training Epoch 6   5.3% | batch:         5 of        94\t|\tloss: 2182.35\n",
      "Training Epoch 6   6.4% | batch:         6 of        94\t|\tloss: 2246.85\n",
      "Training Epoch 6   7.4% | batch:         7 of        94\t|\tloss: 1691.54\n",
      "Training Epoch 6   8.5% | batch:         8 of        94\t|\tloss: 1914.68\n",
      "Training Epoch 6   9.6% | batch:         9 of        94\t|\tloss: 2967.18\n",
      "Training Epoch 6  10.6% | batch:        10 of        94\t|\tloss: 1713.84\n",
      "Training Epoch 6  11.7% | batch:        11 of        94\t|\tloss: 3534.46\n",
      "Training Epoch 6  12.8% | batch:        12 of        94\t|\tloss: 2108.62\n",
      "Training Epoch 6  13.8% | batch:        13 of        94\t|\tloss: 1919.11\n",
      "Training Epoch 6  14.9% | batch:        14 of        94\t|\tloss: 2093.51\n",
      "Training Epoch 6  16.0% | batch:        15 of        94\t|\tloss: 2273.6\n",
      "Training Epoch 6  17.0% | batch:        16 of        94\t|\tloss: 4496.7\n",
      "Training Epoch 6  18.1% | batch:        17 of        94\t|\tloss: 2747.58\n",
      "Training Epoch 6  19.1% | batch:        18 of        94\t|\tloss: 2535.81\n",
      "Training Epoch 6  20.2% | batch:        19 of        94\t|\tloss: 1937.37\n",
      "Training Epoch 6  21.3% | batch:        20 of        94\t|\tloss: 1594.36\n",
      "Training Epoch 6  22.3% | batch:        21 of        94\t|\tloss: 1703.36\n",
      "Training Epoch 6  23.4% | batch:        22 of        94\t|\tloss: 3660.06\n",
      "Training Epoch 6  24.5% | batch:        23 of        94\t|\tloss: 3290.59\n",
      "Training Epoch 6  25.5% | batch:        24 of        94\t|\tloss: 1585.75\n",
      "Training Epoch 6  26.6% | batch:        25 of        94\t|\tloss: 2325.86\n",
      "Training Epoch 6  27.7% | batch:        26 of        94\t|\tloss: 1690.56\n",
      "Training Epoch 6  28.7% | batch:        27 of        94\t|\tloss: 4078.13\n",
      "Training Epoch 6  29.8% | batch:        28 of        94\t|\tloss: 1895.83\n",
      "Training Epoch 6  30.9% | batch:        29 of        94\t|\tloss: 4261.98\n",
      "Training Epoch 6  31.9% | batch:        30 of        94\t|\tloss: 2218.01\n",
      "Training Epoch 6  33.0% | batch:        31 of        94\t|\tloss: 2142.94\n",
      "Training Epoch 6  34.0% | batch:        32 of        94\t|\tloss: 2385.52\n",
      "Training Epoch 6  35.1% | batch:        33 of        94\t|\tloss: 2152.03\n",
      "Training Epoch 6  36.2% | batch:        34 of        94\t|\tloss: 2401.77\n",
      "Training Epoch 6  37.2% | batch:        35 of        94\t|\tloss: 2267.74\n",
      "Training Epoch 6  38.3% | batch:        36 of        94\t|\tloss: 2548.7\n",
      "Training Epoch 6  39.4% | batch:        37 of        94\t|\tloss: 4070.17\n",
      "Training Epoch 6  40.4% | batch:        38 of        94\t|\tloss: 2604.16\n",
      "Training Epoch 6  41.5% | batch:        39 of        94\t|\tloss: 2466.3\n",
      "Training Epoch 6  42.6% | batch:        40 of        94\t|\tloss: 2792.74\n",
      "Training Epoch 6  43.6% | batch:        41 of        94\t|\tloss: 1700.47\n",
      "Training Epoch 6  44.7% | batch:        42 of        94\t|\tloss: 3719.89\n",
      "Training Epoch 6  45.7% | batch:        43 of        94\t|\tloss: 2845.92\n",
      "Training Epoch 6  46.8% | batch:        44 of        94\t|\tloss: 2308.2\n",
      "Training Epoch 6  47.9% | batch:        45 of        94\t|\tloss: 2348.03\n",
      "Training Epoch 6  48.9% | batch:        46 of        94\t|\tloss: 3251.8\n",
      "Training Epoch 6  50.0% | batch:        47 of        94\t|\tloss: 1965.27\n",
      "Training Epoch 6  51.1% | batch:        48 of        94\t|\tloss: 2047\n",
      "Training Epoch 6  52.1% | batch:        49 of        94\t|\tloss: 1597.94\n",
      "Training Epoch 6  53.2% | batch:        50 of        94\t|\tloss: 2808.31\n",
      "Training Epoch 6  54.3% | batch:        51 of        94\t|\tloss: 2796.86\n",
      "Training Epoch 6  55.3% | batch:        52 of        94\t|\tloss: 2345.6\n",
      "Training Epoch 6  56.4% | batch:        53 of        94\t|\tloss: 1895.77\n",
      "Training Epoch 6  57.4% | batch:        54 of        94\t|\tloss: 2110.34\n",
      "Training Epoch 6  58.5% | batch:        55 of        94\t|\tloss: 3216.78\n",
      "Training Epoch 6  59.6% | batch:        56 of        94\t|\tloss: 1764.77\n",
      "Training Epoch 6  60.6% | batch:        57 of        94\t|\tloss: 1926.73\n",
      "Training Epoch 6  61.7% | batch:        58 of        94\t|\tloss: 3124.23\n",
      "Training Epoch 6  62.8% | batch:        59 of        94\t|\tloss: 1722.6\n",
      "Training Epoch 6  63.8% | batch:        60 of        94\t|\tloss: 1930.2\n",
      "Training Epoch 6  64.9% | batch:        61 of        94\t|\tloss: 2295.35\n",
      "Training Epoch 6  66.0% | batch:        62 of        94\t|\tloss: 3020.1\n",
      "Training Epoch 6  67.0% | batch:        63 of        94\t|\tloss: 1146.61\n",
      "Training Epoch 6  68.1% | batch:        64 of        94\t|\tloss: 2106.24\n",
      "Training Epoch 6  69.1% | batch:        65 of        94\t|\tloss: 2201.93\n",
      "Training Epoch 6  70.2% | batch:        66 of        94\t|\tloss: 2274.28\n",
      "Training Epoch 6  71.3% | batch:        67 of        94\t|\tloss: 2460.75\n",
      "Training Epoch 6  72.3% | batch:        68 of        94\t|\tloss: 3590.92\n",
      "Training Epoch 6  73.4% | batch:        69 of        94\t|\tloss: 3337.91\n",
      "Training Epoch 6  74.5% | batch:        70 of        94\t|\tloss: 3342.87\n",
      "Training Epoch 6  75.5% | batch:        71 of        94\t|\tloss: 2249.92\n",
      "Training Epoch 6  76.6% | batch:        72 of        94\t|\tloss: 1791.24\n",
      "Training Epoch 6  77.7% | batch:        73 of        94\t|\tloss: 2566\n",
      "Training Epoch 6  78.7% | batch:        74 of        94\t|\tloss: 4407.73\n",
      "Training Epoch 6  79.8% | batch:        75 of        94\t|\tloss: 5113.46\n",
      "Training Epoch 6  80.9% | batch:        76 of        94\t|\tloss: 2597.57\n",
      "Training Epoch 6  81.9% | batch:        77 of        94\t|\tloss: 4661.48\n",
      "Training Epoch 6  83.0% | batch:        78 of        94\t|\tloss: 2109.71\n",
      "Training Epoch 6  84.0% | batch:        79 of        94\t|\tloss: 1947.8\n",
      "Training Epoch 6  85.1% | batch:        80 of        94\t|\tloss: 5716.39\n",
      "Training Epoch 6  86.2% | batch:        81 of        94\t|\tloss: 2550.33\n",
      "Training Epoch 6  87.2% | batch:        82 of        94\t|\tloss: 1996.02\n",
      "Training Epoch 6  88.3% | batch:        83 of        94\t|\tloss: 2553.92\n",
      "Training Epoch 6  89.4% | batch:        84 of        94\t|\tloss: 2741.27\n",
      "Training Epoch 6  90.4% | batch:        85 of        94\t|\tloss: 1551.44\n",
      "Training Epoch 6  91.5% | batch:        86 of        94\t|\tloss: 2295.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:03,345 | INFO : Epoch 6 Training Summary: epoch: 6.000000 | loss: 2546.459816 | \n",
      "2023-05-04 16:59:03,346 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8314354419708252 seconds\n",
      "\n",
      "2023-05-04 16:59:03,347 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7562137047449748 seconds\n",
      "2023-05-04 16:59:03,347 | INFO : Avg batch train. time: 0.018683124518563562 seconds\n",
      "2023-05-04 16:59:03,348 | INFO : Avg sample train. time: 0.00014735808900360588 seconds\n",
      "2023-05-04 16:59:03,348 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 6  92.6% | batch:        87 of        94\t|\tloss: 3118.6\n",
      "Training Epoch 6  93.6% | batch:        88 of        94\t|\tloss: 1703.04\n",
      "Training Epoch 6  94.7% | batch:        89 of        94\t|\tloss: 2321.63\n",
      "Training Epoch 6  95.7% | batch:        90 of        94\t|\tloss: 5128.7\n",
      "Training Epoch 6  96.8% | batch:        91 of        94\t|\tloss: 1940.67\n",
      "Training Epoch 6  97.9% | batch:        92 of        94\t|\tloss: 2113.63\n",
      "Training Epoch 6  98.9% | batch:        93 of        94\t|\tloss: 971.915\n",
      "\n",
      "Evaluating Epoch 6   0.0% | batch:         0 of        40\t|\tloss: 6218.88\n",
      "Evaluating Epoch 6   2.5% | batch:         1 of        40\t|\tloss: 834.545\n",
      "Evaluating Epoch 6   5.0% | batch:         2 of        40\t|\tloss: 3127.16\n",
      "Evaluating Epoch 6   7.5% | batch:         3 of        40\t|\tloss: 7115.65\n",
      "Evaluating Epoch 6  10.0% | batch:         4 of        40\t|\tloss: 1878.46\n",
      "Evaluating Epoch 6  12.5% | batch:         5 of        40\t|\tloss: 1923.05\n",
      "Evaluating Epoch 6  15.0% | batch:         6 of        40\t|\tloss: 8017.72\n",
      "Evaluating Epoch 6  17.5% | batch:         7 of        40\t|\tloss: 2780.04\n",
      "Evaluating Epoch 6  20.0% | batch:         8 of        40\t|\tloss: 2313.07\n",
      "Evaluating Epoch 6  22.5% | batch:         9 of        40\t|\tloss: 1698.7\n",
      "Evaluating Epoch 6  25.0% | batch:        10 of        40\t|\tloss: 4499.43\n",
      "Evaluating Epoch 6  27.5% | batch:        11 of        40\t|\tloss: 1564.58\n",
      "Evaluating Epoch 6  30.0% | batch:        12 of        40\t|\tloss: 6193.67\n",
      "Evaluating Epoch 6  32.5% | batch:        13 of        40\t|\tloss: 2916.78\n",
      "Evaluating Epoch 6  35.0% | batch:        14 of        40\t|\tloss: 1722.78\n",
      "Evaluating Epoch 6  37.5% | batch:        15 of        40\t|\tloss: 3955.52\n",
      "Evaluating Epoch 6  40.0% | batch:        16 of        40\t|\tloss: 4905.16\n",
      "Evaluating Epoch 6  42.5% | batch:        17 of        40\t|\tloss: 2462.24\n",
      "Evaluating Epoch 6  45.0% | batch:        18 of        40\t|\tloss: 2534.94\n",
      "Evaluating Epoch 6  47.5% | batch:        19 of        40\t|\tloss: 4402.68\n",
      "Evaluating Epoch 6  50.0% | batch:        20 of        40\t|\tloss: 5127.76\n",
      "Evaluating Epoch 6  52.5% | batch:        21 of        40\t|\tloss: 1239.4\n",
      "Evaluating Epoch 6  55.0% | batch:        22 of        40\t|\tloss: 3071.58\n",
      "Evaluating Epoch 6  57.5% | batch:        23 of        40\t|\tloss: 2557.42\n",
      "Evaluating Epoch 6  60.0% | batch:        24 of        40\t|\tloss: 1433.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:03,796 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44724011421203613 seconds\n",
      "\n",
      "2023-05-04 16:59:03,797 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5477815205792347 seconds\n",
      "2023-05-04 16:59:03,797 | INFO : Avg batch val. time: 0.013694538014480867 seconds\n",
      "2023-05-04 16:59:03,798 | INFO : Avg sample val. time: 0.00010851456429858056 seconds\n",
      "2023-05-04 16:59:03,799 | INFO : Epoch 6 Validation Summary: epoch: 6.000000 | loss: 3797.538635 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 6  62.5% | batch:        25 of        40\t|\tloss: 2979.91\n",
      "Evaluating Epoch 6  65.0% | batch:        26 of        40\t|\tloss: 10335.3\n",
      "Evaluating Epoch 6  67.5% | batch:        27 of        40\t|\tloss: 2787.02\n",
      "Evaluating Epoch 6  70.0% | batch:        28 of        40\t|\tloss: 1929.56\n",
      "Evaluating Epoch 6  72.5% | batch:        29 of        40\t|\tloss: 8833.55\n",
      "Evaluating Epoch 6  75.0% | batch:        30 of        40\t|\tloss: 1659.15\n",
      "Evaluating Epoch 6  77.5% | batch:        31 of        40\t|\tloss: 1696.82\n",
      "Evaluating Epoch 6  80.0% | batch:        32 of        40\t|\tloss: 7562.93\n",
      "Evaluating Epoch 6  82.5% | batch:        33 of        40\t|\tloss: 6094.76\n",
      "Evaluating Epoch 6  85.0% | batch:        34 of        40\t|\tloss: 1096.13\n",
      "Evaluating Epoch 6  87.5% | batch:        35 of        40\t|\tloss: 4861.67\n",
      "Evaluating Epoch 6  90.0% | batch:        36 of        40\t|\tloss: 4629.97\n",
      "Evaluating Epoch 6  92.5% | batch:        37 of        40\t|\tloss: 2335.25\n",
      "Evaluating Epoch 6  95.0% | batch:        38 of        40\t|\tloss: 3835.62\n",
      "Evaluating Epoch 6  97.5% | batch:        39 of        40\t|\tloss: 10589.7\n",
      "\n",
      "Training Epoch 7   0.0% | batch:         0 of        94\t|\tloss: 2733.33\n",
      "Training Epoch 7   1.1% | batch:         1 of        94\t|\tloss: 1650.32\n",
      "Training Epoch 7   2.1% | batch:         2 of        94\t|\tloss: 3441.05\n",
      "Training Epoch 7   3.2% | batch:         3 of        94\t|\tloss: 5110.32\n",
      "Training Epoch 7   4.3% | batch:         4 of        94\t|\tloss: 3217.39\n",
      "Training Epoch 7   5.3% | batch:         5 of        94\t|\tloss: 2566.34\n",
      "Training Epoch 7   6.4% | batch:         6 of        94\t|\tloss: 1761.46\n",
      "Training Epoch 7   7.4% | batch:         7 of        94\t|\tloss: 2058.24\n",
      "Training Epoch 7   8.5% | batch:         8 of        94\t|\tloss: 3900.92\n",
      "Training Epoch 7   9.6% | batch:         9 of        94\t|\tloss: 2037.32\n",
      "Training Epoch 7  10.6% | batch:        10 of        94\t|\tloss: 2033.16\n",
      "Training Epoch 7  11.7% | batch:        11 of        94\t|\tloss: 1867.39\n",
      "Training Epoch 7  12.8% | batch:        12 of        94\t|\tloss: 1526.65\n",
      "Training Epoch 7  13.8% | batch:        13 of        94\t|\tloss: 2473.9\n",
      "Training Epoch 7  14.9% | batch:        14 of        94\t|\tloss: 2166.45\n",
      "Training Epoch 7  16.0% | batch:        15 of        94\t|\tloss: 2131.83\n",
      "Training Epoch 7  17.0% | batch:        16 of        94\t|\tloss: 1877.92\n",
      "Training Epoch 7  18.1% | batch:        17 of        94\t|\tloss: 2537.23\n",
      "Training Epoch 7  19.1% | batch:        18 of        94\t|\tloss: 2027.94\n",
      "Training Epoch 7  20.2% | batch:        19 of        94\t|\tloss: 2254.27\n",
      "Training Epoch 7  21.3% | batch:        20 of        94\t|\tloss: 2419.06\n",
      "Training Epoch 7  22.3% | batch:        21 of        94\t|\tloss: 1750.42\n",
      "Training Epoch 7  23.4% | batch:        22 of        94\t|\tloss: 3785.87\n",
      "Training Epoch 7  24.5% | batch:        23 of        94\t|\tloss: 1986.37\n",
      "Training Epoch 7  25.5% | batch:        24 of        94\t|\tloss: 2275.12\n",
      "Training Epoch 7  26.6% | batch:        25 of        94\t|\tloss: 2810.32\n",
      "Training Epoch 7  27.7% | batch:        26 of        94\t|\tloss: 1338.4\n",
      "Training Epoch 7  28.7% | batch:        27 of        94\t|\tloss: 2523.68\n",
      "Training Epoch 7  29.8% | batch:        28 of        94\t|\tloss: 2055.18\n",
      "Training Epoch 7  30.9% | batch:        29 of        94\t|\tloss: 2272.63\n",
      "Training Epoch 7  31.9% | batch:        30 of        94\t|\tloss: 4044.2\n",
      "Training Epoch 7  33.0% | batch:        31 of        94\t|\tloss: 3502.19\n",
      "Training Epoch 7  34.0% | batch:        32 of        94\t|\tloss: 2151.23\n",
      "Training Epoch 7  35.1% | batch:        33 of        94\t|\tloss: 2281.08\n",
      "Training Epoch 7  36.2% | batch:        34 of        94\t|\tloss: 2182.61\n",
      "Training Epoch 7  37.2% | batch:        35 of        94\t|\tloss: 1766.02\n",
      "Training Epoch 7  38.3% | batch:        36 of        94\t|\tloss: 3569.54\n",
      "Training Epoch 7  39.4% | batch:        37 of        94\t|\tloss: 1631.18\n",
      "Training Epoch 7  40.4% | batch:        38 of        94\t|\tloss: 1337.14\n",
      "Training Epoch 7  41.5% | batch:        39 of        94\t|\tloss: 1835.13\n",
      "Training Epoch 7  42.6% | batch:        40 of        94\t|\tloss: 2682.31\n",
      "Training Epoch 7  43.6% | batch:        41 of        94\t|\tloss: 2500.35\n",
      "Training Epoch 7  44.7% | batch:        42 of        94\t|\tloss: 2819.68\n",
      "Training Epoch 7  45.7% | batch:        43 of        94\t|\tloss: 2046.95\n",
      "Training Epoch 7  46.8% | batch:        44 of        94\t|\tloss: 3147.36\n",
      "Training Epoch 7  47.9% | batch:        45 of        94\t|\tloss: 1644.21\n",
      "Training Epoch 7  48.9% | batch:        46 of        94\t|\tloss: 2370.39\n",
      "Training Epoch 7  50.0% | batch:        47 of        94\t|\tloss: 2712.44\n",
      "Training Epoch 7  51.1% | batch:        48 of        94\t|\tloss: 1780.49\n",
      "Training Epoch 7  52.1% | batch:        49 of        94\t|\tloss: 1350.56\n",
      "Training Epoch 7  53.2% | batch:        50 of        94\t|\tloss: 1589.38\n",
      "Training Epoch 7  54.3% | batch:        51 of        94\t|\tloss: 3008.02\n",
      "Training Epoch 7  55.3% | batch:        52 of        94\t|\tloss: 3042.73\n",
      "Training Epoch 7  56.4% | batch:        53 of        94\t|\tloss: 2183.77\n",
      "Training Epoch 7  57.4% | batch:        54 of        94\t|\tloss: 1692.4\n",
      "Training Epoch 7  58.5% | batch:        55 of        94\t|\tloss: 1673.37\n",
      "Training Epoch 7  59.6% | batch:        56 of        94\t|\tloss: 2337.15\n",
      "Training Epoch 7  60.6% | batch:        57 of        94\t|\tloss: 3545.7\n",
      "Training Epoch 7  61.7% | batch:        58 of        94\t|\tloss: 1899.95\n",
      "Training Epoch 7  62.8% | batch:        59 of        94\t|\tloss: 2401.38\n",
      "Training Epoch 7  63.8% | batch:        60 of        94\t|\tloss: 2692.61\n",
      "Training Epoch 7  64.9% | batch:        61 of        94\t|\tloss: 3134.33\n",
      "Training Epoch 7  66.0% | batch:        62 of        94\t|\tloss: 2359.08\n",
      "Training Epoch 7  67.0% | batch:        63 of        94\t|\tloss: 1824.68\n",
      "Training Epoch 7  68.1% | batch:        64 of        94\t|\tloss: 2131.81\n",
      "Training Epoch 7  69.1% | batch:        65 of        94\t|\tloss: 2572.79\n",
      "Training Epoch 7  70.2% | batch:        66 of        94\t|\tloss: 1768.05\n",
      "Training Epoch 7  71.3% | batch:        67 of        94\t|\tloss: 1948.25\n",
      "Training Epoch 7  72.3% | batch:        68 of        94\t|\tloss: 2199.89\n",
      "Training Epoch 7  73.4% | batch:        69 of        94\t|\tloss: 2186.15\n",
      "Training Epoch 7  74.5% | batch:        70 of        94\t|\tloss: 2762.87\n",
      "Training Epoch 7  75.5% | batch:        71 of        94\t|\tloss: 9205.04\n",
      "Training Epoch 7  76.6% | batch:        72 of        94\t|\tloss: 1978.1\n",
      "Training Epoch 7  77.7% | batch:        73 of        94\t|\tloss: 2373.25\n",
      "Training Epoch 7  78.7% | batch:        74 of        94\t|\tloss: 1789.62\n",
      "Training Epoch 7  79.8% | batch:        75 of        94\t|\tloss: 2248.66\n",
      "Training Epoch 7  80.9% | batch:        76 of        94\t|\tloss: 2230.28\n",
      "Training Epoch 7  81.9% | batch:        77 of        94\t|\tloss: 2650.27\n",
      "Training Epoch 7  83.0% | batch:        78 of        94\t|\tloss: 1983.61\n",
      "Training Epoch 7  84.0% | batch:        79 of        94\t|\tloss: 2807.05\n",
      "Training Epoch 7  85.1% | batch:        80 of        94\t|\tloss: 1769.39\n",
      "Training Epoch 7  86.2% | batch:        81 of        94\t|\tloss: 2962.86\n",
      "Training Epoch 7  87.2% | batch:        82 of        94\t|\tloss: 1549.69\n",
      "Training Epoch 7  88.3% | batch:        83 of        94\t|\tloss: 1594.02\n",
      "Training Epoch 7  89.4% | batch:        84 of        94\t|\tloss: 2271.84\n",
      "Training Epoch 7  90.4% | batch:        85 of        94\t|\tloss: 1299.06\n",
      "Training Epoch 7  91.5% | batch:        86 of        94\t|\tloss: 2827.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:05,678 | INFO : Epoch 7 Training Summary: epoch: 7.000000 | loss: 2391.471305 | \n",
      "2023-05-04 16:59:05,679 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8473477363586426 seconds\n",
      "\n",
      "2023-05-04 16:59:05,680 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7692328521183558 seconds\n",
      "2023-05-04 16:59:05,680 | INFO : Avg batch train. time: 0.01882162608636549 seconds\n",
      "2023-05-04 16:59:05,681 | INFO : Avg sample train. time: 0.00014845048264124482 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 7  92.6% | batch:        87 of        94\t|\tloss: 2068.77\n",
      "Training Epoch 7  93.6% | batch:        88 of        94\t|\tloss: 2713.9\n",
      "Training Epoch 7  94.7% | batch:        89 of        94\t|\tloss: 1689.01\n",
      "Training Epoch 7  95.7% | batch:        90 of        94\t|\tloss: 1421.47\n",
      "Training Epoch 7  96.8% | batch:        91 of        94\t|\tloss: 1529.91\n",
      "Training Epoch 7  97.9% | batch:        92 of        94\t|\tloss: 2416.13\n",
      "Training Epoch 7  98.9% | batch:        93 of        94\t|\tloss: 3560.17\n",
      "\n",
      "Training Epoch 8   0.0% | batch:         0 of        94\t|\tloss: 1249.11\n",
      "Training Epoch 8   1.1% | batch:         1 of        94\t|\tloss: 1830.44\n",
      "Training Epoch 8   2.1% | batch:         2 of        94\t|\tloss: 2007.98\n",
      "Training Epoch 8   3.2% | batch:         3 of        94\t|\tloss: 2689.99\n",
      "Training Epoch 8   4.3% | batch:         4 of        94\t|\tloss: 2036.72\n",
      "Training Epoch 8   5.3% | batch:         5 of        94\t|\tloss: 1900.21\n",
      "Training Epoch 8   6.4% | batch:         6 of        94\t|\tloss: 2348.44\n",
      "Training Epoch 8   7.4% | batch:         7 of        94\t|\tloss: 1172.14\n",
      "Training Epoch 8   8.5% | batch:         8 of        94\t|\tloss: 1959.93\n",
      "Training Epoch 8   9.6% | batch:         9 of        94\t|\tloss: 1929.52\n",
      "Training Epoch 8  10.6% | batch:        10 of        94\t|\tloss: 4264.84\n",
      "Training Epoch 8  11.7% | batch:        11 of        94\t|\tloss: 1545.1\n",
      "Training Epoch 8  12.8% | batch:        12 of        94\t|\tloss: 4566.67\n",
      "Training Epoch 8  13.8% | batch:        13 of        94\t|\tloss: 1707.39\n",
      "Training Epoch 8  14.9% | batch:        14 of        94\t|\tloss: 1977.45\n",
      "Training Epoch 8  16.0% | batch:        15 of        94\t|\tloss: 1536.83\n",
      "Training Epoch 8  17.0% | batch:        16 of        94\t|\tloss: 1282.15\n",
      "Training Epoch 8  18.1% | batch:        17 of        94\t|\tloss: 1496.56\n",
      "Training Epoch 8  19.1% | batch:        18 of        94\t|\tloss: 2103.01\n",
      "Training Epoch 8  20.2% | batch:        19 of        94\t|\tloss: 1766.1\n",
      "Training Epoch 8  21.3% | batch:        20 of        94\t|\tloss: 1834.04\n",
      "Training Epoch 8  22.3% | batch:        21 of        94\t|\tloss: 1859.19\n",
      "Training Epoch 8  23.4% | batch:        22 of        94\t|\tloss: 1676.11\n",
      "Training Epoch 8  24.5% | batch:        23 of        94\t|\tloss: 1630.3\n",
      "Training Epoch 8  25.5% | batch:        24 of        94\t|\tloss: 2247.37\n",
      "Training Epoch 8  26.6% | batch:        25 of        94\t|\tloss: 5281.63\n",
      "Training Epoch 8  27.7% | batch:        26 of        94\t|\tloss: 5027.38\n",
      "Training Epoch 8  28.7% | batch:        27 of        94\t|\tloss: 2665.54\n",
      "Training Epoch 8  29.8% | batch:        28 of        94\t|\tloss: 5262.01\n",
      "Training Epoch 8  30.9% | batch:        29 of        94\t|\tloss: 1978.66\n",
      "Training Epoch 8  31.9% | batch:        30 of        94\t|\tloss: 2102.16\n",
      "Training Epoch 8  33.0% | batch:        31 of        94\t|\tloss: 1726.87\n",
      "Training Epoch 8  34.0% | batch:        32 of        94\t|\tloss: 1686.67\n",
      "Training Epoch 8  35.1% | batch:        33 of        94\t|\tloss: 2424.5\n",
      "Training Epoch 8  36.2% | batch:        34 of        94\t|\tloss: 2190.37\n",
      "Training Epoch 8  37.2% | batch:        35 of        94\t|\tloss: 1260.58\n",
      "Training Epoch 8  38.3% | batch:        36 of        94\t|\tloss: 1557.9\n",
      "Training Epoch 8  39.4% | batch:        37 of        94\t|\tloss: 2250.52\n",
      "Training Epoch 8  40.4% | batch:        38 of        94\t|\tloss: 1647.19\n",
      "Training Epoch 8  41.5% | batch:        39 of        94\t|\tloss: 1622.15\n",
      "Training Epoch 8  42.6% | batch:        40 of        94\t|\tloss: 1594.41\n",
      "Training Epoch 8  43.6% | batch:        41 of        94\t|\tloss: 2271.02\n",
      "Training Epoch 8  44.7% | batch:        42 of        94\t|\tloss: 1702.44\n",
      "Training Epoch 8  45.7% | batch:        43 of        94\t|\tloss: 2506.76\n",
      "Training Epoch 8  46.8% | batch:        44 of        94\t|\tloss: 2491.09\n",
      "Training Epoch 8  47.9% | batch:        45 of        94\t|\tloss: 1253.51\n",
      "Training Epoch 8  48.9% | batch:        46 of        94\t|\tloss: 3640.23\n",
      "Training Epoch 8  50.0% | batch:        47 of        94\t|\tloss: 2189.81\n",
      "Training Epoch 8  51.1% | batch:        48 of        94\t|\tloss: 1417.28\n",
      "Training Epoch 8  52.1% | batch:        49 of        94\t|\tloss: 1964.83\n",
      "Training Epoch 8  53.2% | batch:        50 of        94\t|\tloss: 2553.8\n",
      "Training Epoch 8  54.3% | batch:        51 of        94\t|\tloss: 2475.32\n",
      "Training Epoch 8  55.3% | batch:        52 of        94\t|\tloss: 2138.86\n",
      "Training Epoch 8  56.4% | batch:        53 of        94\t|\tloss: 3116.59\n",
      "Training Epoch 8  57.4% | batch:        54 of        94\t|\tloss: 2834.29\n",
      "Training Epoch 8  58.5% | batch:        55 of        94\t|\tloss: 2216.06\n",
      "Training Epoch 8  59.6% | batch:        56 of        94\t|\tloss: 3467.37\n",
      "Training Epoch 8  60.6% | batch:        57 of        94\t|\tloss: 2199.44\n",
      "Training Epoch 8  61.7% | batch:        58 of        94\t|\tloss: 2084.61\n",
      "Training Epoch 8  62.8% | batch:        59 of        94\t|\tloss: 2706.63\n",
      "Training Epoch 8  63.8% | batch:        60 of        94\t|\tloss: 2458.25\n",
      "Training Epoch 8  64.9% | batch:        61 of        94\t|\tloss: 2680.7\n",
      "Training Epoch 8  66.0% | batch:        62 of        94\t|\tloss: 2067.07\n",
      "Training Epoch 8  67.0% | batch:        63 of        94\t|\tloss: 3289.53\n",
      "Training Epoch 8  68.1% | batch:        64 of        94\t|\tloss: 2936.18\n",
      "Training Epoch 8  69.1% | batch:        65 of        94\t|\tloss: 2172.66\n",
      "Training Epoch 8  70.2% | batch:        66 of        94\t|\tloss: 1516.12\n",
      "Training Epoch 8  71.3% | batch:        67 of        94\t|\tloss: 3302.12\n",
      "Training Epoch 8  72.3% | batch:        68 of        94\t|\tloss: 3096.96\n",
      "Training Epoch 8  73.4% | batch:        69 of        94\t|\tloss: 3806.78\n",
      "Training Epoch 8  74.5% | batch:        70 of        94\t|\tloss: 1588.33\n",
      "Training Epoch 8  75.5% | batch:        71 of        94\t|\tloss: 2148.63\n",
      "Training Epoch 8  76.6% | batch:        72 of        94\t|\tloss: 2157.28\n",
      "Training Epoch 8  77.7% | batch:        73 of        94\t|\tloss: 3571.89\n",
      "Training Epoch 8  78.7% | batch:        74 of        94\t|\tloss: 2595.96\n",
      "Training Epoch 8  79.8% | batch:        75 of        94\t|\tloss: 2004.08\n",
      "Training Epoch 8  80.9% | batch:        76 of        94\t|\tloss: 1500.75\n",
      "Training Epoch 8  81.9% | batch:        77 of        94\t|\tloss: 1877.39\n",
      "Training Epoch 8  83.0% | batch:        78 of        94\t|\tloss: 3788.11\n",
      "Training Epoch 8  84.0% | batch:        79 of        94\t|\tloss: 1725.06\n",
      "Training Epoch 8  85.1% | batch:        80 of        94\t|\tloss: 2186.3\n",
      "Training Epoch 8  86.2% | batch:        81 of        94\t|\tloss: 2159.79\n",
      "Training Epoch 8  87.2% | batch:        82 of        94\t|\tloss: 2133.17\n",
      "Training Epoch 8  88.3% | batch:        83 of        94\t|\tloss: 2658.92\n",
      "Training Epoch 8  89.4% | batch:        84 of        94\t|\tloss: 1993.81\n",
      "Training Epoch 8  90.4% | batch:        85 of        94\t|\tloss: 2579.61\n",
      "Training Epoch 8  91.5% | batch:        86 of        94\t|\tloss: 2851.76\n",
      "Training Epoch 8  92.6% | batch:        87 of        94\t|\tloss: 1788.03\n",
      "Training Epoch 8  93.6% | batch:        88 of        94\t|\tloss: 2468.43\n",
      "Training Epoch 8  94.7% | batch:        89 of        94\t|\tloss: 1584.16\n",
      "Training Epoch 8  95.7% | batch:        90 of        94\t|\tloss: 2163.54\n",
      "Training Epoch 8  96.8% | batch:        91 of        94\t|\tloss: 1491.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:07,501 | INFO : Epoch 8 Training Summary: epoch: 8.000000 | loss: 2328.114295 | \n",
      "2023-05-04 16:59:07,502 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7999322414398193 seconds\n",
      "\n",
      "2023-05-04 16:59:07,503 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7730702757835388 seconds\n",
      "2023-05-04 16:59:07,503 | INFO : Avg batch train. time: 0.018862449742378072 seconds\n",
      "2023-05-04 16:59:07,504 | INFO : Avg sample train. time: 0.00014877246818119976 seconds\n",
      "2023-05-04 16:59:07,504 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 8  97.9% | batch:        92 of        94\t|\tloss: 4008.03\n",
      "Training Epoch 8  98.9% | batch:        93 of        94\t|\tloss: 2669.6\n",
      "\n",
      "Evaluating Epoch 8   0.0% | batch:         0 of        40\t|\tloss: 5762.48\n",
      "Evaluating Epoch 8   2.5% | batch:         1 of        40\t|\tloss: 805.998\n",
      "Evaluating Epoch 8   5.0% | batch:         2 of        40\t|\tloss: 2373.31\n",
      "Evaluating Epoch 8   7.5% | batch:         3 of        40\t|\tloss: 6511.2\n",
      "Evaluating Epoch 8  10.0% | batch:         4 of        40\t|\tloss: 1693.6\n",
      "Evaluating Epoch 8  12.5% | batch:         5 of        40\t|\tloss: 1698.39\n",
      "Evaluating Epoch 8  15.0% | batch:         6 of        40\t|\tloss: 7742.99\n",
      "Evaluating Epoch 8  17.5% | batch:         7 of        40\t|\tloss: 2550.13\n",
      "Evaluating Epoch 8  20.0% | batch:         8 of        40\t|\tloss: 2174.57\n",
      "Evaluating Epoch 8  22.5% | batch:         9 of        40\t|\tloss: 1808.27\n",
      "Evaluating Epoch 8  25.0% | batch:        10 of        40\t|\tloss: 4261.4\n",
      "Evaluating Epoch 8  27.5% | batch:        11 of        40\t|\tloss: 1406.33\n",
      "Evaluating Epoch 8  30.0% | batch:        12 of        40\t|\tloss: 6649.25\n",
      "Evaluating Epoch 8  32.5% | batch:        13 of        40\t|\tloss: 2607.04\n",
      "Evaluating Epoch 8  35.0% | batch:        14 of        40\t|\tloss: 1648.16\n",
      "Evaluating Epoch 8  37.5% | batch:        15 of        40\t|\tloss: 3913.75\n",
      "Evaluating Epoch 8  40.0% | batch:        16 of        40\t|\tloss: 4451.15\n",
      "Evaluating Epoch 8  42.5% | batch:        17 of        40\t|\tloss: 2027.55\n",
      "Evaluating Epoch 8  45.0% | batch:        18 of        40\t|\tloss: 1951.02\n",
      "Evaluating Epoch 8  47.5% | batch:        19 of        40\t|\tloss: 4219.36\n",
      "Evaluating Epoch 8  50.0% | batch:        20 of        40\t|\tloss: 4479.56\n",
      "Evaluating Epoch 8  52.5% | batch:        21 of        40\t|\tloss: 967.996\n",
      "Evaluating Epoch 8  55.0% | batch:        22 of        40\t|\tloss: 3017.14\n",
      "Evaluating Epoch 8  57.5% | batch:        23 of        40\t|\tloss: 2529.35\n",
      "Evaluating Epoch 8  60.0% | batch:        24 of        40\t|\tloss: 1448.36\n",
      "Evaluating Epoch 8  62.5% | batch:        25 of        40\t|\tloss: 3280.5\n",
      "Evaluating Epoch 8  65.0% | batch:        26 of        40\t|\tloss: 8680.89\n",
      "Evaluating Epoch 8  67.5% | batch:        27 of        40\t|\tloss: 2274.6\n",
      "Evaluating Epoch 8  70.0% | batch:        28 of        40\t|\tloss: 1876.6\n",
      "Evaluating Epoch 8  72.5% | batch:        29 of        40\t|\tloss: 8472.7\n",
      "Evaluating Epoch 8  75.0% | batch:        30 of        40\t|\tloss: 1593.23\n",
      "Evaluating Epoch 8  77.5% | batch:        31 of        40\t|\tloss: 1342.51\n",
      "Evaluating Epoch 8  80.0% | batch:        32 of        40\t|\tloss: 6987.34\n",
      "Evaluating Epoch 8  82.5% | batch:        33 of        40\t|\tloss: 5590.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:07,951 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4461042881011963 seconds\n",
      "\n",
      "2023-05-04 16:59:07,952 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5471726748757734 seconds\n",
      "2023-05-04 16:59:07,952 | INFO : Avg batch val. time: 0.013679316871894335 seconds\n",
      "2023-05-04 16:59:07,953 | INFO : Avg sample val. time: 0.00010839395302610407 seconds\n",
      "2023-05-04 16:59:07,954 | INFO : Epoch 8 Validation Summary: epoch: 8.000000 | loss: 3540.974869 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 8  85.0% | batch:        34 of        40\t|\tloss: 894.833\n",
      "Evaluating Epoch 8  87.5% | batch:        35 of        40\t|\tloss: 4456.58\n",
      "Evaluating Epoch 8  90.0% | batch:        36 of        40\t|\tloss: 5182.31\n",
      "Evaluating Epoch 8  92.5% | batch:        37 of        40\t|\tloss: 2080.83\n",
      "Evaluating Epoch 8  95.0% | batch:        38 of        40\t|\tloss: 3873.51\n",
      "Evaluating Epoch 8  97.5% | batch:        39 of        40\t|\tloss: 9969.78\n",
      "\n",
      "Training Epoch 9   0.0% | batch:         0 of        94\t|\tloss: 2964.91\n",
      "Training Epoch 9   1.1% | batch:         1 of        94\t|\tloss: 1730.74\n",
      "Training Epoch 9   2.1% | batch:         2 of        94\t|\tloss: 2775.06\n",
      "Training Epoch 9   3.2% | batch:         3 of        94\t|\tloss: 2386.66\n",
      "Training Epoch 9   4.3% | batch:         4 of        94\t|\tloss: 1335.64\n",
      "Training Epoch 9   5.3% | batch:         5 of        94\t|\tloss: 1834.8\n",
      "Training Epoch 9   6.4% | batch:         6 of        94\t|\tloss: 3280.52\n",
      "Training Epoch 9   7.4% | batch:         7 of        94\t|\tloss: 4366.02\n",
      "Training Epoch 9   8.5% | batch:         8 of        94\t|\tloss: 1931.53\n",
      "Training Epoch 9   9.6% | batch:         9 of        94\t|\tloss: 2361.76\n",
      "Training Epoch 9  10.6% | batch:        10 of        94\t|\tloss: 5079.15\n",
      "Training Epoch 9  11.7% | batch:        11 of        94\t|\tloss: 2071.5\n",
      "Training Epoch 9  12.8% | batch:        12 of        94\t|\tloss: 1203.15\n",
      "Training Epoch 9  13.8% | batch:        13 of        94\t|\tloss: 1879.83\n",
      "Training Epoch 9  14.9% | batch:        14 of        94\t|\tloss: 2025.94\n",
      "Training Epoch 9  16.0% | batch:        15 of        94\t|\tloss: 2060.82\n",
      "Training Epoch 9  17.0% | batch:        16 of        94\t|\tloss: 1631.92\n",
      "Training Epoch 9  18.1% | batch:        17 of        94\t|\tloss: 1936.43\n",
      "Training Epoch 9  19.1% | batch:        18 of        94\t|\tloss: 1417.74\n",
      "Training Epoch 9  20.2% | batch:        19 of        94\t|\tloss: 3091.05\n",
      "Training Epoch 9  21.3% | batch:        20 of        94\t|\tloss: 3112.07\n",
      "Training Epoch 9  22.3% | batch:        21 of        94\t|\tloss: 1087.81\n",
      "Training Epoch 9  23.4% | batch:        22 of        94\t|\tloss: 1998.01\n",
      "Training Epoch 9  24.5% | batch:        23 of        94\t|\tloss: 1499.12\n",
      "Training Epoch 9  25.5% | batch:        24 of        94\t|\tloss: 2129.2\n",
      "Training Epoch 9  26.6% | batch:        25 of        94\t|\tloss: 1854.91\n",
      "Training Epoch 9  27.7% | batch:        26 of        94\t|\tloss: 2538.44\n",
      "Training Epoch 9  28.7% | batch:        27 of        94\t|\tloss: 4181.75\n",
      "Training Epoch 9  29.8% | batch:        28 of        94\t|\tloss: 1673.98\n",
      "Training Epoch 9  30.9% | batch:        29 of        94\t|\tloss: 2193.05\n",
      "Training Epoch 9  31.9% | batch:        30 of        94\t|\tloss: 3208.97\n",
      "Training Epoch 9  33.0% | batch:        31 of        94\t|\tloss: 2036.58\n",
      "Training Epoch 9  34.0% | batch:        32 of        94\t|\tloss: 2315.89\n",
      "Training Epoch 9  35.1% | batch:        33 of        94\t|\tloss: 3518.22\n",
      "Training Epoch 9  36.2% | batch:        34 of        94\t|\tloss: 1686.64\n",
      "Training Epoch 9  37.2% | batch:        35 of        94\t|\tloss: 1841.92\n",
      "Training Epoch 9  38.3% | batch:        36 of        94\t|\tloss: 1843.16\n",
      "Training Epoch 9  39.4% | batch:        37 of        94\t|\tloss: 2291.14\n",
      "Training Epoch 9  40.4% | batch:        38 of        94\t|\tloss: 1420.71\n",
      "Training Epoch 9  41.5% | batch:        39 of        94\t|\tloss: 1803.93\n",
      "Training Epoch 9  42.6% | batch:        40 of        94\t|\tloss: 1853.38\n",
      "Training Epoch 9  43.6% | batch:        41 of        94\t|\tloss: 2076.71\n",
      "Training Epoch 9  44.7% | batch:        42 of        94\t|\tloss: 1313.46\n",
      "Training Epoch 9  45.7% | batch:        43 of        94\t|\tloss: 1864.71\n",
      "Training Epoch 9  46.8% | batch:        44 of        94\t|\tloss: 2784.06\n",
      "Training Epoch 9  47.9% | batch:        45 of        94\t|\tloss: 5496.6\n",
      "Training Epoch 9  48.9% | batch:        46 of        94\t|\tloss: 2308.73\n",
      "Training Epoch 9  50.0% | batch:        47 of        94\t|\tloss: 1489.28\n",
      "Training Epoch 9  51.1% | batch:        48 of        94\t|\tloss: 2493.82\n",
      "Training Epoch 9  52.1% | batch:        49 of        94\t|\tloss: 1680.94\n",
      "Training Epoch 9  53.2% | batch:        50 of        94\t|\tloss: 3817.18\n",
      "Training Epoch 9  54.3% | batch:        51 of        94\t|\tloss: 2295.93\n",
      "Training Epoch 9  55.3% | batch:        52 of        94\t|\tloss: 4130.51\n",
      "Training Epoch 9  56.4% | batch:        53 of        94\t|\tloss: 2004.4\n",
      "Training Epoch 9  57.4% | batch:        54 of        94\t|\tloss: 2048.89\n",
      "Training Epoch 9  58.5% | batch:        55 of        94\t|\tloss: 2228.79\n",
      "Training Epoch 9  59.6% | batch:        56 of        94\t|\tloss: 1762.77\n",
      "Training Epoch 9  60.6% | batch:        57 of        94\t|\tloss: 1605.94\n",
      "Training Epoch 9  61.7% | batch:        58 of        94\t|\tloss: 2145.24\n",
      "Training Epoch 9  62.8% | batch:        59 of        94\t|\tloss: 3091.57\n",
      "Training Epoch 9  63.8% | batch:        60 of        94\t|\tloss: 2524.43\n",
      "Training Epoch 9  64.9% | batch:        61 of        94\t|\tloss: 2121.88\n",
      "Training Epoch 9  66.0% | batch:        62 of        94\t|\tloss: 1419.22\n",
      "Training Epoch 9  67.0% | batch:        63 of        94\t|\tloss: 1322.46\n",
      "Training Epoch 9  68.1% | batch:        64 of        94\t|\tloss: 4052.07\n",
      "Training Epoch 9  69.1% | batch:        65 of        94\t|\tloss: 1840.67\n",
      "Training Epoch 9  70.2% | batch:        66 of        94\t|\tloss: 2518.98\n",
      "Training Epoch 9  71.3% | batch:        67 of        94\t|\tloss: 2230.53\n",
      "Training Epoch 9  72.3% | batch:        68 of        94\t|\tloss: 2527.39\n",
      "Training Epoch 9  73.4% | batch:        69 of        94\t|\tloss: 2510.08\n",
      "Training Epoch 9  74.5% | batch:        70 of        94\t|\tloss: 1376.7\n",
      "Training Epoch 9  75.5% | batch:        71 of        94\t|\tloss: 1912.87\n",
      "Training Epoch 9  76.6% | batch:        72 of        94\t|\tloss: 1885.89\n",
      "Training Epoch 9  77.7% | batch:        73 of        94\t|\tloss: 1398.77\n",
      "Training Epoch 9  78.7% | batch:        74 of        94\t|\tloss: 1543.58\n",
      "Training Epoch 9  79.8% | batch:        75 of        94\t|\tloss: 3632.4\n",
      "Training Epoch 9  80.9% | batch:        76 of        94\t|\tloss: 1860.9\n",
      "Training Epoch 9  81.9% | batch:        77 of        94\t|\tloss: 1273.9\n",
      "Training Epoch 9  83.0% | batch:        78 of        94\t|\tloss: 2201.28\n",
      "Training Epoch 9  84.0% | batch:        79 of        94\t|\tloss: 2333.05\n",
      "Training Epoch 9  85.1% | batch:        80 of        94\t|\tloss: 1782.9\n",
      "Training Epoch 9  86.2% | batch:        81 of        94\t|\tloss: 1673.69\n",
      "Training Epoch 9  87.2% | batch:        82 of        94\t|\tloss: 1333.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:09,785 | INFO : Epoch 9 Training Summary: epoch: 9.000000 | loss: 2251.730577 | \n",
      "2023-05-04 16:59:09,786 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8002912998199463 seconds\n",
      "\n",
      "2023-05-04 16:59:09,787 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7760948340098064 seconds\n",
      "2023-05-04 16:59:09,787 | INFO : Avg batch train. time: 0.018894625893721345 seconds\n",
      "2023-05-04 16:59:09,788 | INFO : Avg sample train. time: 0.00014902624886808244 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 9  88.3% | batch:        83 of        94\t|\tloss: 2906.36\n",
      "Training Epoch 9  89.4% | batch:        84 of        94\t|\tloss: 1231.97\n",
      "Training Epoch 9  90.4% | batch:        85 of        94\t|\tloss: 1838.71\n",
      "Training Epoch 9  91.5% | batch:        86 of        94\t|\tloss: 2248.08\n",
      "Training Epoch 9  92.6% | batch:        87 of        94\t|\tloss: 2640.76\n",
      "Training Epoch 9  93.6% | batch:        88 of        94\t|\tloss: 1851.67\n",
      "Training Epoch 9  94.7% | batch:        89 of        94\t|\tloss: 1782.46\n",
      "Training Epoch 9  95.7% | batch:        90 of        94\t|\tloss: 1560.73\n",
      "Training Epoch 9  96.8% | batch:        91 of        94\t|\tloss: 3087.63\n",
      "Training Epoch 9  97.9% | batch:        92 of        94\t|\tloss: 1685.94\n",
      "Training Epoch 9  98.9% | batch:        93 of        94\t|\tloss: 13274.4\n",
      "\n",
      "Training Epoch 10   0.0% | batch:         0 of        94\t|\tloss: 1618.8\n",
      "Training Epoch 10   1.1% | batch:         1 of        94\t|\tloss: 2168.07\n",
      "Training Epoch 10   2.1% | batch:         2 of        94\t|\tloss: 1688.54\n",
      "Training Epoch 10   3.2% | batch:         3 of        94\t|\tloss: 1461.69\n",
      "Training Epoch 10   4.3% | batch:         4 of        94\t|\tloss: 2806.65\n",
      "Training Epoch 10   5.3% | batch:         5 of        94\t|\tloss: 1613.39\n",
      "Training Epoch 10   6.4% | batch:         6 of        94\t|\tloss: 2057.03\n",
      "Training Epoch 10   7.4% | batch:         7 of        94\t|\tloss: 2262.27\n",
      "Training Epoch 10   8.5% | batch:         8 of        94\t|\tloss: 2713.36\n",
      "Training Epoch 10   9.6% | batch:         9 of        94\t|\tloss: 1693.42\n",
      "Training Epoch 10  10.6% | batch:        10 of        94\t|\tloss: 3415.54\n",
      "Training Epoch 10  11.7% | batch:        11 of        94\t|\tloss: 1677.11\n",
      "Training Epoch 10  12.8% | batch:        12 of        94\t|\tloss: 1975.06\n",
      "Training Epoch 10  13.8% | batch:        13 of        94\t|\tloss: 2602.27\n",
      "Training Epoch 10  14.9% | batch:        14 of        94\t|\tloss: 1853.48\n",
      "Training Epoch 10  16.0% | batch:        15 of        94\t|\tloss: 4162.11\n",
      "Training Epoch 10  17.0% | batch:        16 of        94\t|\tloss: 2159.79\n",
      "Training Epoch 10  18.1% | batch:        17 of        94\t|\tloss: 2685.79\n",
      "Training Epoch 10  19.1% | batch:        18 of        94\t|\tloss: 2534.22\n",
      "Training Epoch 10  20.2% | batch:        19 of        94\t|\tloss: 2311.61\n",
      "Training Epoch 10  21.3% | batch:        20 of        94\t|\tloss: 1521.07\n",
      "Training Epoch 10  22.3% | batch:        21 of        94\t|\tloss: 1442.34\n",
      "Training Epoch 10  23.4% | batch:        22 of        94\t|\tloss: 3426.01\n",
      "Training Epoch 10  24.5% | batch:        23 of        94\t|\tloss: 2145.48\n",
      "Training Epoch 10  25.5% | batch:        24 of        94\t|\tloss: 2501.42\n",
      "Training Epoch 10  26.6% | batch:        25 of        94\t|\tloss: 1739.99\n",
      "Training Epoch 10  27.7% | batch:        26 of        94\t|\tloss: 3421.65\n",
      "Training Epoch 10  28.7% | batch:        27 of        94\t|\tloss: 1892.55\n",
      "Training Epoch 10  29.8% | batch:        28 of        94\t|\tloss: 3040.02\n",
      "Training Epoch 10  30.9% | batch:        29 of        94\t|\tloss: 2327.91\n",
      "Training Epoch 10  31.9% | batch:        30 of        94\t|\tloss: 3907.69\n",
      "Training Epoch 10  33.0% | batch:        31 of        94\t|\tloss: 2838.06\n",
      "Training Epoch 10  34.0% | batch:        32 of        94\t|\tloss: 1563.17\n",
      "Training Epoch 10  35.1% | batch:        33 of        94\t|\tloss: 1704.32\n",
      "Training Epoch 10  36.2% | batch:        34 of        94\t|\tloss: 2026.84\n",
      "Training Epoch 10  37.2% | batch:        35 of        94\t|\tloss: 2484.27\n",
      "Training Epoch 10  38.3% | batch:        36 of        94\t|\tloss: 1536.43\n",
      "Training Epoch 10  39.4% | batch:        37 of        94\t|\tloss: 2678.07\n",
      "Training Epoch 10  40.4% | batch:        38 of        94\t|\tloss: 3320.62\n",
      "Training Epoch 10  41.5% | batch:        39 of        94\t|\tloss: 1977.9\n",
      "Training Epoch 10  42.6% | batch:        40 of        94\t|\tloss: 2585.25\n",
      "Training Epoch 10  43.6% | batch:        41 of        94\t|\tloss: 2100.93\n",
      "Training Epoch 10  44.7% | batch:        42 of        94\t|\tloss: 1952.76\n",
      "Training Epoch 10  45.7% | batch:        43 of        94\t|\tloss: 1559.16\n",
      "Training Epoch 10  46.8% | batch:        44 of        94\t|\tloss: 1710.5\n",
      "Training Epoch 10  47.9% | batch:        45 of        94\t|\tloss: 2625.46\n",
      "Training Epoch 10  48.9% | batch:        46 of        94\t|\tloss: 1412.27\n",
      "Training Epoch 10  50.0% | batch:        47 of        94\t|\tloss: 2124.13\n",
      "Training Epoch 10  51.1% | batch:        48 of        94\t|\tloss: 1326.55\n",
      "Training Epoch 10  52.1% | batch:        49 of        94\t|\tloss: 1554.56\n",
      "Training Epoch 10  53.2% | batch:        50 of        94\t|\tloss: 1773.6\n",
      "Training Epoch 10  54.3% | batch:        51 of        94\t|\tloss: 1439.19\n",
      "Training Epoch 10  55.3% | batch:        52 of        94\t|\tloss: 2286.27\n",
      "Training Epoch 10  56.4% | batch:        53 of        94\t|\tloss: 1566.45\n",
      "Training Epoch 10  57.4% | batch:        54 of        94\t|\tloss: 2242.5\n",
      "Training Epoch 10  58.5% | batch:        55 of        94\t|\tloss: 1492.38\n",
      "Training Epoch 10  59.6% | batch:        56 of        94\t|\tloss: 1828.95\n",
      "Training Epoch 10  60.6% | batch:        57 of        94\t|\tloss: 1865.92\n",
      "Training Epoch 10  61.7% | batch:        58 of        94\t|\tloss: 3307.57\n",
      "Training Epoch 10  62.8% | batch:        59 of        94\t|\tloss: 1914.68\n",
      "Training Epoch 10  63.8% | batch:        60 of        94\t|\tloss: 1819.95\n",
      "Training Epoch 10  64.9% | batch:        61 of        94\t|\tloss: 1830.04\n",
      "Training Epoch 10  66.0% | batch:        62 of        94\t|\tloss: 1585.73\n",
      "Training Epoch 10  67.0% | batch:        63 of        94\t|\tloss: 1607.93\n",
      "Training Epoch 10  68.1% | batch:        64 of        94\t|\tloss: 2373.13\n",
      "Training Epoch 10  69.1% | batch:        65 of        94\t|\tloss: 1623.21\n",
      "Training Epoch 10  70.2% | batch:        66 of        94\t|\tloss: 1602.04\n",
      "Training Epoch 10  71.3% | batch:        67 of        94\t|\tloss: 1728.28\n",
      "Training Epoch 10  72.3% | batch:        68 of        94\t|\tloss: 2285.61\n",
      "Training Epoch 10  73.4% | batch:        69 of        94\t|\tloss: 1667.53\n",
      "Training Epoch 10  74.5% | batch:        70 of        94\t|\tloss: 2169.49\n",
      "Training Epoch 10  75.5% | batch:        71 of        94\t|\tloss: 2266.34\n",
      "Training Epoch 10  76.6% | batch:        72 of        94\t|\tloss: 1639.8\n",
      "Training Epoch 10  77.7% | batch:        73 of        94\t|\tloss: 4908.72\n",
      "Training Epoch 10  78.7% | batch:        74 of        94\t|\tloss: 2378.93\n",
      "Training Epoch 10  79.8% | batch:        75 of        94\t|\tloss: 2357\n",
      "Training Epoch 10  80.9% | batch:        76 of        94\t|\tloss: 1531.74\n",
      "Training Epoch 10  81.9% | batch:        77 of        94\t|\tloss: 1669.22\n",
      "Training Epoch 10  83.0% | batch:        78 of        94\t|\tloss: 2588.83\n",
      "Training Epoch 10  84.0% | batch:        79 of        94\t|\tloss: 1734.32\n",
      "Training Epoch 10  85.1% | batch:        80 of        94\t|\tloss: 1373.89\n",
      "Training Epoch 10  86.2% | batch:        81 of        94\t|\tloss: 2850.09\n",
      "Training Epoch 10  87.2% | batch:        82 of        94\t|\tloss: 4067.72\n",
      "Training Epoch 10  88.3% | batch:        83 of        94\t|\tloss: 1831.8\n",
      "Training Epoch 10  89.4% | batch:        84 of        94\t|\tloss: 3151.02\n",
      "Training Epoch 10  90.4% | batch:        85 of        94\t|\tloss: 2194.23\n",
      "Training Epoch 10  91.5% | batch:        86 of        94\t|\tloss: 2552.88\n",
      "Training Epoch 10  92.6% | batch:        87 of        94\t|\tloss: 1748.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:11,611 | INFO : Epoch 10 Training Summary: epoch: 10.000000 | loss: 2242.418972 | \n",
      "2023-05-04 16:59:11,612 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8026251792907715 seconds\n",
      "\n",
      "2023-05-04 16:59:11,613 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7787478685379028 seconds\n",
      "2023-05-04 16:59:11,613 | INFO : Avg batch train. time: 0.018922849665296837 seconds\n",
      "2023-05-04 16:59:11,614 | INFO : Avg sample train. time: 0.00014924885622905713 seconds\n",
      "2023-05-04 16:59:11,615 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 10  93.6% | batch:        88 of        94\t|\tloss: 2451.59\n",
      "Training Epoch 10  94.7% | batch:        89 of        94\t|\tloss: 2991.4\n",
      "Training Epoch 10  95.7% | batch:        90 of        94\t|\tloss: 2420.43\n",
      "Training Epoch 10  96.8% | batch:        91 of        94\t|\tloss: 4653.94\n",
      "Training Epoch 10  97.9% | batch:        92 of        94\t|\tloss: 1627.99\n",
      "Training Epoch 10  98.9% | batch:        93 of        94\t|\tloss: 17203.6\n",
      "\n",
      "Evaluating Epoch 10   0.0% | batch:         0 of        40\t|\tloss: 6294.77\n",
      "Evaluating Epoch 10   2.5% | batch:         1 of        40\t|\tloss: 975.24\n",
      "Evaluating Epoch 10   5.0% | batch:         2 of        40\t|\tloss: 3149.62\n",
      "Evaluating Epoch 10   7.5% | batch:         3 of        40\t|\tloss: 7170.63\n",
      "Evaluating Epoch 10  10.0% | batch:         4 of        40\t|\tloss: 1532.16\n",
      "Evaluating Epoch 10  12.5% | batch:         5 of        40\t|\tloss: 1784.71\n",
      "Evaluating Epoch 10  15.0% | batch:         6 of        40\t|\tloss: 7576.63\n",
      "Evaluating Epoch 10  17.5% | batch:         7 of        40\t|\tloss: 2581.4\n",
      "Evaluating Epoch 10  20.0% | batch:         8 of        40\t|\tloss: 2627.96\n",
      "Evaluating Epoch 10  22.5% | batch:         9 of        40\t|\tloss: 1865.03\n",
      "Evaluating Epoch 10  25.0% | batch:        10 of        40\t|\tloss: 4621.03\n",
      "Evaluating Epoch 10  27.5% | batch:        11 of        40\t|\tloss: 1451.5\n",
      "Evaluating Epoch 10  30.0% | batch:        12 of        40\t|\tloss: 6652.28\n",
      "Evaluating Epoch 10  32.5% | batch:        13 of        40\t|\tloss: 2765.11\n",
      "Evaluating Epoch 10  35.0% | batch:        14 of        40\t|\tloss: 1895.54\n",
      "Evaluating Epoch 10  37.5% | batch:        15 of        40\t|\tloss: 3615.35\n",
      "Evaluating Epoch 10  40.0% | batch:        16 of        40\t|\tloss: 4316.32\n",
      "Evaluating Epoch 10  42.5% | batch:        17 of        40\t|\tloss: 2445.59\n",
      "Evaluating Epoch 10  45.0% | batch:        18 of        40\t|\tloss: 2143.44\n",
      "Evaluating Epoch 10  47.5% | batch:        19 of        40\t|\tloss: 4657.42\n",
      "Evaluating Epoch 10  50.0% | batch:        20 of        40\t|\tloss: 4311.58\n",
      "Evaluating Epoch 10  52.5% | batch:        21 of        40\t|\tloss: 1004.5\n",
      "Evaluating Epoch 10  55.0% | batch:        22 of        40\t|\tloss: 3772.03\n",
      "Evaluating Epoch 10  57.5% | batch:        23 of        40\t|\tloss: 2507.76\n",
      "Evaluating Epoch 10  60.0% | batch:        24 of        40\t|\tloss: 1495.84\n",
      "Evaluating Epoch 10  62.5% | batch:        25 of        40\t|\tloss: 3116.42\n",
      "Evaluating Epoch 10  65.0% | batch:        26 of        40\t|\tloss: 10308.3\n",
      "Evaluating Epoch 10  67.5% | batch:        27 of        40\t|\tloss: 2638.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:12,064 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4488492012023926 seconds\n",
      "\n",
      "2023-05-04 16:59:12,065 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.546587416103908 seconds\n",
      "2023-05-04 16:59:12,066 | INFO : Avg batch val. time: 0.013664685402597701 seconds\n",
      "2023-05-04 16:59:12,066 | INFO : Avg sample val. time: 0.00010827801428365848 seconds\n",
      "2023-05-04 16:59:12,067 | INFO : Epoch 10 Validation Summary: epoch: 10.000000 | loss: 3797.960105 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 10  70.0% | batch:        28 of        40\t|\tloss: 1866.3\n",
      "Evaluating Epoch 10  72.5% | batch:        29 of        40\t|\tloss: 8806.97\n",
      "Evaluating Epoch 10  75.0% | batch:        30 of        40\t|\tloss: 1644.28\n",
      "Evaluating Epoch 10  77.5% | batch:        31 of        40\t|\tloss: 1655.01\n",
      "Evaluating Epoch 10  80.0% | batch:        32 of        40\t|\tloss: 7803.86\n",
      "Evaluating Epoch 10  82.5% | batch:        33 of        40\t|\tloss: 6050.63\n",
      "Evaluating Epoch 10  85.0% | batch:        34 of        40\t|\tloss: 1149.14\n",
      "Evaluating Epoch 10  87.5% | batch:        35 of        40\t|\tloss: 5030.87\n",
      "Evaluating Epoch 10  90.0% | batch:        36 of        40\t|\tloss: 5409.25\n",
      "Evaluating Epoch 10  92.5% | batch:        37 of        40\t|\tloss: 2349.89\n",
      "Evaluating Epoch 10  95.0% | batch:        38 of        40\t|\tloss: 3667.25\n",
      "Evaluating Epoch 10  97.5% | batch:        39 of        40\t|\tloss: 11593\n",
      "\n",
      "Training Epoch 11   0.0% | batch:         0 of        94\t|\tloss: 4751.1\n",
      "Training Epoch 11   1.1% | batch:         1 of        94\t|\tloss: 1507.13\n",
      "Training Epoch 11   2.1% | batch:         2 of        94\t|\tloss: 2479.32\n",
      "Training Epoch 11   3.2% | batch:         3 of        94\t|\tloss: 1339.71\n",
      "Training Epoch 11   4.3% | batch:         4 of        94\t|\tloss: 1648.02\n",
      "Training Epoch 11   5.3% | batch:         5 of        94\t|\tloss: 1799.38\n",
      "Training Epoch 11   6.4% | batch:         6 of        94\t|\tloss: 1268.51\n",
      "Training Epoch 11   7.4% | batch:         7 of        94\t|\tloss: 3405.4\n",
      "Training Epoch 11   8.5% | batch:         8 of        94\t|\tloss: 2020.52\n",
      "Training Epoch 11   9.6% | batch:         9 of        94\t|\tloss: 2959.4\n",
      "Training Epoch 11  10.6% | batch:        10 of        94\t|\tloss: 2165.29\n",
      "Training Epoch 11  11.7% | batch:        11 of        94\t|\tloss: 1787.85\n",
      "Training Epoch 11  12.8% | batch:        12 of        94\t|\tloss: 2708.57\n",
      "Training Epoch 11  13.8% | batch:        13 of        94\t|\tloss: 1518.66\n",
      "Training Epoch 11  14.9% | batch:        14 of        94\t|\tloss: 2840.52\n",
      "Training Epoch 11  16.0% | batch:        15 of        94\t|\tloss: 1331.99\n",
      "Training Epoch 11  17.0% | batch:        16 of        94\t|\tloss: 1244.37\n",
      "Training Epoch 11  18.1% | batch:        17 of        94\t|\tloss: 2022.04\n",
      "Training Epoch 11  19.1% | batch:        18 of        94\t|\tloss: 2740.36\n",
      "Training Epoch 11  20.2% | batch:        19 of        94\t|\tloss: 1858.6\n",
      "Training Epoch 11  21.3% | batch:        20 of        94\t|\tloss: 1982.89\n",
      "Training Epoch 11  22.3% | batch:        21 of        94\t|\tloss: 1437.14\n",
      "Training Epoch 11  23.4% | batch:        22 of        94\t|\tloss: 2242.86\n",
      "Training Epoch 11  24.5% | batch:        23 of        94\t|\tloss: 2220.15\n",
      "Training Epoch 11  25.5% | batch:        24 of        94\t|\tloss: 1921.65\n",
      "Training Epoch 11  26.6% | batch:        25 of        94\t|\tloss: 2235.03\n",
      "Training Epoch 11  27.7% | batch:        26 of        94\t|\tloss: 2007.58\n",
      "Training Epoch 11  28.7% | batch:        27 of        94\t|\tloss: 2071.07\n",
      "Training Epoch 11  29.8% | batch:        28 of        94\t|\tloss: 2839.8\n",
      "Training Epoch 11  30.9% | batch:        29 of        94\t|\tloss: 1862.32\n",
      "Training Epoch 11  31.9% | batch:        30 of        94\t|\tloss: 1372.08\n",
      "Training Epoch 11  33.0% | batch:        31 of        94\t|\tloss: 2565.36\n",
      "Training Epoch 11  34.0% | batch:        32 of        94\t|\tloss: 1996.51\n",
      "Training Epoch 11  35.1% | batch:        33 of        94\t|\tloss: 1826.29\n",
      "Training Epoch 11  36.2% | batch:        34 of        94\t|\tloss: 3044.31\n",
      "Training Epoch 11  37.2% | batch:        35 of        94\t|\tloss: 1821.63\n",
      "Training Epoch 11  38.3% | batch:        36 of        94\t|\tloss: 2827.83\n",
      "Training Epoch 11  39.4% | batch:        37 of        94\t|\tloss: 3667.03\n",
      "Training Epoch 11  40.4% | batch:        38 of        94\t|\tloss: 1556.77\n",
      "Training Epoch 11  41.5% | batch:        39 of        94\t|\tloss: 1904.35\n",
      "Training Epoch 11  42.6% | batch:        40 of        94\t|\tloss: 1874.94\n",
      "Training Epoch 11  43.6% | batch:        41 of        94\t|\tloss: 1830.99\n",
      "Training Epoch 11  44.7% | batch:        42 of        94\t|\tloss: 2769.63\n",
      "Training Epoch 11  45.7% | batch:        43 of        94\t|\tloss: 3407.07\n",
      "Training Epoch 11  46.8% | batch:        44 of        94\t|\tloss: 2008.18\n",
      "Training Epoch 11  47.9% | batch:        45 of        94\t|\tloss: 1690.65\n",
      "Training Epoch 11  48.9% | batch:        46 of        94\t|\tloss: 2650.28\n",
      "Training Epoch 11  50.0% | batch:        47 of        94\t|\tloss: 3284.03\n",
      "Training Epoch 11  51.1% | batch:        48 of        94\t|\tloss: 2131.15\n",
      "Training Epoch 11  52.1% | batch:        49 of        94\t|\tloss: 1921.67\n",
      "Training Epoch 11  53.2% | batch:        50 of        94\t|\tloss: 2449.55\n",
      "Training Epoch 11  54.3% | batch:        51 of        94\t|\tloss: 2726.75\n",
      "Training Epoch 11  55.3% | batch:        52 of        94\t|\tloss: 1309.33\n",
      "Training Epoch 11  56.4% | batch:        53 of        94\t|\tloss: 1225.73\n",
      "Training Epoch 11  57.4% | batch:        54 of        94\t|\tloss: 2551.31\n",
      "Training Epoch 11  58.5% | batch:        55 of        94\t|\tloss: 3791.1\n",
      "Training Epoch 11  59.6% | batch:        56 of        94\t|\tloss: 1407.53\n",
      "Training Epoch 11  60.6% | batch:        57 of        94\t|\tloss: 2094.22\n",
      "Training Epoch 11  61.7% | batch:        58 of        94\t|\tloss: 2065.39\n",
      "Training Epoch 11  62.8% | batch:        59 of        94\t|\tloss: 1783.52\n",
      "Training Epoch 11  63.8% | batch:        60 of        94\t|\tloss: 1933.43\n",
      "Training Epoch 11  64.9% | batch:        61 of        94\t|\tloss: 2067.79\n",
      "Training Epoch 11  66.0% | batch:        62 of        94\t|\tloss: 1421.45\n",
      "Training Epoch 11  67.0% | batch:        63 of        94\t|\tloss: 1920.56\n",
      "Training Epoch 11  68.1% | batch:        64 of        94\t|\tloss: 1357.33\n",
      "Training Epoch 11  69.1% | batch:        65 of        94\t|\tloss: 2658.19\n",
      "Training Epoch 11  70.2% | batch:        66 of        94\t|\tloss: 1527.03\n",
      "Training Epoch 11  71.3% | batch:        67 of        94\t|\tloss: 2963.99\n",
      "Training Epoch 11  72.3% | batch:        68 of        94\t|\tloss: 1415.59\n",
      "Training Epoch 11  73.4% | batch:        69 of        94\t|\tloss: 2431.86\n",
      "Training Epoch 11  74.5% | batch:        70 of        94\t|\tloss: 3132.94\n",
      "Training Epoch 11  75.5% | batch:        71 of        94\t|\tloss: 3992.11\n",
      "Training Epoch 11  76.6% | batch:        72 of        94\t|\tloss: 1887.61\n",
      "Training Epoch 11  77.7% | batch:        73 of        94\t|\tloss: 1873.09\n",
      "Training Epoch 11  78.7% | batch:        74 of        94\t|\tloss: 1189.25\n",
      "Training Epoch 11  79.8% | batch:        75 of        94\t|\tloss: 1778.54\n",
      "Training Epoch 11  80.9% | batch:        76 of        94\t|\tloss: 1879.8\n",
      "Training Epoch 11  81.9% | batch:        77 of        94\t|\tloss: 1736.2\n",
      "Training Epoch 11  83.0% | batch:        78 of        94\t|\tloss: 1663.3\n",
      "Training Epoch 11  84.0% | batch:        79 of        94\t|\tloss: 2418.79\n",
      "Training Epoch 11  85.1% | batch:        80 of        94\t|\tloss: 2451.61\n",
      "Training Epoch 11  86.2% | batch:        81 of        94\t|\tloss: 1954.64\n",
      "Training Epoch 11  87.2% | batch:        82 of        94\t|\tloss: 3796.68\n",
      "Training Epoch 11  88.3% | batch:        83 of        94\t|\tloss: 2717.33\n",
      "Training Epoch 11  89.4% | batch:        84 of        94\t|\tloss: 2696.12\n",
      "Training Epoch 11  90.4% | batch:        85 of        94\t|\tloss: 1503.4\n",
      "Training Epoch 11  91.5% | batch:        86 of        94\t|\tloss: 1565.11\n",
      "Training Epoch 11  92.6% | batch:        87 of        94\t|\tloss: 1465.91\n",
      "Training Epoch 11  93.6% | batch:        88 of        94\t|\tloss: 1388.43\n",
      "Training Epoch 11  94.7% | batch:        89 of        94\t|\tloss: 1918.2\n",
      "Training Epoch 11  95.7% | batch:        90 of        94\t|\tloss: 3680.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:13,895 | INFO : Epoch 11 Training Summary: epoch: 11.000000 | loss: 2188.609396 | \n",
      "2023-05-04 16:59:13,896 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8064558506011963 seconds\n",
      "\n",
      "2023-05-04 16:59:13,897 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7812667759982022 seconds\n",
      "2023-05-04 16:59:13,897 | INFO : Avg batch train. time: 0.018949646553172363 seconds\n",
      "2023-05-04 16:59:13,898 | INFO : Avg sample train. time: 0.00014946020943096174 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 11  96.8% | batch:        91 of        94\t|\tloss: 3806.88\n",
      "Training Epoch 11  97.9% | batch:        92 of        94\t|\tloss: 1497.87\n",
      "Training Epoch 11  98.9% | batch:        93 of        94\t|\tloss: 2893.81\n",
      "\n",
      "Training Epoch 12   0.0% | batch:         0 of        94\t|\tloss: 2142.82\n",
      "Training Epoch 12   1.1% | batch:         1 of        94\t|\tloss: 1989.46\n",
      "Training Epoch 12   2.1% | batch:         2 of        94\t|\tloss: 4332.1\n",
      "Training Epoch 12   3.2% | batch:         3 of        94\t|\tloss: 2394.64\n",
      "Training Epoch 12   4.3% | batch:         4 of        94\t|\tloss: 2810.64\n",
      "Training Epoch 12   5.3% | batch:         5 of        94\t|\tloss: 2062.81\n",
      "Training Epoch 12   6.4% | batch:         6 of        94\t|\tloss: 3059.11\n",
      "Training Epoch 12   7.4% | batch:         7 of        94\t|\tloss: 4900.4\n",
      "Training Epoch 12   8.5% | batch:         8 of        94\t|\tloss: 2199.13\n",
      "Training Epoch 12   9.6% | batch:         9 of        94\t|\tloss: 2265.81\n",
      "Training Epoch 12  10.6% | batch:        10 of        94\t|\tloss: 1229.53\n",
      "Training Epoch 12  11.7% | batch:        11 of        94\t|\tloss: 1992.84\n",
      "Training Epoch 12  12.8% | batch:        12 of        94\t|\tloss: 1668.11\n",
      "Training Epoch 12  13.8% | batch:        13 of        94\t|\tloss: 1369.96\n",
      "Training Epoch 12  14.9% | batch:        14 of        94\t|\tloss: 1500.45\n",
      "Training Epoch 12  16.0% | batch:        15 of        94\t|\tloss: 1261.88\n",
      "Training Epoch 12  17.0% | batch:        16 of        94\t|\tloss: 1988.93\n",
      "Training Epoch 12  18.1% | batch:        17 of        94\t|\tloss: 1436.53\n",
      "Training Epoch 12  19.1% | batch:        18 of        94\t|\tloss: 2347.12\n",
      "Training Epoch 12  20.2% | batch:        19 of        94\t|\tloss: 2319.94\n",
      "Training Epoch 12  21.3% | batch:        20 of        94\t|\tloss: 2138.58\n",
      "Training Epoch 12  22.3% | batch:        21 of        94\t|\tloss: 1397.26\n",
      "Training Epoch 12  23.4% | batch:        22 of        94\t|\tloss: 1378.01\n",
      "Training Epoch 12  24.5% | batch:        23 of        94\t|\tloss: 2609.82\n",
      "Training Epoch 12  25.5% | batch:        24 of        94\t|\tloss: 2908.09\n",
      "Training Epoch 12  26.6% | batch:        25 of        94\t|\tloss: 1239.2\n",
      "Training Epoch 12  27.7% | batch:        26 of        94\t|\tloss: 3115.98\n",
      "Training Epoch 12  28.7% | batch:        27 of        94\t|\tloss: 1480.02\n",
      "Training Epoch 12  29.8% | batch:        28 of        94\t|\tloss: 6190.29\n",
      "Training Epoch 12  30.9% | batch:        29 of        94\t|\tloss: 1582.8\n",
      "Training Epoch 12  31.9% | batch:        30 of        94\t|\tloss: 1287.77\n",
      "Training Epoch 12  33.0% | batch:        31 of        94\t|\tloss: 3545.85\n",
      "Training Epoch 12  34.0% | batch:        32 of        94\t|\tloss: 1599.13\n",
      "Training Epoch 12  35.1% | batch:        33 of        94\t|\tloss: 2527.1\n",
      "Training Epoch 12  36.2% | batch:        34 of        94\t|\tloss: 2208.31\n",
      "Training Epoch 12  37.2% | batch:        35 of        94\t|\tloss: 1903.11\n",
      "Training Epoch 12  38.3% | batch:        36 of        94\t|\tloss: 2309.67\n",
      "Training Epoch 12  39.4% | batch:        37 of        94\t|\tloss: 2649.95\n",
      "Training Epoch 12  40.4% | batch:        38 of        94\t|\tloss: 2927.93\n",
      "Training Epoch 12  41.5% | batch:        39 of        94\t|\tloss: 2724.58\n",
      "Training Epoch 12  42.6% | batch:        40 of        94\t|\tloss: 1672.84\n",
      "Training Epoch 12  43.6% | batch:        41 of        94\t|\tloss: 1548.83\n",
      "Training Epoch 12  44.7% | batch:        42 of        94\t|\tloss: 3590.2\n",
      "Training Epoch 12  45.7% | batch:        43 of        94\t|\tloss: 1688.26\n",
      "Training Epoch 12  46.8% | batch:        44 of        94\t|\tloss: 1597.18\n",
      "Training Epoch 12  47.9% | batch:        45 of        94\t|\tloss: 2251.08\n",
      "Training Epoch 12  48.9% | batch:        46 of        94\t|\tloss: 1511.58\n",
      "Training Epoch 12  50.0% | batch:        47 of        94\t|\tloss: 2629.09\n",
      "Training Epoch 12  51.1% | batch:        48 of        94\t|\tloss: 1276.31\n",
      "Training Epoch 12  52.1% | batch:        49 of        94\t|\tloss: 1850.11\n",
      "Training Epoch 12  53.2% | batch:        50 of        94\t|\tloss: 1174.47\n",
      "Training Epoch 12  54.3% | batch:        51 of        94\t|\tloss: 1270.11\n",
      "Training Epoch 12  55.3% | batch:        52 of        94\t|\tloss: 2845.23\n",
      "Training Epoch 12  56.4% | batch:        53 of        94\t|\tloss: 1496.5\n",
      "Training Epoch 12  57.4% | batch:        54 of        94\t|\tloss: 1575.41\n",
      "Training Epoch 12  58.5% | batch:        55 of        94\t|\tloss: 2089.55\n",
      "Training Epoch 12  59.6% | batch:        56 of        94\t|\tloss: 1257.04\n",
      "Training Epoch 12  60.6% | batch:        57 of        94\t|\tloss: 1724.99\n",
      "Training Epoch 12  61.7% | batch:        58 of        94\t|\tloss: 3084.57\n",
      "Training Epoch 12  62.8% | batch:        59 of        94\t|\tloss: 1634.88\n",
      "Training Epoch 12  63.8% | batch:        60 of        94\t|\tloss: 2083.73\n",
      "Training Epoch 12  64.9% | batch:        61 of        94\t|\tloss: 2281.59\n",
      "Training Epoch 12  66.0% | batch:        62 of        94\t|\tloss: 3406.6\n",
      "Training Epoch 12  67.0% | batch:        63 of        94\t|\tloss: 3972.41\n",
      "Training Epoch 12  68.1% | batch:        64 of        94\t|\tloss: 1310.12\n",
      "Training Epoch 12  69.1% | batch:        65 of        94\t|\tloss: 1236.29\n",
      "Training Epoch 12  70.2% | batch:        66 of        94\t|\tloss: 1956.31\n",
      "Training Epoch 12  71.3% | batch:        67 of        94\t|\tloss: 2436.7\n",
      "Training Epoch 12  72.3% | batch:        68 of        94\t|\tloss: 2610.8\n",
      "Training Epoch 12  73.4% | batch:        69 of        94\t|\tloss: 2082.97\n",
      "Training Epoch 12  74.5% | batch:        70 of        94\t|\tloss: 1623.21\n",
      "Training Epoch 12  75.5% | batch:        71 of        94\t|\tloss: 2510.31\n",
      "Training Epoch 12  76.6% | batch:        72 of        94\t|\tloss: 2049.94\n",
      "Training Epoch 12  77.7% | batch:        73 of        94\t|\tloss: 1980.9\n",
      "Training Epoch 12  78.7% | batch:        74 of        94\t|\tloss: 2079.51\n",
      "Training Epoch 12  79.8% | batch:        75 of        94\t|\tloss: 1952.02\n",
      "Training Epoch 12  80.9% | batch:        76 of        94\t|\tloss: 2762.66\n",
      "Training Epoch 12  81.9% | batch:        77 of        94\t|\tloss: 1183.6\n",
      "Training Epoch 12  83.0% | batch:        78 of        94\t|\tloss: 2157.34\n",
      "Training Epoch 12  84.0% | batch:        79 of        94\t|\tloss: 1310.09\n",
      "Training Epoch 12  85.1% | batch:        80 of        94\t|\tloss: 1924.11\n",
      "Training Epoch 12  86.2% | batch:        81 of        94\t|\tloss: 1567.49\n",
      "Training Epoch 12  87.2% | batch:        82 of        94\t|\tloss: 1704.84\n",
      "Training Epoch 12  88.3% | batch:        83 of        94\t|\tloss: 1360.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:15,723 | INFO : Epoch 12 Training Summary: epoch: 12.000000 | loss: 2113.725252 | \n",
      "2023-05-04 16:59:15,724 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8049404621124268 seconds\n",
      "\n",
      "2023-05-04 16:59:15,725 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7832395831743877 seconds\n",
      "2023-05-04 16:59:15,725 | INFO : Avg batch train. time: 0.018970633863557317 seconds\n",
      "2023-05-04 16:59:15,726 | INFO : Avg sample train. time: 0.0001496257411624759 seconds\n",
      "2023-05-04 16:59:15,726 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 12  89.4% | batch:        84 of        94\t|\tloss: 1467.65\n",
      "Training Epoch 12  90.4% | batch:        85 of        94\t|\tloss: 2047.56\n",
      "Training Epoch 12  91.5% | batch:        86 of        94\t|\tloss: 1521.13\n",
      "Training Epoch 12  92.6% | batch:        87 of        94\t|\tloss: 1775.33\n",
      "Training Epoch 12  93.6% | batch:        88 of        94\t|\tloss: 1382.44\n",
      "Training Epoch 12  94.7% | batch:        89 of        94\t|\tloss: 2060.22\n",
      "Training Epoch 12  95.7% | batch:        90 of        94\t|\tloss: 1854.65\n",
      "Training Epoch 12  96.8% | batch:        91 of        94\t|\tloss: 2465.72\n",
      "Training Epoch 12  97.9% | batch:        92 of        94\t|\tloss: 1792.81\n",
      "Training Epoch 12  98.9% | batch:        93 of        94\t|\tloss: 1210.51\n",
      "\n",
      "Evaluating Epoch 12   0.0% | batch:         0 of        40\t|\tloss: 7069.69\n",
      "Evaluating Epoch 12   2.5% | batch:         1 of        40\t|\tloss: 968.068\n",
      "Evaluating Epoch 12   5.0% | batch:         2 of        40\t|\tloss: 2820.74\n",
      "Evaluating Epoch 12   7.5% | batch:         3 of        40\t|\tloss: 7116.78\n",
      "Evaluating Epoch 12  10.0% | batch:         4 of        40\t|\tloss: 1719.6\n",
      "Evaluating Epoch 12  12.5% | batch:         5 of        40\t|\tloss: 1634.64\n",
      "Evaluating Epoch 12  15.0% | batch:         6 of        40\t|\tloss: 7433.33\n",
      "Evaluating Epoch 12  17.5% | batch:         7 of        40\t|\tloss: 2476.91\n",
      "Evaluating Epoch 12  20.0% | batch:         8 of        40\t|\tloss: 2513.25\n",
      "Evaluating Epoch 12  22.5% | batch:         9 of        40\t|\tloss: 1776.34\n",
      "Evaluating Epoch 12  25.0% | batch:        10 of        40\t|\tloss: 4732.35\n",
      "Evaluating Epoch 12  27.5% | batch:        11 of        40\t|\tloss: 1606.15\n",
      "Evaluating Epoch 12  30.0% | batch:        12 of        40\t|\tloss: 8302.23\n",
      "Evaluating Epoch 12  32.5% | batch:        13 of        40\t|\tloss: 3070.99\n",
      "Evaluating Epoch 12  35.0% | batch:        14 of        40\t|\tloss: 1803.72\n",
      "Evaluating Epoch 12  37.5% | batch:        15 of        40\t|\tloss: 3803.97\n",
      "Evaluating Epoch 12  40.0% | batch:        16 of        40\t|\tloss: 4957.38\n",
      "Evaluating Epoch 12  42.5% | batch:        17 of        40\t|\tloss: 2136.66\n",
      "Evaluating Epoch 12  45.0% | batch:        18 of        40\t|\tloss: 2404.81\n",
      "Evaluating Epoch 12  47.5% | batch:        19 of        40\t|\tloss: 5169.71\n",
      "Evaluating Epoch 12  50.0% | batch:        20 of        40\t|\tloss: 4544.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:16,178 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45076560974121094 seconds\n",
      "\n",
      "2023-05-04 16:59:16,179 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5460204231668506 seconds\n",
      "2023-05-04 16:59:16,179 | INFO : Avg batch val. time: 0.013650510579171266 seconds\n",
      "2023-05-04 16:59:16,180 | INFO : Avg sample val. time: 0.00010816569397124616 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 12  52.5% | batch:        21 of        40\t|\tloss: 1003.91\n",
      "Evaluating Epoch 12  55.0% | batch:        22 of        40\t|\tloss: 3309.43\n",
      "Evaluating Epoch 12  57.5% | batch:        23 of        40\t|\tloss: 2681.32\n",
      "Evaluating Epoch 12  60.0% | batch:        24 of        40\t|\tloss: 1415.43\n",
      "Evaluating Epoch 12  62.5% | batch:        25 of        40\t|\tloss: 3820.73\n",
      "Evaluating Epoch 12  65.0% | batch:        26 of        40\t|\tloss: 10341.5\n",
      "Evaluating Epoch 12  67.5% | batch:        27 of        40\t|\tloss: 2620.48\n",
      "Evaluating Epoch 12  70.0% | batch:        28 of        40\t|\tloss: 2082.21\n",
      "Evaluating Epoch 12  72.5% | batch:        29 of        40\t|\tloss: 9011.97\n",
      "Evaluating Epoch 12  75.0% | batch:        30 of        40\t|\tloss: 1561.22\n",
      "Evaluating Epoch 12  77.5% | batch:        31 of        40\t|\tloss: 2089.79\n",
      "Evaluating Epoch 12  80.0% | batch:        32 of        40\t|\tloss: 7823.5\n",
      "Evaluating Epoch 12  82.5% | batch:        33 of        40\t|\tloss: 6170.94\n",
      "Evaluating Epoch 12  85.0% | batch:        34 of        40\t|\tloss: 1069.96\n",
      "Evaluating Epoch 12  87.5% | batch:        35 of        40\t|\tloss: 5315.89\n",
      "Evaluating Epoch 12  90.0% | batch:        36 of        40\t|\tloss: 6477.84\n",
      "Evaluating Epoch 12  92.5% | batch:        37 of        40\t|\tloss: 2283.88\n",
      "Evaluating Epoch 12  95.0% | batch:        38 of        40\t|\tloss: 4058.65\n",
      "Evaluating Epoch 12  97.5% | batch:        39 of        40\t|\tloss: 11826.8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:16,181 | INFO : Epoch 12 Validation Summary: epoch: 12.000000 | loss: 3965.129589 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 13   0.0% | batch:         0 of        94\t|\tloss: 2616.9\n",
      "Training Epoch 13   1.1% | batch:         1 of        94\t|\tloss: 1517.91\n",
      "Training Epoch 13   2.1% | batch:         2 of        94\t|\tloss: 2289.48\n",
      "Training Epoch 13   3.2% | batch:         3 of        94\t|\tloss: 1522.22\n",
      "Training Epoch 13   4.3% | batch:         4 of        94\t|\tloss: 2501.49\n",
      "Training Epoch 13   5.3% | batch:         5 of        94\t|\tloss: 3424.76\n",
      "Training Epoch 13   6.4% | batch:         6 of        94\t|\tloss: 1559.3\n",
      "Training Epoch 13   7.4% | batch:         7 of        94\t|\tloss: 2081.9\n",
      "Training Epoch 13   8.5% | batch:         8 of        94\t|\tloss: 1501.24\n",
      "Training Epoch 13   9.6% | batch:         9 of        94\t|\tloss: 2129.12\n",
      "Training Epoch 13  10.6% | batch:        10 of        94\t|\tloss: 1517.37\n",
      "Training Epoch 13  11.7% | batch:        11 of        94\t|\tloss: 1595.48\n",
      "Training Epoch 13  12.8% | batch:        12 of        94\t|\tloss: 2159.84\n",
      "Training Epoch 13  13.8% | batch:        13 of        94\t|\tloss: 1716.23\n",
      "Training Epoch 13  14.9% | batch:        14 of        94\t|\tloss: 1580.88\n",
      "Training Epoch 13  16.0% | batch:        15 of        94\t|\tloss: 1373.68\n",
      "Training Epoch 13  17.0% | batch:        16 of        94\t|\tloss: 2647.23\n",
      "Training Epoch 13  18.1% | batch:        17 of        94\t|\tloss: 1932.07\n",
      "Training Epoch 13  19.1% | batch:        18 of        94\t|\tloss: 1629.4\n",
      "Training Epoch 13  20.2% | batch:        19 of        94\t|\tloss: 1900.43\n",
      "Training Epoch 13  21.3% | batch:        20 of        94\t|\tloss: 2399.56\n",
      "Training Epoch 13  22.3% | batch:        21 of        94\t|\tloss: 2015.07\n",
      "Training Epoch 13  23.4% | batch:        22 of        94\t|\tloss: 1193.61\n",
      "Training Epoch 13  24.5% | batch:        23 of        94\t|\tloss: 2518.64\n",
      "Training Epoch 13  25.5% | batch:        24 of        94\t|\tloss: 1597.69\n",
      "Training Epoch 13  26.6% | batch:        25 of        94\t|\tloss: 2076.07\n",
      "Training Epoch 13  27.7% | batch:        26 of        94\t|\tloss: 2446.28\n",
      "Training Epoch 13  28.7% | batch:        27 of        94\t|\tloss: 1667.62\n",
      "Training Epoch 13  29.8% | batch:        28 of        94\t|\tloss: 1876.16\n",
      "Training Epoch 13  30.9% | batch:        29 of        94\t|\tloss: 2809.12\n",
      "Training Epoch 13  31.9% | batch:        30 of        94\t|\tloss: 4124.79\n",
      "Training Epoch 13  33.0% | batch:        31 of        94\t|\tloss: 1739.09\n",
      "Training Epoch 13  34.0% | batch:        32 of        94\t|\tloss: 1519.14\n",
      "Training Epoch 13  35.1% | batch:        33 of        94\t|\tloss: 1402.62\n",
      "Training Epoch 13  36.2% | batch:        34 of        94\t|\tloss: 1760.08\n",
      "Training Epoch 13  37.2% | batch:        35 of        94\t|\tloss: 1576.33\n",
      "Training Epoch 13  38.3% | batch:        36 of        94\t|\tloss: 2506.55\n",
      "Training Epoch 13  39.4% | batch:        37 of        94\t|\tloss: 1466.06\n",
      "Training Epoch 13  40.4% | batch:        38 of        94\t|\tloss: 1650.81\n",
      "Training Epoch 13  41.5% | batch:        39 of        94\t|\tloss: 1558.87\n",
      "Training Epoch 13  42.6% | batch:        40 of        94\t|\tloss: 1564.65\n",
      "Training Epoch 13  43.6% | batch:        41 of        94\t|\tloss: 1942.18\n",
      "Training Epoch 13  44.7% | batch:        42 of        94\t|\tloss: 4853.29\n",
      "Training Epoch 13  45.7% | batch:        43 of        94\t|\tloss: 2656.18\n",
      "Training Epoch 13  46.8% | batch:        44 of        94\t|\tloss: 1929.1\n",
      "Training Epoch 13  47.9% | batch:        45 of        94\t|\tloss: 3457.89\n",
      "Training Epoch 13  48.9% | batch:        46 of        94\t|\tloss: 2529.85\n",
      "Training Epoch 13  50.0% | batch:        47 of        94\t|\tloss: 1612.63\n",
      "Training Epoch 13  51.1% | batch:        48 of        94\t|\tloss: 1569.8\n",
      "Training Epoch 13  52.1% | batch:        49 of        94\t|\tloss: 1760.39\n",
      "Training Epoch 13  53.2% | batch:        50 of        94\t|\tloss: 2836.64\n",
      "Training Epoch 13  54.3% | batch:        51 of        94\t|\tloss: 1899.32\n",
      "Training Epoch 13  55.3% | batch:        52 of        94\t|\tloss: 2033.14\n",
      "Training Epoch 13  56.4% | batch:        53 of        94\t|\tloss: 2673.93\n",
      "Training Epoch 13  57.4% | batch:        54 of        94\t|\tloss: 1320.2\n",
      "Training Epoch 13  58.5% | batch:        55 of        94\t|\tloss: 1646.68\n",
      "Training Epoch 13  59.6% | batch:        56 of        94\t|\tloss: 2269.51\n",
      "Training Epoch 13  60.6% | batch:        57 of        94\t|\tloss: 2931.89\n",
      "Training Epoch 13  61.7% | batch:        58 of        94\t|\tloss: 1894.69\n",
      "Training Epoch 13  62.8% | batch:        59 of        94\t|\tloss: 1611.65\n",
      "Training Epoch 13  63.8% | batch:        60 of        94\t|\tloss: 1935.13\n",
      "Training Epoch 13  64.9% | batch:        61 of        94\t|\tloss: 2036.34\n",
      "Training Epoch 13  66.0% | batch:        62 of        94\t|\tloss: 3807.96\n",
      "Training Epoch 13  67.0% | batch:        63 of        94\t|\tloss: 1581.87\n",
      "Training Epoch 13  68.1% | batch:        64 of        94\t|\tloss: 2293.48\n",
      "Training Epoch 13  69.1% | batch:        65 of        94\t|\tloss: 1355.54\n",
      "Training Epoch 13  70.2% | batch:        66 of        94\t|\tloss: 1495.64\n",
      "Training Epoch 13  71.3% | batch:        67 of        94\t|\tloss: 2475.58\n",
      "Training Epoch 13  72.3% | batch:        68 of        94\t|\tloss: 2090.68\n",
      "Training Epoch 13  73.4% | batch:        69 of        94\t|\tloss: 1779.82\n",
      "Training Epoch 13  74.5% | batch:        70 of        94\t|\tloss: 1727.04\n",
      "Training Epoch 13  75.5% | batch:        71 of        94\t|\tloss: 1598.44\n",
      "Training Epoch 13  76.6% | batch:        72 of        94\t|\tloss: 2401.46\n",
      "Training Epoch 13  77.7% | batch:        73 of        94\t|\tloss: 1810.71\n",
      "Training Epoch 13  78.7% | batch:        74 of        94\t|\tloss: 2634.24\n",
      "Training Epoch 13  79.8% | batch:        75 of        94\t|\tloss: 2809.34\n",
      "Training Epoch 13  80.9% | batch:        76 of        94\t|\tloss: 2047.92\n",
      "Training Epoch 13  81.9% | batch:        77 of        94\t|\tloss: 2042.04\n",
      "Training Epoch 13  83.0% | batch:        78 of        94\t|\tloss: 1678.2\n",
      "Training Epoch 13  84.0% | batch:        79 of        94\t|\tloss: 2181.39\n",
      "Training Epoch 13  85.1% | batch:        80 of        94\t|\tloss: 2792.98\n",
      "Training Epoch 13  86.2% | batch:        81 of        94\t|\tloss: 1416.24\n",
      "Training Epoch 13  87.2% | batch:        82 of        94\t|\tloss: 2603.71\n",
      "Training Epoch 13  88.3% | batch:        83 of        94\t|\tloss: 2124.38\n",
      "Training Epoch 13  89.4% | batch:        84 of        94\t|\tloss: 2161.06\n",
      "Training Epoch 13  90.4% | batch:        85 of        94\t|\tloss: 2225.26\n",
      "Training Epoch 13  91.5% | batch:        86 of        94\t|\tloss: 2629.16\n",
      "Training Epoch 13  92.6% | batch:        87 of        94\t|\tloss: 2209.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:18,000 | INFO : Epoch 13 Training Summary: epoch: 13.000000 | loss: 2118.476698 | \n",
      "2023-05-04 16:59:18,001 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7979376316070557 seconds\n",
      "\n",
      "2023-05-04 16:59:18,002 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7843702022845929 seconds\n",
      "2023-05-04 16:59:18,003 | INFO : Avg batch train. time: 0.01898266172643184 seconds\n",
      "2023-05-04 16:59:18,003 | INFO : Avg sample train. time: 0.0001497206076761699 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 13  93.6% | batch:        88 of        94\t|\tloss: 2513.46\n",
      "Training Epoch 13  94.7% | batch:        89 of        94\t|\tloss: 2688.82\n",
      "Training Epoch 13  95.7% | batch:        90 of        94\t|\tloss: 2809.17\n",
      "Training Epoch 13  96.8% | batch:        91 of        94\t|\tloss: 2855.27\n",
      "Training Epoch 13  97.9% | batch:        92 of        94\t|\tloss: 2236.74\n",
      "Training Epoch 13  98.9% | batch:        93 of        94\t|\tloss: 975.636\n",
      "\n",
      "Training Epoch 14   0.0% | batch:         0 of        94\t|\tloss: 2903.43\n",
      "Training Epoch 14   1.1% | batch:         1 of        94\t|\tloss: 2385.22\n",
      "Training Epoch 14   2.1% | batch:         2 of        94\t|\tloss: 1569.39\n",
      "Training Epoch 14   3.2% | batch:         3 of        94\t|\tloss: 1927.22\n",
      "Training Epoch 14   4.3% | batch:         4 of        94\t|\tloss: 2026.18\n",
      "Training Epoch 14   5.3% | batch:         5 of        94\t|\tloss: 1405.2\n",
      "Training Epoch 14   6.4% | batch:         6 of        94\t|\tloss: 2184.7\n",
      "Training Epoch 14   7.4% | batch:         7 of        94\t|\tloss: 1647.82\n",
      "Training Epoch 14   8.5% | batch:         8 of        94\t|\tloss: 1647.26\n",
      "Training Epoch 14   9.6% | batch:         9 of        94\t|\tloss: 1624.61\n",
      "Training Epoch 14  10.6% | batch:        10 of        94\t|\tloss: 3260.88\n",
      "Training Epoch 14  11.7% | batch:        11 of        94\t|\tloss: 1784.9\n",
      "Training Epoch 14  12.8% | batch:        12 of        94\t|\tloss: 1832.24\n",
      "Training Epoch 14  13.8% | batch:        13 of        94\t|\tloss: 2044.08\n",
      "Training Epoch 14  14.9% | batch:        14 of        94\t|\tloss: 1562.9\n",
      "Training Epoch 14  16.0% | batch:        15 of        94\t|\tloss: 2057.52\n",
      "Training Epoch 14  17.0% | batch:        16 of        94\t|\tloss: 4005.18\n",
      "Training Epoch 14  18.1% | batch:        17 of        94\t|\tloss: 1668.57\n",
      "Training Epoch 14  19.1% | batch:        18 of        94\t|\tloss: 3688.52\n",
      "Training Epoch 14  20.2% | batch:        19 of        94\t|\tloss: 1628.17\n",
      "Training Epoch 14  21.3% | batch:        20 of        94\t|\tloss: 1992.83\n",
      "Training Epoch 14  22.3% | batch:        21 of        94\t|\tloss: 1697.15\n",
      "Training Epoch 14  23.4% | batch:        22 of        94\t|\tloss: 1737.5\n",
      "Training Epoch 14  24.5% | batch:        23 of        94\t|\tloss: 2134.44\n",
      "Training Epoch 14  25.5% | batch:        24 of        94\t|\tloss: 1389.62\n",
      "Training Epoch 14  26.6% | batch:        25 of        94\t|\tloss: 3696.08\n",
      "Training Epoch 14  27.7% | batch:        26 of        94\t|\tloss: 1052.62\n",
      "Training Epoch 14  28.7% | batch:        27 of        94\t|\tloss: 3317.32\n",
      "Training Epoch 14  29.8% | batch:        28 of        94\t|\tloss: 2105.73\n",
      "Training Epoch 14  30.9% | batch:        29 of        94\t|\tloss: 2571.25\n",
      "Training Epoch 14  31.9% | batch:        30 of        94\t|\tloss: 2854.39\n",
      "Training Epoch 14  33.0% | batch:        31 of        94\t|\tloss: 1529.03\n",
      "Training Epoch 14  34.0% | batch:        32 of        94\t|\tloss: 1807.11\n",
      "Training Epoch 14  35.1% | batch:        33 of        94\t|\tloss: 1959.16\n",
      "Training Epoch 14  36.2% | batch:        34 of        94\t|\tloss: 2171.07\n",
      "Training Epoch 14  37.2% | batch:        35 of        94\t|\tloss: 2427.09\n",
      "Training Epoch 14  38.3% | batch:        36 of        94\t|\tloss: 2492.9\n",
      "Training Epoch 14  39.4% | batch:        37 of        94\t|\tloss: 1693.74\n",
      "Training Epoch 14  40.4% | batch:        38 of        94\t|\tloss: 2045.43\n",
      "Training Epoch 14  41.5% | batch:        39 of        94\t|\tloss: 1423.26\n",
      "Training Epoch 14  42.6% | batch:        40 of        94\t|\tloss: 1767.02\n",
      "Training Epoch 14  43.6% | batch:        41 of        94\t|\tloss: 4711.64\n",
      "Training Epoch 14  44.7% | batch:        42 of        94\t|\tloss: 1587.26\n",
      "Training Epoch 14  45.7% | batch:        43 of        94\t|\tloss: 1876.82\n",
      "Training Epoch 14  46.8% | batch:        44 of        94\t|\tloss: 1997.99\n",
      "Training Epoch 14  47.9% | batch:        45 of        94\t|\tloss: 1898.04\n",
      "Training Epoch 14  48.9% | batch:        46 of        94\t|\tloss: 1958.09\n",
      "Training Epoch 14  50.0% | batch:        47 of        94\t|\tloss: 2433.77\n",
      "Training Epoch 14  51.1% | batch:        48 of        94\t|\tloss: 2020.15\n",
      "Training Epoch 14  52.1% | batch:        49 of        94\t|\tloss: 2016.26\n",
      "Training Epoch 14  53.2% | batch:        50 of        94\t|\tloss: 2164.22\n",
      "Training Epoch 14  54.3% | batch:        51 of        94\t|\tloss: 2437.65\n",
      "Training Epoch 14  55.3% | batch:        52 of        94\t|\tloss: 2125.65\n",
      "Training Epoch 14  56.4% | batch:        53 of        94\t|\tloss: 1358.57\n",
      "Training Epoch 14  57.4% | batch:        54 of        94\t|\tloss: 1781.28\n",
      "Training Epoch 14  58.5% | batch:        55 of        94\t|\tloss: 1677.99\n",
      "Training Epoch 14  59.6% | batch:        56 of        94\t|\tloss: 1115.07\n",
      "Training Epoch 14  60.6% | batch:        57 of        94\t|\tloss: 2048.51\n",
      "Training Epoch 14  61.7% | batch:        58 of        94\t|\tloss: 2387.39\n",
      "Training Epoch 14  62.8% | batch:        59 of        94\t|\tloss: 2301.93\n",
      "Training Epoch 14  63.8% | batch:        60 of        94\t|\tloss: 1491.48\n",
      "Training Epoch 14  64.9% | batch:        61 of        94\t|\tloss: 1851.18\n",
      "Training Epoch 14  66.0% | batch:        62 of        94\t|\tloss: 1788.59\n",
      "Training Epoch 14  67.0% | batch:        63 of        94\t|\tloss: 1984.63\n",
      "Training Epoch 14  68.1% | batch:        64 of        94\t|\tloss: 1394.26\n",
      "Training Epoch 14  69.1% | batch:        65 of        94\t|\tloss: 1658.6\n",
      "Training Epoch 14  70.2% | batch:        66 of        94\t|\tloss: 2259.66\n",
      "Training Epoch 14  71.3% | batch:        67 of        94\t|\tloss: 1821.14\n",
      "Training Epoch 14  72.3% | batch:        68 of        94\t|\tloss: 1384.59\n",
      "Training Epoch 14  73.4% | batch:        69 of        94\t|\tloss: 1901.64\n",
      "Training Epoch 14  74.5% | batch:        70 of        94\t|\tloss: 1316.99\n",
      "Training Epoch 14  75.5% | batch:        71 of        94\t|\tloss: 1422.19\n",
      "Training Epoch 14  76.6% | batch:        72 of        94\t|\tloss: 1409.75\n",
      "Training Epoch 14  77.7% | batch:        73 of        94\t|\tloss: 1755.9\n",
      "Training Epoch 14  78.7% | batch:        74 of        94\t|\tloss: 2623.77\n",
      "Training Epoch 14  79.8% | batch:        75 of        94\t|\tloss: 1753.43\n",
      "Training Epoch 14  80.9% | batch:        76 of        94\t|\tloss: 2449.74\n",
      "Training Epoch 14  81.9% | batch:        77 of        94\t|\tloss: 1718.36\n",
      "Training Epoch 14  83.0% | batch:        78 of        94\t|\tloss: 1313.31\n",
      "Training Epoch 14  84.0% | batch:        79 of        94\t|\tloss: 2782.35\n",
      "Training Epoch 14  85.1% | batch:        80 of        94\t|\tloss: 1176.01\n",
      "Training Epoch 14  86.2% | batch:        81 of        94\t|\tloss: 1122.36\n",
      "Training Epoch 14  87.2% | batch:        82 of        94\t|\tloss: 2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:19,781 | INFO : Epoch 14 Training Summary: epoch: 14.000000 | loss: 2064.342126 | \n",
      "2023-05-04 16:59:19,782 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7572331428527832 seconds\n",
      "\n",
      "2023-05-04 16:59:19,783 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7824318408966064 seconds\n",
      "2023-05-04 16:59:19,783 | INFO : Avg batch train. time: 0.018962040860602197 seconds\n",
      "2023-05-04 16:59:19,784 | INFO : Avg sample train. time: 0.0001495579661769262 seconds\n",
      "2023-05-04 16:59:19,784 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 14  88.3% | batch:        83 of        94\t|\tloss: 3487.9\n",
      "Training Epoch 14  89.4% | batch:        84 of        94\t|\tloss: 1401.18\n",
      "Training Epoch 14  90.4% | batch:        85 of        94\t|\tloss: 2405.65\n",
      "Training Epoch 14  91.5% | batch:        86 of        94\t|\tloss: 2228.53\n",
      "Training Epoch 14  92.6% | batch:        87 of        94\t|\tloss: 3289.09\n",
      "Training Epoch 14  93.6% | batch:        88 of        94\t|\tloss: 3055.29\n",
      "Training Epoch 14  94.7% | batch:        89 of        94\t|\tloss: 3141.64\n",
      "Training Epoch 14  95.7% | batch:        90 of        94\t|\tloss: 1691.49\n",
      "Training Epoch 14  96.8% | batch:        91 of        94\t|\tloss: 1583.99\n",
      "Training Epoch 14  97.9% | batch:        92 of        94\t|\tloss: 2477.46\n",
      "Training Epoch 14  98.9% | batch:        93 of        94\t|\tloss: 2847.13\n",
      "\n",
      "Evaluating Epoch 14   0.0% | batch:         0 of        40\t|\tloss: 6080.63\n",
      "Evaluating Epoch 14   2.5% | batch:         1 of        40\t|\tloss: 908.966\n",
      "Evaluating Epoch 14   5.0% | batch:         2 of        40\t|\tloss: 3966.83\n",
      "Evaluating Epoch 14   7.5% | batch:         3 of        40\t|\tloss: 5599.54\n",
      "Evaluating Epoch 14  10.0% | batch:         4 of        40\t|\tloss: 1476.58\n",
      "Evaluating Epoch 14  12.5% | batch:         5 of        40\t|\tloss: 1729.13\n",
      "Evaluating Epoch 14  15.0% | batch:         6 of        40\t|\tloss: 7052.2\n",
      "Evaluating Epoch 14  17.5% | batch:         7 of        40\t|\tloss: 2651.45\n",
      "Evaluating Epoch 14  20.0% | batch:         8 of        40\t|\tloss: 2476.53\n",
      "Evaluating Epoch 14  22.5% | batch:         9 of        40\t|\tloss: 2424.83\n",
      "Evaluating Epoch 14  25.0% | batch:        10 of        40\t|\tloss: 3977.57\n",
      "Evaluating Epoch 14  27.5% | batch:        11 of        40\t|\tloss: 1573.69\n",
      "Evaluating Epoch 14  30.0% | batch:        12 of        40\t|\tloss: 5731.68\n",
      "Evaluating Epoch 14  32.5% | batch:        13 of        40\t|\tloss: 2532.75\n",
      "Evaluating Epoch 14  35.0% | batch:        14 of        40\t|\tloss: 1901.5\n",
      "Evaluating Epoch 14  37.5% | batch:        15 of        40\t|\tloss: 3830.28\n",
      "Evaluating Epoch 14  40.0% | batch:        16 of        40\t|\tloss: 3278.26\n",
      "Evaluating Epoch 14  42.5% | batch:        17 of        40\t|\tloss: 2293.87\n",
      "Evaluating Epoch 14  45.0% | batch:        18 of        40\t|\tloss: 2235.73\n",
      "Evaluating Epoch 14  47.5% | batch:        19 of        40\t|\tloss: 3228.68\n",
      "Evaluating Epoch 14  50.0% | batch:        20 of        40\t|\tloss: 3535.68\n",
      "Evaluating Epoch 14  52.5% | batch:        21 of        40\t|\tloss: 1024.87\n",
      "Evaluating Epoch 14  55.0% | batch:        22 of        40\t|\tloss: 3766.73\n",
      "Evaluating Epoch 14  57.5% | batch:        23 of        40\t|\tloss: 2480.65\n",
      "Evaluating Epoch 14  60.0% | batch:        24 of        40\t|\tloss: 1477.26\n",
      "Evaluating Epoch 14  62.5% | batch:        25 of        40\t|\tloss: 3290.44\n",
      "Evaluating Epoch 14  65.0% | batch:        26 of        40\t|\tloss: 6602.09\n",
      "Evaluating Epoch 14  67.5% | batch:        27 of        40\t|\tloss: 2843.29\n",
      "Evaluating Epoch 14  70.0% | batch:        28 of        40\t|\tloss: 2058.71\n",
      "Evaluating Epoch 14  72.5% | batch:        29 of        40\t|\tloss: 6740.3\n",
      "Evaluating Epoch 14  75.0% | batch:        30 of        40\t|\tloss: 1658.87\n",
      "Evaluating Epoch 14  77.5% | batch:        31 of        40\t|\tloss: 2063.03\n",
      "Evaluating Epoch 14  80.0% | batch:        32 of        40\t|\tloss: 7902.18\n",
      "Evaluating Epoch 14  82.5% | batch:        33 of        40\t|\tloss: 5247.7\n",
      "Evaluating Epoch 14  85.0% | batch:        34 of        40\t|\tloss: 1219.16\n",
      "Evaluating Epoch 14  87.5% | batch:        35 of        40\t|\tloss: 4947.68\n",
      "Evaluating Epoch 14  90.0% | batch:        36 of        40\t|\tloss: 4158.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:20,232 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4466104507446289 seconds\n",
      "\n",
      "2023-05-04 16:59:20,232 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5454356586231904 seconds\n",
      "2023-05-04 16:59:20,233 | INFO : Avg batch val. time: 0.013635891465579761 seconds\n",
      "2023-05-04 16:59:20,233 | INFO : Avg sample val. time: 0.00010804985313454644 seconds\n",
      "2023-05-04 16:59:20,234 | INFO : Epoch 14 Validation Summary: epoch: 14.000000 | loss: 3424.168099 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 14  92.5% | batch:        37 of        40\t|\tloss: 2406.94\n",
      "Evaluating Epoch 14  95.0% | batch:        38 of        40\t|\tloss: 3649.32\n",
      "Evaluating Epoch 14  97.5% | batch:        39 of        40\t|\tloss: 6895.84\n",
      "\n",
      "Training Epoch 15   0.0% | batch:         0 of        94\t|\tloss: 1467.87\n",
      "Training Epoch 15   1.1% | batch:         1 of        94\t|\tloss: 3705.46\n",
      "Training Epoch 15   2.1% | batch:         2 of        94\t|\tloss: 1720.98\n",
      "Training Epoch 15   3.2% | batch:         3 of        94\t|\tloss: 2129.1\n",
      "Training Epoch 15   4.3% | batch:         4 of        94\t|\tloss: 2290.79\n",
      "Training Epoch 15   5.3% | batch:         5 of        94\t|\tloss: 1650.34\n",
      "Training Epoch 15   6.4% | batch:         6 of        94\t|\tloss: 1893.35\n",
      "Training Epoch 15   7.4% | batch:         7 of        94\t|\tloss: 1854.82\n",
      "Training Epoch 15   8.5% | batch:         8 of        94\t|\tloss: 1240.09\n",
      "Training Epoch 15   9.6% | batch:         9 of        94\t|\tloss: 2003.76\n",
      "Training Epoch 15  10.6% | batch:        10 of        94\t|\tloss: 4109.29\n",
      "Training Epoch 15  11.7% | batch:        11 of        94\t|\tloss: 1428.39\n",
      "Training Epoch 15  12.8% | batch:        12 of        94\t|\tloss: 1856.83\n",
      "Training Epoch 15  13.8% | batch:        13 of        94\t|\tloss: 1768.26\n",
      "Training Epoch 15  14.9% | batch:        14 of        94\t|\tloss: 1368.48\n",
      "Training Epoch 15  16.0% | batch:        15 of        94\t|\tloss: 1181.91\n",
      "Training Epoch 15  17.0% | batch:        16 of        94\t|\tloss: 1743.09\n",
      "Training Epoch 15  18.1% | batch:        17 of        94\t|\tloss: 1438.51\n",
      "Training Epoch 15  19.1% | batch:        18 of        94\t|\tloss: 1392.45\n",
      "Training Epoch 15  20.2% | batch:        19 of        94\t|\tloss: 1748.69\n",
      "Training Epoch 15  21.3% | batch:        20 of        94\t|\tloss: 1289.82\n",
      "Training Epoch 15  22.3% | batch:        21 of        94\t|\tloss: 2904.66\n",
      "Training Epoch 15  23.4% | batch:        22 of        94\t|\tloss: 2235.22\n",
      "Training Epoch 15  24.5% | batch:        23 of        94\t|\tloss: 2420.68\n",
      "Training Epoch 15  25.5% | batch:        24 of        94\t|\tloss: 1237\n",
      "Training Epoch 15  26.6% | batch:        25 of        94\t|\tloss: 1556.76\n",
      "Training Epoch 15  27.7% | batch:        26 of        94\t|\tloss: 2139.53\n",
      "Training Epoch 15  28.7% | batch:        27 of        94\t|\tloss: 2180.35\n",
      "Training Epoch 15  29.8% | batch:        28 of        94\t|\tloss: 4121.97\n",
      "Training Epoch 15  30.9% | batch:        29 of        94\t|\tloss: 1540.14\n",
      "Training Epoch 15  31.9% | batch:        30 of        94\t|\tloss: 1497.4\n",
      "Training Epoch 15  33.0% | batch:        31 of        94\t|\tloss: 3358.98\n",
      "Training Epoch 15  34.0% | batch:        32 of        94\t|\tloss: 1424.03\n",
      "Training Epoch 15  35.1% | batch:        33 of        94\t|\tloss: 2055.6\n",
      "Training Epoch 15  36.2% | batch:        34 of        94\t|\tloss: 1489.76\n",
      "Training Epoch 15  37.2% | batch:        35 of        94\t|\tloss: 1593.11\n",
      "Training Epoch 15  38.3% | batch:        36 of        94\t|\tloss: 3279.24\n",
      "Training Epoch 15  39.4% | batch:        37 of        94\t|\tloss: 2264.45\n",
      "Training Epoch 15  40.4% | batch:        38 of        94\t|\tloss: 1689.15\n",
      "Training Epoch 15  41.5% | batch:        39 of        94\t|\tloss: 1485.19\n",
      "Training Epoch 15  42.6% | batch:        40 of        94\t|\tloss: 1365.55\n",
      "Training Epoch 15  43.6% | batch:        41 of        94\t|\tloss: 2150.71\n",
      "Training Epoch 15  44.7% | batch:        42 of        94\t|\tloss: 1352.86\n",
      "Training Epoch 15  45.7% | batch:        43 of        94\t|\tloss: 1471.03\n",
      "Training Epoch 15  46.8% | batch:        44 of        94\t|\tloss: 2461.61\n",
      "Training Epoch 15  47.9% | batch:        45 of        94\t|\tloss: 1499.18\n",
      "Training Epoch 15  48.9% | batch:        46 of        94\t|\tloss: 1695.92\n",
      "Training Epoch 15  50.0% | batch:        47 of        94\t|\tloss: 1436.28\n",
      "Training Epoch 15  51.1% | batch:        48 of        94\t|\tloss: 1156.64\n",
      "Training Epoch 15  52.1% | batch:        49 of        94\t|\tloss: 1254.16\n",
      "Training Epoch 15  53.2% | batch:        50 of        94\t|\tloss: 2141.65\n",
      "Training Epoch 15  54.3% | batch:        51 of        94\t|\tloss: 2489.68\n",
      "Training Epoch 15  55.3% | batch:        52 of        94\t|\tloss: 1915.32\n",
      "Training Epoch 15  56.4% | batch:        53 of        94\t|\tloss: 2886.48\n",
      "Training Epoch 15  57.4% | batch:        54 of        94\t|\tloss: 3990.8\n",
      "Training Epoch 15  58.5% | batch:        55 of        94\t|\tloss: 1554.32\n",
      "Training Epoch 15  59.6% | batch:        56 of        94\t|\tloss: 4323.55\n",
      "Training Epoch 15  60.6% | batch:        57 of        94\t|\tloss: 2808.54\n",
      "Training Epoch 15  61.7% | batch:        58 of        94\t|\tloss: 2062.21\n",
      "Training Epoch 15  62.8% | batch:        59 of        94\t|\tloss: 1766.15\n",
      "Training Epoch 15  63.8% | batch:        60 of        94\t|\tloss: 2364.53\n",
      "Training Epoch 15  64.9% | batch:        61 of        94\t|\tloss: 1542.02\n",
      "Training Epoch 15  66.0% | batch:        62 of        94\t|\tloss: 1760.49\n",
      "Training Epoch 15  67.0% | batch:        63 of        94\t|\tloss: 2324.32\n",
      "Training Epoch 15  68.1% | batch:        64 of        94\t|\tloss: 1455.69\n",
      "Training Epoch 15  69.1% | batch:        65 of        94\t|\tloss: 1524.53\n",
      "Training Epoch 15  70.2% | batch:        66 of        94\t|\tloss: 1553.38\n",
      "Training Epoch 15  71.3% | batch:        67 of        94\t|\tloss: 1157.88\n",
      "Training Epoch 15  72.3% | batch:        68 of        94\t|\tloss: 1558.93\n",
      "Training Epoch 15  73.4% | batch:        69 of        94\t|\tloss: 2200.56\n",
      "Training Epoch 15  74.5% | batch:        70 of        94\t|\tloss: 1737.81\n",
      "Training Epoch 15  75.5% | batch:        71 of        94\t|\tloss: 1997.19\n",
      "Training Epoch 15  76.6% | batch:        72 of        94\t|\tloss: 1363.15\n",
      "Training Epoch 15  77.7% | batch:        73 of        94\t|\tloss: 2202.33\n",
      "Training Epoch 15  78.7% | batch:        74 of        94\t|\tloss: 1744.18\n",
      "Training Epoch 15  79.8% | batch:        75 of        94\t|\tloss: 2429.08\n",
      "Training Epoch 15  80.9% | batch:        76 of        94\t|\tloss: 1987.51\n",
      "Training Epoch 15  81.9% | batch:        77 of        94\t|\tloss: 1683.16\n",
      "Training Epoch 15  83.0% | batch:        78 of        94\t|\tloss: 1620.74\n",
      "Training Epoch 15  84.0% | batch:        79 of        94\t|\tloss: 1464.66\n",
      "Training Epoch 15  85.1% | batch:        80 of        94\t|\tloss: 2401.37\n",
      "Training Epoch 15  86.2% | batch:        81 of        94\t|\tloss: 1145.74\n",
      "Training Epoch 15  87.2% | batch:        82 of        94\t|\tloss: 2578.88\n",
      "Training Epoch 15  88.3% | batch:        83 of        94\t|\tloss: 1720.96\n",
      "Training Epoch 15  89.4% | batch:        84 of        94\t|\tloss: 1464.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:22,061 | INFO : Epoch 15 Training Summary: epoch: 15.000000 | loss: 1978.707004 | \n",
      "2023-05-04 16:59:22,062 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7958006858825684 seconds\n",
      "\n",
      "2023-05-04 16:59:22,062 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.783323097229004 seconds\n",
      "2023-05-04 16:59:22,063 | INFO : Avg batch train. time: 0.01897152231094685 seconds\n",
      "2023-05-04 16:59:22,064 | INFO : Avg sample train. time: 0.0001496327485508478 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 15  90.4% | batch:        85 of        94\t|\tloss: 3177.37\n",
      "Training Epoch 15  91.5% | batch:        86 of        94\t|\tloss: 3491.39\n",
      "Training Epoch 15  92.6% | batch:        87 of        94\t|\tloss: 1829.63\n",
      "Training Epoch 15  93.6% | batch:        88 of        94\t|\tloss: 1466.72\n",
      "Training Epoch 15  94.7% | batch:        89 of        94\t|\tloss: 2506.26\n",
      "Training Epoch 15  95.7% | batch:        90 of        94\t|\tloss: 1189.2\n",
      "Training Epoch 15  96.8% | batch:        91 of        94\t|\tloss: 1749.45\n",
      "Training Epoch 15  97.9% | batch:        92 of        94\t|\tloss: 2127.96\n",
      "Training Epoch 15  98.9% | batch:        93 of        94\t|\tloss: 1613.38\n",
      "\n",
      "Training Epoch 16   0.0% | batch:         0 of        94\t|\tloss: 1320.4\n",
      "Training Epoch 16   1.1% | batch:         1 of        94\t|\tloss: 1576.4\n",
      "Training Epoch 16   2.1% | batch:         2 of        94\t|\tloss: 1162.21\n",
      "Training Epoch 16   3.2% | batch:         3 of        94\t|\tloss: 1213.16\n",
      "Training Epoch 16   4.3% | batch:         4 of        94\t|\tloss: 1806.75\n",
      "Training Epoch 16   5.3% | batch:         5 of        94\t|\tloss: 1776.33\n",
      "Training Epoch 16   6.4% | batch:         6 of        94\t|\tloss: 1478.74\n",
      "Training Epoch 16   7.4% | batch:         7 of        94\t|\tloss: 2324.08\n",
      "Training Epoch 16   8.5% | batch:         8 of        94\t|\tloss: 3241.74\n",
      "Training Epoch 16   9.6% | batch:         9 of        94\t|\tloss: 1422.83\n",
      "Training Epoch 16  10.6% | batch:        10 of        94\t|\tloss: 1230.47\n",
      "Training Epoch 16  11.7% | batch:        11 of        94\t|\tloss: 1439.48\n",
      "Training Epoch 16  12.8% | batch:        12 of        94\t|\tloss: 1585.33\n",
      "Training Epoch 16  13.8% | batch:        13 of        94\t|\tloss: 1261.29\n",
      "Training Epoch 16  14.9% | batch:        14 of        94\t|\tloss: 2291.31\n",
      "Training Epoch 16  16.0% | batch:        15 of        94\t|\tloss: 2176.41\n",
      "Training Epoch 16  17.0% | batch:        16 of        94\t|\tloss: 1623.73\n",
      "Training Epoch 16  18.1% | batch:        17 of        94\t|\tloss: 2107.54\n",
      "Training Epoch 16  19.1% | batch:        18 of        94\t|\tloss: 1790.66\n",
      "Training Epoch 16  20.2% | batch:        19 of        94\t|\tloss: 1225.98\n",
      "Training Epoch 16  21.3% | batch:        20 of        94\t|\tloss: 1311.58\n",
      "Training Epoch 16  22.3% | batch:        21 of        94\t|\tloss: 4237.33\n",
      "Training Epoch 16  23.4% | batch:        22 of        94\t|\tloss: 1345.76\n",
      "Training Epoch 16  24.5% | batch:        23 of        94\t|\tloss: 1747.71\n",
      "Training Epoch 16  25.5% | batch:        24 of        94\t|\tloss: 2346.34\n",
      "Training Epoch 16  26.6% | batch:        25 of        94\t|\tloss: 1310.74\n",
      "Training Epoch 16  27.7% | batch:        26 of        94\t|\tloss: 1733.43\n",
      "Training Epoch 16  28.7% | batch:        27 of        94\t|\tloss: 1264.62\n",
      "Training Epoch 16  29.8% | batch:        28 of        94\t|\tloss: 2234.6\n",
      "Training Epoch 16  30.9% | batch:        29 of        94\t|\tloss: 3035.91\n",
      "Training Epoch 16  31.9% | batch:        30 of        94\t|\tloss: 1963.52\n",
      "Training Epoch 16  33.0% | batch:        31 of        94\t|\tloss: 1783.22\n",
      "Training Epoch 16  34.0% | batch:        32 of        94\t|\tloss: 1218.72\n",
      "Training Epoch 16  35.1% | batch:        33 of        94\t|\tloss: 2195.31\n",
      "Training Epoch 16  36.2% | batch:        34 of        94\t|\tloss: 1601.24\n",
      "Training Epoch 16  37.2% | batch:        35 of        94\t|\tloss: 2191.15\n",
      "Training Epoch 16  38.3% | batch:        36 of        94\t|\tloss: 1997.66\n",
      "Training Epoch 16  39.4% | batch:        37 of        94\t|\tloss: 1364.37\n",
      "Training Epoch 16  40.4% | batch:        38 of        94\t|\tloss: 1601.64\n",
      "Training Epoch 16  41.5% | batch:        39 of        94\t|\tloss: 1864.79\n",
      "Training Epoch 16  42.6% | batch:        40 of        94\t|\tloss: 1286.24\n",
      "Training Epoch 16  43.6% | batch:        41 of        94\t|\tloss: 1679.54\n",
      "Training Epoch 16  44.7% | batch:        42 of        94\t|\tloss: 1628.35\n",
      "Training Epoch 16  45.7% | batch:        43 of        94\t|\tloss: 1855.96\n",
      "Training Epoch 16  46.8% | batch:        44 of        94\t|\tloss: 1666.94\n",
      "Training Epoch 16  47.9% | batch:        45 of        94\t|\tloss: 1516.74\n",
      "Training Epoch 16  48.9% | batch:        46 of        94\t|\tloss: 1835.16\n",
      "Training Epoch 16  50.0% | batch:        47 of        94\t|\tloss: 1704.97\n",
      "Training Epoch 16  51.1% | batch:        48 of        94\t|\tloss: 3852.53\n",
      "Training Epoch 16  52.1% | batch:        49 of        94\t|\tloss: 1682.6\n",
      "Training Epoch 16  53.2% | batch:        50 of        94\t|\tloss: 1994.42\n",
      "Training Epoch 16  54.3% | batch:        51 of        94\t|\tloss: 1752.08\n",
      "Training Epoch 16  55.3% | batch:        52 of        94\t|\tloss: 1385.4\n",
      "Training Epoch 16  56.4% | batch:        53 of        94\t|\tloss: 1866.85\n",
      "Training Epoch 16  57.4% | batch:        54 of        94\t|\tloss: 1883.47\n",
      "Training Epoch 16  58.5% | batch:        55 of        94\t|\tloss: 1563.47\n",
      "Training Epoch 16  59.6% | batch:        56 of        94\t|\tloss: 1100.83\n",
      "Training Epoch 16  60.6% | batch:        57 of        94\t|\tloss: 1831.34\n",
      "Training Epoch 16  61.7% | batch:        58 of        94\t|\tloss: 2217.78\n",
      "Training Epoch 16  62.8% | batch:        59 of        94\t|\tloss: 2770.41\n",
      "Training Epoch 16  63.8% | batch:        60 of        94\t|\tloss: 1768.82\n",
      "Training Epoch 16  64.9% | batch:        61 of        94\t|\tloss: 1727.31\n",
      "Training Epoch 16  66.0% | batch:        62 of        94\t|\tloss: 2019.09\n",
      "Training Epoch 16  67.0% | batch:        63 of        94\t|\tloss: 1522.83\n",
      "Training Epoch 16  68.1% | batch:        64 of        94\t|\tloss: 1372.34\n",
      "Training Epoch 16  69.1% | batch:        65 of        94\t|\tloss: 1292.49\n",
      "Training Epoch 16  70.2% | batch:        66 of        94\t|\tloss: 1517.82\n",
      "Training Epoch 16  71.3% | batch:        67 of        94\t|\tloss: 1791.72\n",
      "Training Epoch 16  72.3% | batch:        68 of        94\t|\tloss: 3009.7\n",
      "Training Epoch 16  73.4% | batch:        69 of        94\t|\tloss: 2354.53\n",
      "Training Epoch 16  74.5% | batch:        70 of        94\t|\tloss: 2043.14\n",
      "Training Epoch 16  75.5% | batch:        71 of        94\t|\tloss: 2474.54\n",
      "Training Epoch 16  76.6% | batch:        72 of        94\t|\tloss: 2033.56\n",
      "Training Epoch 16  77.7% | batch:        73 of        94\t|\tloss: 1563.41\n",
      "Training Epoch 16  78.7% | batch:        74 of        94\t|\tloss: 2369.09\n",
      "Training Epoch 16  79.8% | batch:        75 of        94\t|\tloss: 4316.91\n",
      "Training Epoch 16  80.9% | batch:        76 of        94\t|\tloss: 2502.82\n",
      "Training Epoch 16  81.9% | batch:        77 of        94\t|\tloss: 1639.07\n",
      "Training Epoch 16  83.0% | batch:        78 of        94\t|\tloss: 1638.66\n",
      "Training Epoch 16  84.0% | batch:        79 of        94\t|\tloss: 5042.55\n",
      "Training Epoch 16  85.1% | batch:        80 of        94\t|\tloss: 1721.31\n",
      "Training Epoch 16  86.2% | batch:        81 of        94\t|\tloss: 1234.08\n",
      "Training Epoch 16  87.2% | batch:        82 of        94\t|\tloss: 2113.24\n",
      "Training Epoch 16  88.3% | batch:        83 of        94\t|\tloss: 1498.31\n",
      "Training Epoch 16  89.4% | batch:        84 of        94\t|\tloss: 1428.86\n",
      "Training Epoch 16  90.4% | batch:        85 of        94\t|\tloss: 1337.35\n",
      "Training Epoch 16  91.5% | batch:        86 of        94\t|\tloss: 2091.58\n",
      "Training Epoch 16  92.6% | batch:        87 of        94\t|\tloss: 1754.01\n",
      "Training Epoch 16  93.6% | batch:        88 of        94\t|\tloss: 3203.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:23,874 | INFO : Epoch 16 Training Summary: epoch: 16.000000 | loss: 1897.015984 | \n",
      "2023-05-04 16:59:23,875 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7901179790496826 seconds\n",
      "\n",
      "2023-05-04 16:59:23,876 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7837477773427963 seconds\n",
      "2023-05-04 16:59:23,876 | INFO : Avg batch train. time: 0.018976040184497833 seconds\n",
      "2023-05-04 16:59:23,877 | INFO : Avg sample train. time: 0.00014966838205594866 seconds\n",
      "2023-05-04 16:59:23,877 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 16  94.7% | batch:        89 of        94\t|\tloss: 2020.3\n",
      "Training Epoch 16  95.7% | batch:        90 of        94\t|\tloss: 1626.38\n",
      "Training Epoch 16  96.8% | batch:        91 of        94\t|\tloss: 1403.36\n",
      "Training Epoch 16  97.9% | batch:        92 of        94\t|\tloss: 1360.31\n",
      "Training Epoch 16  98.9% | batch:        93 of        94\t|\tloss: 3263.56\n",
      "\n",
      "Evaluating Epoch 16   0.0% | batch:         0 of        40\t|\tloss: 6780.89\n",
      "Evaluating Epoch 16   2.5% | batch:         1 of        40\t|\tloss: 1087.4\n",
      "Evaluating Epoch 16   5.0% | batch:         2 of        40\t|\tloss: 2630.13\n",
      "Evaluating Epoch 16   7.5% | batch:         3 of        40\t|\tloss: 6487.78\n",
      "Evaluating Epoch 16  10.0% | batch:         4 of        40\t|\tloss: 2323.82\n",
      "Evaluating Epoch 16  12.5% | batch:         5 of        40\t|\tloss: 1987.23\n",
      "Evaluating Epoch 16  15.0% | batch:         6 of        40\t|\tloss: 7069.98\n",
      "Evaluating Epoch 16  17.5% | batch:         7 of        40\t|\tloss: 3108.14\n",
      "Evaluating Epoch 16  20.0% | batch:         8 of        40\t|\tloss: 2536.91\n",
      "Evaluating Epoch 16  22.5% | batch:         9 of        40\t|\tloss: 1609.68\n",
      "Evaluating Epoch 16  25.0% | batch:        10 of        40\t|\tloss: 4781.18\n",
      "Evaluating Epoch 16  27.5% | batch:        11 of        40\t|\tloss: 1230.14\n",
      "Evaluating Epoch 16  30.0% | batch:        12 of        40\t|\tloss: 5753.04\n",
      "Evaluating Epoch 16  32.5% | batch:        13 of        40\t|\tloss: 2969.27\n",
      "Evaluating Epoch 16  35.0% | batch:        14 of        40\t|\tloss: 1856.92\n",
      "Evaluating Epoch 16  37.5% | batch:        15 of        40\t|\tloss: 2979.1\n",
      "Evaluating Epoch 16  40.0% | batch:        16 of        40\t|\tloss: 4191.79\n",
      "Evaluating Epoch 16  42.5% | batch:        17 of        40\t|\tloss: 2498.98\n",
      "Evaluating Epoch 16  45.0% | batch:        18 of        40\t|\tloss: 1997.75\n",
      "Evaluating Epoch 16  47.5% | batch:        19 of        40\t|\tloss: 4605.41\n",
      "Evaluating Epoch 16  50.0% | batch:        20 of        40\t|\tloss: 4931.44\n",
      "Evaluating Epoch 16  52.5% | batch:        21 of        40\t|\tloss: 1148.04\n",
      "Evaluating Epoch 16  55.0% | batch:        22 of        40\t|\tloss: 3414.33\n",
      "Evaluating Epoch 16  57.5% | batch:        23 of        40\t|\tloss: 2579.75\n",
      "Evaluating Epoch 16  60.0% | batch:        24 of        40\t|\tloss: 1637.68\n",
      "Evaluating Epoch 16  62.5% | batch:        25 of        40\t|\tloss: 2506.74\n",
      "Evaluating Epoch 16  65.0% | batch:        26 of        40\t|\tloss: 9027.16\n",
      "Evaluating Epoch 16  67.5% | batch:        27 of        40\t|\tloss: 2908.85\n",
      "Evaluating Epoch 16  70.0% | batch:        28 of        40\t|\tloss: 1518.89\n",
      "Evaluating Epoch 16  72.5% | batch:        29 of        40\t|\tloss: 8130.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:24,330 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45236706733703613 seconds\n",
      "\n",
      "2023-05-04 16:59:24,331 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5448913978554352 seconds\n",
      "2023-05-04 16:59:24,332 | INFO : Avg batch val. time: 0.01362228494638588 seconds\n",
      "2023-05-04 16:59:24,332 | INFO : Avg sample val. time: 0.00010794203602524468 seconds\n",
      "2023-05-04 16:59:24,333 | INFO : Epoch 16 Validation Summary: epoch: 16.000000 | loss: 3661.593735 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 16  75.0% | batch:        30 of        40\t|\tloss: 1791.76\n",
      "Evaluating Epoch 16  77.5% | batch:        31 of        40\t|\tloss: 1573.1\n",
      "Evaluating Epoch 16  80.0% | batch:        32 of        40\t|\tloss: 7412.94\n",
      "Evaluating Epoch 16  82.5% | batch:        33 of        40\t|\tloss: 6152.54\n",
      "Evaluating Epoch 16  85.0% | batch:        34 of        40\t|\tloss: 796.869\n",
      "Evaluating Epoch 16  87.5% | batch:        35 of        40\t|\tloss: 4798.39\n",
      "Evaluating Epoch 16  90.0% | batch:        36 of        40\t|\tloss: 5615.03\n",
      "Evaluating Epoch 16  92.5% | batch:        37 of        40\t|\tloss: 2373.74\n",
      "Evaluating Epoch 16  95.0% | batch:        38 of        40\t|\tloss: 3130.77\n",
      "Evaluating Epoch 16  97.5% | batch:        39 of        40\t|\tloss: 10218\n",
      "\n",
      "Training Epoch 17   0.0% | batch:         0 of        94\t|\tloss: 1293.13\n",
      "Training Epoch 17   1.1% | batch:         1 of        94\t|\tloss: 1551.37\n",
      "Training Epoch 17   2.1% | batch:         2 of        94\t|\tloss: 2070.57\n",
      "Training Epoch 17   3.2% | batch:         3 of        94\t|\tloss: 1673.4\n",
      "Training Epoch 17   4.3% | batch:         4 of        94\t|\tloss: 3763.44\n",
      "Training Epoch 17   5.3% | batch:         5 of        94\t|\tloss: 1728.47\n",
      "Training Epoch 17   6.4% | batch:         6 of        94\t|\tloss: 1647.11\n",
      "Training Epoch 17   7.4% | batch:         7 of        94\t|\tloss: 1369.03\n",
      "Training Epoch 17   8.5% | batch:         8 of        94\t|\tloss: 1421.57\n",
      "Training Epoch 17   9.6% | batch:         9 of        94\t|\tloss: 2409.9\n",
      "Training Epoch 17  10.6% | batch:        10 of        94\t|\tloss: 1903.07\n",
      "Training Epoch 17  11.7% | batch:        11 of        94\t|\tloss: 1725.07\n",
      "Training Epoch 17  12.8% | batch:        12 of        94\t|\tloss: 2276.65\n",
      "Training Epoch 17  13.8% | batch:        13 of        94\t|\tloss: 2919.01\n",
      "Training Epoch 17  14.9% | batch:        14 of        94\t|\tloss: 1526.32\n",
      "Training Epoch 17  16.0% | batch:        15 of        94\t|\tloss: 1467.43\n",
      "Training Epoch 17  17.0% | batch:        16 of        94\t|\tloss: 1857.33\n",
      "Training Epoch 17  18.1% | batch:        17 of        94\t|\tloss: 1796.89\n",
      "Training Epoch 17  19.1% | batch:        18 of        94\t|\tloss: 1507.55\n",
      "Training Epoch 17  20.2% | batch:        19 of        94\t|\tloss: 1943.14\n",
      "Training Epoch 17  21.3% | batch:        20 of        94\t|\tloss: 1577.62\n",
      "Training Epoch 17  22.3% | batch:        21 of        94\t|\tloss: 1708.99\n",
      "Training Epoch 17  23.4% | batch:        22 of        94\t|\tloss: 1561.57\n",
      "Training Epoch 17  24.5% | batch:        23 of        94\t|\tloss: 2547.49\n",
      "Training Epoch 17  25.5% | batch:        24 of        94\t|\tloss: 1561.09\n",
      "Training Epoch 17  26.6% | batch:        25 of        94\t|\tloss: 3540.97\n",
      "Training Epoch 17  27.7% | batch:        26 of        94\t|\tloss: 2094.68\n",
      "Training Epoch 17  28.7% | batch:        27 of        94\t|\tloss: 1212.3\n",
      "Training Epoch 17  29.8% | batch:        28 of        94\t|\tloss: 1564.14\n",
      "Training Epoch 17  30.9% | batch:        29 of        94\t|\tloss: 1293.23\n",
      "Training Epoch 17  31.9% | batch:        30 of        94\t|\tloss: 1711.37\n",
      "Training Epoch 17  33.0% | batch:        31 of        94\t|\tloss: 1862.86\n",
      "Training Epoch 17  34.0% | batch:        32 of        94\t|\tloss: 1691.05\n",
      "Training Epoch 17  35.1% | batch:        33 of        94\t|\tloss: 1459.99\n",
      "Training Epoch 17  36.2% | batch:        34 of        94\t|\tloss: 1221.7\n",
      "Training Epoch 17  37.2% | batch:        35 of        94\t|\tloss: 2655.32\n",
      "Training Epoch 17  38.3% | batch:        36 of        94\t|\tloss: 1525.86\n",
      "Training Epoch 17  39.4% | batch:        37 of        94\t|\tloss: 1495.13\n",
      "Training Epoch 17  40.4% | batch:        38 of        94\t|\tloss: 1383.13\n",
      "Training Epoch 17  41.5% | batch:        39 of        94\t|\tloss: 2028.31\n",
      "Training Epoch 17  42.6% | batch:        40 of        94\t|\tloss: 1200.97\n",
      "Training Epoch 17  43.6% | batch:        41 of        94\t|\tloss: 2542.95\n",
      "Training Epoch 17  44.7% | batch:        42 of        94\t|\tloss: 1298.91\n",
      "Training Epoch 17  45.7% | batch:        43 of        94\t|\tloss: 4177.79\n",
      "Training Epoch 17  46.8% | batch:        44 of        94\t|\tloss: 1420.4\n",
      "Training Epoch 17  47.9% | batch:        45 of        94\t|\tloss: 1667.94\n",
      "Training Epoch 17  48.9% | batch:        46 of        94\t|\tloss: 2584.9\n",
      "Training Epoch 17  50.0% | batch:        47 of        94\t|\tloss: 2452.17\n",
      "Training Epoch 17  51.1% | batch:        48 of        94\t|\tloss: 1667.53\n",
      "Training Epoch 17  52.1% | batch:        49 of        94\t|\tloss: 1376.42\n",
      "Training Epoch 17  53.2% | batch:        50 of        94\t|\tloss: 2165.33\n",
      "Training Epoch 17  54.3% | batch:        51 of        94\t|\tloss: 1524.48\n",
      "Training Epoch 17  55.3% | batch:        52 of        94\t|\tloss: 1540.09\n",
      "Training Epoch 17  56.4% | batch:        53 of        94\t|\tloss: 1208.56\n",
      "Training Epoch 17  57.4% | batch:        54 of        94\t|\tloss: 2992.87\n",
      "Training Epoch 17  58.5% | batch:        55 of        94\t|\tloss: 3853.78\n",
      "Training Epoch 17  59.6% | batch:        56 of        94\t|\tloss: 1908.43\n",
      "Training Epoch 17  60.6% | batch:        57 of        94\t|\tloss: 1430.16\n",
      "Training Epoch 17  61.7% | batch:        58 of        94\t|\tloss: 1410.13\n",
      "Training Epoch 17  62.8% | batch:        59 of        94\t|\tloss: 2085.45\n",
      "Training Epoch 17  63.8% | batch:        60 of        94\t|\tloss: 1883.61\n",
      "Training Epoch 17  64.9% | batch:        61 of        94\t|\tloss: 1788.26\n",
      "Training Epoch 17  66.0% | batch:        62 of        94\t|\tloss: 2222.71\n",
      "Training Epoch 17  67.0% | batch:        63 of        94\t|\tloss: 4183.94\n",
      "Training Epoch 17  68.1% | batch:        64 of        94\t|\tloss: 1090.29\n",
      "Training Epoch 17  69.1% | batch:        65 of        94\t|\tloss: 1463.11\n",
      "Training Epoch 17  70.2% | batch:        66 of        94\t|\tloss: 2271.5\n",
      "Training Epoch 17  71.3% | batch:        67 of        94\t|\tloss: 1070.06\n",
      "Training Epoch 17  72.3% | batch:        68 of        94\t|\tloss: 1194.39\n",
      "Training Epoch 17  73.4% | batch:        69 of        94\t|\tloss: 1908.39\n",
      "Training Epoch 17  74.5% | batch:        70 of        94\t|\tloss: 2737.52\n",
      "Training Epoch 17  75.5% | batch:        71 of        94\t|\tloss: 2029.08\n",
      "Training Epoch 17  76.6% | batch:        72 of        94\t|\tloss: 2046.79\n",
      "Training Epoch 17  77.7% | batch:        73 of        94\t|\tloss: 1997.4\n",
      "Training Epoch 17  78.7% | batch:        74 of        94\t|\tloss: 1981.46\n",
      "Training Epoch 17  79.8% | batch:        75 of        94\t|\tloss: 1201.77\n",
      "Training Epoch 17  80.9% | batch:        76 of        94\t|\tloss: 1625.32\n",
      "Training Epoch 17  81.9% | batch:        77 of        94\t|\tloss: 1138.05\n",
      "Training Epoch 17  83.0% | batch:        78 of        94\t|\tloss: 1997.48\n",
      "Training Epoch 17  84.0% | batch:        79 of        94\t|\tloss: 2276.67\n",
      "Training Epoch 17  85.1% | batch:        80 of        94\t|\tloss: 1472.5\n",
      "Training Epoch 17  86.2% | batch:        81 of        94\t|\tloss: 2194.83\n",
      "Training Epoch 17  87.2% | batch:        82 of        94\t|\tloss: 3412.35\n",
      "Training Epoch 17  88.3% | batch:        83 of        94\t|\tloss: 1967.11\n",
      "Training Epoch 17  89.4% | batch:        84 of        94\t|\tloss: 1275.58\n",
      "Training Epoch 17  90.4% | batch:        85 of        94\t|\tloss: 3358.47\n",
      "Training Epoch 17  91.5% | batch:        86 of        94\t|\tloss: 1965.39\n",
      "Training Epoch 17  92.6% | batch:        87 of        94\t|\tloss: 2270.31\n",
      "Training Epoch 17  93.6% | batch:        88 of        94\t|\tloss: 2053.28\n",
      "Training Epoch 17  94.7% | batch:        89 of        94\t|\tloss: 2116.36\n",
      "Training Epoch 17  95.7% | batch:        90 of        94\t|\tloss: 2958.28\n",
      "Training Epoch 17  96.8% | batch:        91 of        94\t|\tloss: 2687.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:26,154 | INFO : Epoch 17 Training Summary: epoch: 17.000000 | loss: 1949.820852 | \n",
      "2023-05-04 16:59:26,155 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8011305332183838 seconds\n",
      "\n",
      "2023-05-04 16:59:26,156 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7847702923943014 seconds\n",
      "2023-05-04 16:59:26,157 | INFO : Avg batch train. time: 0.018986918004194695 seconds\n",
      "2023-05-04 16:59:26,157 | INFO : Avg sample train. time: 0.00014975417791527953 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 17  97.9% | batch:        92 of        94\t|\tloss: 1525.2\n",
      "Training Epoch 17  98.9% | batch:        93 of        94\t|\tloss: 1144.33\n",
      "\n",
      "Training Epoch 18   0.0% | batch:         0 of        94\t|\tloss: 1316.79\n",
      "Training Epoch 18   1.1% | batch:         1 of        94\t|\tloss: 1741.72\n",
      "Training Epoch 18   2.1% | batch:         2 of        94\t|\tloss: 1822.14\n",
      "Training Epoch 18   3.2% | batch:         3 of        94\t|\tloss: 1198.31\n",
      "Training Epoch 18   4.3% | batch:         4 of        94\t|\tloss: 1558.95\n",
      "Training Epoch 18   5.3% | batch:         5 of        94\t|\tloss: 1518.51\n",
      "Training Epoch 18   6.4% | batch:         6 of        94\t|\tloss: 4478.14\n",
      "Training Epoch 18   7.4% | batch:         7 of        94\t|\tloss: 1873.9\n",
      "Training Epoch 18   8.5% | batch:         8 of        94\t|\tloss: 1212.73\n",
      "Training Epoch 18   9.6% | batch:         9 of        94\t|\tloss: 2178.69\n",
      "Training Epoch 18  10.6% | batch:        10 of        94\t|\tloss: 1491.28\n",
      "Training Epoch 18  11.7% | batch:        11 of        94\t|\tloss: 829.941\n",
      "Training Epoch 18  12.8% | batch:        12 of        94\t|\tloss: 2780.01\n",
      "Training Epoch 18  13.8% | batch:        13 of        94\t|\tloss: 3665.71\n",
      "Training Epoch 18  14.9% | batch:        14 of        94\t|\tloss: 1537.44\n",
      "Training Epoch 18  16.0% | batch:        15 of        94\t|\tloss: 1353.89\n",
      "Training Epoch 18  17.0% | batch:        16 of        94\t|\tloss: 2562.73\n",
      "Training Epoch 18  18.1% | batch:        17 of        94\t|\tloss: 1855.86\n",
      "Training Epoch 18  19.1% | batch:        18 of        94\t|\tloss: 1763.53\n",
      "Training Epoch 18  20.2% | batch:        19 of        94\t|\tloss: 1488.4\n",
      "Training Epoch 18  21.3% | batch:        20 of        94\t|\tloss: 4436.64\n",
      "Training Epoch 18  22.3% | batch:        21 of        94\t|\tloss: 1032.61\n",
      "Training Epoch 18  23.4% | batch:        22 of        94\t|\tloss: 1327.82\n",
      "Training Epoch 18  24.5% | batch:        23 of        94\t|\tloss: 1280.98\n",
      "Training Epoch 18  25.5% | batch:        24 of        94\t|\tloss: 1946.64\n",
      "Training Epoch 18  26.6% | batch:        25 of        94\t|\tloss: 1445.69\n",
      "Training Epoch 18  27.7% | batch:        26 of        94\t|\tloss: 1849.66\n",
      "Training Epoch 18  28.7% | batch:        27 of        94\t|\tloss: 2001.96\n",
      "Training Epoch 18  29.8% | batch:        28 of        94\t|\tloss: 1241.98\n",
      "Training Epoch 18  30.9% | batch:        29 of        94\t|\tloss: 2614.85\n",
      "Training Epoch 18  31.9% | batch:        30 of        94\t|\tloss: 2950.02\n",
      "Training Epoch 18  33.0% | batch:        31 of        94\t|\tloss: 981.774\n",
      "Training Epoch 18  34.0% | batch:        32 of        94\t|\tloss: 1736.88\n",
      "Training Epoch 18  35.1% | batch:        33 of        94\t|\tloss: 1700.18\n",
      "Training Epoch 18  36.2% | batch:        34 of        94\t|\tloss: 2084.53\n",
      "Training Epoch 18  37.2% | batch:        35 of        94\t|\tloss: 1830.73\n",
      "Training Epoch 18  38.3% | batch:        36 of        94\t|\tloss: 1574.89\n",
      "Training Epoch 18  39.4% | batch:        37 of        94\t|\tloss: 6604.5\n",
      "Training Epoch 18  40.4% | batch:        38 of        94\t|\tloss: 1532.6\n",
      "Training Epoch 18  41.5% | batch:        39 of        94\t|\tloss: 1660.79\n",
      "Training Epoch 18  42.6% | batch:        40 of        94\t|\tloss: 2034.48\n",
      "Training Epoch 18  43.6% | batch:        41 of        94\t|\tloss: 1482.45\n",
      "Training Epoch 18  44.7% | batch:        42 of        94\t|\tloss: 1758.76\n",
      "Training Epoch 18  45.7% | batch:        43 of        94\t|\tloss: 1414.87\n",
      "Training Epoch 18  46.8% | batch:        44 of        94\t|\tloss: 1634.62\n",
      "Training Epoch 18  47.9% | batch:        45 of        94\t|\tloss: 2046.19\n",
      "Training Epoch 18  48.9% | batch:        46 of        94\t|\tloss: 1556.34\n",
      "Training Epoch 18  50.0% | batch:        47 of        94\t|\tloss: 1850.35\n",
      "Training Epoch 18  51.1% | batch:        48 of        94\t|\tloss: 2077.52\n",
      "Training Epoch 18  52.1% | batch:        49 of        94\t|\tloss: 2653.15\n",
      "Training Epoch 18  53.2% | batch:        50 of        94\t|\tloss: 1309.03\n",
      "Training Epoch 18  54.3% | batch:        51 of        94\t|\tloss: 1306.92\n",
      "Training Epoch 18  55.3% | batch:        52 of        94\t|\tloss: 1500.81\n",
      "Training Epoch 18  56.4% | batch:        53 of        94\t|\tloss: 1338.04\n",
      "Training Epoch 18  57.4% | batch:        54 of        94\t|\tloss: 2941.38\n",
      "Training Epoch 18  58.5% | batch:        55 of        94\t|\tloss: 2315.74\n",
      "Training Epoch 18  59.6% | batch:        56 of        94\t|\tloss: 1604.8\n",
      "Training Epoch 18  60.6% | batch:        57 of        94\t|\tloss: 2274.39\n",
      "Training Epoch 18  61.7% | batch:        58 of        94\t|\tloss: 3064.15\n",
      "Training Epoch 18  62.8% | batch:        59 of        94\t|\tloss: 2739.55\n",
      "Training Epoch 18  63.8% | batch:        60 of        94\t|\tloss: 2578.25\n",
      "Training Epoch 18  64.9% | batch:        61 of        94\t|\tloss: 1711.37\n",
      "Training Epoch 18  66.0% | batch:        62 of        94\t|\tloss: 2875\n",
      "Training Epoch 18  67.0% | batch:        63 of        94\t|\tloss: 2909.15\n",
      "Training Epoch 18  68.1% | batch:        64 of        94\t|\tloss: 1734.24\n",
      "Training Epoch 18  69.1% | batch:        65 of        94\t|\tloss: 2017\n",
      "Training Epoch 18  70.2% | batch:        66 of        94\t|\tloss: 1711.13\n",
      "Training Epoch 18  71.3% | batch:        67 of        94\t|\tloss: 1849.91\n",
      "Training Epoch 18  72.3% | batch:        68 of        94\t|\tloss: 1182.32\n",
      "Training Epoch 18  73.4% | batch:        69 of        94\t|\tloss: 1264.23\n",
      "Training Epoch 18  74.5% | batch:        70 of        94\t|\tloss: 1891.35\n",
      "Training Epoch 18  75.5% | batch:        71 of        94\t|\tloss: 1666.51\n",
      "Training Epoch 18  76.6% | batch:        72 of        94\t|\tloss: 1092.86\n",
      "Training Epoch 18  77.7% | batch:        73 of        94\t|\tloss: 1973.97\n",
      "Training Epoch 18  78.7% | batch:        74 of        94\t|\tloss: 1214.93\n",
      "Training Epoch 18  79.8% | batch:        75 of        94\t|\tloss: 1719.56\n",
      "Training Epoch 18  80.9% | batch:        76 of        94\t|\tloss: 1530.03\n",
      "Training Epoch 18  81.9% | batch:        77 of        94\t|\tloss: 1937.28\n",
      "Training Epoch 18  83.0% | batch:        78 of        94\t|\tloss: 3355.36\n",
      "Training Epoch 18  84.0% | batch:        79 of        94\t|\tloss: 2385.41\n",
      "Training Epoch 18  85.1% | batch:        80 of        94\t|\tloss: 1734.42\n",
      "Training Epoch 18  86.2% | batch:        81 of        94\t|\tloss: 1302.34\n",
      "Training Epoch 18  87.2% | batch:        82 of        94\t|\tloss: 1541.56\n",
      "Training Epoch 18  88.3% | batch:        83 of        94\t|\tloss: 2030.33\n",
      "Training Epoch 18  89.4% | batch:        84 of        94\t|\tloss: 1557.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:27,978 | INFO : Epoch 18 Training Summary: epoch: 18.000000 | loss: 1922.330842 | \n",
      "2023-05-04 16:59:27,979 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8002865314483643 seconds\n",
      "\n",
      "2023-05-04 16:59:27,979 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7856323056750827 seconds\n",
      "2023-05-04 16:59:27,980 | INFO : Avg batch train. time: 0.01899608835824556 seconds\n",
      "2023-05-04 16:59:27,980 | INFO : Avg sample train. time: 0.00014982650660136623 seconds\n",
      "2023-05-04 16:59:27,980 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 18  90.4% | batch:        85 of        94\t|\tloss: 2483.76\n",
      "Training Epoch 18  91.5% | batch:        86 of        94\t|\tloss: 1405.21\n",
      "Training Epoch 18  92.6% | batch:        87 of        94\t|\tloss: 1358.43\n",
      "Training Epoch 18  93.6% | batch:        88 of        94\t|\tloss: 1404.25\n",
      "Training Epoch 18  94.7% | batch:        89 of        94\t|\tloss: 1983.73\n",
      "Training Epoch 18  95.7% | batch:        90 of        94\t|\tloss: 1419.85\n",
      "Training Epoch 18  96.8% | batch:        91 of        94\t|\tloss: 1406.53\n",
      "Training Epoch 18  97.9% | batch:        92 of        94\t|\tloss: 1274.79\n",
      "Training Epoch 18  98.9% | batch:        93 of        94\t|\tloss: 4723.49\n",
      "\n",
      "Evaluating Epoch 18   0.0% | batch:         0 of        40\t|\tloss: 6559.5\n",
      "Evaluating Epoch 18   2.5% | batch:         1 of        40\t|\tloss: 1069.85\n",
      "Evaluating Epoch 18   5.0% | batch:         2 of        40\t|\tloss: 3993.48\n",
      "Evaluating Epoch 18   7.5% | batch:         3 of        40\t|\tloss: 6687.17\n",
      "Evaluating Epoch 18  10.0% | batch:         4 of        40\t|\tloss: 2406.24\n",
      "Evaluating Epoch 18  12.5% | batch:         5 of        40\t|\tloss: 2542.12\n",
      "Evaluating Epoch 18  15.0% | batch:         6 of        40\t|\tloss: 7412\n",
      "Evaluating Epoch 18  17.5% | batch:         7 of        40\t|\tloss: 2725.62\n",
      "Evaluating Epoch 18  20.0% | batch:         8 of        40\t|\tloss: 2480.23\n",
      "Evaluating Epoch 18  22.5% | batch:         9 of        40\t|\tloss: 2244.17\n",
      "Evaluating Epoch 18  25.0% | batch:        10 of        40\t|\tloss: 4227.99\n",
      "Evaluating Epoch 18  27.5% | batch:        11 of        40\t|\tloss: 1109.47\n",
      "Evaluating Epoch 18  30.0% | batch:        12 of        40\t|\tloss: 5719.36\n",
      "Evaluating Epoch 18  32.5% | batch:        13 of        40\t|\tloss: 2905.59\n",
      "Evaluating Epoch 18  35.0% | batch:        14 of        40\t|\tloss: 1773.66\n",
      "Evaluating Epoch 18  37.5% | batch:        15 of        40\t|\tloss: 4072.45\n",
      "Evaluating Epoch 18  40.0% | batch:        16 of        40\t|\tloss: 4657.71\n",
      "Evaluating Epoch 18  42.5% | batch:        17 of        40\t|\tloss: 2195.19\n",
      "Evaluating Epoch 18  45.0% | batch:        18 of        40\t|\tloss: 2007.81\n",
      "Evaluating Epoch 18  47.5% | batch:        19 of        40\t|\tloss: 4604.44\n",
      "Evaluating Epoch 18  50.0% | batch:        20 of        40\t|\tloss: 3935.18\n",
      "Evaluating Epoch 18  52.5% | batch:        21 of        40\t|\tloss: 834.919\n",
      "Evaluating Epoch 18  55.0% | batch:        22 of        40\t|\tloss: 3886.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:28,429 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4479522705078125 seconds\n",
      "\n",
      "2023-05-04 16:59:28,429 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5443277982778327 seconds\n",
      "2023-05-04 16:59:28,430 | INFO : Avg batch val. time: 0.013608194956945818 seconds\n",
      "2023-05-04 16:59:28,431 | INFO : Avg sample val. time: 0.00010783038793142487 seconds\n",
      "2023-05-04 16:59:28,431 | INFO : Epoch 18 Validation Summary: epoch: 18.000000 | loss: 3785.351697 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 18  57.5% | batch:        23 of        40\t|\tloss: 2802.22\n",
      "Evaluating Epoch 18  60.0% | batch:        24 of        40\t|\tloss: 1471.25\n",
      "Evaluating Epoch 18  62.5% | batch:        25 of        40\t|\tloss: 3145.38\n",
      "Evaluating Epoch 18  65.0% | batch:        26 of        40\t|\tloss: 8902.18\n",
      "Evaluating Epoch 18  67.5% | batch:        27 of        40\t|\tloss: 2481.32\n",
      "Evaluating Epoch 18  70.0% | batch:        28 of        40\t|\tloss: 2041.2\n",
      "Evaluating Epoch 18  72.5% | batch:        29 of        40\t|\tloss: 8282.7\n",
      "Evaluating Epoch 18  75.0% | batch:        30 of        40\t|\tloss: 1647.42\n",
      "Evaluating Epoch 18  77.5% | batch:        31 of        40\t|\tloss: 1954.72\n",
      "Evaluating Epoch 18  80.0% | batch:        32 of        40\t|\tloss: 8156.97\n",
      "Evaluating Epoch 18  82.5% | batch:        33 of        40\t|\tloss: 6613.04\n",
      "Evaluating Epoch 18  85.0% | batch:        34 of        40\t|\tloss: 903.174\n",
      "Evaluating Epoch 18  87.5% | batch:        35 of        40\t|\tloss: 5716.08\n",
      "Evaluating Epoch 18  90.0% | batch:        36 of        40\t|\tloss: 5498.15\n",
      "Evaluating Epoch 18  92.5% | batch:        37 of        40\t|\tloss: 2187.94\n",
      "Evaluating Epoch 18  95.0% | batch:        38 of        40\t|\tloss: 3531.94\n",
      "Evaluating Epoch 18  97.5% | batch:        39 of        40\t|\tloss: 8910.85\n",
      "\n",
      "Training Epoch 19   0.0% | batch:         0 of        94\t|\tloss: 1554.46\n",
      "Training Epoch 19   1.1% | batch:         1 of        94\t|\tloss: 1326\n",
      "Training Epoch 19   2.1% | batch:         2 of        94\t|\tloss: 1291.98\n",
      "Training Epoch 19   3.2% | batch:         3 of        94\t|\tloss: 1346.37\n",
      "Training Epoch 19   4.3% | batch:         4 of        94\t|\tloss: 1383.97\n",
      "Training Epoch 19   5.3% | batch:         5 of        94\t|\tloss: 1404.31\n",
      "Training Epoch 19   6.4% | batch:         6 of        94\t|\tloss: 1468.27\n",
      "Training Epoch 19   7.4% | batch:         7 of        94\t|\tloss: 1265.26\n",
      "Training Epoch 19   8.5% | batch:         8 of        94\t|\tloss: 1986.96\n",
      "Training Epoch 19   9.6% | batch:         9 of        94\t|\tloss: 1333.99\n",
      "Training Epoch 19  10.6% | batch:        10 of        94\t|\tloss: 1768.43\n",
      "Training Epoch 19  11.7% | batch:        11 of        94\t|\tloss: 1792.29\n",
      "Training Epoch 19  12.8% | batch:        12 of        94\t|\tloss: 3349.91\n",
      "Training Epoch 19  13.8% | batch:        13 of        94\t|\tloss: 2230.84\n",
      "Training Epoch 19  14.9% | batch:        14 of        94\t|\tloss: 2121.17\n",
      "Training Epoch 19  16.0% | batch:        15 of        94\t|\tloss: 1962.15\n",
      "Training Epoch 19  17.0% | batch:        16 of        94\t|\tloss: 1160.6\n",
      "Training Epoch 19  18.1% | batch:        17 of        94\t|\tloss: 1857.52\n",
      "Training Epoch 19  19.1% | batch:        18 of        94\t|\tloss: 1638.77\n",
      "Training Epoch 19  20.2% | batch:        19 of        94\t|\tloss: 1711.4\n",
      "Training Epoch 19  21.3% | batch:        20 of        94\t|\tloss: 1225.57\n",
      "Training Epoch 19  22.3% | batch:        21 of        94\t|\tloss: 1315.58\n",
      "Training Epoch 19  23.4% | batch:        22 of        94\t|\tloss: 2102.81\n",
      "Training Epoch 19  24.5% | batch:        23 of        94\t|\tloss: 1326.72\n",
      "Training Epoch 19  25.5% | batch:        24 of        94\t|\tloss: 2411.35\n",
      "Training Epoch 19  26.6% | batch:        25 of        94\t|\tloss: 1500.89\n",
      "Training Epoch 19  27.7% | batch:        26 of        94\t|\tloss: 1477.25\n",
      "Training Epoch 19  28.7% | batch:        27 of        94\t|\tloss: 1924.05\n",
      "Training Epoch 19  29.8% | batch:        28 of        94\t|\tloss: 1754.69\n",
      "Training Epoch 19  30.9% | batch:        29 of        94\t|\tloss: 2302.34\n",
      "Training Epoch 19  31.9% | batch:        30 of        94\t|\tloss: 1470.44\n",
      "Training Epoch 19  33.0% | batch:        31 of        94\t|\tloss: 2057.25\n",
      "Training Epoch 19  34.0% | batch:        32 of        94\t|\tloss: 1608.35\n",
      "Training Epoch 19  35.1% | batch:        33 of        94\t|\tloss: 1851.92\n",
      "Training Epoch 19  36.2% | batch:        34 of        94\t|\tloss: 1538.95\n",
      "Training Epoch 19  37.2% | batch:        35 of        94\t|\tloss: 1031.49\n",
      "Training Epoch 19  38.3% | batch:        36 of        94\t|\tloss: 1225.35\n",
      "Training Epoch 19  39.4% | batch:        37 of        94\t|\tloss: 3884.92\n",
      "Training Epoch 19  40.4% | batch:        38 of        94\t|\tloss: 1305.05\n",
      "Training Epoch 19  41.5% | batch:        39 of        94\t|\tloss: 2340.01\n",
      "Training Epoch 19  42.6% | batch:        40 of        94\t|\tloss: 3891.4\n",
      "Training Epoch 19  43.6% | batch:        41 of        94\t|\tloss: 1682.93\n",
      "Training Epoch 19  44.7% | batch:        42 of        94\t|\tloss: 2199.66\n",
      "Training Epoch 19  45.7% | batch:        43 of        94\t|\tloss: 2131.29\n",
      "Training Epoch 19  46.8% | batch:        44 of        94\t|\tloss: 1889.01\n",
      "Training Epoch 19  47.9% | batch:        45 of        94\t|\tloss: 1910.6\n",
      "Training Epoch 19  48.9% | batch:        46 of        94\t|\tloss: 2101.92\n",
      "Training Epoch 19  50.0% | batch:        47 of        94\t|\tloss: 2827.23\n",
      "Training Epoch 19  51.1% | batch:        48 of        94\t|\tloss: 1153.21\n",
      "Training Epoch 19  52.1% | batch:        49 of        94\t|\tloss: 1641.66\n",
      "Training Epoch 19  53.2% | batch:        50 of        94\t|\tloss: 2224.91\n",
      "Training Epoch 19  54.3% | batch:        51 of        94\t|\tloss: 1416.44\n",
      "Training Epoch 19  55.3% | batch:        52 of        94\t|\tloss: 1996.44\n",
      "Training Epoch 19  56.4% | batch:        53 of        94\t|\tloss: 1727.18\n",
      "Training Epoch 19  57.4% | batch:        54 of        94\t|\tloss: 1672.97\n",
      "Training Epoch 19  58.5% | batch:        55 of        94\t|\tloss: 4405.28\n",
      "Training Epoch 19  59.6% | batch:        56 of        94\t|\tloss: 1852.91\n",
      "Training Epoch 19  60.6% | batch:        57 of        94\t|\tloss: 1902.81\n",
      "Training Epoch 19  61.7% | batch:        58 of        94\t|\tloss: 1421.11\n",
      "Training Epoch 19  62.8% | batch:        59 of        94\t|\tloss: 1846.05\n",
      "Training Epoch 19  63.8% | batch:        60 of        94\t|\tloss: 2428.63\n",
      "Training Epoch 19  64.9% | batch:        61 of        94\t|\tloss: 1637.27\n",
      "Training Epoch 19  66.0% | batch:        62 of        94\t|\tloss: 1896.7\n",
      "Training Epoch 19  67.0% | batch:        63 of        94\t|\tloss: 1595.31\n",
      "Training Epoch 19  68.1% | batch:        64 of        94\t|\tloss: 3036.38\n",
      "Training Epoch 19  69.1% | batch:        65 of        94\t|\tloss: 1809.95\n",
      "Training Epoch 19  70.2% | batch:        66 of        94\t|\tloss: 1579.58\n",
      "Training Epoch 19  71.3% | batch:        67 of        94\t|\tloss: 1291.17\n",
      "Training Epoch 19  72.3% | batch:        68 of        94\t|\tloss: 1472.22\n",
      "Training Epoch 19  73.4% | batch:        69 of        94\t|\tloss: 1448.59\n",
      "Training Epoch 19  74.5% | batch:        70 of        94\t|\tloss: 3081.05\n",
      "Training Epoch 19  75.5% | batch:        71 of        94\t|\tloss: 2178.27\n",
      "Training Epoch 19  76.6% | batch:        72 of        94\t|\tloss: 2130.65\n",
      "Training Epoch 19  77.7% | batch:        73 of        94\t|\tloss: 1588.35\n",
      "Training Epoch 19  78.7% | batch:        74 of        94\t|\tloss: 1670.2\n",
      "Training Epoch 19  79.8% | batch:        75 of        94\t|\tloss: 2995.56\n",
      "Training Epoch 19  80.9% | batch:        76 of        94\t|\tloss: 1767.32\n",
      "Training Epoch 19  81.9% | batch:        77 of        94\t|\tloss: 1626.22\n",
      "Training Epoch 19  83.0% | batch:        78 of        94\t|\tloss: 2139.11\n",
      "Training Epoch 19  84.0% | batch:        79 of        94\t|\tloss: 1850.22\n",
      "Training Epoch 19  85.1% | batch:        80 of        94\t|\tloss: 1745.79\n",
      "Training Epoch 19  86.2% | batch:        81 of        94\t|\tloss: 2374.68\n",
      "Training Epoch 19  87.2% | batch:        82 of        94\t|\tloss: 1869.42\n",
      "Training Epoch 19  88.3% | batch:        83 of        94\t|\tloss: 1530.39\n",
      "Training Epoch 19  89.4% | batch:        84 of        94\t|\tloss: 1166.36\n",
      "Training Epoch 19  90.4% | batch:        85 of        94\t|\tloss: 1606.16\n",
      "Training Epoch 19  91.5% | batch:        86 of        94\t|\tloss: 2093.21\n",
      "Training Epoch 19  92.6% | batch:        87 of        94\t|\tloss: 1551.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:30,246 | INFO : Epoch 19 Training Summary: epoch: 19.000000 | loss: 1873.326408 | \n",
      "2023-05-04 16:59:30,247 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7940967082977295 seconds\n",
      "\n",
      "2023-05-04 16:59:30,248 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.786077800549959 seconds\n",
      "2023-05-04 16:59:30,249 | INFO : Avg batch train. time: 0.019000827665425095 seconds\n",
      "2023-05-04 16:59:30,249 | INFO : Avg sample train. time: 0.00014986388660429258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 19  93.6% | batch:        88 of        94\t|\tloss: 1658.81\n",
      "Training Epoch 19  94.7% | batch:        89 of        94\t|\tloss: 2335.26\n",
      "Training Epoch 19  95.7% | batch:        90 of        94\t|\tloss: 1738.94\n",
      "Training Epoch 19  96.8% | batch:        91 of        94\t|\tloss: 1835.22\n",
      "Training Epoch 19  97.9% | batch:        92 of        94\t|\tloss: 2078.92\n",
      "Training Epoch 19  98.9% | batch:        93 of        94\t|\tloss: 1030.03\n",
      "\n",
      "Training Epoch 20   0.0% | batch:         0 of        94\t|\tloss: 1292.84\n",
      "Training Epoch 20   1.1% | batch:         1 of        94\t|\tloss: 2787.5\n",
      "Training Epoch 20   2.1% | batch:         2 of        94\t|\tloss: 1703.15\n",
      "Training Epoch 20   3.2% | batch:         3 of        94\t|\tloss: 1382.74\n",
      "Training Epoch 20   4.3% | batch:         4 of        94\t|\tloss: 1912.36\n",
      "Training Epoch 20   5.3% | batch:         5 of        94\t|\tloss: 1673.67\n",
      "Training Epoch 20   6.4% | batch:         6 of        94\t|\tloss: 1636.17\n",
      "Training Epoch 20   7.4% | batch:         7 of        94\t|\tloss: 1983.26\n",
      "Training Epoch 20   8.5% | batch:         8 of        94\t|\tloss: 1268.53\n",
      "Training Epoch 20   9.6% | batch:         9 of        94\t|\tloss: 1642.52\n",
      "Training Epoch 20  10.6% | batch:        10 of        94\t|\tloss: 1379.58\n",
      "Training Epoch 20  11.7% | batch:        11 of        94\t|\tloss: 1265.01\n",
      "Training Epoch 20  12.8% | batch:        12 of        94\t|\tloss: 1497.95\n",
      "Training Epoch 20  13.8% | batch:        13 of        94\t|\tloss: 1990.82\n",
      "Training Epoch 20  14.9% | batch:        14 of        94\t|\tloss: 7094.6\n",
      "Training Epoch 20  16.0% | batch:        15 of        94\t|\tloss: 947.585\n",
      "Training Epoch 20  17.0% | batch:        16 of        94\t|\tloss: 1478.48\n",
      "Training Epoch 20  18.1% | batch:        17 of        94\t|\tloss: 2437.35\n",
      "Training Epoch 20  19.1% | batch:        18 of        94\t|\tloss: 1699.07\n",
      "Training Epoch 20  20.2% | batch:        19 of        94\t|\tloss: 2114.58\n",
      "Training Epoch 20  21.3% | batch:        20 of        94\t|\tloss: 2125.99\n",
      "Training Epoch 20  22.3% | batch:        21 of        94\t|\tloss: 1150\n",
      "Training Epoch 20  23.4% | batch:        22 of        94\t|\tloss: 1542.14\n",
      "Training Epoch 20  24.5% | batch:        23 of        94\t|\tloss: 1398.09\n",
      "Training Epoch 20  25.5% | batch:        24 of        94\t|\tloss: 1853.84\n",
      "Training Epoch 20  26.6% | batch:        25 of        94\t|\tloss: 1424.07\n",
      "Training Epoch 20  27.7% | batch:        26 of        94\t|\tloss: 1395.81\n",
      "Training Epoch 20  28.7% | batch:        27 of        94\t|\tloss: 2312.62\n",
      "Training Epoch 20  29.8% | batch:        28 of        94\t|\tloss: 1381.94\n",
      "Training Epoch 20  30.9% | batch:        29 of        94\t|\tloss: 1296.84\n",
      "Training Epoch 20  31.9% | batch:        30 of        94\t|\tloss: 2606.67\n",
      "Training Epoch 20  33.0% | batch:        31 of        94\t|\tloss: 2066.84\n",
      "Training Epoch 20  34.0% | batch:        32 of        94\t|\tloss: 2405.83\n",
      "Training Epoch 20  35.1% | batch:        33 of        94\t|\tloss: 1520.06\n",
      "Training Epoch 20  36.2% | batch:        34 of        94\t|\tloss: 1774.01\n",
      "Training Epoch 20  37.2% | batch:        35 of        94\t|\tloss: 1285.46\n",
      "Training Epoch 20  38.3% | batch:        36 of        94\t|\tloss: 1567.36\n",
      "Training Epoch 20  39.4% | batch:        37 of        94\t|\tloss: 1494.51\n",
      "Training Epoch 20  40.4% | batch:        38 of        94\t|\tloss: 1874.11\n",
      "Training Epoch 20  41.5% | batch:        39 of        94\t|\tloss: 2161.8\n",
      "Training Epoch 20  42.6% | batch:        40 of        94\t|\tloss: 1545.33\n",
      "Training Epoch 20  43.6% | batch:        41 of        94\t|\tloss: 1393.35\n",
      "Training Epoch 20  44.7% | batch:        42 of        94\t|\tloss: 1528.25\n",
      "Training Epoch 20  45.7% | batch:        43 of        94\t|\tloss: 1386.43\n",
      "Training Epoch 20  46.8% | batch:        44 of        94\t|\tloss: 1410.47\n",
      "Training Epoch 20  47.9% | batch:        45 of        94\t|\tloss: 2027.35\n",
      "Training Epoch 20  48.9% | batch:        46 of        94\t|\tloss: 1297.28\n",
      "Training Epoch 20  50.0% | batch:        47 of        94\t|\tloss: 2286.03\n",
      "Training Epoch 20  51.1% | batch:        48 of        94\t|\tloss: 2103.44\n",
      "Training Epoch 20  52.1% | batch:        49 of        94\t|\tloss: 4489.71\n",
      "Training Epoch 20  53.2% | batch:        50 of        94\t|\tloss: 1392.83\n",
      "Training Epoch 20  54.3% | batch:        51 of        94\t|\tloss: 1678.99\n",
      "Training Epoch 20  55.3% | batch:        52 of        94\t|\tloss: 1671.49\n",
      "Training Epoch 20  56.4% | batch:        53 of        94\t|\tloss: 1616.78\n",
      "Training Epoch 20  57.4% | batch:        54 of        94\t|\tloss: 1498.33\n",
      "Training Epoch 20  58.5% | batch:        55 of        94\t|\tloss: 1662.32\n",
      "Training Epoch 20  59.6% | batch:        56 of        94\t|\tloss: 1214.22\n",
      "Training Epoch 20  60.6% | batch:        57 of        94\t|\tloss: 1303.89\n",
      "Training Epoch 20  61.7% | batch:        58 of        94\t|\tloss: 2442.34\n",
      "Training Epoch 20  62.8% | batch:        59 of        94\t|\tloss: 1615.2\n",
      "Training Epoch 20  63.8% | batch:        60 of        94\t|\tloss: 1171.43\n",
      "Training Epoch 20  64.9% | batch:        61 of        94\t|\tloss: 1251.86\n",
      "Training Epoch 20  66.0% | batch:        62 of        94\t|\tloss: 3392.86\n",
      "Training Epoch 20  67.0% | batch:        63 of        94\t|\tloss: 1752.64\n",
      "Training Epoch 20  68.1% | batch:        64 of        94\t|\tloss: 2508.34\n",
      "Training Epoch 20  69.1% | batch:        65 of        94\t|\tloss: 1754.4\n",
      "Training Epoch 20  70.2% | batch:        66 of        94\t|\tloss: 1675.74\n",
      "Training Epoch 20  71.3% | batch:        67 of        94\t|\tloss: 1612.07\n",
      "Training Epoch 20  72.3% | batch:        68 of        94\t|\tloss: 3169.42\n",
      "Training Epoch 20  73.4% | batch:        69 of        94\t|\tloss: 1192.74\n",
      "Training Epoch 20  74.5% | batch:        70 of        94\t|\tloss: 1602.26\n",
      "Training Epoch 20  75.5% | batch:        71 of        94\t|\tloss: 1610.26\n",
      "Training Epoch 20  76.6% | batch:        72 of        94\t|\tloss: 1424.1\n",
      "Training Epoch 20  77.7% | batch:        73 of        94\t|\tloss: 1511.05\n",
      "Training Epoch 20  78.7% | batch:        74 of        94\t|\tloss: 1600.11\n",
      "Training Epoch 20  79.8% | batch:        75 of        94\t|\tloss: 1406.22\n",
      "Training Epoch 20  80.9% | batch:        76 of        94\t|\tloss: 2162.1\n",
      "Training Epoch 20  81.9% | batch:        77 of        94\t|\tloss: 1902.49\n",
      "Training Epoch 20  83.0% | batch:        78 of        94\t|\tloss: 2298.01\n",
      "Training Epoch 20  84.0% | batch:        79 of        94\t|\tloss: 1973.42\n",
      "Training Epoch 20  85.1% | batch:        80 of        94\t|\tloss: 1577.62\n",
      "Training Epoch 20  86.2% | batch:        81 of        94\t|\tloss: 1502.64\n",
      "Training Epoch 20  87.2% | batch:        82 of        94\t|\tloss: 4795.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:32,034 | INFO : Epoch 20 Training Summary: epoch: 20.000000 | loss: 1855.127020 | \n",
      "2023-05-04 16:59:32,035 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7649588584899902 seconds\n",
      "\n",
      "2023-05-04 16:59:32,036 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7850218534469604 seconds\n",
      "2023-05-04 16:59:32,037 | INFO : Avg batch train. time: 0.018989594185605963 seconds\n",
      "2023-05-04 16:59:32,038 | INFO : Avg sample train. time: 0.00014977528557198863 seconds\n",
      "2023-05-04 16:59:32,039 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 20  88.3% | batch:        83 of        94\t|\tloss: 1875.67\n",
      "Training Epoch 20  89.4% | batch:        84 of        94\t|\tloss: 1618.97\n",
      "Training Epoch 20  90.4% | batch:        85 of        94\t|\tloss: 2404.59\n",
      "Training Epoch 20  91.5% | batch:        86 of        94\t|\tloss: 2124.87\n",
      "Training Epoch 20  92.6% | batch:        87 of        94\t|\tloss: 1634.24\n",
      "Training Epoch 20  93.6% | batch:        88 of        94\t|\tloss: 1861.11\n",
      "Training Epoch 20  94.7% | batch:        89 of        94\t|\tloss: 1165.64\n",
      "Training Epoch 20  95.7% | batch:        90 of        94\t|\tloss: 1216.39\n",
      "Training Epoch 20  96.8% | batch:        91 of        94\t|\tloss: 2555.52\n",
      "Training Epoch 20  97.9% | batch:        92 of        94\t|\tloss: 1852.95\n",
      "Training Epoch 20  98.9% | batch:        93 of        94\t|\tloss: 1666.41\n",
      "\n",
      "Evaluating Epoch 20   0.0% | batch:         0 of        40\t|\tloss: 5957.51\n",
      "Evaluating Epoch 20   2.5% | batch:         1 of        40\t|\tloss: 1405.63\n",
      "Evaluating Epoch 20   5.0% | batch:         2 of        40\t|\tloss: 2814.87\n",
      "Evaluating Epoch 20   7.5% | batch:         3 of        40\t|\tloss: 6356.63\n",
      "Evaluating Epoch 20  10.0% | batch:         4 of        40\t|\tloss: 2584.02\n",
      "Evaluating Epoch 20  12.5% | batch:         5 of        40\t|\tloss: 2111.4\n",
      "Evaluating Epoch 20  15.0% | batch:         6 of        40\t|\tloss: 7137.37\n",
      "Evaluating Epoch 20  17.5% | batch:         7 of        40\t|\tloss: 2835.85\n",
      "Evaluating Epoch 20  20.0% | batch:         8 of        40\t|\tloss: 3076.83\n",
      "Evaluating Epoch 20  22.5% | batch:         9 of        40\t|\tloss: 2049.97\n",
      "Evaluating Epoch 20  25.0% | batch:        10 of        40\t|\tloss: 4527.98\n",
      "Evaluating Epoch 20  27.5% | batch:        11 of        40\t|\tloss: 1483.86\n",
      "Evaluating Epoch 20  30.0% | batch:        12 of        40\t|\tloss: 5826.94\n",
      "Evaluating Epoch 20  32.5% | batch:        13 of        40\t|\tloss: 2540.96\n",
      "Evaluating Epoch 20  35.0% | batch:        14 of        40\t|\tloss: 2010.64\n",
      "Evaluating Epoch 20  37.5% | batch:        15 of        40\t|\tloss: 3541.34\n",
      "Evaluating Epoch 20  40.0% | batch:        16 of        40\t|\tloss: 3744.82\n",
      "Evaluating Epoch 20  42.5% | batch:        17 of        40\t|\tloss: 2326.71\n",
      "Evaluating Epoch 20  45.0% | batch:        18 of        40\t|\tloss: 2412.69\n",
      "Evaluating Epoch 20  47.5% | batch:        19 of        40\t|\tloss: 5124.69\n",
      "Evaluating Epoch 20  50.0% | batch:        20 of        40\t|\tloss: 4765.76\n",
      "Evaluating Epoch 20  52.5% | batch:        21 of        40\t|\tloss: 2013.61\n",
      "Evaluating Epoch 20  55.0% | batch:        22 of        40\t|\tloss: 3944.75\n",
      "Evaluating Epoch 20  57.5% | batch:        23 of        40\t|\tloss: 2981.47\n",
      "Evaluating Epoch 20  60.0% | batch:        24 of        40\t|\tloss: 2157.42\n",
      "Evaluating Epoch 20  62.5% | batch:        25 of        40\t|\tloss: 3317.07\n",
      "Evaluating Epoch 20  65.0% | batch:        26 of        40\t|\tloss: 8633.91\n",
      "Evaluating Epoch 20  67.5% | batch:        27 of        40\t|\tloss: 3125.89\n",
      "Evaluating Epoch 20  70.0% | batch:        28 of        40\t|\tloss: 1803.58\n",
      "Evaluating Epoch 20  72.5% | batch:        29 of        40\t|\tloss: 9100.25\n",
      "Evaluating Epoch 20  75.0% | batch:        30 of        40\t|\tloss: 1904.69\n",
      "Evaluating Epoch 20  77.5% | batch:        31 of        40\t|\tloss: 1639.61\n",
      "Evaluating Epoch 20  80.0% | batch:        32 of        40\t|\tloss: 8002.25\n",
      "Evaluating Epoch 20  82.5% | batch:        33 of        40\t|\tloss: 5967.96\n",
      "Evaluating Epoch 20  85.0% | batch:        34 of        40\t|\tloss: 951.219\n",
      "Evaluating Epoch 20  87.5% | batch:        35 of        40\t|\tloss: 5105.66\n",
      "Evaluating Epoch 20  90.0% | batch:        36 of        40\t|\tloss: 4808.44\n",
      "Evaluating Epoch 20  92.5% | batch:        37 of        40\t|\tloss: 2646.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:32,492 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45214366912841797 seconds\n",
      "\n",
      "2023-05-04 16:59:32,493 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5437949420399748 seconds\n",
      "2023-05-04 16:59:32,493 | INFO : Avg batch val. time: 0.01359487355099937 seconds\n",
      "2023-05-04 16:59:32,494 | INFO : Avg sample val. time: 0.00010772483003961466 seconds\n",
      "2023-05-04 16:59:32,495 | INFO : Epoch 20 Validation Summary: epoch: 20.000000 | loss: 3797.878984 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 20  95.0% | batch:        38 of        40\t|\tloss: 3308.04\n",
      "Evaluating Epoch 20  97.5% | batch:        39 of        40\t|\tloss: 8526\n",
      "\n",
      "Training Epoch 21   0.0% | batch:         0 of        94\t|\tloss: 2414.6\n",
      "Training Epoch 21   1.1% | batch:         1 of        94\t|\tloss: 1510.35\n",
      "Training Epoch 21   2.1% | batch:         2 of        94\t|\tloss: 1976.32\n",
      "Training Epoch 21   3.2% | batch:         3 of        94\t|\tloss: 1345.77\n",
      "Training Epoch 21   4.3% | batch:         4 of        94\t|\tloss: 1227.1\n",
      "Training Epoch 21   5.3% | batch:         5 of        94\t|\tloss: 1815.02\n",
      "Training Epoch 21   6.4% | batch:         6 of        94\t|\tloss: 1468.64\n",
      "Training Epoch 21   7.4% | batch:         7 of        94\t|\tloss: 2893.12\n",
      "Training Epoch 21   8.5% | batch:         8 of        94\t|\tloss: 1547.7\n",
      "Training Epoch 21   9.6% | batch:         9 of        94\t|\tloss: 1824.13\n",
      "Training Epoch 21  10.6% | batch:        10 of        94\t|\tloss: 1540.96\n",
      "Training Epoch 21  11.7% | batch:        11 of        94\t|\tloss: 2010.97\n",
      "Training Epoch 21  12.8% | batch:        12 of        94\t|\tloss: 1262.66\n",
      "Training Epoch 21  13.8% | batch:        13 of        94\t|\tloss: 1612.65\n",
      "Training Epoch 21  14.9% | batch:        14 of        94\t|\tloss: 1839.87\n",
      "Training Epoch 21  16.0% | batch:        15 of        94\t|\tloss: 1613.65\n",
      "Training Epoch 21  17.0% | batch:        16 of        94\t|\tloss: 2116.04\n",
      "Training Epoch 21  18.1% | batch:        17 of        94\t|\tloss: 1557.5\n",
      "Training Epoch 21  19.1% | batch:        18 of        94\t|\tloss: 2168.11\n",
      "Training Epoch 21  20.2% | batch:        19 of        94\t|\tloss: 1559.16\n",
      "Training Epoch 21  21.3% | batch:        20 of        94\t|\tloss: 2496.03\n",
      "Training Epoch 21  22.3% | batch:        21 of        94\t|\tloss: 4597.49\n",
      "Training Epoch 21  23.4% | batch:        22 of        94\t|\tloss: 3621.91\n",
      "Training Epoch 21  24.5% | batch:        23 of        94\t|\tloss: 1304.88\n",
      "Training Epoch 21  25.5% | batch:        24 of        94\t|\tloss: 945.842\n",
      "Training Epoch 21  26.6% | batch:        25 of        94\t|\tloss: 1724.77\n",
      "Training Epoch 21  27.7% | batch:        26 of        94\t|\tloss: 943.867\n",
      "Training Epoch 21  28.7% | batch:        27 of        94\t|\tloss: 4295.14\n",
      "Training Epoch 21  29.8% | batch:        28 of        94\t|\tloss: 1134.09\n",
      "Training Epoch 21  30.9% | batch:        29 of        94\t|\tloss: 2954.98\n",
      "Training Epoch 21  31.9% | batch:        30 of        94\t|\tloss: 3026.46\n",
      "Training Epoch 21  33.0% | batch:        31 of        94\t|\tloss: 2278.4\n",
      "Training Epoch 21  34.0% | batch:        32 of        94\t|\tloss: 1185.26\n",
      "Training Epoch 21  35.1% | batch:        33 of        94\t|\tloss: 1101.31\n",
      "Training Epoch 21  36.2% | batch:        34 of        94\t|\tloss: 1155.85\n",
      "Training Epoch 21  37.2% | batch:        35 of        94\t|\tloss: 1648.82\n",
      "Training Epoch 21  38.3% | batch:        36 of        94\t|\tloss: 2084.4\n",
      "Training Epoch 21  39.4% | batch:        37 of        94\t|\tloss: 1214.08\n",
      "Training Epoch 21  40.4% | batch:        38 of        94\t|\tloss: 1590.84\n",
      "Training Epoch 21  41.5% | batch:        39 of        94\t|\tloss: 1867.6\n",
      "Training Epoch 21  42.6% | batch:        40 of        94\t|\tloss: 2083.07\n",
      "Training Epoch 21  43.6% | batch:        41 of        94\t|\tloss: 1607.39\n",
      "Training Epoch 21  44.7% | batch:        42 of        94\t|\tloss: 2116.33\n",
      "Training Epoch 21  45.7% | batch:        43 of        94\t|\tloss: 1494.57\n",
      "Training Epoch 21  46.8% | batch:        44 of        94\t|\tloss: 1646.59\n",
      "Training Epoch 21  47.9% | batch:        45 of        94\t|\tloss: 865.68\n",
      "Training Epoch 21  48.9% | batch:        46 of        94\t|\tloss: 1338.34\n",
      "Training Epoch 21  50.0% | batch:        47 of        94\t|\tloss: 1041.07\n",
      "Training Epoch 21  51.1% | batch:        48 of        94\t|\tloss: 1945.52\n",
      "Training Epoch 21  52.1% | batch:        49 of        94\t|\tloss: 1377.69\n",
      "Training Epoch 21  53.2% | batch:        50 of        94\t|\tloss: 1502.47\n",
      "Training Epoch 21  54.3% | batch:        51 of        94\t|\tloss: 1635.74\n",
      "Training Epoch 21  55.3% | batch:        52 of        94\t|\tloss: 1392.75\n",
      "Training Epoch 21  56.4% | batch:        53 of        94\t|\tloss: 1326.76\n",
      "Training Epoch 21  57.4% | batch:        54 of        94\t|\tloss: 1974.77\n",
      "Training Epoch 21  58.5% | batch:        55 of        94\t|\tloss: 3657.37\n",
      "Training Epoch 21  59.6% | batch:        56 of        94\t|\tloss: 1691.2\n",
      "Training Epoch 21  60.6% | batch:        57 of        94\t|\tloss: 1576.06\n",
      "Training Epoch 21  61.7% | batch:        58 of        94\t|\tloss: 1066.16\n",
      "Training Epoch 21  62.8% | batch:        59 of        94\t|\tloss: 1612.02\n",
      "Training Epoch 21  63.8% | batch:        60 of        94\t|\tloss: 2027.07\n",
      "Training Epoch 21  64.9% | batch:        61 of        94\t|\tloss: 1738.36\n",
      "Training Epoch 21  66.0% | batch:        62 of        94\t|\tloss: 1828.06\n",
      "Training Epoch 21  67.0% | batch:        63 of        94\t|\tloss: 1585.78\n",
      "Training Epoch 21  68.1% | batch:        64 of        94\t|\tloss: 2442.48\n",
      "Training Epoch 21  69.1% | batch:        65 of        94\t|\tloss: 1839.12\n",
      "Training Epoch 21  70.2% | batch:        66 of        94\t|\tloss: 1622.01\n",
      "Training Epoch 21  71.3% | batch:        67 of        94\t|\tloss: 2229.26\n",
      "Training Epoch 21  72.3% | batch:        68 of        94\t|\tloss: 2021.34\n",
      "Training Epoch 21  73.4% | batch:        69 of        94\t|\tloss: 1805.33\n",
      "Training Epoch 21  74.5% | batch:        70 of        94\t|\tloss: 1934.77\n",
      "Training Epoch 21  75.5% | batch:        71 of        94\t|\tloss: 1234.53\n",
      "Training Epoch 21  76.6% | batch:        72 of        94\t|\tloss: 1453.8\n",
      "Training Epoch 21  77.7% | batch:        73 of        94\t|\tloss: 1789.57\n",
      "Training Epoch 21  78.7% | batch:        74 of        94\t|\tloss: 1547.19\n",
      "Training Epoch 21  79.8% | batch:        75 of        94\t|\tloss: 1180.16\n",
      "Training Epoch 21  80.9% | batch:        76 of        94\t|\tloss: 2611.04\n",
      "Training Epoch 21  81.9% | batch:        77 of        94\t|\tloss: 1369.94\n",
      "Training Epoch 21  83.0% | batch:        78 of        94\t|\tloss: 2350.59\n",
      "Training Epoch 21  84.0% | batch:        79 of        94\t|\tloss: 3662.44\n",
      "Training Epoch 21  85.1% | batch:        80 of        94\t|\tloss: 2903.64\n",
      "Training Epoch 21  86.2% | batch:        81 of        94\t|\tloss: 1342.03\n",
      "Training Epoch 21  87.2% | batch:        82 of        94\t|\tloss: 1554.82\n",
      "Training Epoch 21  88.3% | batch:        83 of        94\t|\tloss: 2706.2\n",
      "Training Epoch 21  89.4% | batch:        84 of        94\t|\tloss: 2277.37\n",
      "Training Epoch 21  90.4% | batch:        85 of        94\t|\tloss: 1187.71\n",
      "Training Epoch 21  91.5% | batch:        86 of        94\t|\tloss: 2097.98\n",
      "Training Epoch 21  92.6% | batch:        87 of        94\t|\tloss: 3930.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:34,262 | INFO : Epoch 21 Training Summary: epoch: 21.000000 | loss: 1885.288044 | \n",
      "2023-05-04 16:59:34,263 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7455921173095703 seconds\n",
      "\n",
      "2023-05-04 16:59:34,264 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7831442469642276 seconds\n",
      "2023-05-04 16:59:34,264 | INFO : Avg batch train. time: 0.018969619648555612 seconds\n",
      "2023-05-04 16:59:34,265 | INFO : Avg sample train. time: 0.0001496177418160956 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 21  93.6% | batch:        88 of        94\t|\tloss: 1944.05\n",
      "Training Epoch 21  94.7% | batch:        89 of        94\t|\tloss: 1741.85\n",
      "Training Epoch 21  95.7% | batch:        90 of        94\t|\tloss: 2702.15\n",
      "Training Epoch 21  96.8% | batch:        91 of        94\t|\tloss: 1812.98\n",
      "Training Epoch 21  97.9% | batch:        92 of        94\t|\tloss: 1464.26\n",
      "Training Epoch 21  98.9% | batch:        93 of        94\t|\tloss: 1566.24\n",
      "\n",
      "Training Epoch 22   0.0% | batch:         0 of        94\t|\tloss: 1505.35\n",
      "Training Epoch 22   1.1% | batch:         1 of        94\t|\tloss: 1428.27\n",
      "Training Epoch 22   2.1% | batch:         2 of        94\t|\tloss: 950.562\n",
      "Training Epoch 22   3.2% | batch:         3 of        94\t|\tloss: 1313.44\n",
      "Training Epoch 22   4.3% | batch:         4 of        94\t|\tloss: 2459.27\n",
      "Training Epoch 22   5.3% | batch:         5 of        94\t|\tloss: 2493.05\n",
      "Training Epoch 22   6.4% | batch:         6 of        94\t|\tloss: 2005.21\n",
      "Training Epoch 22   7.4% | batch:         7 of        94\t|\tloss: 1577.72\n",
      "Training Epoch 22   8.5% | batch:         8 of        94\t|\tloss: 1607.36\n",
      "Training Epoch 22   9.6% | batch:         9 of        94\t|\tloss: 1107.04\n",
      "Training Epoch 22  10.6% | batch:        10 of        94\t|\tloss: 1242.02\n",
      "Training Epoch 22  11.7% | batch:        11 of        94\t|\tloss: 1539.96\n",
      "Training Epoch 22  12.8% | batch:        12 of        94\t|\tloss: 2029.26\n",
      "Training Epoch 22  13.8% | batch:        13 of        94\t|\tloss: 2346.42\n",
      "Training Epoch 22  14.9% | batch:        14 of        94\t|\tloss: 1233.09\n",
      "Training Epoch 22  16.0% | batch:        15 of        94\t|\tloss: 1354.21\n",
      "Training Epoch 22  17.0% | batch:        16 of        94\t|\tloss: 1314.32\n",
      "Training Epoch 22  18.1% | batch:        17 of        94\t|\tloss: 1215.9\n",
      "Training Epoch 22  19.1% | batch:        18 of        94\t|\tloss: 1453.08\n",
      "Training Epoch 22  20.2% | batch:        19 of        94\t|\tloss: 2035.42\n",
      "Training Epoch 22  21.3% | batch:        20 of        94\t|\tloss: 1977.7\n",
      "Training Epoch 22  22.3% | batch:        21 of        94\t|\tloss: 1834.94\n",
      "Training Epoch 22  23.4% | batch:        22 of        94\t|\tloss: 2150.73\n",
      "Training Epoch 22  24.5% | batch:        23 of        94\t|\tloss: 1513.52\n",
      "Training Epoch 22  25.5% | batch:        24 of        94\t|\tloss: 1349.88\n",
      "Training Epoch 22  26.6% | batch:        25 of        94\t|\tloss: 1739.5\n",
      "Training Epoch 22  27.7% | batch:        26 of        94\t|\tloss: 1426.44\n",
      "Training Epoch 22  28.7% | batch:        27 of        94\t|\tloss: 1049.89\n",
      "Training Epoch 22  29.8% | batch:        28 of        94\t|\tloss: 1585.58\n",
      "Training Epoch 22  30.9% | batch:        29 of        94\t|\tloss: 1239.2\n",
      "Training Epoch 22  31.9% | batch:        30 of        94\t|\tloss: 2385.03\n",
      "Training Epoch 22  33.0% | batch:        31 of        94\t|\tloss: 2153.28\n",
      "Training Epoch 22  34.0% | batch:        32 of        94\t|\tloss: 1760.62\n",
      "Training Epoch 22  35.1% | batch:        33 of        94\t|\tloss: 1460.18\n",
      "Training Epoch 22  36.2% | batch:        34 of        94\t|\tloss: 1224.3\n",
      "Training Epoch 22  37.2% | batch:        35 of        94\t|\tloss: 2504.29\n",
      "Training Epoch 22  38.3% | batch:        36 of        94\t|\tloss: 1427.63\n",
      "Training Epoch 22  39.4% | batch:        37 of        94\t|\tloss: 1869.07\n",
      "Training Epoch 22  40.4% | batch:        38 of        94\t|\tloss: 2903\n",
      "Training Epoch 22  41.5% | batch:        39 of        94\t|\tloss: 1757.26\n",
      "Training Epoch 22  42.6% | batch:        40 of        94\t|\tloss: 1598.8\n",
      "Training Epoch 22  43.6% | batch:        41 of        94\t|\tloss: 1442.03\n",
      "Training Epoch 22  44.7% | batch:        42 of        94\t|\tloss: 2041.33\n",
      "Training Epoch 22  45.7% | batch:        43 of        94\t|\tloss: 1184.2\n",
      "Training Epoch 22  46.8% | batch:        44 of        94\t|\tloss: 2303.65\n",
      "Training Epoch 22  47.9% | batch:        45 of        94\t|\tloss: 1634.98\n",
      "Training Epoch 22  48.9% | batch:        46 of        94\t|\tloss: 1385.07\n",
      "Training Epoch 22  50.0% | batch:        47 of        94\t|\tloss: 1544.56\n",
      "Training Epoch 22  51.1% | batch:        48 of        94\t|\tloss: 2139.8\n",
      "Training Epoch 22  52.1% | batch:        49 of        94\t|\tloss: 2896.1\n",
      "Training Epoch 22  53.2% | batch:        50 of        94\t|\tloss: 2555.09\n",
      "Training Epoch 22  54.3% | batch:        51 of        94\t|\tloss: 1082.56\n",
      "Training Epoch 22  55.3% | batch:        52 of        94\t|\tloss: 3701.41\n",
      "Training Epoch 22  56.4% | batch:        53 of        94\t|\tloss: 1119.39\n",
      "Training Epoch 22  57.4% | batch:        54 of        94\t|\tloss: 1225.85\n",
      "Training Epoch 22  58.5% | batch:        55 of        94\t|\tloss: 1293.61\n",
      "Training Epoch 22  59.6% | batch:        56 of        94\t|\tloss: 1741.09\n",
      "Training Epoch 22  60.6% | batch:        57 of        94\t|\tloss: 1236.72\n",
      "Training Epoch 22  61.7% | batch:        58 of        94\t|\tloss: 1575.48\n",
      "Training Epoch 22  62.8% | batch:        59 of        94\t|\tloss: 1528.95\n",
      "Training Epoch 22  63.8% | batch:        60 of        94\t|\tloss: 3535.45\n",
      "Training Epoch 22  64.9% | batch:        61 of        94\t|\tloss: 1346.14\n",
      "Training Epoch 22  66.0% | batch:        62 of        94\t|\tloss: 1119.63\n",
      "Training Epoch 22  67.0% | batch:        63 of        94\t|\tloss: 1857.6\n",
      "Training Epoch 22  68.1% | batch:        64 of        94\t|\tloss: 2725.48\n",
      "Training Epoch 22  69.1% | batch:        65 of        94\t|\tloss: 1366.66\n",
      "Training Epoch 22  70.2% | batch:        66 of        94\t|\tloss: 1731.41\n",
      "Training Epoch 22  71.3% | batch:        67 of        94\t|\tloss: 1321.13\n",
      "Training Epoch 22  72.3% | batch:        68 of        94\t|\tloss: 1123.29\n",
      "Training Epoch 22  73.4% | batch:        69 of        94\t|\tloss: 1701.52\n",
      "Training Epoch 22  74.5% | batch:        70 of        94\t|\tloss: 2486.62\n",
      "Training Epoch 22  75.5% | batch:        71 of        94\t|\tloss: 1601.81\n",
      "Training Epoch 22  76.6% | batch:        72 of        94\t|\tloss: 1312.27\n",
      "Training Epoch 22  77.7% | batch:        73 of        94\t|\tloss: 1477.74\n",
      "Training Epoch 22  78.7% | batch:        74 of        94\t|\tloss: 4697.7\n",
      "Training Epoch 22  79.8% | batch:        75 of        94\t|\tloss: 1341.42\n",
      "Training Epoch 22  80.9% | batch:        76 of        94\t|\tloss: 1961.22\n",
      "Training Epoch 22  81.9% | batch:        77 of        94\t|\tloss: 1697.16\n",
      "Training Epoch 22  83.0% | batch:        78 of        94\t|\tloss: 4245.82\n",
      "Training Epoch 22  84.0% | batch:        79 of        94\t|\tloss: 1376.28\n",
      "Training Epoch 22  85.1% | batch:        80 of        94\t|\tloss: 1444.93\n",
      "Training Epoch 22  86.2% | batch:        81 of        94\t|\tloss: 2975.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:36,084 | INFO : Epoch 22 Training Summary: epoch: 22.000000 | loss: 1823.558616 | \n",
      "2023-05-04 16:59:36,085 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7985351085662842 seconds\n",
      "\n",
      "2023-05-04 16:59:36,086 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.783843831582503 seconds\n",
      "2023-05-04 16:59:36,086 | INFO : Avg batch train. time: 0.018977062038111732 seconds\n",
      "2023-05-04 16:59:36,087 | INFO : Avg sample train. time: 0.00014967644164981566 seconds\n",
      "2023-05-04 16:59:36,087 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 22  87.2% | batch:        82 of        94\t|\tloss: 1040.72\n",
      "Training Epoch 22  88.3% | batch:        83 of        94\t|\tloss: 2013.56\n",
      "Training Epoch 22  89.4% | batch:        84 of        94\t|\tloss: 2780.68\n",
      "Training Epoch 22  90.4% | batch:        85 of        94\t|\tloss: 1699.5\n",
      "Training Epoch 22  91.5% | batch:        86 of        94\t|\tloss: 1978.06\n",
      "Training Epoch 22  92.6% | batch:        87 of        94\t|\tloss: 1484.9\n",
      "Training Epoch 22  93.6% | batch:        88 of        94\t|\tloss: 3624.72\n",
      "Training Epoch 22  94.7% | batch:        89 of        94\t|\tloss: 1490.87\n",
      "Training Epoch 22  95.7% | batch:        90 of        94\t|\tloss: 1301.27\n",
      "Training Epoch 22  96.8% | batch:        91 of        94\t|\tloss: 1852.67\n",
      "Training Epoch 22  97.9% | batch:        92 of        94\t|\tloss: 3178.34\n",
      "Training Epoch 22  98.9% | batch:        93 of        94\t|\tloss: 1320.19\n",
      "\n",
      "Evaluating Epoch 22   0.0% | batch:         0 of        40\t|\tloss: 7297.59\n",
      "Evaluating Epoch 22   2.5% | batch:         1 of        40\t|\tloss: 968.631\n",
      "Evaluating Epoch 22   5.0% | batch:         2 of        40\t|\tloss: 3603.94\n",
      "Evaluating Epoch 22   7.5% | batch:         3 of        40\t|\tloss: 6754.26\n",
      "Evaluating Epoch 22  10.0% | batch:         4 of        40\t|\tloss: 1870.5\n",
      "Evaluating Epoch 22  12.5% | batch:         5 of        40\t|\tloss: 1858.66\n",
      "Evaluating Epoch 22  15.0% | batch:         6 of        40\t|\tloss: 7148.73\n",
      "Evaluating Epoch 22  17.5% | batch:         7 of        40\t|\tloss: 2412.02\n",
      "Evaluating Epoch 22  20.0% | batch:         8 of        40\t|\tloss: 2432.65\n",
      "Evaluating Epoch 22  22.5% | batch:         9 of        40\t|\tloss: 2046.11\n",
      "Evaluating Epoch 22  25.0% | batch:        10 of        40\t|\tloss: 4482.37\n",
      "Evaluating Epoch 22  27.5% | batch:        11 of        40\t|\tloss: 1292.88\n",
      "Evaluating Epoch 22  30.0% | batch:        12 of        40\t|\tloss: 5674.36\n",
      "Evaluating Epoch 22  32.5% | batch:        13 of        40\t|\tloss: 2822.47\n",
      "Evaluating Epoch 22  35.0% | batch:        14 of        40\t|\tloss: 1882.03\n",
      "Evaluating Epoch 22  37.5% | batch:        15 of        40\t|\tloss: 3330.2\n",
      "Evaluating Epoch 22  40.0% | batch:        16 of        40\t|\tloss: 5433.91\n",
      "Evaluating Epoch 22  42.5% | batch:        17 of        40\t|\tloss: 2447.42\n",
      "Evaluating Epoch 22  45.0% | batch:        18 of        40\t|\tloss: 2384.21\n",
      "Evaluating Epoch 22  47.5% | batch:        19 of        40\t|\tloss: 4413.98\n",
      "Evaluating Epoch 22  50.0% | batch:        20 of        40\t|\tloss: 4462.67\n",
      "Evaluating Epoch 22  52.5% | batch:        21 of        40\t|\tloss: 1096.56\n",
      "Evaluating Epoch 22  55.0% | batch:        22 of        40\t|\tloss: 4796.71\n",
      "Evaluating Epoch 22  57.5% | batch:        23 of        40\t|\tloss: 3191.44\n",
      "Evaluating Epoch 22  60.0% | batch:        24 of        40\t|\tloss: 1483.71\n",
      "Evaluating Epoch 22  62.5% | batch:        25 of        40\t|\tloss: 3046.23\n",
      "Evaluating Epoch 22  65.0% | batch:        26 of        40\t|\tloss: 8504.43\n",
      "Evaluating Epoch 22  67.5% | batch:        27 of        40\t|\tloss: 2682.98\n",
      "Evaluating Epoch 22  70.0% | batch:        28 of        40\t|\tloss: 1912.68\n",
      "Evaluating Epoch 22  72.5% | batch:        29 of        40\t|\tloss: 8887.89\n",
      "Evaluating Epoch 22  75.0% | batch:        30 of        40\t|\tloss: 2068.7\n",
      "Evaluating Epoch 22  77.5% | batch:        31 of        40\t|\tloss: 1693.64\n",
      "Evaluating Epoch 22  80.0% | batch:        32 of        40\t|\tloss: 8664.19\n",
      "Evaluating Epoch 22  82.5% | batch:        33 of        40\t|\tloss: 6418.32\n",
      "Evaluating Epoch 22  85.0% | batch:        34 of        40\t|\tloss: 1062.67\n",
      "Evaluating Epoch 22  87.5% | batch:        35 of        40\t|\tloss: 5757.04\n",
      "Evaluating Epoch 22  90.0% | batch:        36 of        40\t|\tloss: 5509.4\n",
      "Evaluating Epoch 22  92.5% | batch:        37 of        40\t|\tloss: 2462.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:36,538 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45043468475341797 seconds\n",
      "\n",
      "2023-05-04 16:59:36,539 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5432583888371786 seconds\n",
      "2023-05-04 16:59:36,540 | INFO : Avg batch val. time: 0.013581459720929464 seconds\n",
      "2023-05-04 16:59:36,540 | INFO : Avg sample val. time: 0.00010761853978549496 seconds\n",
      "2023-05-04 16:59:36,541 | INFO : Epoch 22 Validation Summary: epoch: 22.000000 | loss: 3843.169482 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 22  95.0% | batch:        38 of        40\t|\tloss: 3226.86\n",
      "Evaluating Epoch 22  97.5% | batch:        39 of        40\t|\tloss: 9323.63\n",
      "\n",
      "Training Epoch 23   0.0% | batch:         0 of        94\t|\tloss: 1302.63\n",
      "Training Epoch 23   1.1% | batch:         1 of        94\t|\tloss: 1458.24\n",
      "Training Epoch 23   2.1% | batch:         2 of        94\t|\tloss: 1143.04\n",
      "Training Epoch 23   3.2% | batch:         3 of        94\t|\tloss: 3878.87\n",
      "Training Epoch 23   4.3% | batch:         4 of        94\t|\tloss: 1616.07\n",
      "Training Epoch 23   5.3% | batch:         5 of        94\t|\tloss: 1637.83\n",
      "Training Epoch 23   6.4% | batch:         6 of        94\t|\tloss: 1738.61\n",
      "Training Epoch 23   7.4% | batch:         7 of        94\t|\tloss: 1480.1\n",
      "Training Epoch 23   8.5% | batch:         8 of        94\t|\tloss: 1580.88\n",
      "Training Epoch 23   9.6% | batch:         9 of        94\t|\tloss: 1723.2\n",
      "Training Epoch 23  10.6% | batch:        10 of        94\t|\tloss: 1793.3\n",
      "Training Epoch 23  11.7% | batch:        11 of        94\t|\tloss: 1535.84\n",
      "Training Epoch 23  12.8% | batch:        12 of        94\t|\tloss: 3062.71\n",
      "Training Epoch 23  13.8% | batch:        13 of        94\t|\tloss: 2111.92\n",
      "Training Epoch 23  14.9% | batch:        14 of        94\t|\tloss: 2530.62\n",
      "Training Epoch 23  16.0% | batch:        15 of        94\t|\tloss: 1225.87\n",
      "Training Epoch 23  17.0% | batch:        16 of        94\t|\tloss: 3124.43\n",
      "Training Epoch 23  18.1% | batch:        17 of        94\t|\tloss: 3550.62\n",
      "Training Epoch 23  19.1% | batch:        18 of        94\t|\tloss: 1204.45\n",
      "Training Epoch 23  20.2% | batch:        19 of        94\t|\tloss: 6016.27\n",
      "Training Epoch 23  21.3% | batch:        20 of        94\t|\tloss: 2484.61\n",
      "Training Epoch 23  22.3% | batch:        21 of        94\t|\tloss: 1555.08\n",
      "Training Epoch 23  23.4% | batch:        22 of        94\t|\tloss: 1455.36\n",
      "Training Epoch 23  24.5% | batch:        23 of        94\t|\tloss: 1326.29\n",
      "Training Epoch 23  25.5% | batch:        24 of        94\t|\tloss: 1174.46\n",
      "Training Epoch 23  26.6% | batch:        25 of        94\t|\tloss: 1174.49\n",
      "Training Epoch 23  27.7% | batch:        26 of        94\t|\tloss: 1541.27\n",
      "Training Epoch 23  28.7% | batch:        27 of        94\t|\tloss: 1804.13\n",
      "Training Epoch 23  29.8% | batch:        28 of        94\t|\tloss: 1176.49\n",
      "Training Epoch 23  30.9% | batch:        29 of        94\t|\tloss: 1340.91\n",
      "Training Epoch 23  31.9% | batch:        30 of        94\t|\tloss: 1160.59\n",
      "Training Epoch 23  33.0% | batch:        31 of        94\t|\tloss: 1213.27\n",
      "Training Epoch 23  34.0% | batch:        32 of        94\t|\tloss: 2186.85\n",
      "Training Epoch 23  35.1% | batch:        33 of        94\t|\tloss: 2033.76\n",
      "Training Epoch 23  36.2% | batch:        34 of        94\t|\tloss: 1592.56\n",
      "Training Epoch 23  37.2% | batch:        35 of        94\t|\tloss: 1563.36\n",
      "Training Epoch 23  38.3% | batch:        36 of        94\t|\tloss: 1064.45\n",
      "Training Epoch 23  39.4% | batch:        37 of        94\t|\tloss: 1093.47\n",
      "Training Epoch 23  40.4% | batch:        38 of        94\t|\tloss: 1317.71\n",
      "Training Epoch 23  41.5% | batch:        39 of        94\t|\tloss: 1487.32\n",
      "Training Epoch 23  42.6% | batch:        40 of        94\t|\tloss: 1068.33\n",
      "Training Epoch 23  43.6% | batch:        41 of        94\t|\tloss: 1823.01\n",
      "Training Epoch 23  44.7% | batch:        42 of        94\t|\tloss: 1006.77\n",
      "Training Epoch 23  45.7% | batch:        43 of        94\t|\tloss: 1690.82\n",
      "Training Epoch 23  46.8% | batch:        44 of        94\t|\tloss: 1191.93\n",
      "Training Epoch 23  47.9% | batch:        45 of        94\t|\tloss: 1352.42\n",
      "Training Epoch 23  48.9% | batch:        46 of        94\t|\tloss: 1330.03\n",
      "Training Epoch 23  50.0% | batch:        47 of        94\t|\tloss: 1475.16\n",
      "Training Epoch 23  51.1% | batch:        48 of        94\t|\tloss: 2383.63\n",
      "Training Epoch 23  52.1% | batch:        49 of        94\t|\tloss: 1973.97\n",
      "Training Epoch 23  53.2% | batch:        50 of        94\t|\tloss: 1575.33\n",
      "Training Epoch 23  54.3% | batch:        51 of        94\t|\tloss: 1621.39\n",
      "Training Epoch 23  55.3% | batch:        52 of        94\t|\tloss: 1566.87\n",
      "Training Epoch 23  56.4% | batch:        53 of        94\t|\tloss: 1616.94\n",
      "Training Epoch 23  57.4% | batch:        54 of        94\t|\tloss: 3000.03\n",
      "Training Epoch 23  58.5% | batch:        55 of        94\t|\tloss: 3174.54\n",
      "Training Epoch 23  59.6% | batch:        56 of        94\t|\tloss: 2244.72\n",
      "Training Epoch 23  60.6% | batch:        57 of        94\t|\tloss: 1388.43\n",
      "Training Epoch 23  61.7% | batch:        58 of        94\t|\tloss: 1340.82\n",
      "Training Epoch 23  62.8% | batch:        59 of        94\t|\tloss: 1750.21\n",
      "Training Epoch 23  63.8% | batch:        60 of        94\t|\tloss: 1543.21\n",
      "Training Epoch 23  64.9% | batch:        61 of        94\t|\tloss: 1714.55\n",
      "Training Epoch 23  66.0% | batch:        62 of        94\t|\tloss: 1637.54\n",
      "Training Epoch 23  67.0% | batch:        63 of        94\t|\tloss: 1865.76\n",
      "Training Epoch 23  68.1% | batch:        64 of        94\t|\tloss: 2094.76\n",
      "Training Epoch 23  69.1% | batch:        65 of        94\t|\tloss: 1539.62\n",
      "Training Epoch 23  70.2% | batch:        66 of        94\t|\tloss: 1054.44\n",
      "Training Epoch 23  71.3% | batch:        67 of        94\t|\tloss: 1940.6\n",
      "Training Epoch 23  72.3% | batch:        68 of        94\t|\tloss: 1420.63\n",
      "Training Epoch 23  73.4% | batch:        69 of        94\t|\tloss: 1163.33\n",
      "Training Epoch 23  74.5% | batch:        70 of        94\t|\tloss: 1838.26\n",
      "Training Epoch 23  75.5% | batch:        71 of        94\t|\tloss: 1192.14\n",
      "Training Epoch 23  76.6% | batch:        72 of        94\t|\tloss: 2940.22\n",
      "Training Epoch 23  77.7% | batch:        73 of        94\t|\tloss: 2198.99\n",
      "Training Epoch 23  78.7% | batch:        74 of        94\t|\tloss: 2154.14\n",
      "Training Epoch 23  79.8% | batch:        75 of        94\t|\tloss: 1434.44\n",
      "Training Epoch 23  80.9% | batch:        76 of        94\t|\tloss: 1128.38\n",
      "Training Epoch 23  81.9% | batch:        77 of        94\t|\tloss: 2062.85\n",
      "Training Epoch 23  83.0% | batch:        78 of        94\t|\tloss: 2946.56\n",
      "Training Epoch 23  84.0% | batch:        79 of        94\t|\tloss: 1544.94\n",
      "Training Epoch 23  85.1% | batch:        80 of        94\t|\tloss: 1904.59\n",
      "Training Epoch 23  86.2% | batch:        81 of        94\t|\tloss: 1374.5\n",
      "Training Epoch 23  87.2% | batch:        82 of        94\t|\tloss: 1826.8\n",
      "Training Epoch 23  88.3% | batch:        83 of        94\t|\tloss: 2346.48\n",
      "Training Epoch 23  89.4% | batch:        84 of        94\t|\tloss: 3726.1\n",
      "Training Epoch 23  90.4% | batch:        85 of        94\t|\tloss: 1909.12\n",
      "Training Epoch 23  91.5% | batch:        86 of        94\t|\tloss: 1371.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:38,346 | INFO : Epoch 23 Training Summary: epoch: 23.000000 | loss: 1804.458165 | \n",
      "2023-05-04 16:59:38,347 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7843775749206543 seconds\n",
      "\n",
      "2023-05-04 16:59:38,348 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7838670378145964 seconds\n",
      "2023-05-04 16:59:38,349 | INFO : Avg batch train. time: 0.01897730891292124 seconds\n",
      "2023-05-04 16:59:38,349 | INFO : Avg sample train. time: 0.00014967838880807153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 23  92.6% | batch:        87 of        94\t|\tloss: 1144.49\n",
      "Training Epoch 23  93.6% | batch:        88 of        94\t|\tloss: 2325.11\n",
      "Training Epoch 23  94.7% | batch:        89 of        94\t|\tloss: 2090.04\n",
      "Training Epoch 23  95.7% | batch:        90 of        94\t|\tloss: 1345.92\n",
      "Training Epoch 23  96.8% | batch:        91 of        94\t|\tloss: 1211.28\n",
      "Training Epoch 23  97.9% | batch:        92 of        94\t|\tloss: 1805.1\n",
      "Training Epoch 23  98.9% | batch:        93 of        94\t|\tloss: 1627.45\n",
      "\n",
      "Training Epoch 24   0.0% | batch:         0 of        94\t|\tloss: 2005.92\n",
      "Training Epoch 24   1.1% | batch:         1 of        94\t|\tloss: 1470.72\n",
      "Training Epoch 24   2.1% | batch:         2 of        94\t|\tloss: 1648.23\n",
      "Training Epoch 24   3.2% | batch:         3 of        94\t|\tloss: 1883.61\n",
      "Training Epoch 24   4.3% | batch:         4 of        94\t|\tloss: 2004.92\n",
      "Training Epoch 24   5.3% | batch:         5 of        94\t|\tloss: 1464.57\n",
      "Training Epoch 24   6.4% | batch:         6 of        94\t|\tloss: 1506.51\n",
      "Training Epoch 24   7.4% | batch:         7 of        94\t|\tloss: 1657.01\n",
      "Training Epoch 24   8.5% | batch:         8 of        94\t|\tloss: 1574.35\n",
      "Training Epoch 24   9.6% | batch:         9 of        94\t|\tloss: 1794.07\n",
      "Training Epoch 24  10.6% | batch:        10 of        94\t|\tloss: 1507.97\n",
      "Training Epoch 24  11.7% | batch:        11 of        94\t|\tloss: 1611.36\n",
      "Training Epoch 24  12.8% | batch:        12 of        94\t|\tloss: 1258.11\n",
      "Training Epoch 24  13.8% | batch:        13 of        94\t|\tloss: 1400.67\n",
      "Training Epoch 24  14.9% | batch:        14 of        94\t|\tloss: 1134.21\n",
      "Training Epoch 24  16.0% | batch:        15 of        94\t|\tloss: 1465.58\n",
      "Training Epoch 24  17.0% | batch:        16 of        94\t|\tloss: 1487.55\n",
      "Training Epoch 24  18.1% | batch:        17 of        94\t|\tloss: 1533.69\n",
      "Training Epoch 24  19.1% | batch:        18 of        94\t|\tloss: 1777.31\n",
      "Training Epoch 24  20.2% | batch:        19 of        94\t|\tloss: 1374.66\n",
      "Training Epoch 24  21.3% | batch:        20 of        94\t|\tloss: 2008.5\n",
      "Training Epoch 24  22.3% | batch:        21 of        94\t|\tloss: 1189.96\n",
      "Training Epoch 24  23.4% | batch:        22 of        94\t|\tloss: 1050.75\n",
      "Training Epoch 24  24.5% | batch:        23 of        94\t|\tloss: 1302.34\n",
      "Training Epoch 24  25.5% | batch:        24 of        94\t|\tloss: 2500.49\n",
      "Training Epoch 24  26.6% | batch:        25 of        94\t|\tloss: 1535.03\n",
      "Training Epoch 24  27.7% | batch:        26 of        94\t|\tloss: 1780.93\n",
      "Training Epoch 24  28.7% | batch:        27 of        94\t|\tloss: 1724.02\n",
      "Training Epoch 24  29.8% | batch:        28 of        94\t|\tloss: 3218.08\n",
      "Training Epoch 24  30.9% | batch:        29 of        94\t|\tloss: 2070.6\n",
      "Training Epoch 24  31.9% | batch:        30 of        94\t|\tloss: 982.811\n",
      "Training Epoch 24  33.0% | batch:        31 of        94\t|\tloss: 1305.75\n",
      "Training Epoch 24  34.0% | batch:        32 of        94\t|\tloss: 1265.46\n",
      "Training Epoch 24  35.1% | batch:        33 of        94\t|\tloss: 1576.18\n",
      "Training Epoch 24  36.2% | batch:        34 of        94\t|\tloss: 1228.7\n",
      "Training Epoch 24  37.2% | batch:        35 of        94\t|\tloss: 1822.49\n",
      "Training Epoch 24  38.3% | batch:        36 of        94\t|\tloss: 1699.96\n",
      "Training Epoch 24  39.4% | batch:        37 of        94\t|\tloss: 1976.42\n",
      "Training Epoch 24  40.4% | batch:        38 of        94\t|\tloss: 1490.4\n",
      "Training Epoch 24  41.5% | batch:        39 of        94\t|\tloss: 2619.71\n",
      "Training Epoch 24  42.6% | batch:        40 of        94\t|\tloss: 1727.78\n",
      "Training Epoch 24  43.6% | batch:        41 of        94\t|\tloss: 1270.29\n",
      "Training Epoch 24  44.7% | batch:        42 of        94\t|\tloss: 1731.65\n",
      "Training Epoch 24  45.7% | batch:        43 of        94\t|\tloss: 2036.27\n",
      "Training Epoch 24  46.8% | batch:        44 of        94\t|\tloss: 1638.11\n",
      "Training Epoch 24  47.9% | batch:        45 of        94\t|\tloss: 1048.33\n",
      "Training Epoch 24  48.9% | batch:        46 of        94\t|\tloss: 1851.1\n",
      "Training Epoch 24  50.0% | batch:        47 of        94\t|\tloss: 1544.54\n",
      "Training Epoch 24  51.1% | batch:        48 of        94\t|\tloss: 2996.92\n",
      "Training Epoch 24  52.1% | batch:        49 of        94\t|\tloss: 1362.48\n",
      "Training Epoch 24  53.2% | batch:        50 of        94\t|\tloss: 2154.14\n",
      "Training Epoch 24  54.3% | batch:        51 of        94\t|\tloss: 1576.09\n",
      "Training Epoch 24  55.3% | batch:        52 of        94\t|\tloss: 2243.33\n",
      "Training Epoch 24  56.4% | batch:        53 of        94\t|\tloss: 1133.07\n",
      "Training Epoch 24  57.4% | batch:        54 of        94\t|\tloss: 1330.36\n",
      "Training Epoch 24  58.5% | batch:        55 of        94\t|\tloss: 1744.74\n",
      "Training Epoch 24  59.6% | batch:        56 of        94\t|\tloss: 1456.75\n",
      "Training Epoch 24  60.6% | batch:        57 of        94\t|\tloss: 1042.78\n",
      "Training Epoch 24  61.7% | batch:        58 of        94\t|\tloss: 2177.19\n",
      "Training Epoch 24  62.8% | batch:        59 of        94\t|\tloss: 1109.78\n",
      "Training Epoch 24  63.8% | batch:        60 of        94\t|\tloss: 1028.36\n",
      "Training Epoch 24  64.9% | batch:        61 of        94\t|\tloss: 3054.2\n",
      "Training Epoch 24  66.0% | batch:        62 of        94\t|\tloss: 1711.48\n",
      "Training Epoch 24  67.0% | batch:        63 of        94\t|\tloss: 2087.43\n",
      "Training Epoch 24  68.1% | batch:        64 of        94\t|\tloss: 2910.94\n",
      "Training Epoch 24  69.1% | batch:        65 of        94\t|\tloss: 1759.16\n",
      "Training Epoch 24  70.2% | batch:        66 of        94\t|\tloss: 1196.67\n",
      "Training Epoch 24  71.3% | batch:        67 of        94\t|\tloss: 1354.66\n",
      "Training Epoch 24  72.3% | batch:        68 of        94\t|\tloss: 1112.79\n",
      "Training Epoch 24  73.4% | batch:        69 of        94\t|\tloss: 1223.62\n",
      "Training Epoch 24  74.5% | batch:        70 of        94\t|\tloss: 1248.32\n",
      "Training Epoch 24  75.5% | batch:        71 of        94\t|\tloss: 7812.84\n",
      "Training Epoch 24  76.6% | batch:        72 of        94\t|\tloss: 1506.22\n",
      "Training Epoch 24  77.7% | batch:        73 of        94\t|\tloss: 1299.97\n",
      "Training Epoch 24  78.7% | batch:        74 of        94\t|\tloss: 4569.42\n",
      "Training Epoch 24  79.8% | batch:        75 of        94\t|\tloss: 990.416\n",
      "Training Epoch 24  80.9% | batch:        76 of        94\t|\tloss: 1566.86\n",
      "Training Epoch 24  81.9% | batch:        77 of        94\t|\tloss: 1505.8\n",
      "Training Epoch 24  83.0% | batch:        78 of        94\t|\tloss: 1973.75\n",
      "Training Epoch 24  84.0% | batch:        79 of        94\t|\tloss: 2080.31\n",
      "Training Epoch 24  85.1% | batch:        80 of        94\t|\tloss: 1938.84\n",
      "Training Epoch 24  86.2% | batch:        81 of        94\t|\tloss: 1617.28\n",
      "Training Epoch 24  87.2% | batch:        82 of        94\t|\tloss: 1772.8\n",
      "Training Epoch 24  88.3% | batch:        83 of        94\t|\tloss: 1509.46\n",
      "Training Epoch 24  89.4% | batch:        84 of        94\t|\tloss: 2416.7\n",
      "Training Epoch 24  90.4% | batch:        85 of        94\t|\tloss: 1356.13\n",
      "Training Epoch 24  91.5% | batch:        86 of        94\t|\tloss: 992.252\n",
      "Training Epoch 24  92.6% | batch:        87 of        94\t|\tloss: 1165.62\n",
      "Training Epoch 24  93.6% | batch:        88 of        94\t|\tloss: 1837.3\n",
      "Training Epoch 24  94.7% | batch:        89 of        94\t|\tloss: 1602.03\n",
      "Training Epoch 24  95.7% | batch:        90 of        94\t|\tloss: 1284.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:40,172 | INFO : Epoch 24 Training Summary: epoch: 24.000000 | loss: 1766.531342 | \n",
      "2023-05-04 16:59:40,173 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8024227619171143 seconds\n",
      "\n",
      "2023-05-04 16:59:40,174 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7846401929855347 seconds\n",
      "2023-05-04 16:59:40,174 | INFO : Avg batch train. time: 0.01898553396793122 seconds\n",
      "2023-05-04 16:59:40,175 | INFO : Avg sample train. time: 0.00014974326170377031 seconds\n",
      "2023-05-04 16:59:40,175 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 24  96.8% | batch:        91 of        94\t|\tloss: 1209.94\n",
      "Training Epoch 24  97.9% | batch:        92 of        94\t|\tloss: 4300.04\n",
      "Training Epoch 24  98.9% | batch:        93 of        94\t|\tloss: 3646.9\n",
      "\n",
      "Evaluating Epoch 24   0.0% | batch:         0 of        40\t|\tloss: 6224.62\n",
      "Evaluating Epoch 24   2.5% | batch:         1 of        40\t|\tloss: 1082.98\n",
      "Evaluating Epoch 24   5.0% | batch:         2 of        40\t|\tloss: 2766.79\n",
      "Evaluating Epoch 24   7.5% | batch:         3 of        40\t|\tloss: 6513.29\n",
      "Evaluating Epoch 24  10.0% | batch:         4 of        40\t|\tloss: 2543.63\n",
      "Evaluating Epoch 24  12.5% | batch:         5 of        40\t|\tloss: 2268.99\n",
      "Evaluating Epoch 24  15.0% | batch:         6 of        40\t|\tloss: 7181.24\n",
      "Evaluating Epoch 24  17.5% | batch:         7 of        40\t|\tloss: 2905.79\n",
      "Evaluating Epoch 24  20.0% | batch:         8 of        40\t|\tloss: 2372.05\n",
      "Evaluating Epoch 24  22.5% | batch:         9 of        40\t|\tloss: 2230.75\n",
      "Evaluating Epoch 24  25.0% | batch:        10 of        40\t|\tloss: 4573.14\n",
      "Evaluating Epoch 24  27.5% | batch:        11 of        40\t|\tloss: 1248.48\n",
      "Evaluating Epoch 24  30.0% | batch:        12 of        40\t|\tloss: 5897.04\n",
      "Evaluating Epoch 24  32.5% | batch:        13 of        40\t|\tloss: 2844.06\n",
      "Evaluating Epoch 24  35.0% | batch:        14 of        40\t|\tloss: 1830.28\n",
      "Evaluating Epoch 24  37.5% | batch:        15 of        40\t|\tloss: 3282.4\n",
      "Evaluating Epoch 24  40.0% | batch:        16 of        40\t|\tloss: 4924.53\n",
      "Evaluating Epoch 24  42.5% | batch:        17 of        40\t|\tloss: 2535.73\n",
      "Evaluating Epoch 24  45.0% | batch:        18 of        40\t|\tloss: 2271.97\n",
      "Evaluating Epoch 24  47.5% | batch:        19 of        40\t|\tloss: 4325.19\n",
      "Evaluating Epoch 24  50.0% | batch:        20 of        40\t|\tloss: 4244.35\n",
      "Evaluating Epoch 24  52.5% | batch:        21 of        40\t|\tloss: 897.747\n",
      "Evaluating Epoch 24  55.0% | batch:        22 of        40\t|\tloss: 3772.65\n",
      "Evaluating Epoch 24  57.5% | batch:        23 of        40\t|\tloss: 2967.48\n",
      "Evaluating Epoch 24  60.0% | batch:        24 of        40\t|\tloss: 1643.15\n",
      "Evaluating Epoch 24  62.5% | batch:        25 of        40\t|\tloss: 2827.22\n",
      "Evaluating Epoch 24  65.0% | batch:        26 of        40\t|\tloss: 9005.58\n",
      "Evaluating Epoch 24  67.5% | batch:        27 of        40\t|\tloss: 2482.53\n",
      "Evaluating Epoch 24  70.0% | batch:        28 of        40\t|\tloss: 1598.56\n",
      "Evaluating Epoch 24  72.5% | batch:        29 of        40\t|\tloss: 9416.08\n",
      "Evaluating Epoch 24  75.0% | batch:        30 of        40\t|\tloss: 1684.42\n",
      "Evaluating Epoch 24  77.5% | batch:        31 of        40\t|\tloss: 1860.45\n",
      "Evaluating Epoch 24  80.0% | batch:        32 of        40\t|\tloss: 7879.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:40,624 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44756650924682617 seconds\n",
      "\n",
      "2023-05-04 16:59:40,624 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5427115780966623 seconds\n",
      "2023-05-04 16:59:40,625 | INFO : Avg batch val. time: 0.013567789452416556 seconds\n",
      "2023-05-04 16:59:40,625 | INFO : Avg sample val. time: 0.00010751021753103452 seconds\n",
      "2023-05-04 16:59:40,626 | INFO : Epoch 24 Validation Summary: epoch: 24.000000 | loss: 3750.551769 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 24  82.5% | batch:        33 of        40\t|\tloss: 5963.61\n",
      "Evaluating Epoch 24  85.0% | batch:        34 of        40\t|\tloss: 933.29\n",
      "Evaluating Epoch 24  87.5% | batch:        35 of        40\t|\tloss: 5452.04\n",
      "Evaluating Epoch 24  90.0% | batch:        36 of        40\t|\tloss: 5373.57\n",
      "Evaluating Epoch 24  92.5% | batch:        37 of        40\t|\tloss: 2412.56\n",
      "Evaluating Epoch 24  95.0% | batch:        38 of        40\t|\tloss: 3431.15\n",
      "Evaluating Epoch 24  97.5% | batch:        39 of        40\t|\tloss: 9698.9\n",
      "\n",
      "Training Epoch 25   0.0% | batch:         0 of        94\t|\tloss: 1656.81\n",
      "Training Epoch 25   1.1% | batch:         1 of        94\t|\tloss: 1877.45\n",
      "Training Epoch 25   2.1% | batch:         2 of        94\t|\tloss: 1810.7\n",
      "Training Epoch 25   3.2% | batch:         3 of        94\t|\tloss: 2066.81\n",
      "Training Epoch 25   4.3% | batch:         4 of        94\t|\tloss: 2844.79\n",
      "Training Epoch 25   5.3% | batch:         5 of        94\t|\tloss: 1605.13\n",
      "Training Epoch 25   6.4% | batch:         6 of        94\t|\tloss: 1148.54\n",
      "Training Epoch 25   7.4% | batch:         7 of        94\t|\tloss: 1513.45\n",
      "Training Epoch 25   8.5% | batch:         8 of        94\t|\tloss: 1402.02\n",
      "Training Epoch 25   9.6% | batch:         9 of        94\t|\tloss: 1084.83\n",
      "Training Epoch 25  10.6% | batch:        10 of        94\t|\tloss: 1243.06\n",
      "Training Epoch 25  11.7% | batch:        11 of        94\t|\tloss: 1991.08\n",
      "Training Epoch 25  12.8% | batch:        12 of        94\t|\tloss: 1270.4\n",
      "Training Epoch 25  13.8% | batch:        13 of        94\t|\tloss: 1090.01\n",
      "Training Epoch 25  14.9% | batch:        14 of        94\t|\tloss: 1768.88\n",
      "Training Epoch 25  16.0% | batch:        15 of        94\t|\tloss: 1803.26\n",
      "Training Epoch 25  17.0% | batch:        16 of        94\t|\tloss: 2160.08\n",
      "Training Epoch 25  18.1% | batch:        17 of        94\t|\tloss: 1408.05\n",
      "Training Epoch 25  19.1% | batch:        18 of        94\t|\tloss: 1205.04\n",
      "Training Epoch 25  20.2% | batch:        19 of        94\t|\tloss: 1557.96\n",
      "Training Epoch 25  21.3% | batch:        20 of        94\t|\tloss: 1082.43\n",
      "Training Epoch 25  22.3% | batch:        21 of        94\t|\tloss: 1670.18\n",
      "Training Epoch 25  23.4% | batch:        22 of        94\t|\tloss: 1289.25\n",
      "Training Epoch 25  24.5% | batch:        23 of        94\t|\tloss: 1671.14\n",
      "Training Epoch 25  25.5% | batch:        24 of        94\t|\tloss: 1521.81\n",
      "Training Epoch 25  26.6% | batch:        25 of        94\t|\tloss: 2385.86\n",
      "Training Epoch 25  27.7% | batch:        26 of        94\t|\tloss: 1362.3\n",
      "Training Epoch 25  28.7% | batch:        27 of        94\t|\tloss: 1237.11\n",
      "Training Epoch 25  29.8% | batch:        28 of        94\t|\tloss: 1874.06\n",
      "Training Epoch 25  30.9% | batch:        29 of        94\t|\tloss: 1456.43\n",
      "Training Epoch 25  31.9% | batch:        30 of        94\t|\tloss: 1635.61\n",
      "Training Epoch 25  33.0% | batch:        31 of        94\t|\tloss: 3792.31\n",
      "Training Epoch 25  34.0% | batch:        32 of        94\t|\tloss: 1337.1\n",
      "Training Epoch 25  35.1% | batch:        33 of        94\t|\tloss: 1371.31\n",
      "Training Epoch 25  36.2% | batch:        34 of        94\t|\tloss: 2877.92\n",
      "Training Epoch 25  37.2% | batch:        35 of        94\t|\tloss: 1590.01\n",
      "Training Epoch 25  38.3% | batch:        36 of        94\t|\tloss: 1025.82\n",
      "Training Epoch 25  39.4% | batch:        37 of        94\t|\tloss: 1253.6\n",
      "Training Epoch 25  40.4% | batch:        38 of        94\t|\tloss: 2023.85\n",
      "Training Epoch 25  41.5% | batch:        39 of        94\t|\tloss: 1499.59\n",
      "Training Epoch 25  42.6% | batch:        40 of        94\t|\tloss: 1305.95\n",
      "Training Epoch 25  43.6% | batch:        41 of        94\t|\tloss: 1390.11\n",
      "Training Epoch 25  44.7% | batch:        42 of        94\t|\tloss: 1478.14\n",
      "Training Epoch 25  45.7% | batch:        43 of        94\t|\tloss: 1379.99\n",
      "Training Epoch 25  46.8% | batch:        44 of        94\t|\tloss: 1265.26\n",
      "Training Epoch 25  47.9% | batch:        45 of        94\t|\tloss: 1298.5\n",
      "Training Epoch 25  48.9% | batch:        46 of        94\t|\tloss: 4321.83\n",
      "Training Epoch 25  50.0% | batch:        47 of        94\t|\tloss: 1227.4\n",
      "Training Epoch 25  51.1% | batch:        48 of        94\t|\tloss: 1600.11\n",
      "Training Epoch 25  52.1% | batch:        49 of        94\t|\tloss: 1867.23\n",
      "Training Epoch 25  53.2% | batch:        50 of        94\t|\tloss: 1315.44\n",
      "Training Epoch 25  54.3% | batch:        51 of        94\t|\tloss: 1192.24\n",
      "Training Epoch 25  55.3% | batch:        52 of        94\t|\tloss: 1000.12\n",
      "Training Epoch 25  56.4% | batch:        53 of        94\t|\tloss: 1603.54\n",
      "Training Epoch 25  57.4% | batch:        54 of        94\t|\tloss: 1793.56\n",
      "Training Epoch 25  58.5% | batch:        55 of        94\t|\tloss: 1598.74\n",
      "Training Epoch 25  59.6% | batch:        56 of        94\t|\tloss: 1216.46\n",
      "Training Epoch 25  60.6% | batch:        57 of        94\t|\tloss: 3737.1\n",
      "Training Epoch 25  61.7% | batch:        58 of        94\t|\tloss: 1189.5\n",
      "Training Epoch 25  62.8% | batch:        59 of        94\t|\tloss: 3013.94\n",
      "Training Epoch 25  63.8% | batch:        60 of        94\t|\tloss: 1331.06\n",
      "Training Epoch 25  64.9% | batch:        61 of        94\t|\tloss: 1179.74\n",
      "Training Epoch 25  66.0% | batch:        62 of        94\t|\tloss: 2025.01\n",
      "Training Epoch 25  67.0% | batch:        63 of        94\t|\tloss: 1206.02\n",
      "Training Epoch 25  68.1% | batch:        64 of        94\t|\tloss: 1486.65\n",
      "Training Epoch 25  69.1% | batch:        65 of        94\t|\tloss: 1506.87\n",
      "Training Epoch 25  70.2% | batch:        66 of        94\t|\tloss: 1613.81\n",
      "Training Epoch 25  71.3% | batch:        67 of        94\t|\tloss: 1054.84\n",
      "Training Epoch 25  72.3% | batch:        68 of        94\t|\tloss: 1852.05\n",
      "Training Epoch 25  73.4% | batch:        69 of        94\t|\tloss: 1503.53\n",
      "Training Epoch 25  74.5% | batch:        70 of        94\t|\tloss: 2236.57\n",
      "Training Epoch 25  75.5% | batch:        71 of        94\t|\tloss: 1667.41\n",
      "Training Epoch 25  76.6% | batch:        72 of        94\t|\tloss: 2018.68\n",
      "Training Epoch 25  77.7% | batch:        73 of        94\t|\tloss: 1634.97\n",
      "Training Epoch 25  78.7% | batch:        74 of        94\t|\tloss: 2344.21\n",
      "Training Epoch 25  79.8% | batch:        75 of        94\t|\tloss: 1262.39\n",
      "Training Epoch 25  80.9% | batch:        76 of        94\t|\tloss: 987.883\n",
      "Training Epoch 25  81.9% | batch:        77 of        94\t|\tloss: 1253.1\n",
      "Training Epoch 25  83.0% | batch:        78 of        94\t|\tloss: 1259.59\n",
      "Training Epoch 25  84.0% | batch:        79 of        94\t|\tloss: 3223.48\n",
      "Training Epoch 25  85.1% | batch:        80 of        94\t|\tloss: 2483.32\n",
      "Training Epoch 25  86.2% | batch:        81 of        94\t|\tloss: 1985.79\n",
      "Training Epoch 25  87.2% | batch:        82 of        94\t|\tloss: 1174.08\n",
      "Training Epoch 25  88.3% | batch:        83 of        94\t|\tloss: 4192.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:42,459 | INFO : Epoch 25 Training Summary: epoch: 25.000000 | loss: 1704.731655 | \n",
      "2023-05-04 16:59:42,460 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8118855953216553 seconds\n",
      "\n",
      "2023-05-04 16:59:42,460 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7857300090789794 seconds\n",
      "2023-05-04 16:59:42,461 | INFO : Avg batch train. time: 0.018997127756159356 seconds\n",
      "2023-05-04 16:59:42,461 | INFO : Avg sample train. time: 0.00014983470457115115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 25  89.4% | batch:        84 of        94\t|\tloss: 1215.63\n",
      "Training Epoch 25  90.4% | batch:        85 of        94\t|\tloss: 1000.66\n",
      "Training Epoch 25  91.5% | batch:        86 of        94\t|\tloss: 1579.54\n",
      "Training Epoch 25  92.6% | batch:        87 of        94\t|\tloss: 1893.23\n",
      "Training Epoch 25  93.6% | batch:        88 of        94\t|\tloss: 1153.21\n",
      "Training Epoch 25  94.7% | batch:        89 of        94\t|\tloss: 1635.54\n",
      "Training Epoch 25  95.7% | batch:        90 of        94\t|\tloss: 2038.4\n",
      "Training Epoch 25  96.8% | batch:        91 of        94\t|\tloss: 1664.06\n",
      "Training Epoch 25  97.9% | batch:        92 of        94\t|\tloss: 2685.68\n",
      "Training Epoch 25  98.9% | batch:        93 of        94\t|\tloss: 1058.58\n",
      "\n",
      "Training Epoch 26   0.0% | batch:         0 of        94\t|\tloss: 2064.6\n",
      "Training Epoch 26   1.1% | batch:         1 of        94\t|\tloss: 2122.88\n",
      "Training Epoch 26   2.1% | batch:         2 of        94\t|\tloss: 2072.09\n",
      "Training Epoch 26   3.2% | batch:         3 of        94\t|\tloss: 1562.04\n",
      "Training Epoch 26   4.3% | batch:         4 of        94\t|\tloss: 1304.51\n",
      "Training Epoch 26   5.3% | batch:         5 of        94\t|\tloss: 1433.01\n",
      "Training Epoch 26   6.4% | batch:         6 of        94\t|\tloss: 1209.8\n",
      "Training Epoch 26   7.4% | batch:         7 of        94\t|\tloss: 1234.47\n",
      "Training Epoch 26   8.5% | batch:         8 of        94\t|\tloss: 1700.35\n",
      "Training Epoch 26   9.6% | batch:         9 of        94\t|\tloss: 1623.78\n",
      "Training Epoch 26  10.6% | batch:        10 of        94\t|\tloss: 1532.74\n",
      "Training Epoch 26  11.7% | batch:        11 of        94\t|\tloss: 1801.23\n",
      "Training Epoch 26  12.8% | batch:        12 of        94\t|\tloss: 1387.53\n",
      "Training Epoch 26  13.8% | batch:        13 of        94\t|\tloss: 1713.88\n",
      "Training Epoch 26  14.9% | batch:        14 of        94\t|\tloss: 1461.05\n",
      "Training Epoch 26  16.0% | batch:        15 of        94\t|\tloss: 3067.95\n",
      "Training Epoch 26  17.0% | batch:        16 of        94\t|\tloss: 1323.45\n",
      "Training Epoch 26  18.1% | batch:        17 of        94\t|\tloss: 1164.93\n",
      "Training Epoch 26  19.1% | batch:        18 of        94\t|\tloss: 1197.26\n",
      "Training Epoch 26  20.2% | batch:        19 of        94\t|\tloss: 1418.79\n",
      "Training Epoch 26  21.3% | batch:        20 of        94\t|\tloss: 1302.42\n",
      "Training Epoch 26  22.3% | batch:        21 of        94\t|\tloss: 1232.97\n",
      "Training Epoch 26  23.4% | batch:        22 of        94\t|\tloss: 4447.83\n",
      "Training Epoch 26  24.5% | batch:        23 of        94\t|\tloss: 1243.22\n",
      "Training Epoch 26  25.5% | batch:        24 of        94\t|\tloss: 1307.83\n",
      "Training Epoch 26  26.6% | batch:        25 of        94\t|\tloss: 1934.14\n",
      "Training Epoch 26  27.7% | batch:        26 of        94\t|\tloss: 1844.49\n",
      "Training Epoch 26  28.7% | batch:        27 of        94\t|\tloss: 1572.58\n",
      "Training Epoch 26  29.8% | batch:        28 of        94\t|\tloss: 3364.58\n",
      "Training Epoch 26  30.9% | batch:        29 of        94\t|\tloss: 895.762\n",
      "Training Epoch 26  31.9% | batch:        30 of        94\t|\tloss: 2298.92\n",
      "Training Epoch 26  33.0% | batch:        31 of        94\t|\tloss: 1203.59\n",
      "Training Epoch 26  34.0% | batch:        32 of        94\t|\tloss: 4213.11\n",
      "Training Epoch 26  35.1% | batch:        33 of        94\t|\tloss: 1190.23\n",
      "Training Epoch 26  36.2% | batch:        34 of        94\t|\tloss: 2345.68\n",
      "Training Epoch 26  37.2% | batch:        35 of        94\t|\tloss: 2506.88\n",
      "Training Epoch 26  38.3% | batch:        36 of        94\t|\tloss: 2924.03\n",
      "Training Epoch 26  39.4% | batch:        37 of        94\t|\tloss: 1972.42\n",
      "Training Epoch 26  40.4% | batch:        38 of        94\t|\tloss: 1297.26\n",
      "Training Epoch 26  41.5% | batch:        39 of        94\t|\tloss: 1549.93\n",
      "Training Epoch 26  42.6% | batch:        40 of        94\t|\tloss: 1405.51\n",
      "Training Epoch 26  43.6% | batch:        41 of        94\t|\tloss: 1283.66\n",
      "Training Epoch 26  44.7% | batch:        42 of        94\t|\tloss: 1534.41\n",
      "Training Epoch 26  45.7% | batch:        43 of        94\t|\tloss: 2406.51\n",
      "Training Epoch 26  46.8% | batch:        44 of        94\t|\tloss: 1776.43\n",
      "Training Epoch 26  47.9% | batch:        45 of        94\t|\tloss: 1517.53\n",
      "Training Epoch 26  48.9% | batch:        46 of        94\t|\tloss: 1414.49\n",
      "Training Epoch 26  50.0% | batch:        47 of        94\t|\tloss: 2030.51\n",
      "Training Epoch 26  51.1% | batch:        48 of        94\t|\tloss: 1445.49\n",
      "Training Epoch 26  52.1% | batch:        49 of        94\t|\tloss: 2779.04\n",
      "Training Epoch 26  53.2% | batch:        50 of        94\t|\tloss: 1704.49\n",
      "Training Epoch 26  54.3% | batch:        51 of        94\t|\tloss: 3415.46\n",
      "Training Epoch 26  55.3% | batch:        52 of        94\t|\tloss: 1778.43\n",
      "Training Epoch 26  56.4% | batch:        53 of        94\t|\tloss: 1123.45\n",
      "Training Epoch 26  57.4% | batch:        54 of        94\t|\tloss: 1089.68\n",
      "Training Epoch 26  58.5% | batch:        55 of        94\t|\tloss: 1439.12\n",
      "Training Epoch 26  59.6% | batch:        56 of        94\t|\tloss: 1376.15\n",
      "Training Epoch 26  60.6% | batch:        57 of        94\t|\tloss: 1428.49\n",
      "Training Epoch 26  61.7% | batch:        58 of        94\t|\tloss: 1374.46\n",
      "Training Epoch 26  62.8% | batch:        59 of        94\t|\tloss: 1092.75\n",
      "Training Epoch 26  63.8% | batch:        60 of        94\t|\tloss: 1273.31\n",
      "Training Epoch 26  64.9% | batch:        61 of        94\t|\tloss: 1736.87\n",
      "Training Epoch 26  66.0% | batch:        62 of        94\t|\tloss: 2149.8\n",
      "Training Epoch 26  67.0% | batch:        63 of        94\t|\tloss: 1631.62\n",
      "Training Epoch 26  68.1% | batch:        64 of        94\t|\tloss: 1909.25\n",
      "Training Epoch 26  69.1% | batch:        65 of        94\t|\tloss: 964.41\n",
      "Training Epoch 26  70.2% | batch:        66 of        94\t|\tloss: 1301.46\n",
      "Training Epoch 26  71.3% | batch:        67 of        94\t|\tloss: 1265.24\n",
      "Training Epoch 26  72.3% | batch:        68 of        94\t|\tloss: 1124.57\n",
      "Training Epoch 26  73.4% | batch:        69 of        94\t|\tloss: 1257.22\n",
      "Training Epoch 26  74.5% | batch:        70 of        94\t|\tloss: 1106.98\n",
      "Training Epoch 26  75.5% | batch:        71 of        94\t|\tloss: 2734.03\n",
      "Training Epoch 26  76.6% | batch:        72 of        94\t|\tloss: 1126.3\n",
      "Training Epoch 26  77.7% | batch:        73 of        94\t|\tloss: 1640.38\n",
      "Training Epoch 26  78.7% | batch:        74 of        94\t|\tloss: 1545.9\n",
      "Training Epoch 26  79.8% | batch:        75 of        94\t|\tloss: 1344.15\n",
      "Training Epoch 26  80.9% | batch:        76 of        94\t|\tloss: 1597.92\n",
      "Training Epoch 26  81.9% | batch:        77 of        94\t|\tloss: 1415.92\n",
      "Training Epoch 26  83.0% | batch:        78 of        94\t|\tloss: 2007.58\n",
      "Training Epoch 26  84.0% | batch:        79 of        94\t|\tloss: 1768.82\n",
      "Training Epoch 26  85.1% | batch:        80 of        94\t|\tloss: 1556.41\n",
      "Training Epoch 26  86.2% | batch:        81 of        94\t|\tloss: 1150.58\n",
      "Training Epoch 26  87.2% | batch:        82 of        94\t|\tloss: 2048.05\n",
      "Training Epoch 26  88.3% | batch:        83 of        94\t|\tloss: 1346.92\n",
      "Training Epoch 26  89.4% | batch:        84 of        94\t|\tloss: 2836.06\n",
      "Training Epoch 26  90.4% | batch:        85 of        94\t|\tloss: 1846.54\n",
      "Training Epoch 26  91.5% | batch:        86 of        94\t|\tloss: 2143.93\n",
      "Training Epoch 26  92.6% | batch:        87 of        94\t|\tloss: 2630.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:44,286 | INFO : Epoch 26 Training Summary: epoch: 26.000000 | loss: 1741.373614 | \n",
      "2023-05-04 16:59:44,287 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8039486408233643 seconds\n",
      "\n",
      "2023-05-04 16:59:44,287 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7864307256845326 seconds\n",
      "2023-05-04 16:59:44,288 | INFO : Avg batch train. time: 0.019004582188133327 seconds\n",
      "2023-05-04 16:59:44,288 | INFO : Avg sample train. time: 0.0001498934993861833 seconds\n",
      "2023-05-04 16:59:44,289 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 26  93.6% | batch:        88 of        94\t|\tloss: 1941.75\n",
      "Training Epoch 26  94.7% | batch:        89 of        94\t|\tloss: 1785.49\n",
      "Training Epoch 26  95.7% | batch:        90 of        94\t|\tloss: 1255.82\n",
      "Training Epoch 26  96.8% | batch:        91 of        94\t|\tloss: 2085.91\n",
      "Training Epoch 26  97.9% | batch:        92 of        94\t|\tloss: 1756.49\n",
      "Training Epoch 26  98.9% | batch:        93 of        94\t|\tloss: 3582.93\n",
      "\n",
      "Evaluating Epoch 26   0.0% | batch:         0 of        40\t|\tloss: 7821.47\n",
      "Evaluating Epoch 26   2.5% | batch:         1 of        40\t|\tloss: 909.773\n",
      "Evaluating Epoch 26   5.0% | batch:         2 of        40\t|\tloss: 2718.51\n",
      "Evaluating Epoch 26   7.5% | batch:         3 of        40\t|\tloss: 7637.09\n",
      "Evaluating Epoch 26  10.0% | batch:         4 of        40\t|\tloss: 1745.01\n",
      "Evaluating Epoch 26  12.5% | batch:         5 of        40\t|\tloss: 1719.2\n",
      "Evaluating Epoch 26  15.0% | batch:         6 of        40\t|\tloss: 8160.89\n",
      "Evaluating Epoch 26  17.5% | batch:         7 of        40\t|\tloss: 3037.08\n",
      "Evaluating Epoch 26  20.0% | batch:         8 of        40\t|\tloss: 2441.38\n",
      "Evaluating Epoch 26  22.5% | batch:         9 of        40\t|\tloss: 2415.63\n",
      "Evaluating Epoch 26  25.0% | batch:        10 of        40\t|\tloss: 5322.48\n",
      "Evaluating Epoch 26  27.5% | batch:        11 of        40\t|\tloss: 1715.17\n",
      "Evaluating Epoch 26  30.0% | batch:        12 of        40\t|\tloss: 7393.76\n",
      "Evaluating Epoch 26  32.5% | batch:        13 of        40\t|\tloss: 3927.52\n",
      "Evaluating Epoch 26  35.0% | batch:        14 of        40\t|\tloss: 2093.97\n",
      "Evaluating Epoch 26  37.5% | batch:        15 of        40\t|\tloss: 4400.98\n",
      "Evaluating Epoch 26  40.0% | batch:        16 of        40\t|\tloss: 4986.59\n",
      "Evaluating Epoch 26  42.5% | batch:        17 of        40\t|\tloss: 2992.17\n",
      "Evaluating Epoch 26  45.0% | batch:        18 of        40\t|\tloss: 2638.11\n",
      "Evaluating Epoch 26  47.5% | batch:        19 of        40\t|\tloss: 6555.32\n",
      "Evaluating Epoch 26  50.0% | batch:        20 of        40\t|\tloss: 5051.86\n",
      "Evaluating Epoch 26  52.5% | batch:        21 of        40\t|\tloss: 1040.98\n",
      "Evaluating Epoch 26  55.0% | batch:        22 of        40\t|\tloss: 4002.81\n",
      "Evaluating Epoch 26  57.5% | batch:        23 of        40\t|\tloss: 4020.15\n",
      "Evaluating Epoch 26  60.0% | batch:        24 of        40\t|\tloss: 1477.9\n",
      "Evaluating Epoch 26  62.5% | batch:        25 of        40\t|\tloss: 4657.05\n",
      "Evaluating Epoch 26  65.0% | batch:        26 of        40\t|\tloss: 12291.9\n",
      "Evaluating Epoch 26  67.5% | batch:        27 of        40\t|\tloss: 2586.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:44,736 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44661688804626465 seconds\n",
      "\n",
      "2023-05-04 16:59:44,737 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5421655855395577 seconds\n",
      "2023-05-04 16:59:44,737 | INFO : Avg batch val. time: 0.013554139638488944 seconds\n",
      "2023-05-04 16:59:44,738 | INFO : Avg sample val. time: 0.00010740205735728164 seconds\n",
      "2023-05-04 16:59:44,739 | INFO : Epoch 26 Validation Summary: epoch: 26.000000 | loss: 4335.406454 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 26  70.0% | batch:        28 of        40\t|\tloss: 2686.72\n",
      "Evaluating Epoch 26  72.5% | batch:        29 of        40\t|\tloss: 10336.6\n",
      "Evaluating Epoch 26  75.0% | batch:        30 of        40\t|\tloss: 1875.71\n",
      "Evaluating Epoch 26  77.5% | batch:        31 of        40\t|\tloss: 1454.29\n",
      "Evaluating Epoch 26  80.0% | batch:        32 of        40\t|\tloss: 7321.96\n",
      "Evaluating Epoch 26  82.5% | batch:        33 of        40\t|\tloss: 6659.98\n",
      "Evaluating Epoch 26  85.0% | batch:        34 of        40\t|\tloss: 1313.48\n",
      "Evaluating Epoch 26  87.5% | batch:        35 of        40\t|\tloss: 4902.5\n",
      "Evaluating Epoch 26  90.0% | batch:        36 of        40\t|\tloss: 7044.76\n",
      "Evaluating Epoch 26  92.5% | batch:        37 of        40\t|\tloss: 2460.86\n",
      "Evaluating Epoch 26  95.0% | batch:        38 of        40\t|\tloss: 4437.69\n",
      "Evaluating Epoch 26  97.5% | batch:        39 of        40\t|\tloss: 10793.2\n",
      "\n",
      "Training Epoch 27   0.0% | batch:         0 of        94\t|\tloss: 3895.93\n",
      "Training Epoch 27   1.1% | batch:         1 of        94\t|\tloss: 2037.99\n",
      "Training Epoch 27   2.1% | batch:         2 of        94\t|\tloss: 1564.41\n",
      "Training Epoch 27   3.2% | batch:         3 of        94\t|\tloss: 1684.63\n",
      "Training Epoch 27   4.3% | batch:         4 of        94\t|\tloss: 1866.87\n",
      "Training Epoch 27   5.3% | batch:         5 of        94\t|\tloss: 2111.59\n",
      "Training Epoch 27   6.4% | batch:         6 of        94\t|\tloss: 1483.55\n",
      "Training Epoch 27   7.4% | batch:         7 of        94\t|\tloss: 6182.74\n",
      "Training Epoch 27   8.5% | batch:         8 of        94\t|\tloss: 2659.66\n",
      "Training Epoch 27   9.6% | batch:         9 of        94\t|\tloss: 1455.86\n",
      "Training Epoch 27  10.6% | batch:        10 of        94\t|\tloss: 1994.15\n",
      "Training Epoch 27  11.7% | batch:        11 of        94\t|\tloss: 779.065\n",
      "Training Epoch 27  12.8% | batch:        12 of        94\t|\tloss: 1779.97\n",
      "Training Epoch 27  13.8% | batch:        13 of        94\t|\tloss: 1389.6\n",
      "Training Epoch 27  14.9% | batch:        14 of        94\t|\tloss: 1274.61\n",
      "Training Epoch 27  16.0% | batch:        15 of        94\t|\tloss: 1351.33\n",
      "Training Epoch 27  17.0% | batch:        16 of        94\t|\tloss: 1546.9\n",
      "Training Epoch 27  18.1% | batch:        17 of        94\t|\tloss: 1348.15\n",
      "Training Epoch 27  19.1% | batch:        18 of        94\t|\tloss: 1625\n",
      "Training Epoch 27  20.2% | batch:        19 of        94\t|\tloss: 820.721\n",
      "Training Epoch 27  21.3% | batch:        20 of        94\t|\tloss: 2392.18\n",
      "Training Epoch 27  22.3% | batch:        21 of        94\t|\tloss: 2616.24\n",
      "Training Epoch 27  23.4% | batch:        22 of        94\t|\tloss: 1985.73\n",
      "Training Epoch 27  24.5% | batch:        23 of        94\t|\tloss: 1186.61\n",
      "Training Epoch 27  25.5% | batch:        24 of        94\t|\tloss: 1176.68\n",
      "Training Epoch 27  26.6% | batch:        25 of        94\t|\tloss: 1435.23\n",
      "Training Epoch 27  27.7% | batch:        26 of        94\t|\tloss: 1456.17\n",
      "Training Epoch 27  28.7% | batch:        27 of        94\t|\tloss: 1090.3\n",
      "Training Epoch 27  29.8% | batch:        28 of        94\t|\tloss: 3723.91\n",
      "Training Epoch 27  30.9% | batch:        29 of        94\t|\tloss: 1282.72\n",
      "Training Epoch 27  31.9% | batch:        30 of        94\t|\tloss: 1913.6\n",
      "Training Epoch 27  33.0% | batch:        31 of        94\t|\tloss: 1343.53\n",
      "Training Epoch 27  34.0% | batch:        32 of        94\t|\tloss: 1828.27\n",
      "Training Epoch 27  35.1% | batch:        33 of        94\t|\tloss: 1216.74\n",
      "Training Epoch 27  36.2% | batch:        34 of        94\t|\tloss: 1533.36\n",
      "Training Epoch 27  37.2% | batch:        35 of        94\t|\tloss: 2114.57\n",
      "Training Epoch 27  38.3% | batch:        36 of        94\t|\tloss: 2898.39\n",
      "Training Epoch 27  39.4% | batch:        37 of        94\t|\tloss: 1123.73\n",
      "Training Epoch 27  40.4% | batch:        38 of        94\t|\tloss: 1406.52\n",
      "Training Epoch 27  41.5% | batch:        39 of        94\t|\tloss: 1217.2\n",
      "Training Epoch 27  42.6% | batch:        40 of        94\t|\tloss: 1382.42\n",
      "Training Epoch 27  43.6% | batch:        41 of        94\t|\tloss: 1326.39\n",
      "Training Epoch 27  44.7% | batch:        42 of        94\t|\tloss: 2110.16\n",
      "Training Epoch 27  45.7% | batch:        43 of        94\t|\tloss: 1446.6\n",
      "Training Epoch 27  46.8% | batch:        44 of        94\t|\tloss: 1634\n",
      "Training Epoch 27  47.9% | batch:        45 of        94\t|\tloss: 1265.12\n",
      "Training Epoch 27  48.9% | batch:        46 of        94\t|\tloss: 1526.48\n",
      "Training Epoch 27  50.0% | batch:        47 of        94\t|\tloss: 1763.95\n",
      "Training Epoch 27  51.1% | batch:        48 of        94\t|\tloss: 916.945\n",
      "Training Epoch 27  52.1% | batch:        49 of        94\t|\tloss: 978.216\n",
      "Training Epoch 27  53.2% | batch:        50 of        94\t|\tloss: 1598.68\n",
      "Training Epoch 27  54.3% | batch:        51 of        94\t|\tloss: 1237.63\n",
      "Training Epoch 27  55.3% | batch:        52 of        94\t|\tloss: 1584.53\n",
      "Training Epoch 27  56.4% | batch:        53 of        94\t|\tloss: 828.295\n",
      "Training Epoch 27  57.4% | batch:        54 of        94\t|\tloss: 1408.72\n",
      "Training Epoch 27  58.5% | batch:        55 of        94\t|\tloss: 1401.92\n",
      "Training Epoch 27  59.6% | batch:        56 of        94\t|\tloss: 2361.94\n",
      "Training Epoch 27  60.6% | batch:        57 of        94\t|\tloss: 1888.31\n",
      "Training Epoch 27  61.7% | batch:        58 of        94\t|\tloss: 1341.32\n",
      "Training Epoch 27  62.8% | batch:        59 of        94\t|\tloss: 2064.07\n",
      "Training Epoch 27  63.8% | batch:        60 of        94\t|\tloss: 1337.93\n",
      "Training Epoch 27  64.9% | batch:        61 of        94\t|\tloss: 2388.98\n",
      "Training Epoch 27  66.0% | batch:        62 of        94\t|\tloss: 2028.12\n",
      "Training Epoch 27  67.0% | batch:        63 of        94\t|\tloss: 1445.67\n",
      "Training Epoch 27  68.1% | batch:        64 of        94\t|\tloss: 1764.79\n",
      "Training Epoch 27  69.1% | batch:        65 of        94\t|\tloss: 2165.94\n",
      "Training Epoch 27  70.2% | batch:        66 of        94\t|\tloss: 1859.86\n",
      "Training Epoch 27  71.3% | batch:        67 of        94\t|\tloss: 1426.43\n",
      "Training Epoch 27  72.3% | batch:        68 of        94\t|\tloss: 1433.52\n",
      "Training Epoch 27  73.4% | batch:        69 of        94\t|\tloss: 2379.81\n",
      "Training Epoch 27  74.5% | batch:        70 of        94\t|\tloss: 1062.72\n",
      "Training Epoch 27  75.5% | batch:        71 of        94\t|\tloss: 1173.2\n",
      "Training Epoch 27  76.6% | batch:        72 of        94\t|\tloss: 2045.82\n",
      "Training Epoch 27  77.7% | batch:        73 of        94\t|\tloss: 1052\n",
      "Training Epoch 27  78.7% | batch:        74 of        94\t|\tloss: 1029.5\n",
      "Training Epoch 27  79.8% | batch:        75 of        94\t|\tloss: 2019.1\n",
      "Training Epoch 27  80.9% | batch:        76 of        94\t|\tloss: 1478.81\n",
      "Training Epoch 27  81.9% | batch:        77 of        94\t|\tloss: 1256.17\n",
      "Training Epoch 27  83.0% | batch:        78 of        94\t|\tloss: 1866.15\n",
      "Training Epoch 27  84.0% | batch:        79 of        94\t|\tloss: 2211.09\n",
      "Training Epoch 27  85.1% | batch:        80 of        94\t|\tloss: 2176.67\n",
      "Training Epoch 27  86.2% | batch:        81 of        94\t|\tloss: 1659.94\n",
      "Training Epoch 27  87.2% | batch:        82 of        94\t|\tloss: 1359.72\n",
      "Training Epoch 27  88.3% | batch:        83 of        94\t|\tloss: 1672.66\n",
      "Training Epoch 27  89.4% | batch:        84 of        94\t|\tloss: 1639.34\n",
      "Training Epoch 27  90.4% | batch:        85 of        94\t|\tloss: 1950.9\n",
      "Training Epoch 27  91.5% | batch:        86 of        94\t|\tloss: 1105.75\n",
      "Training Epoch 27  92.6% | batch:        87 of        94\t|\tloss: 925.538\n",
      "Training Epoch 27  93.6% | batch:        88 of        94\t|\tloss: 1870.34\n",
      "Training Epoch 27  94.7% | batch:        89 of        94\t|\tloss: 972.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:46,578 | INFO : Epoch 27 Training Summary: epoch: 27.000000 | loss: 1687.133006 | \n",
      "2023-05-04 16:59:46,579 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.81290864944458 seconds\n",
      "\n",
      "2023-05-04 16:59:46,579 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7874113895274975 seconds\n",
      "2023-05-04 16:59:46,580 | INFO : Avg batch train. time: 0.01901501478220742 seconds\n",
      "2023-05-04 16:59:46,580 | INFO : Avg sample train. time: 0.00014997578364889222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 27  95.7% | batch:        90 of        94\t|\tloss: 1454.82\n",
      "Training Epoch 27  96.8% | batch:        91 of        94\t|\tloss: 1182.59\n",
      "Training Epoch 27  97.9% | batch:        92 of        94\t|\tloss: 1571.52\n",
      "Training Epoch 27  98.9% | batch:        93 of        94\t|\tloss: 2375.44\n",
      "\n",
      "Training Epoch 28   0.0% | batch:         0 of        94\t|\tloss: 1143.24\n",
      "Training Epoch 28   1.1% | batch:         1 of        94\t|\tloss: 3266.8\n",
      "Training Epoch 28   2.1% | batch:         2 of        94\t|\tloss: 1048.18\n",
      "Training Epoch 28   3.2% | batch:         3 of        94\t|\tloss: 1103.79\n",
      "Training Epoch 28   4.3% | batch:         4 of        94\t|\tloss: 737.397\n",
      "Training Epoch 28   5.3% | batch:         5 of        94\t|\tloss: 1280.22\n",
      "Training Epoch 28   6.4% | batch:         6 of        94\t|\tloss: 1534.4\n",
      "Training Epoch 28   7.4% | batch:         7 of        94\t|\tloss: 1044.75\n",
      "Training Epoch 28   8.5% | batch:         8 of        94\t|\tloss: 1126.69\n",
      "Training Epoch 28   9.6% | batch:         9 of        94\t|\tloss: 1055.75\n",
      "Training Epoch 28  10.6% | batch:        10 of        94\t|\tloss: 925.369\n",
      "Training Epoch 28  11.7% | batch:        11 of        94\t|\tloss: 1325.16\n",
      "Training Epoch 28  12.8% | batch:        12 of        94\t|\tloss: 1240.94\n",
      "Training Epoch 28  13.8% | batch:        13 of        94\t|\tloss: 1253.27\n",
      "Training Epoch 28  14.9% | batch:        14 of        94\t|\tloss: 1768.01\n",
      "Training Epoch 28  16.0% | batch:        15 of        94\t|\tloss: 1304.25\n",
      "Training Epoch 28  17.0% | batch:        16 of        94\t|\tloss: 1352.06\n",
      "Training Epoch 28  18.1% | batch:        17 of        94\t|\tloss: 1150.34\n",
      "Training Epoch 28  19.1% | batch:        18 of        94\t|\tloss: 1387.3\n",
      "Training Epoch 28  20.2% | batch:        19 of        94\t|\tloss: 1567.09\n",
      "Training Epoch 28  21.3% | batch:        20 of        94\t|\tloss: 1993.45\n",
      "Training Epoch 28  22.3% | batch:        21 of        94\t|\tloss: 1026.57\n",
      "Training Epoch 28  23.4% | batch:        22 of        94\t|\tloss: 3093.95\n",
      "Training Epoch 28  24.5% | batch:        23 of        94\t|\tloss: 1606.58\n",
      "Training Epoch 28  25.5% | batch:        24 of        94\t|\tloss: 1121.54\n",
      "Training Epoch 28  26.6% | batch:        25 of        94\t|\tloss: 1341.69\n",
      "Training Epoch 28  27.7% | batch:        26 of        94\t|\tloss: 1438.22\n",
      "Training Epoch 28  28.7% | batch:        27 of        94\t|\tloss: 1201.34\n",
      "Training Epoch 28  29.8% | batch:        28 of        94\t|\tloss: 2157.79\n",
      "Training Epoch 28  30.9% | batch:        29 of        94\t|\tloss: 1302.8\n",
      "Training Epoch 28  31.9% | batch:        30 of        94\t|\tloss: 1361.36\n",
      "Training Epoch 28  33.0% | batch:        31 of        94\t|\tloss: 1696.33\n",
      "Training Epoch 28  34.0% | batch:        32 of        94\t|\tloss: 1419.01\n",
      "Training Epoch 28  35.1% | batch:        33 of        94\t|\tloss: 1951.33\n",
      "Training Epoch 28  36.2% | batch:        34 of        94\t|\tloss: 1964.95\n",
      "Training Epoch 28  37.2% | batch:        35 of        94\t|\tloss: 2837.81\n",
      "Training Epoch 28  38.3% | batch:        36 of        94\t|\tloss: 1069.99\n",
      "Training Epoch 28  39.4% | batch:        37 of        94\t|\tloss: 1305.37\n",
      "Training Epoch 28  40.4% | batch:        38 of        94\t|\tloss: 1487.99\n",
      "Training Epoch 28  41.5% | batch:        39 of        94\t|\tloss: 1538.1\n",
      "Training Epoch 28  42.6% | batch:        40 of        94\t|\tloss: 1243.74\n",
      "Training Epoch 28  43.6% | batch:        41 of        94\t|\tloss: 1176.59\n",
      "Training Epoch 28  44.7% | batch:        42 of        94\t|\tloss: 1201.91\n",
      "Training Epoch 28  45.7% | batch:        43 of        94\t|\tloss: 1245.66\n",
      "Training Epoch 28  46.8% | batch:        44 of        94\t|\tloss: 1273.94\n",
      "Training Epoch 28  47.9% | batch:        45 of        94\t|\tloss: 3937.89\n",
      "Training Epoch 28  48.9% | batch:        46 of        94\t|\tloss: 2063.43\n",
      "Training Epoch 28  50.0% | batch:        47 of        94\t|\tloss: 1677.16\n",
      "Training Epoch 28  51.1% | batch:        48 of        94\t|\tloss: 1580.77\n",
      "Training Epoch 28  52.1% | batch:        49 of        94\t|\tloss: 1292.03\n",
      "Training Epoch 28  53.2% | batch:        50 of        94\t|\tloss: 1104.46\n",
      "Training Epoch 28  54.3% | batch:        51 of        94\t|\tloss: 1354.17\n",
      "Training Epoch 28  55.3% | batch:        52 of        94\t|\tloss: 1006.19\n",
      "Training Epoch 28  56.4% | batch:        53 of        94\t|\tloss: 3589.5\n",
      "Training Epoch 28  57.4% | batch:        54 of        94\t|\tloss: 1612.24\n",
      "Training Epoch 28  58.5% | batch:        55 of        94\t|\tloss: 1612.14\n",
      "Training Epoch 28  59.6% | batch:        56 of        94\t|\tloss: 1059.74\n",
      "Training Epoch 28  60.6% | batch:        57 of        94\t|\tloss: 2325.82\n",
      "Training Epoch 28  61.7% | batch:        58 of        94\t|\tloss: 1967.08\n",
      "Training Epoch 28  62.8% | batch:        59 of        94\t|\tloss: 1496.44\n",
      "Training Epoch 28  63.8% | batch:        60 of        94\t|\tloss: 1030.86\n",
      "Training Epoch 28  64.9% | batch:        61 of        94\t|\tloss: 1439.68\n",
      "Training Epoch 28  66.0% | batch:        62 of        94\t|\tloss: 2048.72\n",
      "Training Epoch 28  67.0% | batch:        63 of        94\t|\tloss: 1304.05\n",
      "Training Epoch 28  68.1% | batch:        64 of        94\t|\tloss: 1588.54\n",
      "Training Epoch 28  69.1% | batch:        65 of        94\t|\tloss: 1049.12\n",
      "Training Epoch 28  70.2% | batch:        66 of        94\t|\tloss: 2438.76\n",
      "Training Epoch 28  71.3% | batch:        67 of        94\t|\tloss: 3744.86\n",
      "Training Epoch 28  72.3% | batch:        68 of        94\t|\tloss: 1920.68\n",
      "Training Epoch 28  73.4% | batch:        69 of        94\t|\tloss: 2398.79\n",
      "Training Epoch 28  74.5% | batch:        70 of        94\t|\tloss: 1371.07\n",
      "Training Epoch 28  75.5% | batch:        71 of        94\t|\tloss: 1196.21\n",
      "Training Epoch 28  76.6% | batch:        72 of        94\t|\tloss: 1441.35\n",
      "Training Epoch 28  77.7% | batch:        73 of        94\t|\tloss: 2919.76\n",
      "Training Epoch 28  78.7% | batch:        74 of        94\t|\tloss: 1258.99\n",
      "Training Epoch 28  79.8% | batch:        75 of        94\t|\tloss: 1292.3\n",
      "Training Epoch 28  80.9% | batch:        76 of        94\t|\tloss: 2081.67\n",
      "Training Epoch 28  81.9% | batch:        77 of        94\t|\tloss: 1631.91\n",
      "Training Epoch 28  83.0% | batch:        78 of        94\t|\tloss: 1104.7\n",
      "Training Epoch 28  84.0% | batch:        79 of        94\t|\tloss: 3365.9\n",
      "Training Epoch 28  85.1% | batch:        80 of        94\t|\tloss: 1844.1\n",
      "Training Epoch 28  86.2% | batch:        81 of        94\t|\tloss: 2230.48\n",
      "Training Epoch 28  87.2% | batch:        82 of        94\t|\tloss: 1130.81\n",
      "Training Epoch 28  88.3% | batch:        83 of        94\t|\tloss: 1111.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:48,402 | INFO : Epoch 28 Training Summary: epoch: 28.000000 | loss: 1626.003852 | \n",
      "2023-05-04 16:59:48,403 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8008477687835693 seconds\n",
      "\n",
      "2023-05-04 16:59:48,403 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7878912602152144 seconds\n",
      "2023-05-04 16:59:48,404 | INFO : Avg batch train. time: 0.019020119789523556 seconds\n",
      "2023-05-04 16:59:48,404 | INFO : Avg sample train. time: 0.0001500160480126879 seconds\n",
      "2023-05-04 16:59:48,405 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 28  89.4% | batch:        84 of        94\t|\tloss: 1308.48\n",
      "Training Epoch 28  90.4% | batch:        85 of        94\t|\tloss: 1340.68\n",
      "Training Epoch 28  91.5% | batch:        86 of        94\t|\tloss: 2536.17\n",
      "Training Epoch 28  92.6% | batch:        87 of        94\t|\tloss: 2012.87\n",
      "Training Epoch 28  93.6% | batch:        88 of        94\t|\tloss: 1584.87\n",
      "Training Epoch 28  94.7% | batch:        89 of        94\t|\tloss: 1283.82\n",
      "Training Epoch 28  95.7% | batch:        90 of        94\t|\tloss: 1807.01\n",
      "Training Epoch 28  96.8% | batch:        91 of        94\t|\tloss: 1254.1\n",
      "Training Epoch 28  97.9% | batch:        92 of        94\t|\tloss: 1708.76\n",
      "Training Epoch 28  98.9% | batch:        93 of        94\t|\tloss: 2398.29\n",
      "\n",
      "Evaluating Epoch 28   0.0% | batch:         0 of        40\t|\tloss: 6791.34\n",
      "Evaluating Epoch 28   2.5% | batch:         1 of        40\t|\tloss: 1321.59\n",
      "Evaluating Epoch 28   5.0% | batch:         2 of        40\t|\tloss: 3487.17\n",
      "Evaluating Epoch 28   7.5% | batch:         3 of        40\t|\tloss: 6712.08\n",
      "Evaluating Epoch 28  10.0% | batch:         4 of        40\t|\tloss: 2696.63\n",
      "Evaluating Epoch 28  12.5% | batch:         5 of        40\t|\tloss: 2543.39\n",
      "Evaluating Epoch 28  15.0% | batch:         6 of        40\t|\tloss: 7982.13\n",
      "Evaluating Epoch 28  17.5% | batch:         7 of        40\t|\tloss: 3313.95\n",
      "Evaluating Epoch 28  20.0% | batch:         8 of        40\t|\tloss: 2809.41\n",
      "Evaluating Epoch 28  22.5% | batch:         9 of        40\t|\tloss: 1947.09\n",
      "Evaluating Epoch 28  25.0% | batch:        10 of        40\t|\tloss: 4608.62\n",
      "Evaluating Epoch 28  27.5% | batch:        11 of        40\t|\tloss: 1459.15\n",
      "Evaluating Epoch 28  30.0% | batch:        12 of        40\t|\tloss: 6205.71\n",
      "Evaluating Epoch 28  32.5% | batch:        13 of        40\t|\tloss: 2871.08\n",
      "Evaluating Epoch 28  35.0% | batch:        14 of        40\t|\tloss: 2150.98\n",
      "Evaluating Epoch 28  37.5% | batch:        15 of        40\t|\tloss: 3388.53\n",
      "Evaluating Epoch 28  40.0% | batch:        16 of        40\t|\tloss: 4279.76\n",
      "Evaluating Epoch 28  42.5% | batch:        17 of        40\t|\tloss: 2931.25\n",
      "Evaluating Epoch 28  45.0% | batch:        18 of        40\t|\tloss: 2490.8\n",
      "Evaluating Epoch 28  47.5% | batch:        19 of        40\t|\tloss: 5054.87\n",
      "Evaluating Epoch 28  50.0% | batch:        20 of        40\t|\tloss: 5001.61\n",
      "Evaluating Epoch 28  52.5% | batch:        21 of        40\t|\tloss: 1322.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:48,854 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44829797744750977 seconds\n",
      "\n",
      "2023-05-04 16:59:48,855 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5416352600701111 seconds\n",
      "2023-05-04 16:59:48,855 | INFO : Avg batch val. time: 0.013540881501752778 seconds\n",
      "2023-05-04 16:59:48,856 | INFO : Avg sample val. time: 0.00010729700080628191 seconds\n",
      "2023-05-04 16:59:48,856 | INFO : Epoch 28 Validation Summary: epoch: 28.000000 | loss: 3966.359620 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 28  55.0% | batch:        22 of        40\t|\tloss: 3785.05\n",
      "Evaluating Epoch 28  57.5% | batch:        23 of        40\t|\tloss: 2954.63\n",
      "Evaluating Epoch 28  60.0% | batch:        24 of        40\t|\tloss: 2026.93\n",
      "Evaluating Epoch 28  62.5% | batch:        25 of        40\t|\tloss: 3629.38\n",
      "Evaluating Epoch 28  65.0% | batch:        26 of        40\t|\tloss: 8929.01\n",
      "Evaluating Epoch 28  67.5% | batch:        27 of        40\t|\tloss: 2952.9\n",
      "Evaluating Epoch 28  70.0% | batch:        28 of        40\t|\tloss: 1955.17\n",
      "Evaluating Epoch 28  72.5% | batch:        29 of        40\t|\tloss: 8967.75\n",
      "Evaluating Epoch 28  75.0% | batch:        30 of        40\t|\tloss: 1712.12\n",
      "Evaluating Epoch 28  77.5% | batch:        31 of        40\t|\tloss: 1601.4\n",
      "Evaluating Epoch 28  80.0% | batch:        32 of        40\t|\tloss: 7880.89\n",
      "Evaluating Epoch 28  82.5% | batch:        33 of        40\t|\tloss: 5776.83\n",
      "Evaluating Epoch 28  85.0% | batch:        34 of        40\t|\tloss: 1069.06\n",
      "Evaluating Epoch 28  87.5% | batch:        35 of        40\t|\tloss: 6180.06\n",
      "Evaluating Epoch 28  90.0% | batch:        36 of        40\t|\tloss: 4985.77\n",
      "Evaluating Epoch 28  92.5% | batch:        37 of        40\t|\tloss: 2665.36\n",
      "Evaluating Epoch 28  95.0% | batch:        38 of        40\t|\tloss: 3721.43\n",
      "Evaluating Epoch 28  97.5% | batch:        39 of        40\t|\tloss: 9737.5\n",
      "\n",
      "Training Epoch 29   0.0% | batch:         0 of        94\t|\tloss: 2068.16\n",
      "Training Epoch 29   1.1% | batch:         1 of        94\t|\tloss: 1162.54\n",
      "Training Epoch 29   2.1% | batch:         2 of        94\t|\tloss: 4890.61\n",
      "Training Epoch 29   3.2% | batch:         3 of        94\t|\tloss: 1122.43\n",
      "Training Epoch 29   4.3% | batch:         4 of        94\t|\tloss: 1069.23\n",
      "Training Epoch 29   5.3% | batch:         5 of        94\t|\tloss: 1866.3\n",
      "Training Epoch 29   6.4% | batch:         6 of        94\t|\tloss: 1879.97\n",
      "Training Epoch 29   7.4% | batch:         7 of        94\t|\tloss: 1097.85\n",
      "Training Epoch 29   8.5% | batch:         8 of        94\t|\tloss: 1547.42\n",
      "Training Epoch 29   9.6% | batch:         9 of        94\t|\tloss: 1052.67\n",
      "Training Epoch 29  10.6% | batch:        10 of        94\t|\tloss: 2409.74\n",
      "Training Epoch 29  11.7% | batch:        11 of        94\t|\tloss: 1365.53\n",
      "Training Epoch 29  12.8% | batch:        12 of        94\t|\tloss: 983.386\n",
      "Training Epoch 29  13.8% | batch:        13 of        94\t|\tloss: 1559.58\n",
      "Training Epoch 29  14.9% | batch:        14 of        94\t|\tloss: 1612.78\n",
      "Training Epoch 29  16.0% | batch:        15 of        94\t|\tloss: 1491.73\n",
      "Training Epoch 29  17.0% | batch:        16 of        94\t|\tloss: 1570.79\n",
      "Training Epoch 29  18.1% | batch:        17 of        94\t|\tloss: 1440.38\n",
      "Training Epoch 29  19.1% | batch:        18 of        94\t|\tloss: 871.926\n",
      "Training Epoch 29  20.2% | batch:        19 of        94\t|\tloss: 1987.75\n",
      "Training Epoch 29  21.3% | batch:        20 of        94\t|\tloss: 1130.91\n",
      "Training Epoch 29  22.3% | batch:        21 of        94\t|\tloss: 1255.56\n",
      "Training Epoch 29  23.4% | batch:        22 of        94\t|\tloss: 1578.29\n",
      "Training Epoch 29  24.5% | batch:        23 of        94\t|\tloss: 1142.9\n",
      "Training Epoch 29  25.5% | batch:        24 of        94\t|\tloss: 966.153\n",
      "Training Epoch 29  26.6% | batch:        25 of        94\t|\tloss: 1244.74\n",
      "Training Epoch 29  27.7% | batch:        26 of        94\t|\tloss: 1455.61\n",
      "Training Epoch 29  28.7% | batch:        27 of        94\t|\tloss: 957.605\n",
      "Training Epoch 29  29.8% | batch:        28 of        94\t|\tloss: 1147.14\n",
      "Training Epoch 29  30.9% | batch:        29 of        94\t|\tloss: 2416.01\n",
      "Training Epoch 29  31.9% | batch:        30 of        94\t|\tloss: 1213.31\n",
      "Training Epoch 29  33.0% | batch:        31 of        94\t|\tloss: 1801.54\n",
      "Training Epoch 29  34.0% | batch:        32 of        94\t|\tloss: 1041.2\n",
      "Training Epoch 29  35.1% | batch:        33 of        94\t|\tloss: 1678.48\n",
      "Training Epoch 29  36.2% | batch:        34 of        94\t|\tloss: 3523.35\n",
      "Training Epoch 29  37.2% | batch:        35 of        94\t|\tloss: 1392.66\n",
      "Training Epoch 29  38.3% | batch:        36 of        94\t|\tloss: 1893.73\n",
      "Training Epoch 29  39.4% | batch:        37 of        94\t|\tloss: 2166.36\n",
      "Training Epoch 29  40.4% | batch:        38 of        94\t|\tloss: 1406.92\n",
      "Training Epoch 29  41.5% | batch:        39 of        94\t|\tloss: 1215.68\n",
      "Training Epoch 29  42.6% | batch:        40 of        94\t|\tloss: 1529\n",
      "Training Epoch 29  43.6% | batch:        41 of        94\t|\tloss: 1823.72\n",
      "Training Epoch 29  44.7% | batch:        42 of        94\t|\tloss: 1385.58\n",
      "Training Epoch 29  45.7% | batch:        43 of        94\t|\tloss: 1433.06\n",
      "Training Epoch 29  46.8% | batch:        44 of        94\t|\tloss: 1263.9\n",
      "Training Epoch 29  47.9% | batch:        45 of        94\t|\tloss: 1234.3\n",
      "Training Epoch 29  48.9% | batch:        46 of        94\t|\tloss: 1092.57\n",
      "Training Epoch 29  50.0% | batch:        47 of        94\t|\tloss: 1678.24\n",
      "Training Epoch 29  51.1% | batch:        48 of        94\t|\tloss: 1751.55\n",
      "Training Epoch 29  52.1% | batch:        49 of        94\t|\tloss: 1216.46\n",
      "Training Epoch 29  53.2% | batch:        50 of        94\t|\tloss: 1677.77\n",
      "Training Epoch 29  54.3% | batch:        51 of        94\t|\tloss: 1154.82\n",
      "Training Epoch 29  55.3% | batch:        52 of        94\t|\tloss: 1471.3\n",
      "Training Epoch 29  56.4% | batch:        53 of        94\t|\tloss: 1295.58\n",
      "Training Epoch 29  57.4% | batch:        54 of        94\t|\tloss: 1477.81\n",
      "Training Epoch 29  58.5% | batch:        55 of        94\t|\tloss: 1764.9\n",
      "Training Epoch 29  59.6% | batch:        56 of        94\t|\tloss: 1294.32\n",
      "Training Epoch 29  60.6% | batch:        57 of        94\t|\tloss: 1186.62\n",
      "Training Epoch 29  61.7% | batch:        58 of        94\t|\tloss: 1433.72\n",
      "Training Epoch 29  62.8% | batch:        59 of        94\t|\tloss: 2032.76\n",
      "Training Epoch 29  63.8% | batch:        60 of        94\t|\tloss: 3077.44\n",
      "Training Epoch 29  64.9% | batch:        61 of        94\t|\tloss: 1957.48\n",
      "Training Epoch 29  66.0% | batch:        62 of        94\t|\tloss: 2625.16\n",
      "Training Epoch 29  67.0% | batch:        63 of        94\t|\tloss: 1500.78\n",
      "Training Epoch 29  68.1% | batch:        64 of        94\t|\tloss: 1380.87\n",
      "Training Epoch 29  69.1% | batch:        65 of        94\t|\tloss: 1521.23\n",
      "Training Epoch 29  70.2% | batch:        66 of        94\t|\tloss: 1086.21\n",
      "Training Epoch 29  71.3% | batch:        67 of        94\t|\tloss: 3321.99\n",
      "Training Epoch 29  72.3% | batch:        68 of        94\t|\tloss: 4065.61\n",
      "Training Epoch 29  73.4% | batch:        69 of        94\t|\tloss: 2420.97\n",
      "Training Epoch 29  74.5% | batch:        70 of        94\t|\tloss: 1105.72\n",
      "Training Epoch 29  75.5% | batch:        71 of        94\t|\tloss: 2152.17\n",
      "Training Epoch 29  76.6% | batch:        72 of        94\t|\tloss: 1217.25\n",
      "Training Epoch 29  77.7% | batch:        73 of        94\t|\tloss: 1965.81\n",
      "Training Epoch 29  78.7% | batch:        74 of        94\t|\tloss: 1373.45\n",
      "Training Epoch 29  79.8% | batch:        75 of        94\t|\tloss: 976.958\n",
      "Training Epoch 29  80.9% | batch:        76 of        94\t|\tloss: 1944.47\n",
      "Training Epoch 29  81.9% | batch:        77 of        94\t|\tloss: 1397.87\n",
      "Training Epoch 29  83.0% | batch:        78 of        94\t|\tloss: 1491.87\n",
      "Training Epoch 29  84.0% | batch:        79 of        94\t|\tloss: 801.965\n",
      "Training Epoch 29  85.1% | batch:        80 of        94\t|\tloss: 2369.09\n",
      "Training Epoch 29  86.2% | batch:        81 of        94\t|\tloss: 1177.45\n",
      "Training Epoch 29  87.2% | batch:        82 of        94\t|\tloss: 920.047\n",
      "Training Epoch 29  88.3% | batch:        83 of        94\t|\tloss: 2546\n",
      "Training Epoch 29  89.4% | batch:        84 of        94\t|\tloss: 2374.37\n",
      "Training Epoch 29  90.4% | batch:        85 of        94\t|\tloss: 1818.88\n",
      "Training Epoch 29  91.5% | batch:        86 of        94\t|\tloss: 1976.57\n",
      "Training Epoch 29  92.6% | batch:        87 of        94\t|\tloss: 1258.57\n",
      "Training Epoch 29  93.6% | batch:        88 of        94\t|\tloss: 2051.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:50,680 | INFO : Epoch 29 Training Summary: epoch: 29.000000 | loss: 1648.236696 | \n",
      "2023-05-04 16:59:50,681 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8020501136779785 seconds\n",
      "\n",
      "2023-05-04 16:59:50,682 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7883794965415165 seconds\n",
      "2023-05-04 16:59:50,682 | INFO : Avg batch train. time: 0.019025313792994856 seconds\n",
      "2023-05-04 16:59:50,683 | INFO : Avg sample train. time: 0.00015005701430957513 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 29  94.7% | batch:        89 of        94\t|\tloss: 1118.4\n",
      "Training Epoch 29  95.7% | batch:        90 of        94\t|\tloss: 1552.24\n",
      "Training Epoch 29  96.8% | batch:        91 of        94\t|\tloss: 2264.6\n",
      "Training Epoch 29  97.9% | batch:        92 of        94\t|\tloss: 1140.87\n",
      "Training Epoch 29  98.9% | batch:        93 of        94\t|\tloss: 5812.23\n",
      "\n",
      "Training Epoch 30   0.0% | batch:         0 of        94\t|\tloss: 2352.79\n",
      "Training Epoch 30   1.1% | batch:         1 of        94\t|\tloss: 1786.1\n",
      "Training Epoch 30   2.1% | batch:         2 of        94\t|\tloss: 943.022\n",
      "Training Epoch 30   3.2% | batch:         3 of        94\t|\tloss: 4205.86\n",
      "Training Epoch 30   4.3% | batch:         4 of        94\t|\tloss: 1934.37\n",
      "Training Epoch 30   5.3% | batch:         5 of        94\t|\tloss: 2663.66\n",
      "Training Epoch 30   6.4% | batch:         6 of        94\t|\tloss: 1813.69\n",
      "Training Epoch 30   7.4% | batch:         7 of        94\t|\tloss: 1329.01\n",
      "Training Epoch 30   8.5% | batch:         8 of        94\t|\tloss: 1352.69\n",
      "Training Epoch 30   9.6% | batch:         9 of        94\t|\tloss: 1336.14\n",
      "Training Epoch 30  10.6% | batch:        10 of        94\t|\tloss: 855.915\n",
      "Training Epoch 30  11.7% | batch:        11 of        94\t|\tloss: 1788.28\n",
      "Training Epoch 30  12.8% | batch:        12 of        94\t|\tloss: 1746.09\n",
      "Training Epoch 30  13.8% | batch:        13 of        94\t|\tloss: 1257.8\n",
      "Training Epoch 30  14.9% | batch:        14 of        94\t|\tloss: 1275.97\n",
      "Training Epoch 30  16.0% | batch:        15 of        94\t|\tloss: 1426.51\n",
      "Training Epoch 30  17.0% | batch:        16 of        94\t|\tloss: 1000.96\n",
      "Training Epoch 30  18.1% | batch:        17 of        94\t|\tloss: 1182.14\n",
      "Training Epoch 30  19.1% | batch:        18 of        94\t|\tloss: 1489.42\n",
      "Training Epoch 30  20.2% | batch:        19 of        94\t|\tloss: 1496.02\n",
      "Training Epoch 30  21.3% | batch:        20 of        94\t|\tloss: 1359.62\n",
      "Training Epoch 30  22.3% | batch:        21 of        94\t|\tloss: 1110.1\n",
      "Training Epoch 30  23.4% | batch:        22 of        94\t|\tloss: 1492.81\n",
      "Training Epoch 30  24.5% | batch:        23 of        94\t|\tloss: 1199.54\n",
      "Training Epoch 30  25.5% | batch:        24 of        94\t|\tloss: 1347.63\n",
      "Training Epoch 30  26.6% | batch:        25 of        94\t|\tloss: 2254.61\n",
      "Training Epoch 30  27.7% | batch:        26 of        94\t|\tloss: 1481.3\n",
      "Training Epoch 30  28.7% | batch:        27 of        94\t|\tloss: 1116.25\n",
      "Training Epoch 30  29.8% | batch:        28 of        94\t|\tloss: 662.442\n",
      "Training Epoch 30  30.9% | batch:        29 of        94\t|\tloss: 1563.18\n",
      "Training Epoch 30  31.9% | batch:        30 of        94\t|\tloss: 1257.91\n",
      "Training Epoch 30  33.0% | batch:        31 of        94\t|\tloss: 812.997\n",
      "Training Epoch 30  34.0% | batch:        32 of        94\t|\tloss: 845.011\n",
      "Training Epoch 30  35.1% | batch:        33 of        94\t|\tloss: 944.284\n",
      "Training Epoch 30  36.2% | batch:        34 of        94\t|\tloss: 2431.12\n",
      "Training Epoch 30  37.2% | batch:        35 of        94\t|\tloss: 1542.05\n",
      "Training Epoch 30  38.3% | batch:        36 of        94\t|\tloss: 1549.3\n",
      "Training Epoch 30  39.4% | batch:        37 of        94\t|\tloss: 1175.14\n",
      "Training Epoch 30  40.4% | batch:        38 of        94\t|\tloss: 1251.58\n",
      "Training Epoch 30  41.5% | batch:        39 of        94\t|\tloss: 1915.51\n",
      "Training Epoch 30  42.6% | batch:        40 of        94\t|\tloss: 1566.03\n",
      "Training Epoch 30  43.6% | batch:        41 of        94\t|\tloss: 1124.84\n",
      "Training Epoch 30  44.7% | batch:        42 of        94\t|\tloss: 1114.52\n",
      "Training Epoch 30  45.7% | batch:        43 of        94\t|\tloss: 1398.21\n",
      "Training Epoch 30  46.8% | batch:        44 of        94\t|\tloss: 2036.65\n",
      "Training Epoch 30  47.9% | batch:        45 of        94\t|\tloss: 1127.06\n",
      "Training Epoch 30  48.9% | batch:        46 of        94\t|\tloss: 1191.7\n",
      "Training Epoch 30  50.0% | batch:        47 of        94\t|\tloss: 1100.81\n",
      "Training Epoch 30  51.1% | batch:        48 of        94\t|\tloss: 2278.65\n",
      "Training Epoch 30  52.1% | batch:        49 of        94\t|\tloss: 1796.67\n",
      "Training Epoch 30  53.2% | batch:        50 of        94\t|\tloss: 1404.75\n",
      "Training Epoch 30  54.3% | batch:        51 of        94\t|\tloss: 1078.67\n",
      "Training Epoch 30  55.3% | batch:        52 of        94\t|\tloss: 1225.56\n",
      "Training Epoch 30  56.4% | batch:        53 of        94\t|\tloss: 1123.19\n",
      "Training Epoch 30  57.4% | batch:        54 of        94\t|\tloss: 3968.98\n",
      "Training Epoch 30  58.5% | batch:        55 of        94\t|\tloss: 2087.24\n",
      "Training Epoch 30  59.6% | batch:        56 of        94\t|\tloss: 1676.85\n",
      "Training Epoch 30  60.6% | batch:        57 of        94\t|\tloss: 1528.53\n",
      "Training Epoch 30  61.7% | batch:        58 of        94\t|\tloss: 2140.97\n",
      "Training Epoch 30  62.8% | batch:        59 of        94\t|\tloss: 1093.69\n",
      "Training Epoch 30  63.8% | batch:        60 of        94\t|\tloss: 2175.01\n",
      "Training Epoch 30  64.9% | batch:        61 of        94\t|\tloss: 879.959\n",
      "Training Epoch 30  66.0% | batch:        62 of        94\t|\tloss: 1391.81\n",
      "Training Epoch 30  67.0% | batch:        63 of        94\t|\tloss: 2200.26\n",
      "Training Epoch 30  68.1% | batch:        64 of        94\t|\tloss: 1599.83\n",
      "Training Epoch 30  69.1% | batch:        65 of        94\t|\tloss: 1774.53\n",
      "Training Epoch 30  70.2% | batch:        66 of        94\t|\tloss: 3203.69\n",
      "Training Epoch 30  71.3% | batch:        67 of        94\t|\tloss: 1510.73\n",
      "Training Epoch 30  72.3% | batch:        68 of        94\t|\tloss: 1565.95\n",
      "Training Epoch 30  73.4% | batch:        69 of        94\t|\tloss: 1674.21\n",
      "Training Epoch 30  74.5% | batch:        70 of        94\t|\tloss: 1267.08\n",
      "Training Epoch 30  75.5% | batch:        71 of        94\t|\tloss: 2233.06\n",
      "Training Epoch 30  76.6% | batch:        72 of        94\t|\tloss: 1353.4\n",
      "Training Epoch 30  77.7% | batch:        73 of        94\t|\tloss: 1599.52\n",
      "Training Epoch 30  78.7% | batch:        74 of        94\t|\tloss: 1456.02\n",
      "Training Epoch 30  79.8% | batch:        75 of        94\t|\tloss: 1595.41\n",
      "Training Epoch 30  80.9% | batch:        76 of        94\t|\tloss: 2434.2\n",
      "Training Epoch 30  81.9% | batch:        77 of        94\t|\tloss: 1552.25\n",
      "Training Epoch 30  83.0% | batch:        78 of        94\t|\tloss: 1287.41\n",
      "Training Epoch 30  84.0% | batch:        79 of        94\t|\tloss: 1651.12\n",
      "Training Epoch 30  85.1% | batch:        80 of        94\t|\tloss: 1433.35\n",
      "Training Epoch 30  86.2% | batch:        81 of        94\t|\tloss: 1295.53\n",
      "Training Epoch 30  87.2% | batch:        82 of        94\t|\tloss: 2000.78\n",
      "Training Epoch 30  88.3% | batch:        83 of        94\t|\tloss: 1496.65\n",
      "Training Epoch 30  89.4% | batch:        84 of        94\t|\tloss: 1084.18\n",
      "Training Epoch 30  90.4% | batch:        85 of        94\t|\tloss: 1676.98\n",
      "Training Epoch 30  91.5% | batch:        86 of        94\t|\tloss: 1352.96\n",
      "Training Epoch 30  92.6% | batch:        87 of        94\t|\tloss: 1235.63\n",
      "Training Epoch 30  93.6% | batch:        88 of        94\t|\tloss: 1103.75\n",
      "Training Epoch 30  94.7% | batch:        89 of        94\t|\tloss: 3418.33\n",
      "Training Epoch 30  95.7% | batch:        90 of        94\t|\tloss: 2978.95\n",
      "Training Epoch 30  96.8% | batch:        91 of        94\t|\tloss: 3586.45\n",
      "Training Epoch 30  97.9% | batch:        92 of        94\t|\tloss: 1600.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:52,505 | INFO : Epoch 30 Training Summary: epoch: 30.000000 | loss: 1626.429840 | \n",
      "2023-05-04 16:59:52,506 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8018853664398193 seconds\n",
      "\n",
      "2023-05-04 16:59:52,507 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7888296922047933 seconds\n",
      "2023-05-04 16:59:52,507 | INFO : Avg batch train. time: 0.01903010310856163 seconds\n",
      "2023-05-04 16:59:52,508 | INFO : Avg sample train. time: 0.00015009478874012362 seconds\n",
      "2023-05-04 16:59:52,508 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 30  98.9% | batch:        93 of        94\t|\tloss: 1403.25\n",
      "\n",
      "Evaluating Epoch 30   0.0% | batch:         0 of        40\t|\tloss: 6978.08\n",
      "Evaluating Epoch 30   2.5% | batch:         1 of        40\t|\tloss: 1125.87\n",
      "Evaluating Epoch 30   5.0% | batch:         2 of        40\t|\tloss: 2915.38\n",
      "Evaluating Epoch 30   7.5% | batch:         3 of        40\t|\tloss: 6886.71\n",
      "Evaluating Epoch 30  10.0% | batch:         4 of        40\t|\tloss: 1939.31\n",
      "Evaluating Epoch 30  12.5% | batch:         5 of        40\t|\tloss: 2125.83\n",
      "Evaluating Epoch 30  15.0% | batch:         6 of        40\t|\tloss: 7346.91\n",
      "Evaluating Epoch 30  17.5% | batch:         7 of        40\t|\tloss: 2873.84\n",
      "Evaluating Epoch 30  20.0% | batch:         8 of        40\t|\tloss: 2473.84\n",
      "Evaluating Epoch 30  22.5% | batch:         9 of        40\t|\tloss: 1809.93\n",
      "Evaluating Epoch 30  25.0% | batch:        10 of        40\t|\tloss: 4590.81\n",
      "Evaluating Epoch 30  27.5% | batch:        11 of        40\t|\tloss: 1659.73\n",
      "Evaluating Epoch 30  30.0% | batch:        12 of        40\t|\tloss: 5287.59\n",
      "Evaluating Epoch 30  32.5% | batch:        13 of        40\t|\tloss: 2970.37\n",
      "Evaluating Epoch 30  35.0% | batch:        14 of        40\t|\tloss: 2007.7\n",
      "Evaluating Epoch 30  37.5% | batch:        15 of        40\t|\tloss: 3088.99\n",
      "Evaluating Epoch 30  40.0% | batch:        16 of        40\t|\tloss: 4906.11\n",
      "Evaluating Epoch 30  42.5% | batch:        17 of        40\t|\tloss: 2714.88\n",
      "Evaluating Epoch 30  45.0% | batch:        18 of        40\t|\tloss: 2338.94\n",
      "Evaluating Epoch 30  47.5% | batch:        19 of        40\t|\tloss: 5196.12\n",
      "Evaluating Epoch 30  50.0% | batch:        20 of        40\t|\tloss: 4386.26\n",
      "Evaluating Epoch 30  52.5% | batch:        21 of        40\t|\tloss: 975.791\n",
      "Evaluating Epoch 30  55.0% | batch:        22 of        40\t|\tloss: 3826.16\n",
      "Evaluating Epoch 30  57.5% | batch:        23 of        40\t|\tloss: 2640.61\n",
      "Evaluating Epoch 30  60.0% | batch:        24 of        40\t|\tloss: 1587.37\n",
      "Evaluating Epoch 30  62.5% | batch:        25 of        40\t|\tloss: 3186.69\n",
      "Evaluating Epoch 30  65.0% | batch:        26 of        40\t|\tloss: 10257.2\n",
      "Evaluating Epoch 30  67.5% | batch:        27 of        40\t|\tloss: 2597.95\n",
      "Evaluating Epoch 30  70.0% | batch:        28 of        40\t|\tloss: 1663.42\n",
      "Evaluating Epoch 30  72.5% | batch:        29 of        40\t|\tloss: 9051.22\n",
      "Evaluating Epoch 30  75.0% | batch:        30 of        40\t|\tloss: 1707.89\n",
      "Evaluating Epoch 30  77.5% | batch:        31 of        40\t|\tloss: 1601.59\n",
      "Evaluating Epoch 30  80.0% | batch:        32 of        40\t|\tloss: 7627.22\n",
      "Evaluating Epoch 30  82.5% | batch:        33 of        40\t|\tloss: 5694.44\n",
      "Evaluating Epoch 30  85.0% | batch:        34 of        40\t|\tloss: 1299.97\n",
      "Evaluating Epoch 30  87.5% | batch:        35 of        40\t|\tloss: 5438.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:52,957 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4472832679748535 seconds\n",
      "\n",
      "2023-05-04 16:59:52,957 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5411051926987894 seconds\n",
      "2023-05-04 16:59:52,958 | INFO : Avg batch val. time: 0.013527629817469735 seconds\n",
      "2023-05-04 16:59:52,958 | INFO : Avg sample val. time: 0.0001071919953840708 seconds\n",
      "2023-05-04 16:59:52,959 | INFO : Epoch 30 Validation Summary: epoch: 30.000000 | loss: 3837.703588 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 30  90.0% | batch:        36 of        40\t|\tloss: 6324.84\n",
      "Evaluating Epoch 30  92.5% | batch:        37 of        40\t|\tloss: 2528.51\n",
      "Evaluating Epoch 30  95.0% | batch:        38 of        40\t|\tloss: 3348.24\n",
      "Evaluating Epoch 30  97.5% | batch:        39 of        40\t|\tloss: 9984.19\n",
      "\n",
      "Training Epoch 31   0.0% | batch:         0 of        94\t|\tloss: 1464.78\n",
      "Training Epoch 31   1.1% | batch:         1 of        94\t|\tloss: 893.164\n",
      "Training Epoch 31   2.1% | batch:         2 of        94\t|\tloss: 1112.99\n",
      "Training Epoch 31   3.2% | batch:         3 of        94\t|\tloss: 1270.44\n",
      "Training Epoch 31   4.3% | batch:         4 of        94\t|\tloss: 3709.9\n",
      "Training Epoch 31   5.3% | batch:         5 of        94\t|\tloss: 3612.97\n",
      "Training Epoch 31   6.4% | batch:         6 of        94\t|\tloss: 1077.58\n",
      "Training Epoch 31   7.4% | batch:         7 of        94\t|\tloss: 1665.94\n",
      "Training Epoch 31   8.5% | batch:         8 of        94\t|\tloss: 1110.19\n",
      "Training Epoch 31   9.6% | batch:         9 of        94\t|\tloss: 1119.36\n",
      "Training Epoch 31  10.6% | batch:        10 of        94\t|\tloss: 948.402\n",
      "Training Epoch 31  11.7% | batch:        11 of        94\t|\tloss: 1589.72\n",
      "Training Epoch 31  12.8% | batch:        12 of        94\t|\tloss: 1519.13\n",
      "Training Epoch 31  13.8% | batch:        13 of        94\t|\tloss: 1919.23\n",
      "Training Epoch 31  14.9% | batch:        14 of        94\t|\tloss: 1112.08\n",
      "Training Epoch 31  16.0% | batch:        15 of        94\t|\tloss: 1738.79\n",
      "Training Epoch 31  17.0% | batch:        16 of        94\t|\tloss: 1538.61\n",
      "Training Epoch 31  18.1% | batch:        17 of        94\t|\tloss: 2080.39\n",
      "Training Epoch 31  19.1% | batch:        18 of        94\t|\tloss: 1069.31\n",
      "Training Epoch 31  20.2% | batch:        19 of        94\t|\tloss: 1473.74\n",
      "Training Epoch 31  21.3% | batch:        20 of        94\t|\tloss: 1432.31\n",
      "Training Epoch 31  22.3% | batch:        21 of        94\t|\tloss: 2146.91\n",
      "Training Epoch 31  23.4% | batch:        22 of        94\t|\tloss: 1245.38\n",
      "Training Epoch 31  24.5% | batch:        23 of        94\t|\tloss: 1168.65\n",
      "Training Epoch 31  25.5% | batch:        24 of        94\t|\tloss: 1061.42\n",
      "Training Epoch 31  26.6% | batch:        25 of        94\t|\tloss: 1460.26\n",
      "Training Epoch 31  27.7% | batch:        26 of        94\t|\tloss: 1667.64\n",
      "Training Epoch 31  28.7% | batch:        27 of        94\t|\tloss: 1285.48\n",
      "Training Epoch 31  29.8% | batch:        28 of        94\t|\tloss: 1269.45\n",
      "Training Epoch 31  30.9% | batch:        29 of        94\t|\tloss: 919.311\n",
      "Training Epoch 31  31.9% | batch:        30 of        94\t|\tloss: 1711.88\n",
      "Training Epoch 31  33.0% | batch:        31 of        94\t|\tloss: 1912.75\n",
      "Training Epoch 31  34.0% | batch:        32 of        94\t|\tloss: 1263.75\n",
      "Training Epoch 31  35.1% | batch:        33 of        94\t|\tloss: 2153.42\n",
      "Training Epoch 31  36.2% | batch:        34 of        94\t|\tloss: 1206.98\n",
      "Training Epoch 31  37.2% | batch:        35 of        94\t|\tloss: 1528.53\n",
      "Training Epoch 31  38.3% | batch:        36 of        94\t|\tloss: 1620.68\n",
      "Training Epoch 31  39.4% | batch:        37 of        94\t|\tloss: 1899.61\n",
      "Training Epoch 31  40.4% | batch:        38 of        94\t|\tloss: 1353.07\n",
      "Training Epoch 31  41.5% | batch:        39 of        94\t|\tloss: 1530.57\n",
      "Training Epoch 31  42.6% | batch:        40 of        94\t|\tloss: 1034.59\n",
      "Training Epoch 31  43.6% | batch:        41 of        94\t|\tloss: 1161.62\n",
      "Training Epoch 31  44.7% | batch:        42 of        94\t|\tloss: 1786.5\n",
      "Training Epoch 31  45.7% | batch:        43 of        94\t|\tloss: 1670.77\n",
      "Training Epoch 31  46.8% | batch:        44 of        94\t|\tloss: 1379.83\n",
      "Training Epoch 31  47.9% | batch:        45 of        94\t|\tloss: 1434.14\n",
      "Training Epoch 31  48.9% | batch:        46 of        94\t|\tloss: 1157.26\n",
      "Training Epoch 31  50.0% | batch:        47 of        94\t|\tloss: 1711.46\n",
      "Training Epoch 31  51.1% | batch:        48 of        94\t|\tloss: 1449.26\n",
      "Training Epoch 31  52.1% | batch:        49 of        94\t|\tloss: 1025.58\n",
      "Training Epoch 31  53.2% | batch:        50 of        94\t|\tloss: 1494.78\n",
      "Training Epoch 31  54.3% | batch:        51 of        94\t|\tloss: 1507.14\n",
      "Training Epoch 31  55.3% | batch:        52 of        94\t|\tloss: 1544.23\n",
      "Training Epoch 31  56.4% | batch:        53 of        94\t|\tloss: 1646.32\n",
      "Training Epoch 31  57.4% | batch:        54 of        94\t|\tloss: 2444.51\n",
      "Training Epoch 31  58.5% | batch:        55 of        94\t|\tloss: 1051.87\n",
      "Training Epoch 31  59.6% | batch:        56 of        94\t|\tloss: 1717.62\n",
      "Training Epoch 31  60.6% | batch:        57 of        94\t|\tloss: 1558.48\n",
      "Training Epoch 31  61.7% | batch:        58 of        94\t|\tloss: 1576.83\n",
      "Training Epoch 31  62.8% | batch:        59 of        94\t|\tloss: 1366.85\n",
      "Training Epoch 31  63.8% | batch:        60 of        94\t|\tloss: 1682.42\n",
      "Training Epoch 31  64.9% | batch:        61 of        94\t|\tloss: 1273.67\n",
      "Training Epoch 31  66.0% | batch:        62 of        94\t|\tloss: 1028.17\n",
      "Training Epoch 31  67.0% | batch:        63 of        94\t|\tloss: 2041.27\n",
      "Training Epoch 31  68.1% | batch:        64 of        94\t|\tloss: 1220.87\n",
      "Training Epoch 31  69.1% | batch:        65 of        94\t|\tloss: 1425.44\n",
      "Training Epoch 31  70.2% | batch:        66 of        94\t|\tloss: 3163.42\n",
      "Training Epoch 31  71.3% | batch:        67 of        94\t|\tloss: 1556.74\n",
      "Training Epoch 31  72.3% | batch:        68 of        94\t|\tloss: 1553.67\n",
      "Training Epoch 31  73.4% | batch:        69 of        94\t|\tloss: 2854.16\n",
      "Training Epoch 31  74.5% | batch:        70 of        94\t|\tloss: 2094.67\n",
      "Training Epoch 31  75.5% | batch:        71 of        94\t|\tloss: 1738.5\n",
      "Training Epoch 31  76.6% | batch:        72 of        94\t|\tloss: 1184.39\n",
      "Training Epoch 31  77.7% | batch:        73 of        94\t|\tloss: 1457.94\n",
      "Training Epoch 31  78.7% | batch:        74 of        94\t|\tloss: 970.863\n",
      "Training Epoch 31  79.8% | batch:        75 of        94\t|\tloss: 1246.81\n",
      "Training Epoch 31  80.9% | batch:        76 of        94\t|\tloss: 1392.42\n",
      "Training Epoch 31  81.9% | batch:        77 of        94\t|\tloss: 1503.65\n",
      "Training Epoch 31  83.0% | batch:        78 of        94\t|\tloss: 1727.5\n",
      "Training Epoch 31  84.0% | batch:        79 of        94\t|\tloss: 1262.51\n",
      "Training Epoch 31  85.1% | batch:        80 of        94\t|\tloss: 1661.53\n",
      "Training Epoch 31  86.2% | batch:        81 of        94\t|\tloss: 1887.96\n",
      "Training Epoch 31  87.2% | batch:        82 of        94\t|\tloss: 1030.09\n",
      "Training Epoch 31  88.3% | batch:        83 of        94\t|\tloss: 1489.94\n",
      "Training Epoch 31  89.4% | batch:        84 of        94\t|\tloss: 2275.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:54,773 | INFO : Epoch 31 Training Summary: epoch: 31.000000 | loss: 1577.332258 | \n",
      "2023-05-04 16:59:54,774 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8016130924224854 seconds\n",
      "\n",
      "2023-05-04 16:59:54,774 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.789242059953751 seconds\n",
      "2023-05-04 16:59:54,775 | INFO : Avg batch train. time: 0.01903448999950799 seconds\n",
      "2023-05-04 16:59:54,775 | INFO : Avg sample train. time: 0.0001501293891553743 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 31  90.4% | batch:        85 of        94\t|\tloss: 1092.3\n",
      "Training Epoch 31  91.5% | batch:        86 of        94\t|\tloss: 1445.76\n",
      "Training Epoch 31  92.6% | batch:        87 of        94\t|\tloss: 2528.32\n",
      "Training Epoch 31  93.6% | batch:        88 of        94\t|\tloss: 991.637\n",
      "Training Epoch 31  94.7% | batch:        89 of        94\t|\tloss: 1134.53\n",
      "Training Epoch 31  95.7% | batch:        90 of        94\t|\tloss: 4255.77\n",
      "Training Epoch 31  96.8% | batch:        91 of        94\t|\tloss: 1342.78\n",
      "Training Epoch 31  97.9% | batch:        92 of        94\t|\tloss: 1035.24\n",
      "Training Epoch 31  98.9% | batch:        93 of        94\t|\tloss: 6668.31\n",
      "\n",
      "Training Epoch 32   0.0% | batch:         0 of        94\t|\tloss: 891.205\n",
      "Training Epoch 32   1.1% | batch:         1 of        94\t|\tloss: 1313.03\n",
      "Training Epoch 32   2.1% | batch:         2 of        94\t|\tloss: 2260.82\n",
      "Training Epoch 32   3.2% | batch:         3 of        94\t|\tloss: 1748.76\n",
      "Training Epoch 32   4.3% | batch:         4 of        94\t|\tloss: 2134.21\n",
      "Training Epoch 32   5.3% | batch:         5 of        94\t|\tloss: 1762.82\n",
      "Training Epoch 32   6.4% | batch:         6 of        94\t|\tloss: 1093.47\n",
      "Training Epoch 32   7.4% | batch:         7 of        94\t|\tloss: 2086.97\n",
      "Training Epoch 32   8.5% | batch:         8 of        94\t|\tloss: 3152.46\n",
      "Training Epoch 32   9.6% | batch:         9 of        94\t|\tloss: 1227.86\n",
      "Training Epoch 32  10.6% | batch:        10 of        94\t|\tloss: 1527.07\n",
      "Training Epoch 32  11.7% | batch:        11 of        94\t|\tloss: 948.855\n",
      "Training Epoch 32  12.8% | batch:        12 of        94\t|\tloss: 1411.39\n",
      "Training Epoch 32  13.8% | batch:        13 of        94\t|\tloss: 3182.38\n",
      "Training Epoch 32  14.9% | batch:        14 of        94\t|\tloss: 1068.61\n",
      "Training Epoch 32  16.0% | batch:        15 of        94\t|\tloss: 787.785\n",
      "Training Epoch 32  17.0% | batch:        16 of        94\t|\tloss: 2193.08\n",
      "Training Epoch 32  18.1% | batch:        17 of        94\t|\tloss: 1220.9\n",
      "Training Epoch 32  19.1% | batch:        18 of        94\t|\tloss: 1237.55\n",
      "Training Epoch 32  20.2% | batch:        19 of        94\t|\tloss: 1607.02\n",
      "Training Epoch 32  21.3% | batch:        20 of        94\t|\tloss: 2197.06\n",
      "Training Epoch 32  22.3% | batch:        21 of        94\t|\tloss: 1502.21\n",
      "Training Epoch 32  23.4% | batch:        22 of        94\t|\tloss: 1520.77\n",
      "Training Epoch 32  24.5% | batch:        23 of        94\t|\tloss: 1117.8\n",
      "Training Epoch 32  25.5% | batch:        24 of        94\t|\tloss: 1837.05\n",
      "Training Epoch 32  26.6% | batch:        25 of        94\t|\tloss: 2291.53\n",
      "Training Epoch 32  27.7% | batch:        26 of        94\t|\tloss: 1452.42\n",
      "Training Epoch 32  28.7% | batch:        27 of        94\t|\tloss: 2218.08\n",
      "Training Epoch 32  29.8% | batch:        28 of        94\t|\tloss: 1987.71\n",
      "Training Epoch 32  30.9% | batch:        29 of        94\t|\tloss: 1434.33\n",
      "Training Epoch 32  31.9% | batch:        30 of        94\t|\tloss: 1362.35\n",
      "Training Epoch 32  33.0% | batch:        31 of        94\t|\tloss: 937.771\n",
      "Training Epoch 32  34.0% | batch:        32 of        94\t|\tloss: 1566.75\n",
      "Training Epoch 32  35.1% | batch:        33 of        94\t|\tloss: 2320.02\n",
      "Training Epoch 32  36.2% | batch:        34 of        94\t|\tloss: 1341.06\n",
      "Training Epoch 32  37.2% | batch:        35 of        94\t|\tloss: 1126.9\n",
      "Training Epoch 32  38.3% | batch:        36 of        94\t|\tloss: 1092.75\n",
      "Training Epoch 32  39.4% | batch:        37 of        94\t|\tloss: 1103.11\n",
      "Training Epoch 32  40.4% | batch:        38 of        94\t|\tloss: 877.589\n",
      "Training Epoch 32  41.5% | batch:        39 of        94\t|\tloss: 1295.58\n",
      "Training Epoch 32  42.6% | batch:        40 of        94\t|\tloss: 3160.97\n",
      "Training Epoch 32  43.6% | batch:        41 of        94\t|\tloss: 2197.23\n",
      "Training Epoch 32  44.7% | batch:        42 of        94\t|\tloss: 1027.62\n",
      "Training Epoch 32  45.7% | batch:        43 of        94\t|\tloss: 2458.86\n",
      "Training Epoch 32  46.8% | batch:        44 of        94\t|\tloss: 917.277\n",
      "Training Epoch 32  47.9% | batch:        45 of        94\t|\tloss: 1400.05\n",
      "Training Epoch 32  48.9% | batch:        46 of        94\t|\tloss: 1694.77\n",
      "Training Epoch 32  50.0% | batch:        47 of        94\t|\tloss: 3621.31\n",
      "Training Epoch 32  51.1% | batch:        48 of        94\t|\tloss: 2174.9\n",
      "Training Epoch 32  52.1% | batch:        49 of        94\t|\tloss: 1624.83\n",
      "Training Epoch 32  53.2% | batch:        50 of        94\t|\tloss: 1523.26\n",
      "Training Epoch 32  54.3% | batch:        51 of        94\t|\tloss: 1374.94\n",
      "Training Epoch 32  55.3% | batch:        52 of        94\t|\tloss: 1676.43\n",
      "Training Epoch 32  56.4% | batch:        53 of        94\t|\tloss: 2389.01\n",
      "Training Epoch 32  57.4% | batch:        54 of        94\t|\tloss: 1334.29\n",
      "Training Epoch 32  58.5% | batch:        55 of        94\t|\tloss: 1511.19\n",
      "Training Epoch 32  59.6% | batch:        56 of        94\t|\tloss: 1432.17\n",
      "Training Epoch 32  60.6% | batch:        57 of        94\t|\tloss: 820.845\n",
      "Training Epoch 32  61.7% | batch:        58 of        94\t|\tloss: 2072.36\n",
      "Training Epoch 32  62.8% | batch:        59 of        94\t|\tloss: 991.14\n",
      "Training Epoch 32  63.8% | batch:        60 of        94\t|\tloss: 1441.45\n",
      "Training Epoch 32  64.9% | batch:        61 of        94\t|\tloss: 1890.3\n",
      "Training Epoch 32  66.0% | batch:        62 of        94\t|\tloss: 1595.26\n",
      "Training Epoch 32  67.0% | batch:        63 of        94\t|\tloss: 1470.75\n",
      "Training Epoch 32  68.1% | batch:        64 of        94\t|\tloss: 1214.5\n",
      "Training Epoch 32  69.1% | batch:        65 of        94\t|\tloss: 1198.14\n",
      "Training Epoch 32  70.2% | batch:        66 of        94\t|\tloss: 1106.93\n",
      "Training Epoch 32  71.3% | batch:        67 of        94\t|\tloss: 2039.25\n",
      "Training Epoch 32  72.3% | batch:        68 of        94\t|\tloss: 1369.13\n",
      "Training Epoch 32  73.4% | batch:        69 of        94\t|\tloss: 1587.21\n",
      "Training Epoch 32  74.5% | batch:        70 of        94\t|\tloss: 3893.86\n",
      "Training Epoch 32  75.5% | batch:        71 of        94\t|\tloss: 1090.65\n",
      "Training Epoch 32  76.6% | batch:        72 of        94\t|\tloss: 1939.7\n",
      "Training Epoch 32  77.7% | batch:        73 of        94\t|\tloss: 1287.6\n",
      "Training Epoch 32  78.7% | batch:        74 of        94\t|\tloss: 1293.19\n",
      "Training Epoch 32  79.8% | batch:        75 of        94\t|\tloss: 1228.97\n",
      "Training Epoch 32  80.9% | batch:        76 of        94\t|\tloss: 1368.84\n",
      "Training Epoch 32  81.9% | batch:        77 of        94\t|\tloss: 1089.46\n",
      "Training Epoch 32  83.0% | batch:        78 of        94\t|\tloss: 1583.47\n",
      "Training Epoch 32  84.0% | batch:        79 of        94\t|\tloss: 638.165\n",
      "Training Epoch 32  85.1% | batch:        80 of        94\t|\tloss: 2221.64\n",
      "Training Epoch 32  86.2% | batch:        81 of        94\t|\tloss: 1294.12\n",
      "Training Epoch 32  87.2% | batch:        82 of        94\t|\tloss: 2003.18\n",
      "Training Epoch 32  88.3% | batch:        83 of        94\t|\tloss: 1113\n",
      "Training Epoch 32  89.4% | batch:        84 of        94\t|\tloss: 1597.18\n",
      "Training Epoch 32  90.4% | batch:        85 of        94\t|\tloss: 813.926\n",
      "Training Epoch 32  91.5% | batch:        86 of        94\t|\tloss: 2129.5\n",
      "Training Epoch 32  92.6% | batch:        87 of        94\t|\tloss: 2174.77\n",
      "Training Epoch 32  93.6% | batch:        88 of        94\t|\tloss: 1253.59\n",
      "Training Epoch 32  94.7% | batch:        89 of        94\t|\tloss: 1224.11\n",
      "Training Epoch 32  95.7% | batch:        90 of        94\t|\tloss: 1610.21\n",
      "Training Epoch 32  96.8% | batch:        91 of        94\t|\tloss: 1387.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:56,547 | INFO : Epoch 32 Training Summary: epoch: 32.000000 | loss: 1604.400592 | \n",
      "2023-05-04 16:59:56,548 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7516937255859375 seconds\n",
      "\n",
      "2023-05-04 16:59:56,549 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.788068674504757 seconds\n",
      "2023-05-04 16:59:56,550 | INFO : Avg batch train. time: 0.01902200717558252 seconds\n",
      "2023-05-04 16:59:56,550 | INFO : Avg sample train. time: 0.000150030934259503 seconds\n",
      "2023-05-04 16:59:56,551 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 32  97.9% | batch:        92 of        94\t|\tloss: 1247.84\n",
      "Training Epoch 32  98.9% | batch:        93 of        94\t|\tloss: 1327.01\n",
      "\n",
      "Evaluating Epoch 32   0.0% | batch:         0 of        40\t|\tloss: 6165.15\n",
      "Evaluating Epoch 32   2.5% | batch:         1 of        40\t|\tloss: 1077.52\n",
      "Evaluating Epoch 32   5.0% | batch:         2 of        40\t|\tloss: 2279.31\n",
      "Evaluating Epoch 32   7.5% | batch:         3 of        40\t|\tloss: 6385.47\n",
      "Evaluating Epoch 32  10.0% | batch:         4 of        40\t|\tloss: 2343.6\n",
      "Evaluating Epoch 32  12.5% | batch:         5 of        40\t|\tloss: 2421.64\n",
      "Evaluating Epoch 32  15.0% | batch:         6 of        40\t|\tloss: 7258.02\n",
      "Evaluating Epoch 32  17.5% | batch:         7 of        40\t|\tloss: 2737.71\n",
      "Evaluating Epoch 32  20.0% | batch:         8 of        40\t|\tloss: 2463.93\n",
      "Evaluating Epoch 32  22.5% | batch:         9 of        40\t|\tloss: 1898.43\n",
      "Evaluating Epoch 32  25.0% | batch:        10 of        40\t|\tloss: 4474.11\n",
      "Evaluating Epoch 32  27.5% | batch:        11 of        40\t|\tloss: 1379.72\n",
      "Evaluating Epoch 32  30.0% | batch:        12 of        40\t|\tloss: 5565.34\n",
      "Evaluating Epoch 32  32.5% | batch:        13 of        40\t|\tloss: 2743.53\n",
      "Evaluating Epoch 32  35.0% | batch:        14 of        40\t|\tloss: 1852.11\n",
      "Evaluating Epoch 32  37.5% | batch:        15 of        40\t|\tloss: 3380.62\n",
      "Evaluating Epoch 32  40.0% | batch:        16 of        40\t|\tloss: 4279.77\n",
      "Evaluating Epoch 32  42.5% | batch:        17 of        40\t|\tloss: 2647.49\n",
      "Evaluating Epoch 32  45.0% | batch:        18 of        40\t|\tloss: 2385.14\n",
      "Evaluating Epoch 32  47.5% | batch:        19 of        40\t|\tloss: 4404.68\n",
      "Evaluating Epoch 32  50.0% | batch:        20 of        40\t|\tloss: 4178.73\n",
      "Evaluating Epoch 32  52.5% | batch:        21 of        40\t|\tloss: 1012.24\n",
      "Evaluating Epoch 32  55.0% | batch:        22 of        40\t|\tloss: 3448.1\n",
      "Evaluating Epoch 32  57.5% | batch:        23 of        40\t|\tloss: 2503.35\n",
      "Evaluating Epoch 32  60.0% | batch:        24 of        40\t|\tloss: 1760.76\n",
      "Evaluating Epoch 32  62.5% | batch:        25 of        40\t|\tloss: 3046.03\n",
      "Evaluating Epoch 32  65.0% | batch:        26 of        40\t|\tloss: 8651.72\n",
      "Evaluating Epoch 32  67.5% | batch:        27 of        40\t|\tloss: 2495.65\n",
      "Evaluating Epoch 32  70.0% | batch:        28 of        40\t|\tloss: 1779.58\n",
      "Evaluating Epoch 32  72.5% | batch:        29 of        40\t|\tloss: 7909.76\n",
      "Evaluating Epoch 32  75.0% | batch:        30 of        40\t|\tloss: 1551.47\n",
      "Evaluating Epoch 32  77.5% | batch:        31 of        40\t|\tloss: 1330.6\n",
      "Evaluating Epoch 32  80.0% | batch:        32 of        40\t|\tloss: 6808.79\n",
      "Evaluating Epoch 32  82.5% | batch:        33 of        40\t|\tloss: 5291.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:57,000 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44844722747802734 seconds\n",
      "\n",
      "2023-05-04 16:59:57,001 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5405875504349863 seconds\n",
      "2023-05-04 16:59:57,001 | INFO : Avg batch val. time: 0.013514688760874657 seconds\n",
      "2023-05-04 16:59:57,002 | INFO : Avg sample val. time: 0.00010708945135399887 seconds\n",
      "2023-05-04 16:59:57,003 | INFO : Epoch 32 Validation Summary: epoch: 32.000000 | loss: 3591.061813 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 32  85.0% | batch:        34 of        40\t|\tloss: 1177.56\n",
      "Evaluating Epoch 32  87.5% | batch:        35 of        40\t|\tloss: 4561.99\n",
      "Evaluating Epoch 32  90.0% | batch:        36 of        40\t|\tloss: 6188.97\n",
      "Evaluating Epoch 32  92.5% | batch:        37 of        40\t|\tloss: 2353.77\n",
      "Evaluating Epoch 32  95.0% | batch:        38 of        40\t|\tloss: 3338.06\n",
      "Evaluating Epoch 32  97.5% | batch:        39 of        40\t|\tloss: 9348.79\n",
      "\n",
      "Training Epoch 33   0.0% | batch:         0 of        94\t|\tloss: 950.301\n",
      "Training Epoch 33   1.1% | batch:         1 of        94\t|\tloss: 1304.89\n",
      "Training Epoch 33   2.1% | batch:         2 of        94\t|\tloss: 2205.4\n",
      "Training Epoch 33   3.2% | batch:         3 of        94\t|\tloss: 1348.76\n",
      "Training Epoch 33   4.3% | batch:         4 of        94\t|\tloss: 3518.7\n",
      "Training Epoch 33   5.3% | batch:         5 of        94\t|\tloss: 1250.68\n",
      "Training Epoch 33   6.4% | batch:         6 of        94\t|\tloss: 3800.54\n",
      "Training Epoch 33   7.4% | batch:         7 of        94\t|\tloss: 838.836\n",
      "Training Epoch 33   8.5% | batch:         8 of        94\t|\tloss: 2087.5\n",
      "Training Epoch 33   9.6% | batch:         9 of        94\t|\tloss: 1601.29\n",
      "Training Epoch 33  10.6% | batch:        10 of        94\t|\tloss: 1663.43\n",
      "Training Epoch 33  11.7% | batch:        11 of        94\t|\tloss: 1279.92\n",
      "Training Epoch 33  12.8% | batch:        12 of        94\t|\tloss: 1323.82\n",
      "Training Epoch 33  13.8% | batch:        13 of        94\t|\tloss: 1400.02\n",
      "Training Epoch 33  14.9% | batch:        14 of        94\t|\tloss: 1777.69\n",
      "Training Epoch 33  16.0% | batch:        15 of        94\t|\tloss: 1298.83\n",
      "Training Epoch 33  17.0% | batch:        16 of        94\t|\tloss: 1278.19\n",
      "Training Epoch 33  18.1% | batch:        17 of        94\t|\tloss: 1672.15\n",
      "Training Epoch 33  19.1% | batch:        18 of        94\t|\tloss: 2694.34\n",
      "Training Epoch 33  20.2% | batch:        19 of        94\t|\tloss: 1499.08\n",
      "Training Epoch 33  21.3% | batch:        20 of        94\t|\tloss: 1165.94\n",
      "Training Epoch 33  22.3% | batch:        21 of        94\t|\tloss: 1185.71\n",
      "Training Epoch 33  23.4% | batch:        22 of        94\t|\tloss: 1220.74\n",
      "Training Epoch 33  24.5% | batch:        23 of        94\t|\tloss: 1380.58\n",
      "Training Epoch 33  25.5% | batch:        24 of        94\t|\tloss: 999.895\n",
      "Training Epoch 33  26.6% | batch:        25 of        94\t|\tloss: 902.799\n",
      "Training Epoch 33  27.7% | batch:        26 of        94\t|\tloss: 1174.35\n",
      "Training Epoch 33  28.7% | batch:        27 of        94\t|\tloss: 1045.4\n",
      "Training Epoch 33  29.8% | batch:        28 of        94\t|\tloss: 1389.83\n",
      "Training Epoch 33  30.9% | batch:        29 of        94\t|\tloss: 1271.47\n",
      "Training Epoch 33  31.9% | batch:        30 of        94\t|\tloss: 1674.55\n",
      "Training Epoch 33  33.0% | batch:        31 of        94\t|\tloss: 1109.32\n",
      "Training Epoch 33  34.0% | batch:        32 of        94\t|\tloss: 3606.82\n",
      "Training Epoch 33  35.1% | batch:        33 of        94\t|\tloss: 3090.06\n",
      "Training Epoch 33  36.2% | batch:        34 of        94\t|\tloss: 1182.68\n",
      "Training Epoch 33  37.2% | batch:        35 of        94\t|\tloss: 1727.99\n",
      "Training Epoch 33  38.3% | batch:        36 of        94\t|\tloss: 1504.07\n",
      "Training Epoch 33  39.4% | batch:        37 of        94\t|\tloss: 3604.97\n",
      "Training Epoch 33  40.4% | batch:        38 of        94\t|\tloss: 1951.79\n",
      "Training Epoch 33  41.5% | batch:        39 of        94\t|\tloss: 1452.58\n",
      "Training Epoch 33  42.6% | batch:        40 of        94\t|\tloss: 1248.37\n",
      "Training Epoch 33  43.6% | batch:        41 of        94\t|\tloss: 1997.79\n",
      "Training Epoch 33  44.7% | batch:        42 of        94\t|\tloss: 1169.68\n",
      "Training Epoch 33  45.7% | batch:        43 of        94\t|\tloss: 1602.69\n",
      "Training Epoch 33  46.8% | batch:        44 of        94\t|\tloss: 2000.37\n",
      "Training Epoch 33  47.9% | batch:        45 of        94\t|\tloss: 1410.02\n",
      "Training Epoch 33  48.9% | batch:        46 of        94\t|\tloss: 1903.5\n",
      "Training Epoch 33  50.0% | batch:        47 of        94\t|\tloss: 2016.63\n",
      "Training Epoch 33  51.1% | batch:        48 of        94\t|\tloss: 1045.89\n",
      "Training Epoch 33  52.1% | batch:        49 of        94\t|\tloss: 1274.55\n",
      "Training Epoch 33  53.2% | batch:        50 of        94\t|\tloss: 1614.76\n",
      "Training Epoch 33  54.3% | batch:        51 of        94\t|\tloss: 1389.56\n",
      "Training Epoch 33  55.3% | batch:        52 of        94\t|\tloss: 2038.56\n",
      "Training Epoch 33  56.4% | batch:        53 of        94\t|\tloss: 946.52\n",
      "Training Epoch 33  57.4% | batch:        54 of        94\t|\tloss: 1331.04\n",
      "Training Epoch 33  58.5% | batch:        55 of        94\t|\tloss: 1066.6\n",
      "Training Epoch 33  59.6% | batch:        56 of        94\t|\tloss: 1384.71\n",
      "Training Epoch 33  60.6% | batch:        57 of        94\t|\tloss: 1119.23\n",
      "Training Epoch 33  61.7% | batch:        58 of        94\t|\tloss: 1067.12\n",
      "Training Epoch 33  62.8% | batch:        59 of        94\t|\tloss: 2251.88\n",
      "Training Epoch 33  63.8% | batch:        60 of        94\t|\tloss: 1414.16\n",
      "Training Epoch 33  64.9% | batch:        61 of        94\t|\tloss: 1500.16\n",
      "Training Epoch 33  66.0% | batch:        62 of        94\t|\tloss: 1565.75\n",
      "Training Epoch 33  67.0% | batch:        63 of        94\t|\tloss: 1322.95\n",
      "Training Epoch 33  68.1% | batch:        64 of        94\t|\tloss: 2499.06\n",
      "Training Epoch 33  69.1% | batch:        65 of        94\t|\tloss: 3728.91\n",
      "Training Epoch 33  70.2% | batch:        66 of        94\t|\tloss: 2059.32\n",
      "Training Epoch 33  71.3% | batch:        67 of        94\t|\tloss: 1020.51\n",
      "Training Epoch 33  72.3% | batch:        68 of        94\t|\tloss: 1760.12\n",
      "Training Epoch 33  73.4% | batch:        69 of        94\t|\tloss: 1760.39\n",
      "Training Epoch 33  74.5% | batch:        70 of        94\t|\tloss: 1182.11\n",
      "Training Epoch 33  75.5% | batch:        71 of        94\t|\tloss: 1155.48\n",
      "Training Epoch 33  76.6% | batch:        72 of        94\t|\tloss: 1225.84\n",
      "Training Epoch 33  77.7% | batch:        73 of        94\t|\tloss: 1099.63\n",
      "Training Epoch 33  78.7% | batch:        74 of        94\t|\tloss: 1392.47\n",
      "Training Epoch 33  79.8% | batch:        75 of        94\t|\tloss: 1171.27\n",
      "Training Epoch 33  80.9% | batch:        76 of        94\t|\tloss: 1745.45\n",
      "Training Epoch 33  81.9% | batch:        77 of        94\t|\tloss: 1609.42\n",
      "Training Epoch 33  83.0% | batch:        78 of        94\t|\tloss: 1398.79\n",
      "Training Epoch 33  84.0% | batch:        79 of        94\t|\tloss: 1361.79\n",
      "Training Epoch 33  85.1% | batch:        80 of        94\t|\tloss: 1994.19\n",
      "Training Epoch 33  86.2% | batch:        81 of        94\t|\tloss: 2784.63\n",
      "Training Epoch 33  87.2% | batch:        82 of        94\t|\tloss: 1245.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:59:58,810 | INFO : Epoch 33 Training Summary: epoch: 33.000000 | loss: 1596.641037 | \n",
      "2023-05-04 16:59:58,811 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7861154079437256 seconds\n",
      "\n",
      "2023-05-04 16:59:58,811 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.788009484608968 seconds\n",
      "2023-05-04 16:59:58,812 | INFO : Avg batch train. time: 0.019021377495840087 seconds\n",
      "2023-05-04 16:59:58,812 | INFO : Avg sample train. time: 0.00015002596783092532 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 33  88.3% | batch:        83 of        94\t|\tloss: 1569.27\n",
      "Training Epoch 33  89.4% | batch:        84 of        94\t|\tloss: 1200.57\n",
      "Training Epoch 33  90.4% | batch:        85 of        94\t|\tloss: 1841.29\n",
      "Training Epoch 33  91.5% | batch:        86 of        94\t|\tloss: 1354.69\n",
      "Training Epoch 33  92.6% | batch:        87 of        94\t|\tloss: 1249.73\n",
      "Training Epoch 33  93.6% | batch:        88 of        94\t|\tloss: 1135.11\n",
      "Training Epoch 33  94.7% | batch:        89 of        94\t|\tloss: 1507.3\n",
      "Training Epoch 33  95.7% | batch:        90 of        94\t|\tloss: 1082.23\n",
      "Training Epoch 33  96.8% | batch:        91 of        94\t|\tloss: 1223.37\n",
      "Training Epoch 33  97.9% | batch:        92 of        94\t|\tloss: 1125.78\n",
      "Training Epoch 33  98.9% | batch:        93 of        94\t|\tloss: 547.746\n",
      "\n",
      "Training Epoch 34   0.0% | batch:         0 of        94\t|\tloss: 1078.22\n",
      "Training Epoch 34   1.1% | batch:         1 of        94\t|\tloss: 1379.52\n",
      "Training Epoch 34   2.1% | batch:         2 of        94\t|\tloss: 1310.33\n",
      "Training Epoch 34   3.2% | batch:         3 of        94\t|\tloss: 1299.67\n",
      "Training Epoch 34   4.3% | batch:         4 of        94\t|\tloss: 904.994\n",
      "Training Epoch 34   5.3% | batch:         5 of        94\t|\tloss: 2094.44\n",
      "Training Epoch 34   6.4% | batch:         6 of        94\t|\tloss: 3490.01\n",
      "Training Epoch 34   7.4% | batch:         7 of        94\t|\tloss: 1083.24\n",
      "Training Epoch 34   8.5% | batch:         8 of        94\t|\tloss: 1131.69\n",
      "Training Epoch 34   9.6% | batch:         9 of        94\t|\tloss: 1759.39\n",
      "Training Epoch 34  10.6% | batch:        10 of        94\t|\tloss: 1303.79\n",
      "Training Epoch 34  11.7% | batch:        11 of        94\t|\tloss: 2776.36\n",
      "Training Epoch 34  12.8% | batch:        12 of        94\t|\tloss: 823.925\n",
      "Training Epoch 34  13.8% | batch:        13 of        94\t|\tloss: 1107.5\n",
      "Training Epoch 34  14.9% | batch:        14 of        94\t|\tloss: 938.165\n",
      "Training Epoch 34  16.0% | batch:        15 of        94\t|\tloss: 1224.56\n",
      "Training Epoch 34  17.0% | batch:        16 of        94\t|\tloss: 1208.9\n",
      "Training Epoch 34  18.1% | batch:        17 of        94\t|\tloss: 852.047\n",
      "Training Epoch 34  19.1% | batch:        18 of        94\t|\tloss: 1300.18\n",
      "Training Epoch 34  20.2% | batch:        19 of        94\t|\tloss: 1867.41\n",
      "Training Epoch 34  21.3% | batch:        20 of        94\t|\tloss: 1331.2\n",
      "Training Epoch 34  22.3% | batch:        21 of        94\t|\tloss: 2415.11\n",
      "Training Epoch 34  23.4% | batch:        22 of        94\t|\tloss: 2141.56\n",
      "Training Epoch 34  24.5% | batch:        23 of        94\t|\tloss: 859.058\n",
      "Training Epoch 34  25.5% | batch:        24 of        94\t|\tloss: 1150.13\n",
      "Training Epoch 34  26.6% | batch:        25 of        94\t|\tloss: 1956.83\n",
      "Training Epoch 34  27.7% | batch:        26 of        94\t|\tloss: 1282.86\n",
      "Training Epoch 34  28.7% | batch:        27 of        94\t|\tloss: 1094.33\n",
      "Training Epoch 34  29.8% | batch:        28 of        94\t|\tloss: 1444.22\n",
      "Training Epoch 34  30.9% | batch:        29 of        94\t|\tloss: 1242.9\n",
      "Training Epoch 34  31.9% | batch:        30 of        94\t|\tloss: 1224.01\n",
      "Training Epoch 34  33.0% | batch:        31 of        94\t|\tloss: 1111.99\n",
      "Training Epoch 34  34.0% | batch:        32 of        94\t|\tloss: 1162.15\n",
      "Training Epoch 34  35.1% | batch:        33 of        94\t|\tloss: 1194.36\n",
      "Training Epoch 34  36.2% | batch:        34 of        94\t|\tloss: 1058.21\n",
      "Training Epoch 34  37.2% | batch:        35 of        94\t|\tloss: 1110.82\n",
      "Training Epoch 34  38.3% | batch:        36 of        94\t|\tloss: 1166.03\n",
      "Training Epoch 34  39.4% | batch:        37 of        94\t|\tloss: 1582.18\n",
      "Training Epoch 34  40.4% | batch:        38 of        94\t|\tloss: 880.141\n",
      "Training Epoch 34  41.5% | batch:        39 of        94\t|\tloss: 1059.32\n",
      "Training Epoch 34  42.6% | batch:        40 of        94\t|\tloss: 786.948\n",
      "Training Epoch 34  43.6% | batch:        41 of        94\t|\tloss: 1555.64\n",
      "Training Epoch 34  44.7% | batch:        42 of        94\t|\tloss: 1036.09\n",
      "Training Epoch 34  45.7% | batch:        43 of        94\t|\tloss: 1273.9\n",
      "Training Epoch 34  46.8% | batch:        44 of        94\t|\tloss: 983.301\n",
      "Training Epoch 34  47.9% | batch:        45 of        94\t|\tloss: 1125.13\n",
      "Training Epoch 34  48.9% | batch:        46 of        94\t|\tloss: 1146.2\n",
      "Training Epoch 34  50.0% | batch:        47 of        94\t|\tloss: 1568.13\n",
      "Training Epoch 34  51.1% | batch:        48 of        94\t|\tloss: 2181.59\n",
      "Training Epoch 34  52.1% | batch:        49 of        94\t|\tloss: 2473.63\n",
      "Training Epoch 34  53.2% | batch:        50 of        94\t|\tloss: 1291.64\n",
      "Training Epoch 34  54.3% | batch:        51 of        94\t|\tloss: 1053.98\n",
      "Training Epoch 34  55.3% | batch:        52 of        94\t|\tloss: 1094.48\n",
      "Training Epoch 34  56.4% | batch:        53 of        94\t|\tloss: 1097.99\n",
      "Training Epoch 34  57.4% | batch:        54 of        94\t|\tloss: 3157.21\n",
      "Training Epoch 34  58.5% | batch:        55 of        94\t|\tloss: 1102.07\n",
      "Training Epoch 34  59.6% | batch:        56 of        94\t|\tloss: 1802.64\n",
      "Training Epoch 34  60.6% | batch:        57 of        94\t|\tloss: 1669.05\n",
      "Training Epoch 34  61.7% | batch:        58 of        94\t|\tloss: 1338.09\n",
      "Training Epoch 34  62.8% | batch:        59 of        94\t|\tloss: 1260.92\n",
      "Training Epoch 34  63.8% | batch:        60 of        94\t|\tloss: 2770.95\n",
      "Training Epoch 34  64.9% | batch:        61 of        94\t|\tloss: 924.805\n",
      "Training Epoch 34  66.0% | batch:        62 of        94\t|\tloss: 1471.93\n",
      "Training Epoch 34  67.0% | batch:        63 of        94\t|\tloss: 1950.05\n",
      "Training Epoch 34  68.1% | batch:        64 of        94\t|\tloss: 1281.01\n",
      "Training Epoch 34  69.1% | batch:        65 of        94\t|\tloss: 1335.79\n",
      "Training Epoch 34  70.2% | batch:        66 of        94\t|\tloss: 1243.84\n",
      "Training Epoch 34  71.3% | batch:        67 of        94\t|\tloss: 2574.75\n",
      "Training Epoch 34  72.3% | batch:        68 of        94\t|\tloss: 2388.17\n",
      "Training Epoch 34  73.4% | batch:        69 of        94\t|\tloss: 1590.67\n",
      "Training Epoch 34  74.5% | batch:        70 of        94\t|\tloss: 2236.92\n",
      "Training Epoch 34  75.5% | batch:        71 of        94\t|\tloss: 863.798\n",
      "Training Epoch 34  76.6% | batch:        72 of        94\t|\tloss: 1619.26\n",
      "Training Epoch 34  77.7% | batch:        73 of        94\t|\tloss: 1206.9\n",
      "Training Epoch 34  78.7% | batch:        74 of        94\t|\tloss: 2278.82\n",
      "Training Epoch 34  79.8% | batch:        75 of        94\t|\tloss: 1224.15\n",
      "Training Epoch 34  80.9% | batch:        76 of        94\t|\tloss: 1249.62\n",
      "Training Epoch 34  81.9% | batch:        77 of        94\t|\tloss: 2627.11\n",
      "Training Epoch 34  83.0% | batch:        78 of        94\t|\tloss: 795.657\n",
      "Training Epoch 34  84.0% | batch:        79 of        94\t|\tloss: 1485.93\n",
      "Training Epoch 34  85.1% | batch:        80 of        94\t|\tloss: 1885.36\n",
      "Training Epoch 34  86.2% | batch:        81 of        94\t|\tloss: 1403.83\n",
      "Training Epoch 34  87.2% | batch:        82 of        94\t|\tloss: 3310.52\n",
      "Training Epoch 34  88.3% | batch:        83 of        94\t|\tloss: 1271.56\n",
      "Training Epoch 34  89.4% | batch:        84 of        94\t|\tloss: 1571.82\n",
      "Training Epoch 34  90.4% | batch:        85 of        94\t|\tloss: 1561.18\n",
      "Training Epoch 34  91.5% | batch:        86 of        94\t|\tloss: 2281.4\n",
      "Training Epoch 34  92.6% | batch:        87 of        94\t|\tloss: 1686.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:00,643 | INFO : Epoch 34 Training Summary: epoch: 34.000000 | loss: 1551.727347 | \n",
      "2023-05-04 17:00:00,644 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8100745677947998 seconds\n",
      "\n",
      "2023-05-04 17:00:00,645 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7886584576438456 seconds\n",
      "2023-05-04 17:00:00,645 | INFO : Avg batch train. time: 0.01902828146429623 seconds\n",
      "2023-05-04 17:00:00,646 | INFO : Avg sample train. time: 0.00015008042101391554 seconds\n",
      "2023-05-04 17:00:00,647 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 34  93.6% | batch:        88 of        94\t|\tloss: 1038.02\n",
      "Training Epoch 34  94.7% | batch:        89 of        94\t|\tloss: 6144.85\n",
      "Training Epoch 34  95.7% | batch:        90 of        94\t|\tloss: 1312.31\n",
      "Training Epoch 34  96.8% | batch:        91 of        94\t|\tloss: 2325.31\n",
      "Training Epoch 34  97.9% | batch:        92 of        94\t|\tloss: 946.917\n",
      "Training Epoch 34  98.9% | batch:        93 of        94\t|\tloss: 2011.54\n",
      "\n",
      "Evaluating Epoch 34   0.0% | batch:         0 of        40\t|\tloss: 5897.63\n",
      "Evaluating Epoch 34   2.5% | batch:         1 of        40\t|\tloss: 1308.99\n",
      "Evaluating Epoch 34   5.0% | batch:         2 of        40\t|\tloss: 2913.58\n",
      "Evaluating Epoch 34   7.5% | batch:         3 of        40\t|\tloss: 6206.12\n",
      "Evaluating Epoch 34  10.0% | batch:         4 of        40\t|\tloss: 2912.71\n",
      "Evaluating Epoch 34  12.5% | batch:         5 of        40\t|\tloss: 2498.2\n",
      "Evaluating Epoch 34  15.0% | batch:         6 of        40\t|\tloss: 7049.25\n",
      "Evaluating Epoch 34  17.5% | batch:         7 of        40\t|\tloss: 3284.1\n",
      "Evaluating Epoch 34  20.0% | batch:         8 of        40\t|\tloss: 2751.67\n",
      "Evaluating Epoch 34  22.5% | batch:         9 of        40\t|\tloss: 1938.65\n",
      "Evaluating Epoch 34  25.0% | batch:        10 of        40\t|\tloss: 4783.32\n",
      "Evaluating Epoch 34  27.5% | batch:        11 of        40\t|\tloss: 1430.39\n",
      "Evaluating Epoch 34  30.0% | batch:        12 of        40\t|\tloss: 5658.35\n",
      "Evaluating Epoch 34  32.5% | batch:        13 of        40\t|\tloss: 2815.71\n",
      "Evaluating Epoch 34  35.0% | batch:        14 of        40\t|\tloss: 2056.21\n",
      "Evaluating Epoch 34  37.5% | batch:        15 of        40\t|\tloss: 2987.94\n",
      "Evaluating Epoch 34  40.0% | batch:        16 of        40\t|\tloss: 4147.98\n",
      "Evaluating Epoch 34  42.5% | batch:        17 of        40\t|\tloss: 2686.03\n",
      "Evaluating Epoch 34  45.0% | batch:        18 of        40\t|\tloss: 2325.72\n",
      "Evaluating Epoch 34  47.5% | batch:        19 of        40\t|\tloss: 3792.64\n",
      "Evaluating Epoch 34  50.0% | batch:        20 of        40\t|\tloss: 4421.2\n",
      "Evaluating Epoch 34  52.5% | batch:        21 of        40\t|\tloss: 1040.33\n",
      "Evaluating Epoch 34  55.0% | batch:        22 of        40\t|\tloss: 3918.68\n",
      "Evaluating Epoch 34  57.5% | batch:        23 of        40\t|\tloss: 2797.82\n",
      "Evaluating Epoch 34  60.0% | batch:        24 of        40\t|\tloss: 1880.56\n",
      "Evaluating Epoch 34  62.5% | batch:        25 of        40\t|\tloss: 3078\n",
      "Evaluating Epoch 34  65.0% | batch:        26 of        40\t|\tloss: 7005.49\n",
      "Evaluating Epoch 34  67.5% | batch:        27 of        40\t|\tloss: 2601.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:01,096 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44863057136535645 seconds\n",
      "\n",
      "2023-05-04 17:00:01,097 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5400766783290439 seconds\n",
      "2023-05-04 17:00:01,097 | INFO : Avg batch val. time: 0.013501916958226098 seconds\n",
      "2023-05-04 17:00:01,098 | INFO : Avg sample val. time: 0.00010698824848039697 seconds\n",
      "2023-05-04 17:00:01,098 | INFO : Epoch 34 Validation Summary: epoch: 34.000000 | loss: 3593.641872 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 34  70.0% | batch:        28 of        40\t|\tloss: 1724.21\n",
      "Evaluating Epoch 34  72.5% | batch:        29 of        40\t|\tloss: 8046.58\n",
      "Evaluating Epoch 34  75.0% | batch:        30 of        40\t|\tloss: 1832.82\n",
      "Evaluating Epoch 34  77.5% | batch:        31 of        40\t|\tloss: 1448.95\n",
      "Evaluating Epoch 34  80.0% | batch:        32 of        40\t|\tloss: 6736.29\n",
      "Evaluating Epoch 34  82.5% | batch:        33 of        40\t|\tloss: 5554.74\n",
      "Evaluating Epoch 34  85.0% | batch:        34 of        40\t|\tloss: 1241.17\n",
      "Evaluating Epoch 34  87.5% | batch:        35 of        40\t|\tloss: 5245.58\n",
      "Evaluating Epoch 34  90.0% | batch:        36 of        40\t|\tloss: 4042.92\n",
      "Evaluating Epoch 34  92.5% | batch:        37 of        40\t|\tloss: 2473.92\n",
      "Evaluating Epoch 34  95.0% | batch:        38 of        40\t|\tloss: 3260.07\n",
      "Evaluating Epoch 34  97.5% | batch:        39 of        40\t|\tloss: 8979.3\n",
      "\n",
      "Training Epoch 35   0.0% | batch:         0 of        94\t|\tloss: 1108.31\n",
      "Training Epoch 35   1.1% | batch:         1 of        94\t|\tloss: 1199.73\n",
      "Training Epoch 35   2.1% | batch:         2 of        94\t|\tloss: 1049.41\n",
      "Training Epoch 35   3.2% | batch:         3 of        94\t|\tloss: 1226.84\n",
      "Training Epoch 35   4.3% | batch:         4 of        94\t|\tloss: 1823.05\n",
      "Training Epoch 35   5.3% | batch:         5 of        94\t|\tloss: 1622.21\n",
      "Training Epoch 35   6.4% | batch:         6 of        94\t|\tloss: 1371.36\n",
      "Training Epoch 35   7.4% | batch:         7 of        94\t|\tloss: 1675.99\n",
      "Training Epoch 35   8.5% | batch:         8 of        94\t|\tloss: 1291.61\n",
      "Training Epoch 35   9.6% | batch:         9 of        94\t|\tloss: 1569.36\n",
      "Training Epoch 35  10.6% | batch:        10 of        94\t|\tloss: 1419.06\n",
      "Training Epoch 35  11.7% | batch:        11 of        94\t|\tloss: 1004.13\n",
      "Training Epoch 35  12.8% | batch:        12 of        94\t|\tloss: 1211.38\n",
      "Training Epoch 35  13.8% | batch:        13 of        94\t|\tloss: 1889.24\n",
      "Training Epoch 35  14.9% | batch:        14 of        94\t|\tloss: 2393.73\n",
      "Training Epoch 35  16.0% | batch:        15 of        94\t|\tloss: 2957.64\n",
      "Training Epoch 35  17.0% | batch:        16 of        94\t|\tloss: 1373.49\n",
      "Training Epoch 35  18.1% | batch:        17 of        94\t|\tloss: 1521.34\n",
      "Training Epoch 35  19.1% | batch:        18 of        94\t|\tloss: 1608.71\n",
      "Training Epoch 35  20.2% | batch:        19 of        94\t|\tloss: 1467.57\n",
      "Training Epoch 35  21.3% | batch:        20 of        94\t|\tloss: 1276.8\n",
      "Training Epoch 35  22.3% | batch:        21 of        94\t|\tloss: 1908.85\n",
      "Training Epoch 35  23.4% | batch:        22 of        94\t|\tloss: 1563.12\n",
      "Training Epoch 35  24.5% | batch:        23 of        94\t|\tloss: 1601\n",
      "Training Epoch 35  25.5% | batch:        24 of        94\t|\tloss: 1160.03\n",
      "Training Epoch 35  26.6% | batch:        25 of        94\t|\tloss: 1185.07\n",
      "Training Epoch 35  27.7% | batch:        26 of        94\t|\tloss: 895.709\n",
      "Training Epoch 35  28.7% | batch:        27 of        94\t|\tloss: 2220.52\n",
      "Training Epoch 35  29.8% | batch:        28 of        94\t|\tloss: 1516.81\n",
      "Training Epoch 35  30.9% | batch:        29 of        94\t|\tloss: 1161.74\n",
      "Training Epoch 35  31.9% | batch:        30 of        94\t|\tloss: 1042.32\n",
      "Training Epoch 35  33.0% | batch:        31 of        94\t|\tloss: 996.804\n",
      "Training Epoch 35  34.0% | batch:        32 of        94\t|\tloss: 1302.31\n",
      "Training Epoch 35  35.1% | batch:        33 of        94\t|\tloss: 1175.69\n",
      "Training Epoch 35  36.2% | batch:        34 of        94\t|\tloss: 1366.67\n",
      "Training Epoch 35  37.2% | batch:        35 of        94\t|\tloss: 1309.02\n",
      "Training Epoch 35  38.3% | batch:        36 of        94\t|\tloss: 1580.22\n",
      "Training Epoch 35  39.4% | batch:        37 of        94\t|\tloss: 996.616\n",
      "Training Epoch 35  40.4% | batch:        38 of        94\t|\tloss: 769.113\n",
      "Training Epoch 35  41.5% | batch:        39 of        94\t|\tloss: 758.195\n",
      "Training Epoch 35  42.6% | batch:        40 of        94\t|\tloss: 1229.99\n",
      "Training Epoch 35  43.6% | batch:        41 of        94\t|\tloss: 1146.47\n",
      "Training Epoch 35  44.7% | batch:        42 of        94\t|\tloss: 1359.51\n",
      "Training Epoch 35  45.7% | batch:        43 of        94\t|\tloss: 931.474\n",
      "Training Epoch 35  46.8% | batch:        44 of        94\t|\tloss: 1662.74\n",
      "Training Epoch 35  47.9% | batch:        45 of        94\t|\tloss: 869.905\n",
      "Training Epoch 35  48.9% | batch:        46 of        94\t|\tloss: 1109.73\n",
      "Training Epoch 35  50.0% | batch:        47 of        94\t|\tloss: 2511.86\n",
      "Training Epoch 35  51.1% | batch:        48 of        94\t|\tloss: 912.159\n",
      "Training Epoch 35  52.1% | batch:        49 of        94\t|\tloss: 1473.01\n",
      "Training Epoch 35  53.2% | batch:        50 of        94\t|\tloss: 1143.19\n",
      "Training Epoch 35  54.3% | batch:        51 of        94\t|\tloss: 1229.83\n",
      "Training Epoch 35  55.3% | batch:        52 of        94\t|\tloss: 1071.69\n",
      "Training Epoch 35  56.4% | batch:        53 of        94\t|\tloss: 2101.54\n",
      "Training Epoch 35  57.4% | batch:        54 of        94\t|\tloss: 1220.09\n",
      "Training Epoch 35  58.5% | batch:        55 of        94\t|\tloss: 1433.68\n",
      "Training Epoch 35  59.6% | batch:        56 of        94\t|\tloss: 3454.67\n",
      "Training Epoch 35  60.6% | batch:        57 of        94\t|\tloss: 1340.52\n",
      "Training Epoch 35  61.7% | batch:        58 of        94\t|\tloss: 1712.48\n",
      "Training Epoch 35  62.8% | batch:        59 of        94\t|\tloss: 1334.08\n",
      "Training Epoch 35  63.8% | batch:        60 of        94\t|\tloss: 1512.63\n",
      "Training Epoch 35  64.9% | batch:        61 of        94\t|\tloss: 2191.57\n",
      "Training Epoch 35  66.0% | batch:        62 of        94\t|\tloss: 1964.25\n",
      "Training Epoch 35  67.0% | batch:        63 of        94\t|\tloss: 1757.76\n",
      "Training Epoch 35  68.1% | batch:        64 of        94\t|\tloss: 2047.36\n",
      "Training Epoch 35  69.1% | batch:        65 of        94\t|\tloss: 1694.96\n",
      "Training Epoch 35  70.2% | batch:        66 of        94\t|\tloss: 1645.62\n",
      "Training Epoch 35  71.3% | batch:        67 of        94\t|\tloss: 3547.46\n",
      "Training Epoch 35  72.3% | batch:        68 of        94\t|\tloss: 1054.54\n",
      "Training Epoch 35  73.4% | batch:        69 of        94\t|\tloss: 2260.36\n",
      "Training Epoch 35  74.5% | batch:        70 of        94\t|\tloss: 1354.96\n",
      "Training Epoch 35  75.5% | batch:        71 of        94\t|\tloss: 948.071\n",
      "Training Epoch 35  76.6% | batch:        72 of        94\t|\tloss: 882.343\n",
      "Training Epoch 35  77.7% | batch:        73 of        94\t|\tloss: 1129.44\n",
      "Training Epoch 35  78.7% | batch:        74 of        94\t|\tloss: 1631.01\n",
      "Training Epoch 35  79.8% | batch:        75 of        94\t|\tloss: 1156.88\n",
      "Training Epoch 35  80.9% | batch:        76 of        94\t|\tloss: 1718.45\n",
      "Training Epoch 35  81.9% | batch:        77 of        94\t|\tloss: 1314.83\n",
      "Training Epoch 35  83.0% | batch:        78 of        94\t|\tloss: 1417.49\n",
      "Training Epoch 35  84.0% | batch:        79 of        94\t|\tloss: 1185.71\n",
      "Training Epoch 35  85.1% | batch:        80 of        94\t|\tloss: 1045.51\n",
      "Training Epoch 35  86.2% | batch:        81 of        94\t|\tloss: 1294.4\n",
      "Training Epoch 35  87.2% | batch:        82 of        94\t|\tloss: 2016.91\n",
      "Training Epoch 35  88.3% | batch:        83 of        94\t|\tloss: 1912.42\n",
      "Training Epoch 35  89.4% | batch:        84 of        94\t|\tloss: 1094.93\n",
      "Training Epoch 35  90.4% | batch:        85 of        94\t|\tloss: 1482.9\n",
      "Training Epoch 35  91.5% | batch:        86 of        94\t|\tloss: 2042.06\n",
      "Training Epoch 35  92.6% | batch:        87 of        94\t|\tloss: 1353.42\n",
      "Training Epoch 35  93.6% | batch:        88 of        94\t|\tloss: 1162.29\n",
      "Training Epoch 35  94.7% | batch:        89 of        94\t|\tloss: 1118.43\n",
      "Training Epoch 35  95.7% | batch:        90 of        94\t|\tloss: 1637.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:02,924 | INFO : Epoch 35 Training Summary: epoch: 35.000000 | loss: 1483.289207 | \n",
      "2023-05-04 17:00:02,925 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.804389238357544 seconds\n",
      "\n",
      "2023-05-04 17:00:02,925 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7891079085213797 seconds\n",
      "2023-05-04 17:00:02,926 | INFO : Avg batch train. time: 0.01903306285661042 seconds\n",
      "2023-05-04 17:00:02,927 | INFO : Avg sample train. time: 0.00015011813295195332 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 35  96.8% | batch:        91 of        94\t|\tloss: 2142.21\n",
      "Training Epoch 35  97.9% | batch:        92 of        94\t|\tloss: 1231.08\n",
      "Training Epoch 35  98.9% | batch:        93 of        94\t|\tloss: 3101.79\n",
      "\n",
      "Training Epoch 36   0.0% | batch:         0 of        94\t|\tloss: 2269.77\n",
      "Training Epoch 36   1.1% | batch:         1 of        94\t|\tloss: 1169.32\n",
      "Training Epoch 36   2.1% | batch:         2 of        94\t|\tloss: 835.378\n",
      "Training Epoch 36   3.2% | batch:         3 of        94\t|\tloss: 1185.03\n",
      "Training Epoch 36   4.3% | batch:         4 of        94\t|\tloss: 1389.84\n",
      "Training Epoch 36   5.3% | batch:         5 of        94\t|\tloss: 2068.57\n",
      "Training Epoch 36   6.4% | batch:         6 of        94\t|\tloss: 1119.22\n",
      "Training Epoch 36   7.4% | batch:         7 of        94\t|\tloss: 3465.33\n",
      "Training Epoch 36   8.5% | batch:         8 of        94\t|\tloss: 1145.93\n",
      "Training Epoch 36   9.6% | batch:         9 of        94\t|\tloss: 1447.46\n",
      "Training Epoch 36  10.6% | batch:        10 of        94\t|\tloss: 2466.72\n",
      "Training Epoch 36  11.7% | batch:        11 of        94\t|\tloss: 1357.91\n",
      "Training Epoch 36  12.8% | batch:        12 of        94\t|\tloss: 885.184\n",
      "Training Epoch 36  13.8% | batch:        13 of        94\t|\tloss: 3835.27\n",
      "Training Epoch 36  14.9% | batch:        14 of        94\t|\tloss: 1092.36\n",
      "Training Epoch 36  16.0% | batch:        15 of        94\t|\tloss: 1080.81\n",
      "Training Epoch 36  17.0% | batch:        16 of        94\t|\tloss: 1099.3\n",
      "Training Epoch 36  18.1% | batch:        17 of        94\t|\tloss: 1312.48\n",
      "Training Epoch 36  19.1% | batch:        18 of        94\t|\tloss: 1199.41\n",
      "Training Epoch 36  20.2% | batch:        19 of        94\t|\tloss: 1683.25\n",
      "Training Epoch 36  21.3% | batch:        20 of        94\t|\tloss: 1087.76\n",
      "Training Epoch 36  22.3% | batch:        21 of        94\t|\tloss: 3256.51\n",
      "Training Epoch 36  23.4% | batch:        22 of        94\t|\tloss: 1266.42\n",
      "Training Epoch 36  24.5% | batch:        23 of        94\t|\tloss: 978.636\n",
      "Training Epoch 36  25.5% | batch:        24 of        94\t|\tloss: 2277.96\n",
      "Training Epoch 36  26.6% | batch:        25 of        94\t|\tloss: 2044.82\n",
      "Training Epoch 36  27.7% | batch:        26 of        94\t|\tloss: 1273.23\n",
      "Training Epoch 36  28.7% | batch:        27 of        94\t|\tloss: 1056.7\n",
      "Training Epoch 36  29.8% | batch:        28 of        94\t|\tloss: 1163.49\n",
      "Training Epoch 36  30.9% | batch:        29 of        94\t|\tloss: 1043.86\n",
      "Training Epoch 36  31.9% | batch:        30 of        94\t|\tloss: 1366.81\n",
      "Training Epoch 36  33.0% | batch:        31 of        94\t|\tloss: 1391.69\n",
      "Training Epoch 36  34.0% | batch:        32 of        94\t|\tloss: 1143.45\n",
      "Training Epoch 36  35.1% | batch:        33 of        94\t|\tloss: 1020.88\n",
      "Training Epoch 36  36.2% | batch:        34 of        94\t|\tloss: 879.863\n",
      "Training Epoch 36  37.2% | batch:        35 of        94\t|\tloss: 1267.17\n",
      "Training Epoch 36  38.3% | batch:        36 of        94\t|\tloss: 2637.46\n",
      "Training Epoch 36  39.4% | batch:        37 of        94\t|\tloss: 1007.08\n",
      "Training Epoch 36  40.4% | batch:        38 of        94\t|\tloss: 1653.9\n",
      "Training Epoch 36  41.5% | batch:        39 of        94\t|\tloss: 1082.35\n",
      "Training Epoch 36  42.6% | batch:        40 of        94\t|\tloss: 1067.43\n",
      "Training Epoch 36  43.6% | batch:        41 of        94\t|\tloss: 1851.71\n",
      "Training Epoch 36  44.7% | batch:        42 of        94\t|\tloss: 2898.43\n",
      "Training Epoch 36  45.7% | batch:        43 of        94\t|\tloss: 1704.69\n",
      "Training Epoch 36  46.8% | batch:        44 of        94\t|\tloss: 1173.96\n",
      "Training Epoch 36  47.9% | batch:        45 of        94\t|\tloss: 2278.8\n",
      "Training Epoch 36  48.9% | batch:        46 of        94\t|\tloss: 1043.69\n",
      "Training Epoch 36  50.0% | batch:        47 of        94\t|\tloss: 1196.49\n",
      "Training Epoch 36  51.1% | batch:        48 of        94\t|\tloss: 2421.33\n",
      "Training Epoch 36  52.1% | batch:        49 of        94\t|\tloss: 1375.35\n",
      "Training Epoch 36  53.2% | batch:        50 of        94\t|\tloss: 1533.28\n",
      "Training Epoch 36  54.3% | batch:        51 of        94\t|\tloss: 1344.39\n",
      "Training Epoch 36  55.3% | batch:        52 of        94\t|\tloss: 1297.54\n",
      "Training Epoch 36  56.4% | batch:        53 of        94\t|\tloss: 1834.25\n",
      "Training Epoch 36  57.4% | batch:        54 of        94\t|\tloss: 1162.9\n",
      "Training Epoch 36  58.5% | batch:        55 of        94\t|\tloss: 1224.09\n",
      "Training Epoch 36  59.6% | batch:        56 of        94\t|\tloss: 1654.66\n",
      "Training Epoch 36  60.6% | batch:        57 of        94\t|\tloss: 1333.2\n",
      "Training Epoch 36  61.7% | batch:        58 of        94\t|\tloss: 1386.04\n",
      "Training Epoch 36  62.8% | batch:        59 of        94\t|\tloss: 1194.94\n",
      "Training Epoch 36  63.8% | batch:        60 of        94\t|\tloss: 1210.32\n",
      "Training Epoch 36  64.9% | batch:        61 of        94\t|\tloss: 1017.24\n",
      "Training Epoch 36  66.0% | batch:        62 of        94\t|\tloss: 827.222\n",
      "Training Epoch 36  67.0% | batch:        63 of        94\t|\tloss: 1167.7\n",
      "Training Epoch 36  68.1% | batch:        64 of        94\t|\tloss: 1015.5\n",
      "Training Epoch 36  69.1% | batch:        65 of        94\t|\tloss: 1497.4\n",
      "Training Epoch 36  70.2% | batch:        66 of        94\t|\tloss: 1196.14\n",
      "Training Epoch 36  71.3% | batch:        67 of        94\t|\tloss: 1584.74\n",
      "Training Epoch 36  72.3% | batch:        68 of        94\t|\tloss: 1657\n",
      "Training Epoch 36  73.4% | batch:        69 of        94\t|\tloss: 1299.69\n",
      "Training Epoch 36  74.5% | batch:        70 of        94\t|\tloss: 1081.42\n",
      "Training Epoch 36  75.5% | batch:        71 of        94\t|\tloss: 1470.03\n",
      "Training Epoch 36  76.6% | batch:        72 of        94\t|\tloss: 1078.74\n",
      "Training Epoch 36  77.7% | batch:        73 of        94\t|\tloss: 1734.41\n",
      "Training Epoch 36  78.7% | batch:        74 of        94\t|\tloss: 1105.48\n",
      "Training Epoch 36  79.8% | batch:        75 of        94\t|\tloss: 1340.44\n",
      "Training Epoch 36  80.9% | batch:        76 of        94\t|\tloss: 1801.57\n",
      "Training Epoch 36  81.9% | batch:        77 of        94\t|\tloss: 2965.28\n",
      "Training Epoch 36  83.0% | batch:        78 of        94\t|\tloss: 1861.84\n",
      "Training Epoch 36  84.0% | batch:        79 of        94\t|\tloss: 1151.02\n",
      "Training Epoch 36  85.1% | batch:        80 of        94\t|\tloss: 1495.38\n",
      "Training Epoch 36  86.2% | batch:        81 of        94\t|\tloss: 916.844\n",
      "Training Epoch 36  87.2% | batch:        82 of        94\t|\tloss: 1297.66\n",
      "Training Epoch 36  88.3% | batch:        83 of        94\t|\tloss: 927.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:04,759 | INFO : Epoch 36 Training Summary: epoch: 36.000000 | loss: 1478.438155 | \n",
      "2023-05-04 17:00:04,760 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.811593770980835 seconds\n",
      "\n",
      "2023-05-04 17:00:04,761 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7897325158119202 seconds\n",
      "2023-05-04 17:00:04,761 | INFO : Avg batch train. time: 0.019039707615020426 seconds\n",
      "2023-05-04 17:00:04,762 | INFO : Avg sample train. time: 0.00015017054168584663 seconds\n",
      "2023-05-04 17:00:04,763 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 36  89.4% | batch:        84 of        94\t|\tloss: 1235.56\n",
      "Training Epoch 36  90.4% | batch:        85 of        94\t|\tloss: 1351.66\n",
      "Training Epoch 36  91.5% | batch:        86 of        94\t|\tloss: 1524.15\n",
      "Training Epoch 36  92.6% | batch:        87 of        94\t|\tloss: 1129\n",
      "Training Epoch 36  93.6% | batch:        88 of        94\t|\tloss: 1732.41\n",
      "Training Epoch 36  94.7% | batch:        89 of        94\t|\tloss: 1637.28\n",
      "Training Epoch 36  95.7% | batch:        90 of        94\t|\tloss: 1293.39\n",
      "Training Epoch 36  96.8% | batch:        91 of        94\t|\tloss: 1502.71\n",
      "Training Epoch 36  97.9% | batch:        92 of        94\t|\tloss: 1454.64\n",
      "Training Epoch 36  98.9% | batch:        93 of        94\t|\tloss: 1001.49\n",
      "\n",
      "Evaluating Epoch 36   0.0% | batch:         0 of        40\t|\tloss: 5364.17\n",
      "Evaluating Epoch 36   2.5% | batch:         1 of        40\t|\tloss: 1118.57\n",
      "Evaluating Epoch 36   5.0% | batch:         2 of        40\t|\tloss: 2622.56\n",
      "Evaluating Epoch 36   7.5% | batch:         3 of        40\t|\tloss: 6245.03\n",
      "Evaluating Epoch 36  10.0% | batch:         4 of        40\t|\tloss: 2750.06\n",
      "Evaluating Epoch 36  12.5% | batch:         5 of        40\t|\tloss: 2285.84\n",
      "Evaluating Epoch 36  15.0% | batch:         6 of        40\t|\tloss: 7361.1\n",
      "Evaluating Epoch 36  17.5% | batch:         7 of        40\t|\tloss: 2631.52\n",
      "Evaluating Epoch 36  20.0% | batch:         8 of        40\t|\tloss: 2715.43\n",
      "Evaluating Epoch 36  22.5% | batch:         9 of        40\t|\tloss: 1758.69\n",
      "Evaluating Epoch 36  25.0% | batch:        10 of        40\t|\tloss: 4072.52\n",
      "Evaluating Epoch 36  27.5% | batch:        11 of        40\t|\tloss: 1405.03\n",
      "Evaluating Epoch 36  30.0% | batch:        12 of        40\t|\tloss: 5870.85\n",
      "Evaluating Epoch 36  32.5% | batch:        13 of        40\t|\tloss: 2397.57\n",
      "Evaluating Epoch 36  35.0% | batch:        14 of        40\t|\tloss: 1833.86\n",
      "Evaluating Epoch 36  37.5% | batch:        15 of        40\t|\tloss: 3255.51\n",
      "Evaluating Epoch 36  40.0% | batch:        16 of        40\t|\tloss: 3494.06\n",
      "Evaluating Epoch 36  42.5% | batch:        17 of        40\t|\tloss: 2501.39\n",
      "Evaluating Epoch 36  45.0% | batch:        18 of        40\t|\tloss: 2415.93\n",
      "Evaluating Epoch 36  47.5% | batch:        19 of        40\t|\tloss: 5759.83\n",
      "Evaluating Epoch 36  50.0% | batch:        20 of        40\t|\tloss: 3675.24\n",
      "Evaluating Epoch 36  52.5% | batch:        21 of        40\t|\tloss: 1279.71\n",
      "Evaluating Epoch 36  55.0% | batch:        22 of        40\t|\tloss: 3953.7\n",
      "Evaluating Epoch 36  57.5% | batch:        23 of        40\t|\tloss: 2607.98\n",
      "Evaluating Epoch 36  60.0% | batch:        24 of        40\t|\tloss: 1679.42\n",
      "Evaluating Epoch 36  62.5% | batch:        25 of        40\t|\tloss: 3003.61\n",
      "Evaluating Epoch 36  65.0% | batch:        26 of        40\t|\tloss: 8843.58\n",
      "Evaluating Epoch 36  67.5% | batch:        27 of        40\t|\tloss: 2241.1\n",
      "Evaluating Epoch 36  70.0% | batch:        28 of        40\t|\tloss: 1823.61\n",
      "Evaluating Epoch 36  72.5% | batch:        29 of        40\t|\tloss: 8493.02\n",
      "Evaluating Epoch 36  75.0% | batch:        30 of        40\t|\tloss: 1522.23\n",
      "Evaluating Epoch 36  77.5% | batch:        31 of        40\t|\tloss: 1452.57\n",
      "Evaluating Epoch 36  80.0% | batch:        32 of        40\t|\tloss: 7224.29\n",
      "Evaluating Epoch 36  82.5% | batch:        33 of        40\t|\tloss: 5232.73\n",
      "Evaluating Epoch 36  85.0% | batch:        34 of        40\t|\tloss: 1075.49\n",
      "Evaluating Epoch 36  87.5% | batch:        35 of        40\t|\tloss: 5079.71\n",
      "Evaluating Epoch 36  90.0% | batch:        36 of        40\t|\tloss: 4812.98\n",
      "Evaluating Epoch 36  92.5% | batch:        37 of        40\t|\tloss: 2382.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:05,214 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44953036308288574 seconds\n",
      "\n",
      "2023-05-04 17:00:05,214 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5395764224437061 seconds\n",
      "2023-05-04 17:00:05,215 | INFO : Avg batch val. time: 0.013489410561092652 seconds\n",
      "2023-05-04 17:00:05,215 | INFO : Avg sample val. time: 0.00010688914866158995 seconds\n",
      "2023-05-04 17:00:05,216 | INFO : Epoch 36 Validation Summary: epoch: 36.000000 | loss: 3599.473662 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 36  95.0% | batch:        38 of        40\t|\tloss: 3184.01\n",
      "Evaluating Epoch 36  97.5% | batch:        39 of        40\t|\tloss: 10347.4\n",
      "\n",
      "Training Epoch 37   0.0% | batch:         0 of        94\t|\tloss: 5177.68\n",
      "Training Epoch 37   1.1% | batch:         1 of        94\t|\tloss: 1212.85\n",
      "Training Epoch 37   2.1% | batch:         2 of        94\t|\tloss: 1510.16\n",
      "Training Epoch 37   3.2% | batch:         3 of        94\t|\tloss: 1765.94\n",
      "Training Epoch 37   4.3% | batch:         4 of        94\t|\tloss: 1098.11\n",
      "Training Epoch 37   5.3% | batch:         5 of        94\t|\tloss: 2162.48\n",
      "Training Epoch 37   6.4% | batch:         6 of        94\t|\tloss: 828.22\n",
      "Training Epoch 37   7.4% | batch:         7 of        94\t|\tloss: 1215.41\n",
      "Training Epoch 37   8.5% | batch:         8 of        94\t|\tloss: 1100.92\n",
      "Training Epoch 37   9.6% | batch:         9 of        94\t|\tloss: 1090.37\n",
      "Training Epoch 37  10.6% | batch:        10 of        94\t|\tloss: 1543.42\n",
      "Training Epoch 37  11.7% | batch:        11 of        94\t|\tloss: 979.573\n",
      "Training Epoch 37  12.8% | batch:        12 of        94\t|\tloss: 1254.16\n",
      "Training Epoch 37  13.8% | batch:        13 of        94\t|\tloss: 1595.46\n",
      "Training Epoch 37  14.9% | batch:        14 of        94\t|\tloss: 2808.26\n",
      "Training Epoch 37  16.0% | batch:        15 of        94\t|\tloss: 914.627\n",
      "Training Epoch 37  17.0% | batch:        16 of        94\t|\tloss: 1312.31\n",
      "Training Epoch 37  18.1% | batch:        17 of        94\t|\tloss: 1096.34\n",
      "Training Epoch 37  19.1% | batch:        18 of        94\t|\tloss: 1163.83\n",
      "Training Epoch 37  20.2% | batch:        19 of        94\t|\tloss: 1625.15\n",
      "Training Epoch 37  21.3% | batch:        20 of        94\t|\tloss: 1567.88\n",
      "Training Epoch 37  22.3% | batch:        21 of        94\t|\tloss: 2193.01\n",
      "Training Epoch 37  23.4% | batch:        22 of        94\t|\tloss: 1188.5\n",
      "Training Epoch 37  24.5% | batch:        23 of        94\t|\tloss: 1247\n",
      "Training Epoch 37  25.5% | batch:        24 of        94\t|\tloss: 1523.24\n",
      "Training Epoch 37  26.6% | batch:        25 of        94\t|\tloss: 1443\n",
      "Training Epoch 37  27.7% | batch:        26 of        94\t|\tloss: 1505.32\n",
      "Training Epoch 37  28.7% | batch:        27 of        94\t|\tloss: 1074.91\n",
      "Training Epoch 37  29.8% | batch:        28 of        94\t|\tloss: 1307.05\n",
      "Training Epoch 37  30.9% | batch:        29 of        94\t|\tloss: 995.453\n",
      "Training Epoch 37  31.9% | batch:        30 of        94\t|\tloss: 1464.71\n",
      "Training Epoch 37  33.0% | batch:        31 of        94\t|\tloss: 1686.75\n",
      "Training Epoch 37  34.0% | batch:        32 of        94\t|\tloss: 2065.03\n",
      "Training Epoch 37  35.1% | batch:        33 of        94\t|\tloss: 1370.08\n",
      "Training Epoch 37  36.2% | batch:        34 of        94\t|\tloss: 1287.84\n",
      "Training Epoch 37  37.2% | batch:        35 of        94\t|\tloss: 1095.47\n",
      "Training Epoch 37  38.3% | batch:        36 of        94\t|\tloss: 1816.83\n",
      "Training Epoch 37  39.4% | batch:        37 of        94\t|\tloss: 2266.56\n",
      "Training Epoch 37  40.4% | batch:        38 of        94\t|\tloss: 1856.88\n",
      "Training Epoch 37  41.5% | batch:        39 of        94\t|\tloss: 1303.48\n",
      "Training Epoch 37  42.6% | batch:        40 of        94\t|\tloss: 1239.1\n",
      "Training Epoch 37  43.6% | batch:        41 of        94\t|\tloss: 3241.69\n",
      "Training Epoch 37  44.7% | batch:        42 of        94\t|\tloss: 1354.42\n",
      "Training Epoch 37  45.7% | batch:        43 of        94\t|\tloss: 1687.27\n",
      "Training Epoch 37  46.8% | batch:        44 of        94\t|\tloss: 1769.68\n",
      "Training Epoch 37  47.9% | batch:        45 of        94\t|\tloss: 1028.3\n",
      "Training Epoch 37  48.9% | batch:        46 of        94\t|\tloss: 1075.14\n",
      "Training Epoch 37  50.0% | batch:        47 of        94\t|\tloss: 1253.69\n",
      "Training Epoch 37  51.1% | batch:        48 of        94\t|\tloss: 1760.04\n",
      "Training Epoch 37  52.1% | batch:        49 of        94\t|\tloss: 1652.89\n",
      "Training Epoch 37  53.2% | batch:        50 of        94\t|\tloss: 1931.62\n",
      "Training Epoch 37  54.3% | batch:        51 of        94\t|\tloss: 897.516\n",
      "Training Epoch 37  55.3% | batch:        52 of        94\t|\tloss: 1622.2\n",
      "Training Epoch 37  56.4% | batch:        53 of        94\t|\tloss: 1538.1\n",
      "Training Epoch 37  57.4% | batch:        54 of        94\t|\tloss: 1630.68\n",
      "Training Epoch 37  58.5% | batch:        55 of        94\t|\tloss: 1410.46\n",
      "Training Epoch 37  59.6% | batch:        56 of        94\t|\tloss: 1152.6\n",
      "Training Epoch 37  60.6% | batch:        57 of        94\t|\tloss: 1574.34\n",
      "Training Epoch 37  61.7% | batch:        58 of        94\t|\tloss: 1450.54\n",
      "Training Epoch 37  62.8% | batch:        59 of        94\t|\tloss: 1177.76\n",
      "Training Epoch 37  63.8% | batch:        60 of        94\t|\tloss: 1120.98\n",
      "Training Epoch 37  64.9% | batch:        61 of        94\t|\tloss: 1077.11\n",
      "Training Epoch 37  66.0% | batch:        62 of        94\t|\tloss: 1266.88\n",
      "Training Epoch 37  67.0% | batch:        63 of        94\t|\tloss: 1607.96\n",
      "Training Epoch 37  68.1% | batch:        64 of        94\t|\tloss: 2583.08\n",
      "Training Epoch 37  69.1% | batch:        65 of        94\t|\tloss: 1401.4\n",
      "Training Epoch 37  70.2% | batch:        66 of        94\t|\tloss: 2079.28\n",
      "Training Epoch 37  71.3% | batch:        67 of        94\t|\tloss: 1036.4\n",
      "Training Epoch 37  72.3% | batch:        68 of        94\t|\tloss: 1108.07\n",
      "Training Epoch 37  73.4% | batch:        69 of        94\t|\tloss: 1101.64\n",
      "Training Epoch 37  74.5% | batch:        70 of        94\t|\tloss: 1918.18\n",
      "Training Epoch 37  75.5% | batch:        71 of        94\t|\tloss: 909.432\n",
      "Training Epoch 37  76.6% | batch:        72 of        94\t|\tloss: 1815.3\n",
      "Training Epoch 37  77.7% | batch:        73 of        94\t|\tloss: 2337.91\n",
      "Training Epoch 37  78.7% | batch:        74 of        94\t|\tloss: 1562.13\n",
      "Training Epoch 37  79.8% | batch:        75 of        94\t|\tloss: 1465.69\n",
      "Training Epoch 37  80.9% | batch:        76 of        94\t|\tloss: 1211.3\n",
      "Training Epoch 37  81.9% | batch:        77 of        94\t|\tloss: 1296.55\n",
      "Training Epoch 37  83.0% | batch:        78 of        94\t|\tloss: 1254.38\n",
      "Training Epoch 37  84.0% | batch:        79 of        94\t|\tloss: 1074.63\n",
      "Training Epoch 37  85.1% | batch:        80 of        94\t|\tloss: 808.746\n",
      "Training Epoch 37  86.2% | batch:        81 of        94\t|\tloss: 1333.53\n",
      "Training Epoch 37  87.2% | batch:        82 of        94\t|\tloss: 1028.58\n",
      "Training Epoch 37  88.3% | batch:        83 of        94\t|\tloss: 1166.49\n",
      "Training Epoch 37  89.4% | batch:        84 of        94\t|\tloss: 907.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:07,066 | INFO : Epoch 37 Training Summary: epoch: 37.000000 | loss: 1494.833209 | \n",
      "2023-05-04 17:00:07,067 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8287231922149658 seconds\n",
      "\n",
      "2023-05-04 17:00:07,068 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7907863178768673 seconds\n",
      "2023-05-04 17:00:07,068 | INFO : Avg batch train. time: 0.019050918275285822 seconds\n",
      "2023-05-04 17:00:07,069 | INFO : Avg sample train. time: 0.00015025896273509543 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 37  90.4% | batch:        85 of        94\t|\tloss: 1378.29\n",
      "Training Epoch 37  91.5% | batch:        86 of        94\t|\tloss: 1624.66\n",
      "Training Epoch 37  92.6% | batch:        87 of        94\t|\tloss: 1223.9\n",
      "Training Epoch 37  93.6% | batch:        88 of        94\t|\tloss: 1047.56\n",
      "Training Epoch 37  94.7% | batch:        89 of        94\t|\tloss: 1188.76\n",
      "Training Epoch 37  95.7% | batch:        90 of        94\t|\tloss: 1246.07\n",
      "Training Epoch 37  96.8% | batch:        91 of        94\t|\tloss: 2914.29\n",
      "Training Epoch 37  97.9% | batch:        92 of        94\t|\tloss: 1746.6\n",
      "Training Epoch 37  98.9% | batch:        93 of        94\t|\tloss: 1619.65\n",
      "\n",
      "Training Epoch 38   0.0% | batch:         0 of        94\t|\tloss: 2258.24\n",
      "Training Epoch 38   1.1% | batch:         1 of        94\t|\tloss: 1125.46\n",
      "Training Epoch 38   2.1% | batch:         2 of        94\t|\tloss: 2514.93\n",
      "Training Epoch 38   3.2% | batch:         3 of        94\t|\tloss: 935.614\n",
      "Training Epoch 38   4.3% | batch:         4 of        94\t|\tloss: 1191.32\n",
      "Training Epoch 38   5.3% | batch:         5 of        94\t|\tloss: 1482.05\n",
      "Training Epoch 38   6.4% | batch:         6 of        94\t|\tloss: 1468.65\n",
      "Training Epoch 38   7.4% | batch:         7 of        94\t|\tloss: 1891.65\n",
      "Training Epoch 38   8.5% | batch:         8 of        94\t|\tloss: 1130.21\n",
      "Training Epoch 38   9.6% | batch:         9 of        94\t|\tloss: 1228.2\n",
      "Training Epoch 38  10.6% | batch:        10 of        94\t|\tloss: 1877.81\n",
      "Training Epoch 38  11.7% | batch:        11 of        94\t|\tloss: 977.313\n",
      "Training Epoch 38  12.8% | batch:        12 of        94\t|\tloss: 1313.54\n",
      "Training Epoch 38  13.8% | batch:        13 of        94\t|\tloss: 1315.64\n",
      "Training Epoch 38  14.9% | batch:        14 of        94\t|\tloss: 1234.19\n",
      "Training Epoch 38  16.0% | batch:        15 of        94\t|\tloss: 1158.8\n",
      "Training Epoch 38  17.0% | batch:        16 of        94\t|\tloss: 1709.09\n",
      "Training Epoch 38  18.1% | batch:        17 of        94\t|\tloss: 1218.29\n",
      "Training Epoch 38  19.1% | batch:        18 of        94\t|\tloss: 1474.62\n",
      "Training Epoch 38  20.2% | batch:        19 of        94\t|\tloss: 1454.31\n",
      "Training Epoch 38  21.3% | batch:        20 of        94\t|\tloss: 2962.02\n",
      "Training Epoch 38  22.3% | batch:        21 of        94\t|\tloss: 3143.41\n",
      "Training Epoch 38  23.4% | batch:        22 of        94\t|\tloss: 1096.9\n",
      "Training Epoch 38  24.5% | batch:        23 of        94\t|\tloss: 1271.96\n",
      "Training Epoch 38  25.5% | batch:        24 of        94\t|\tloss: 1771\n",
      "Training Epoch 38  26.6% | batch:        25 of        94\t|\tloss: 1573.74\n",
      "Training Epoch 38  27.7% | batch:        26 of        94\t|\tloss: 1329.56\n",
      "Training Epoch 38  28.7% | batch:        27 of        94\t|\tloss: 1051.67\n",
      "Training Epoch 38  29.8% | batch:        28 of        94\t|\tloss: 1212.52\n",
      "Training Epoch 38  30.9% | batch:        29 of        94\t|\tloss: 1194.02\n",
      "Training Epoch 38  31.9% | batch:        30 of        94\t|\tloss: 1295.46\n",
      "Training Epoch 38  33.0% | batch:        31 of        94\t|\tloss: 1847.64\n",
      "Training Epoch 38  34.0% | batch:        32 of        94\t|\tloss: 1762.39\n",
      "Training Epoch 38  35.1% | batch:        33 of        94\t|\tloss: 1616.86\n",
      "Training Epoch 38  36.2% | batch:        34 of        94\t|\tloss: 1321.36\n",
      "Training Epoch 38  37.2% | batch:        35 of        94\t|\tloss: 1218.51\n",
      "Training Epoch 38  38.3% | batch:        36 of        94\t|\tloss: 1014.95\n",
      "Training Epoch 38  39.4% | batch:        37 of        94\t|\tloss: 2618.08\n",
      "Training Epoch 38  40.4% | batch:        38 of        94\t|\tloss: 1534.94\n",
      "Training Epoch 38  41.5% | batch:        39 of        94\t|\tloss: 1077.06\n",
      "Training Epoch 38  42.6% | batch:        40 of        94\t|\tloss: 1348.36\n",
      "Training Epoch 38  43.6% | batch:        41 of        94\t|\tloss: 2032.63\n",
      "Training Epoch 38  44.7% | batch:        42 of        94\t|\tloss: 764.696\n",
      "Training Epoch 38  45.7% | batch:        43 of        94\t|\tloss: 1486.08\n",
      "Training Epoch 38  46.8% | batch:        44 of        94\t|\tloss: 2054.75\n",
      "Training Epoch 38  47.9% | batch:        45 of        94\t|\tloss: 1135.56\n",
      "Training Epoch 38  48.9% | batch:        46 of        94\t|\tloss: 1137.56\n",
      "Training Epoch 38  50.0% | batch:        47 of        94\t|\tloss: 775.117\n",
      "Training Epoch 38  51.1% | batch:        48 of        94\t|\tloss: 1269.94\n",
      "Training Epoch 38  52.1% | batch:        49 of        94\t|\tloss: 1415.5\n",
      "Training Epoch 38  53.2% | batch:        50 of        94\t|\tloss: 4995.14\n",
      "Training Epoch 38  54.3% | batch:        51 of        94\t|\tloss: 1473.1\n",
      "Training Epoch 38  55.3% | batch:        52 of        94\t|\tloss: 1014.91\n",
      "Training Epoch 38  56.4% | batch:        53 of        94\t|\tloss: 1426.78\n",
      "Training Epoch 38  57.4% | batch:        54 of        94\t|\tloss: 1081.46\n",
      "Training Epoch 38  58.5% | batch:        55 of        94\t|\tloss: 1032.53\n",
      "Training Epoch 38  59.6% | batch:        56 of        94\t|\tloss: 907.042\n",
      "Training Epoch 38  60.6% | batch:        57 of        94\t|\tloss: 2442.46\n",
      "Training Epoch 38  61.7% | batch:        58 of        94\t|\tloss: 970.8\n",
      "Training Epoch 38  62.8% | batch:        59 of        94\t|\tloss: 1464.42\n",
      "Training Epoch 38  63.8% | batch:        60 of        94\t|\tloss: 2193.33\n",
      "Training Epoch 38  64.9% | batch:        61 of        94\t|\tloss: 1313.47\n",
      "Training Epoch 38  66.0% | batch:        62 of        94\t|\tloss: 972.749\n",
      "Training Epoch 38  67.0% | batch:        63 of        94\t|\tloss: 921.97\n",
      "Training Epoch 38  68.1% | batch:        64 of        94\t|\tloss: 1534.44\n",
      "Training Epoch 38  69.1% | batch:        65 of        94\t|\tloss: 1194.55\n",
      "Training Epoch 38  70.2% | batch:        66 of        94\t|\tloss: 1305.01\n",
      "Training Epoch 38  71.3% | batch:        67 of        94\t|\tloss: 1350.85\n",
      "Training Epoch 38  72.3% | batch:        68 of        94\t|\tloss: 1153.25\n",
      "Training Epoch 38  73.4% | batch:        69 of        94\t|\tloss: 1588.04\n",
      "Training Epoch 38  74.5% | batch:        70 of        94\t|\tloss: 1616.06\n",
      "Training Epoch 38  75.5% | batch:        71 of        94\t|\tloss: 3609.77\n",
      "Training Epoch 38  76.6% | batch:        72 of        94\t|\tloss: 1522.58\n",
      "Training Epoch 38  77.7% | batch:        73 of        94\t|\tloss: 1137.78\n",
      "Training Epoch 38  78.7% | batch:        74 of        94\t|\tloss: 1347.63\n",
      "Training Epoch 38  79.8% | batch:        75 of        94\t|\tloss: 1190.42\n",
      "Training Epoch 38  80.9% | batch:        76 of        94\t|\tloss: 1996.2\n",
      "Training Epoch 38  81.9% | batch:        77 of        94\t|\tloss: 2480.41\n",
      "Training Epoch 38  83.0% | batch:        78 of        94\t|\tloss: 2371.65\n",
      "Training Epoch 38  84.0% | batch:        79 of        94\t|\tloss: 2919.93\n",
      "Training Epoch 38  85.1% | batch:        80 of        94\t|\tloss: 924.041\n",
      "Training Epoch 38  86.2% | batch:        81 of        94\t|\tloss: 1351.01\n",
      "Training Epoch 38  87.2% | batch:        82 of        94\t|\tloss: 1221.11\n",
      "Training Epoch 38  88.3% | batch:        83 of        94\t|\tloss: 1714.05\n",
      "Training Epoch 38  89.4% | batch:        84 of        94\t|\tloss: 1255.33\n",
      "Training Epoch 38  90.4% | batch:        85 of        94\t|\tloss: 1336.69\n",
      "Training Epoch 38  91.5% | batch:        86 of        94\t|\tloss: 1621.66\n",
      "Training Epoch 38  92.6% | batch:        87 of        94\t|\tloss: 1007.95\n",
      "Training Epoch 38  93.6% | batch:        88 of        94\t|\tloss: 1627.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:08,893 | INFO : Epoch 38 Training Summary: epoch: 38.000000 | loss: 1519.933545 | \n",
      "2023-05-04 17:00:08,894 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8042173385620117 seconds\n",
      "\n",
      "2023-05-04 17:00:08,894 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7911397657896344 seconds\n",
      "2023-05-04 17:00:08,895 | INFO : Avg batch train. time: 0.019054678359464196 seconds\n",
      "2023-05-04 17:00:08,896 | INFO : Avg sample train. time: 0.00015028861938157697 seconds\n",
      "2023-05-04 17:00:08,896 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 38  94.7% | batch:        89 of        94\t|\tloss: 1079.58\n",
      "Training Epoch 38  95.7% | batch:        90 of        94\t|\tloss: 1057.43\n",
      "Training Epoch 38  96.8% | batch:        91 of        94\t|\tloss: 1142.38\n",
      "Training Epoch 38  97.9% | batch:        92 of        94\t|\tloss: 1264.19\n",
      "Training Epoch 38  98.9% | batch:        93 of        94\t|\tloss: 865.113\n",
      "\n",
      "Evaluating Epoch 38   0.0% | batch:         0 of        40\t|\tloss: 6229.04\n",
      "Evaluating Epoch 38   2.5% | batch:         1 of        40\t|\tloss: 1254.53\n",
      "Evaluating Epoch 38   5.0% | batch:         2 of        40\t|\tloss: 3356.03\n",
      "Evaluating Epoch 38   7.5% | batch:         3 of        40\t|\tloss: 6569.14\n",
      "Evaluating Epoch 38  10.0% | batch:         4 of        40\t|\tloss: 2149.75\n",
      "Evaluating Epoch 38  12.5% | batch:         5 of        40\t|\tloss: 1874.27\n",
      "Evaluating Epoch 38  15.0% | batch:         6 of        40\t|\tloss: 7318.66\n",
      "Evaluating Epoch 38  17.5% | batch:         7 of        40\t|\tloss: 3394.95\n",
      "Evaluating Epoch 38  20.0% | batch:         8 of        40\t|\tloss: 2923.97\n",
      "Evaluating Epoch 38  22.5% | batch:         9 of        40\t|\tloss: 2013.11\n",
      "Evaluating Epoch 38  25.0% | batch:        10 of        40\t|\tloss: 4743.33\n",
      "Evaluating Epoch 38  27.5% | batch:        11 of        40\t|\tloss: 1523.34\n",
      "Evaluating Epoch 38  30.0% | batch:        12 of        40\t|\tloss: 4954.08\n",
      "Evaluating Epoch 38  32.5% | batch:        13 of        40\t|\tloss: 2650.85\n",
      "Evaluating Epoch 38  35.0% | batch:        14 of        40\t|\tloss: 2139.02\n",
      "Evaluating Epoch 38  37.5% | batch:        15 of        40\t|\tloss: 3068.64\n",
      "Evaluating Epoch 38  40.0% | batch:        16 of        40\t|\tloss: 4372.24\n",
      "Evaluating Epoch 38  42.5% | batch:        17 of        40\t|\tloss: 2891.64\n",
      "Evaluating Epoch 38  45.0% | batch:        18 of        40\t|\tloss: 2381.91\n",
      "Evaluating Epoch 38  47.5% | batch:        19 of        40\t|\tloss: 4826.03\n",
      "Evaluating Epoch 38  50.0% | batch:        20 of        40\t|\tloss: 4567.22\n",
      "Evaluating Epoch 38  52.5% | batch:        21 of        40\t|\tloss: 1362.25\n",
      "Evaluating Epoch 38  55.0% | batch:        22 of        40\t|\tloss: 4340.39\n",
      "Evaluating Epoch 38  57.5% | batch:        23 of        40\t|\tloss: 2980.93\n",
      "Evaluating Epoch 38  60.0% | batch:        24 of        40\t|\tloss: 1595.42\n",
      "Evaluating Epoch 38  62.5% | batch:        25 of        40\t|\tloss: 2890.27\n",
      "Evaluating Epoch 38  65.0% | batch:        26 of        40\t|\tloss: 8813.07\n",
      "Evaluating Epoch 38  67.5% | batch:        27 of        40\t|\tloss: 2560.64\n",
      "Evaluating Epoch 38  70.0% | batch:        28 of        40\t|\tloss: 1781.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:09,346 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44934868812561035 seconds\n",
      "\n",
      "2023-05-04 17:00:09,347 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5390806656617385 seconds\n",
      "2023-05-04 17:00:09,347 | INFO : Avg batch val. time: 0.013477016641543462 seconds\n",
      "2023-05-04 17:00:09,348 | INFO : Avg sample val. time: 0.00010679094010731746 seconds\n",
      "2023-05-04 17:00:09,348 | INFO : Epoch 38 Validation Summary: epoch: 38.000000 | loss: 3740.662902 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 38  72.5% | batch:        29 of        40\t|\tloss: 8425.85\n",
      "Evaluating Epoch 38  75.0% | batch:        30 of        40\t|\tloss: 1921.45\n",
      "Evaluating Epoch 38  77.5% | batch:        31 of        40\t|\tloss: 1787.38\n",
      "Evaluating Epoch 38  80.0% | batch:        32 of        40\t|\tloss: 7465.42\n",
      "Evaluating Epoch 38  82.5% | batch:        33 of        40\t|\tloss: 4894.68\n",
      "Evaluating Epoch 38  85.0% | batch:        34 of        40\t|\tloss: 1391.48\n",
      "Evaluating Epoch 38  87.5% | batch:        35 of        40\t|\tloss: 5652.05\n",
      "Evaluating Epoch 38  90.0% | batch:        36 of        40\t|\tloss: 5435.99\n",
      "Evaluating Epoch 38  92.5% | batch:        37 of        40\t|\tloss: 2589.97\n",
      "Evaluating Epoch 38  95.0% | batch:        38 of        40\t|\tloss: 3182.9\n",
      "Evaluating Epoch 38  97.5% | batch:        39 of        40\t|\tloss: 7426.92\n",
      "\n",
      "Training Epoch 39   0.0% | batch:         0 of        94\t|\tloss: 787.564\n",
      "Training Epoch 39   1.1% | batch:         1 of        94\t|\tloss: 1885.31\n",
      "Training Epoch 39   2.1% | batch:         2 of        94\t|\tloss: 2787.05\n",
      "Training Epoch 39   3.2% | batch:         3 of        94\t|\tloss: 1107.53\n",
      "Training Epoch 39   4.3% | batch:         4 of        94\t|\tloss: 3812.87\n",
      "Training Epoch 39   5.3% | batch:         5 of        94\t|\tloss: 1167.4\n",
      "Training Epoch 39   6.4% | batch:         6 of        94\t|\tloss: 1012.27\n",
      "Training Epoch 39   7.4% | batch:         7 of        94\t|\tloss: 1164.73\n",
      "Training Epoch 39   8.5% | batch:         8 of        94\t|\tloss: 1607.01\n",
      "Training Epoch 39   9.6% | batch:         9 of        94\t|\tloss: 1156.72\n",
      "Training Epoch 39  10.6% | batch:        10 of        94\t|\tloss: 885.715\n",
      "Training Epoch 39  11.7% | batch:        11 of        94\t|\tloss: 1317.97\n",
      "Training Epoch 39  12.8% | batch:        12 of        94\t|\tloss: 2269.82\n",
      "Training Epoch 39  13.8% | batch:        13 of        94\t|\tloss: 2481\n",
      "Training Epoch 39  14.9% | batch:        14 of        94\t|\tloss: 925.299\n",
      "Training Epoch 39  16.0% | batch:        15 of        94\t|\tloss: 1210.77\n",
      "Training Epoch 39  17.0% | batch:        16 of        94\t|\tloss: 1382.03\n",
      "Training Epoch 39  18.1% | batch:        17 of        94\t|\tloss: 1242.29\n",
      "Training Epoch 39  19.1% | batch:        18 of        94\t|\tloss: 1193.92\n",
      "Training Epoch 39  20.2% | batch:        19 of        94\t|\tloss: 1007.47\n",
      "Training Epoch 39  21.3% | batch:        20 of        94\t|\tloss: 1518.01\n",
      "Training Epoch 39  22.3% | batch:        21 of        94\t|\tloss: 1312.98\n",
      "Training Epoch 39  23.4% | batch:        22 of        94\t|\tloss: 1179.44\n",
      "Training Epoch 39  24.5% | batch:        23 of        94\t|\tloss: 765.774\n",
      "Training Epoch 39  25.5% | batch:        24 of        94\t|\tloss: 929.212\n",
      "Training Epoch 39  26.6% | batch:        25 of        94\t|\tloss: 1628.05\n",
      "Training Epoch 39  27.7% | batch:        26 of        94\t|\tloss: 1252.47\n",
      "Training Epoch 39  28.7% | batch:        27 of        94\t|\tloss: 881.861\n",
      "Training Epoch 39  29.8% | batch:        28 of        94\t|\tloss: 1435.67\n",
      "Training Epoch 39  30.9% | batch:        29 of        94\t|\tloss: 1137.77\n",
      "Training Epoch 39  31.9% | batch:        30 of        94\t|\tloss: 1049.33\n",
      "Training Epoch 39  33.0% | batch:        31 of        94\t|\tloss: 932.104\n",
      "Training Epoch 39  34.0% | batch:        32 of        94\t|\tloss: 1102.18\n",
      "Training Epoch 39  35.1% | batch:        33 of        94\t|\tloss: 1864.87\n",
      "Training Epoch 39  36.2% | batch:        34 of        94\t|\tloss: 1815.78\n",
      "Training Epoch 39  37.2% | batch:        35 of        94\t|\tloss: 1021.44\n",
      "Training Epoch 39  38.3% | batch:        36 of        94\t|\tloss: 1007.47\n",
      "Training Epoch 39  39.4% | batch:        37 of        94\t|\tloss: 1032.92\n",
      "Training Epoch 39  40.4% | batch:        38 of        94\t|\tloss: 1464.51\n",
      "Training Epoch 39  41.5% | batch:        39 of        94\t|\tloss: 1224.2\n",
      "Training Epoch 39  42.6% | batch:        40 of        94\t|\tloss: 3236.17\n",
      "Training Epoch 39  43.6% | batch:        41 of        94\t|\tloss: 1366.15\n",
      "Training Epoch 39  44.7% | batch:        42 of        94\t|\tloss: 1659.01\n",
      "Training Epoch 39  45.7% | batch:        43 of        94\t|\tloss: 909.046\n",
      "Training Epoch 39  46.8% | batch:        44 of        94\t|\tloss: 1280.59\n",
      "Training Epoch 39  47.9% | batch:        45 of        94\t|\tloss: 770.42\n",
      "Training Epoch 39  48.9% | batch:        46 of        94\t|\tloss: 1858.28\n",
      "Training Epoch 39  50.0% | batch:        47 of        94\t|\tloss: 1161.39\n",
      "Training Epoch 39  51.1% | batch:        48 of        94\t|\tloss: 1604.64\n",
      "Training Epoch 39  52.1% | batch:        49 of        94\t|\tloss: 1520.3\n",
      "Training Epoch 39  53.2% | batch:        50 of        94\t|\tloss: 902.373\n",
      "Training Epoch 39  54.3% | batch:        51 of        94\t|\tloss: 759.679\n",
      "Training Epoch 39  55.3% | batch:        52 of        94\t|\tloss: 1480.15\n",
      "Training Epoch 39  56.4% | batch:        53 of        94\t|\tloss: 1273.13\n",
      "Training Epoch 39  57.4% | batch:        54 of        94\t|\tloss: 1326.55\n",
      "Training Epoch 39  58.5% | batch:        55 of        94\t|\tloss: 1510.93\n",
      "Training Epoch 39  59.6% | batch:        56 of        94\t|\tloss: 1711.45\n",
      "Training Epoch 39  60.6% | batch:        57 of        94\t|\tloss: 1216.61\n",
      "Training Epoch 39  61.7% | batch:        58 of        94\t|\tloss: 1237.05\n",
      "Training Epoch 39  62.8% | batch:        59 of        94\t|\tloss: 1098.62\n",
      "Training Epoch 39  63.8% | batch:        60 of        94\t|\tloss: 854.543\n",
      "Training Epoch 39  64.9% | batch:        61 of        94\t|\tloss: 2154.3\n",
      "Training Epoch 39  66.0% | batch:        62 of        94\t|\tloss: 1667.74\n",
      "Training Epoch 39  67.0% | batch:        63 of        94\t|\tloss: 1922.28\n",
      "Training Epoch 39  68.1% | batch:        64 of        94\t|\tloss: 1278.95\n",
      "Training Epoch 39  69.1% | batch:        65 of        94\t|\tloss: 1764.03\n",
      "Training Epoch 39  70.2% | batch:        66 of        94\t|\tloss: 932.23\n",
      "Training Epoch 39  71.3% | batch:        67 of        94\t|\tloss: 1746.18\n",
      "Training Epoch 39  72.3% | batch:        68 of        94\t|\tloss: 1791.54\n",
      "Training Epoch 39  73.4% | batch:        69 of        94\t|\tloss: 900.641\n",
      "Training Epoch 39  74.5% | batch:        70 of        94\t|\tloss: 2024.31\n",
      "Training Epoch 39  75.5% | batch:        71 of        94\t|\tloss: 1021.17\n",
      "Training Epoch 39  76.6% | batch:        72 of        94\t|\tloss: 1127.93\n",
      "Training Epoch 39  77.7% | batch:        73 of        94\t|\tloss: 1804.47\n",
      "Training Epoch 39  78.7% | batch:        74 of        94\t|\tloss: 1501.99\n",
      "Training Epoch 39  79.8% | batch:        75 of        94\t|\tloss: 2429.58\n",
      "Training Epoch 39  80.9% | batch:        76 of        94\t|\tloss: 1523.73\n",
      "Training Epoch 39  81.9% | batch:        77 of        94\t|\tloss: 2996.81\n",
      "Training Epoch 39  83.0% | batch:        78 of        94\t|\tloss: 1281.99\n",
      "Training Epoch 39  84.0% | batch:        79 of        94\t|\tloss: 1453.05\n",
      "Training Epoch 39  85.1% | batch:        80 of        94\t|\tloss: 3152.67\n",
      "Training Epoch 39  86.2% | batch:        81 of        94\t|\tloss: 1389.14\n",
      "Training Epoch 39  87.2% | batch:        82 of        94\t|\tloss: 1263.72\n",
      "Training Epoch 39  88.3% | batch:        83 of        94\t|\tloss: 1097.36\n",
      "Training Epoch 39  89.4% | batch:        84 of        94\t|\tloss: 1150.51\n",
      "Training Epoch 39  90.4% | batch:        85 of        94\t|\tloss: 1353.48\n",
      "Training Epoch 39  91.5% | batch:        86 of        94\t|\tloss: 1588.02\n",
      "Training Epoch 39  92.6% | batch:        87 of        94\t|\tloss: 1402.26\n",
      "Training Epoch 39  93.6% | batch:        88 of        94\t|\tloss: 1434.48\n",
      "Training Epoch 39  94.7% | batch:        89 of        94\t|\tloss: 1680.21\n",
      "Training Epoch 39  95.7% | batch:        90 of        94\t|\tloss: 1125.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:11,176 | INFO : Epoch 39 Training Summary: epoch: 39.000000 | loss: 1441.245313 | \n",
      "2023-05-04 17:00:11,177 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8064994812011719 seconds\n",
      "\n",
      "2023-05-04 17:00:11,178 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7915336046463404 seconds\n",
      "2023-05-04 17:00:11,178 | INFO : Avg batch train. time: 0.019058868134535535 seconds\n",
      "2023-05-04 17:00:11,179 | INFO : Avg sample train. time: 0.00015032166509870284 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 39  96.8% | batch:        91 of        94\t|\tloss: 1179.53\n",
      "Training Epoch 39  97.9% | batch:        92 of        94\t|\tloss: 1225.82\n",
      "Training Epoch 39  98.9% | batch:        93 of        94\t|\tloss: 1187.95\n",
      "\n",
      "Training Epoch 40   0.0% | batch:         0 of        94\t|\tloss: 1036.44\n",
      "Training Epoch 40   1.1% | batch:         1 of        94\t|\tloss: 1517.96\n",
      "Training Epoch 40   2.1% | batch:         2 of        94\t|\tloss: 1420.49\n",
      "Training Epoch 40   3.2% | batch:         3 of        94\t|\tloss: 1231.64\n",
      "Training Epoch 40   4.3% | batch:         4 of        94\t|\tloss: 1678.11\n",
      "Training Epoch 40   5.3% | batch:         5 of        94\t|\tloss: 1083.97\n",
      "Training Epoch 40   6.4% | batch:         6 of        94\t|\tloss: 879.325\n",
      "Training Epoch 40   7.4% | batch:         7 of        94\t|\tloss: 1142.51\n",
      "Training Epoch 40   8.5% | batch:         8 of        94\t|\tloss: 1220.05\n",
      "Training Epoch 40   9.6% | batch:         9 of        94\t|\tloss: 1320.98\n",
      "Training Epoch 40  10.6% | batch:        10 of        94\t|\tloss: 2017.85\n",
      "Training Epoch 40  11.7% | batch:        11 of        94\t|\tloss: 1184.52\n",
      "Training Epoch 40  12.8% | batch:        12 of        94\t|\tloss: 2756.33\n",
      "Training Epoch 40  13.8% | batch:        13 of        94\t|\tloss: 915.243\n",
      "Training Epoch 40  14.9% | batch:        14 of        94\t|\tloss: 1643.07\n",
      "Training Epoch 40  16.0% | batch:        15 of        94\t|\tloss: 1084.66\n",
      "Training Epoch 40  17.0% | batch:        16 of        94\t|\tloss: 3582.37\n",
      "Training Epoch 40  18.1% | batch:        17 of        94\t|\tloss: 1484.74\n",
      "Training Epoch 40  19.1% | batch:        18 of        94\t|\tloss: 2145.62\n",
      "Training Epoch 40  20.2% | batch:        19 of        94\t|\tloss: 967.667\n",
      "Training Epoch 40  21.3% | batch:        20 of        94\t|\tloss: 2497.73\n",
      "Training Epoch 40  22.3% | batch:        21 of        94\t|\tloss: 947.247\n",
      "Training Epoch 40  23.4% | batch:        22 of        94\t|\tloss: 1128.14\n",
      "Training Epoch 40  24.5% | batch:        23 of        94\t|\tloss: 1133.63\n",
      "Training Epoch 40  25.5% | batch:        24 of        94\t|\tloss: 1104.67\n",
      "Training Epoch 40  26.6% | batch:        25 of        94\t|\tloss: 1356.26\n",
      "Training Epoch 40  27.7% | batch:        26 of        94\t|\tloss: 1893.48\n",
      "Training Epoch 40  28.7% | batch:        27 of        94\t|\tloss: 984.699\n",
      "Training Epoch 40  29.8% | batch:        28 of        94\t|\tloss: 1272.46\n",
      "Training Epoch 40  30.9% | batch:        29 of        94\t|\tloss: 1214.86\n",
      "Training Epoch 40  31.9% | batch:        30 of        94\t|\tloss: 1377.67\n",
      "Training Epoch 40  33.0% | batch:        31 of        94\t|\tloss: 1568.62\n",
      "Training Epoch 40  34.0% | batch:        32 of        94\t|\tloss: 832.745\n",
      "Training Epoch 40  35.1% | batch:        33 of        94\t|\tloss: 1350.21\n",
      "Training Epoch 40  36.2% | batch:        34 of        94\t|\tloss: 1382.28\n",
      "Training Epoch 40  37.2% | batch:        35 of        94\t|\tloss: 1912.32\n",
      "Training Epoch 40  38.3% | batch:        36 of        94\t|\tloss: 1145.02\n",
      "Training Epoch 40  39.4% | batch:        37 of        94\t|\tloss: 1073.29\n",
      "Training Epoch 40  40.4% | batch:        38 of        94\t|\tloss: 827.177\n",
      "Training Epoch 40  41.5% | batch:        39 of        94\t|\tloss: 738.854\n",
      "Training Epoch 40  42.6% | batch:        40 of        94\t|\tloss: 1533.28\n",
      "Training Epoch 40  43.6% | batch:        41 of        94\t|\tloss: 1166.26\n",
      "Training Epoch 40  44.7% | batch:        42 of        94\t|\tloss: 1196.76\n",
      "Training Epoch 40  45.7% | batch:        43 of        94\t|\tloss: 1624.86\n",
      "Training Epoch 40  46.8% | batch:        44 of        94\t|\tloss: 1785.2\n",
      "Training Epoch 40  47.9% | batch:        45 of        94\t|\tloss: 2031.75\n",
      "Training Epoch 40  48.9% | batch:        46 of        94\t|\tloss: 986.41\n",
      "Training Epoch 40  50.0% | batch:        47 of        94\t|\tloss: 2491.03\n",
      "Training Epoch 40  51.1% | batch:        48 of        94\t|\tloss: 914.447\n",
      "Training Epoch 40  52.1% | batch:        49 of        94\t|\tloss: 1966.2\n",
      "Training Epoch 40  53.2% | batch:        50 of        94\t|\tloss: 1326.38\n",
      "Training Epoch 40  54.3% | batch:        51 of        94\t|\tloss: 1088.54\n",
      "Training Epoch 40  55.3% | batch:        52 of        94\t|\tloss: 1297.22\n",
      "Training Epoch 40  56.4% | batch:        53 of        94\t|\tloss: 1423.99\n",
      "Training Epoch 40  57.4% | batch:        54 of        94\t|\tloss: 3270.93\n",
      "Training Epoch 40  58.5% | batch:        55 of        94\t|\tloss: 859.442\n",
      "Training Epoch 40  59.6% | batch:        56 of        94\t|\tloss: 1778.83\n",
      "Training Epoch 40  60.6% | batch:        57 of        94\t|\tloss: 1840.31\n",
      "Training Epoch 40  61.7% | batch:        58 of        94\t|\tloss: 1411.51\n",
      "Training Epoch 40  62.8% | batch:        59 of        94\t|\tloss: 960.15\n",
      "Training Epoch 40  63.8% | batch:        60 of        94\t|\tloss: 1138\n",
      "Training Epoch 40  64.9% | batch:        61 of        94\t|\tloss: 1251.08\n",
      "Training Epoch 40  66.0% | batch:        62 of        94\t|\tloss: 1163.52\n",
      "Training Epoch 40  67.0% | batch:        63 of        94\t|\tloss: 1016.8\n",
      "Training Epoch 40  68.1% | batch:        64 of        94\t|\tloss: 1728.84\n",
      "Training Epoch 40  69.1% | batch:        65 of        94\t|\tloss: 1852.49\n",
      "Training Epoch 40  70.2% | batch:        66 of        94\t|\tloss: 1085.96\n",
      "Training Epoch 40  71.3% | batch:        67 of        94\t|\tloss: 3785.23\n",
      "Training Epoch 40  72.3% | batch:        68 of        94\t|\tloss: 1219.09\n",
      "Training Epoch 40  73.4% | batch:        69 of        94\t|\tloss: 1152.76\n",
      "Training Epoch 40  74.5% | batch:        70 of        94\t|\tloss: 1175.74\n",
      "Training Epoch 40  75.5% | batch:        71 of        94\t|\tloss: 839.834\n",
      "Training Epoch 40  76.6% | batch:        72 of        94\t|\tloss: 2092.58\n",
      "Training Epoch 40  77.7% | batch:        73 of        94\t|\tloss: 1107.56\n",
      "Training Epoch 40  78.7% | batch:        74 of        94\t|\tloss: 3085.57\n",
      "Training Epoch 40  79.8% | batch:        75 of        94\t|\tloss: 1174.35\n",
      "Training Epoch 40  80.9% | batch:        76 of        94\t|\tloss: 1157.13\n",
      "Training Epoch 40  81.9% | batch:        77 of        94\t|\tloss: 1943.95\n",
      "Training Epoch 40  83.0% | batch:        78 of        94\t|\tloss: 973.366\n",
      "Training Epoch 40  84.0% | batch:        79 of        94\t|\tloss: 2333.33\n",
      "Training Epoch 40  85.1% | batch:        80 of        94\t|\tloss: 1245.3\n",
      "Training Epoch 40  86.2% | batch:        81 of        94\t|\tloss: 1474.18\n",
      "Training Epoch 40  87.2% | batch:        82 of        94\t|\tloss: 1300.36\n",
      "Training Epoch 40  88.3% | batch:        83 of        94\t|\tloss: 883.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:13,004 | INFO : Epoch 40 Training Summary: epoch: 40.000000 | loss: 1465.330204 | \n",
      "2023-05-04 17:00:13,005 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8046622276306152 seconds\n",
      "\n",
      "2023-05-04 17:00:13,006 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7918618202209473 seconds\n",
      "2023-05-04 17:00:13,006 | INFO : Avg batch train. time: 0.019062359789584545 seconds\n",
      "2023-05-04 17:00:13,007 | INFO : Avg sample train. time: 0.0001503492045830632 seconds\n",
      "2023-05-04 17:00:13,008 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 40  89.4% | batch:        84 of        94\t|\tloss: 1229.45\n",
      "Training Epoch 40  90.4% | batch:        85 of        94\t|\tloss: 1251.37\n",
      "Training Epoch 40  91.5% | batch:        86 of        94\t|\tloss: 896.619\n",
      "Training Epoch 40  92.6% | batch:        87 of        94\t|\tloss: 1248.97\n",
      "Training Epoch 40  93.6% | batch:        88 of        94\t|\tloss: 1528.54\n",
      "Training Epoch 40  94.7% | batch:        89 of        94\t|\tloss: 960.52\n",
      "Training Epoch 40  95.7% | batch:        90 of        94\t|\tloss: 2389.62\n",
      "Training Epoch 40  96.8% | batch:        91 of        94\t|\tloss: 1232.06\n",
      "Training Epoch 40  97.9% | batch:        92 of        94\t|\tloss: 2257.82\n",
      "Training Epoch 40  98.9% | batch:        93 of        94\t|\tloss: 2306.47\n",
      "\n",
      "Evaluating Epoch 40   0.0% | batch:         0 of        40\t|\tloss: 6027.25\n",
      "Evaluating Epoch 40   2.5% | batch:         1 of        40\t|\tloss: 1047.51\n",
      "Evaluating Epoch 40   5.0% | batch:         2 of        40\t|\tloss: 2487.47\n",
      "Evaluating Epoch 40   7.5% | batch:         3 of        40\t|\tloss: 6802.6\n",
      "Evaluating Epoch 40  10.0% | batch:         4 of        40\t|\tloss: 2584.72\n",
      "Evaluating Epoch 40  12.5% | batch:         5 of        40\t|\tloss: 2756.14\n",
      "Evaluating Epoch 40  15.0% | batch:         6 of        40\t|\tloss: 7888.26\n",
      "Evaluating Epoch 40  17.5% | batch:         7 of        40\t|\tloss: 3064.52\n",
      "Evaluating Epoch 40  20.0% | batch:         8 of        40\t|\tloss: 2713.03\n",
      "Evaluating Epoch 40  22.5% | batch:         9 of        40\t|\tloss: 1930.18\n",
      "Evaluating Epoch 40  25.0% | batch:        10 of        40\t|\tloss: 4350.54\n",
      "Evaluating Epoch 40  27.5% | batch:        11 of        40\t|\tloss: 1417.71\n",
      "Evaluating Epoch 40  30.0% | batch:        12 of        40\t|\tloss: 6915.38\n",
      "Evaluating Epoch 40  32.5% | batch:        13 of        40\t|\tloss: 2623.9\n",
      "Evaluating Epoch 40  35.0% | batch:        14 of        40\t|\tloss: 1975.77\n",
      "Evaluating Epoch 40  37.5% | batch:        15 of        40\t|\tloss: 3565.66\n",
      "Evaluating Epoch 40  40.0% | batch:        16 of        40\t|\tloss: 4504.26\n",
      "Evaluating Epoch 40  42.5% | batch:        17 of        40\t|\tloss: 2892.93\n",
      "Evaluating Epoch 40  45.0% | batch:        18 of        40\t|\tloss: 2625.05\n",
      "Evaluating Epoch 40  47.5% | batch:        19 of        40\t|\tloss: 6146.92\n",
      "Evaluating Epoch 40  50.0% | batch:        20 of        40\t|\tloss: 4824.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:13,456 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4485039710998535 seconds\n",
      "\n",
      "2023-05-04 17:00:13,457 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5385857110466462 seconds\n",
      "2023-05-04 17:00:13,458 | INFO : Avg batch val. time: 0.013464642776166155 seconds\n",
      "2023-05-04 17:00:13,458 | INFO : Avg sample val. time: 0.00010669289046090456 seconds\n",
      "2023-05-04 17:00:13,459 | INFO : Epoch 40 Validation Summary: epoch: 40.000000 | loss: 3851.754185 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 40  52.5% | batch:        21 of        40\t|\tloss: 1035.33\n",
      "Evaluating Epoch 40  55.0% | batch:        22 of        40\t|\tloss: 3868.7\n",
      "Evaluating Epoch 40  57.5% | batch:        23 of        40\t|\tloss: 2714.49\n",
      "Evaluating Epoch 40  60.0% | batch:        24 of        40\t|\tloss: 1551.02\n",
      "Evaluating Epoch 40  62.5% | batch:        25 of        40\t|\tloss: 3257.68\n",
      "Evaluating Epoch 40  65.0% | batch:        26 of        40\t|\tloss: 8845.67\n",
      "Evaluating Epoch 40  67.5% | batch:        27 of        40\t|\tloss: 2421.15\n",
      "Evaluating Epoch 40  70.0% | batch:        28 of        40\t|\tloss: 1453.06\n",
      "Evaluating Epoch 40  72.5% | batch:        29 of        40\t|\tloss: 8619.78\n",
      "Evaluating Epoch 40  75.0% | batch:        30 of        40\t|\tloss: 1692.21\n",
      "Evaluating Epoch 40  77.5% | batch:        31 of        40\t|\tloss: 1364.93\n",
      "Evaluating Epoch 40  80.0% | batch:        32 of        40\t|\tloss: 6871.56\n",
      "Evaluating Epoch 40  82.5% | batch:        33 of        40\t|\tloss: 5522.66\n",
      "Evaluating Epoch 40  85.0% | batch:        34 of        40\t|\tloss: 984.263\n",
      "Evaluating Epoch 40  87.5% | batch:        35 of        40\t|\tloss: 5512.98\n",
      "Evaluating Epoch 40  90.0% | batch:        36 of        40\t|\tloss: 6194.58\n",
      "Evaluating Epoch 40  92.5% | batch:        37 of        40\t|\tloss: 2455.9\n",
      "Evaluating Epoch 40  95.0% | batch:        38 of        40\t|\tloss: 3682.53\n",
      "Evaluating Epoch 40  97.5% | batch:        39 of        40\t|\tloss: 10766.9\n",
      "\n",
      "Training Epoch 41   0.0% | batch:         0 of        94\t|\tloss: 1220.28\n",
      "Training Epoch 41   1.1% | batch:         1 of        94\t|\tloss: 819.722\n",
      "Training Epoch 41   2.1% | batch:         2 of        94\t|\tloss: 2912.41\n",
      "Training Epoch 41   3.2% | batch:         3 of        94\t|\tloss: 869.835\n",
      "Training Epoch 41   4.3% | batch:         4 of        94\t|\tloss: 963.285\n",
      "Training Epoch 41   5.3% | batch:         5 of        94\t|\tloss: 1953.48\n",
      "Training Epoch 41   6.4% | batch:         6 of        94\t|\tloss: 1671.02\n",
      "Training Epoch 41   7.4% | batch:         7 of        94\t|\tloss: 1332.01\n",
      "Training Epoch 41   8.5% | batch:         8 of        94\t|\tloss: 1641.66\n",
      "Training Epoch 41   9.6% | batch:         9 of        94\t|\tloss: 977.601\n",
      "Training Epoch 41  10.6% | batch:        10 of        94\t|\tloss: 1405.53\n",
      "Training Epoch 41  11.7% | batch:        11 of        94\t|\tloss: 1951.15\n",
      "Training Epoch 41  12.8% | batch:        12 of        94\t|\tloss: 1245.96\n",
      "Training Epoch 41  13.8% | batch:        13 of        94\t|\tloss: 851.794\n",
      "Training Epoch 41  14.9% | batch:        14 of        94\t|\tloss: 1084.09\n",
      "Training Epoch 41  16.0% | batch:        15 of        94\t|\tloss: 1690.25\n",
      "Training Epoch 41  17.0% | batch:        16 of        94\t|\tloss: 1260.04\n",
      "Training Epoch 41  18.1% | batch:        17 of        94\t|\tloss: 1180.71\n",
      "Training Epoch 41  19.1% | batch:        18 of        94\t|\tloss: 916.175\n",
      "Training Epoch 41  20.2% | batch:        19 of        94\t|\tloss: 1448.19\n",
      "Training Epoch 41  21.3% | batch:        20 of        94\t|\tloss: 1509.43\n",
      "Training Epoch 41  22.3% | batch:        21 of        94\t|\tloss: 1617.98\n",
      "Training Epoch 41  23.4% | batch:        22 of        94\t|\tloss: 1045.51\n",
      "Training Epoch 41  24.5% | batch:        23 of        94\t|\tloss: 4216.96\n",
      "Training Epoch 41  25.5% | batch:        24 of        94\t|\tloss: 1161.16\n",
      "Training Epoch 41  26.6% | batch:        25 of        94\t|\tloss: 2831.07\n",
      "Training Epoch 41  27.7% | batch:        26 of        94\t|\tloss: 1243.55\n",
      "Training Epoch 41  28.7% | batch:        27 of        94\t|\tloss: 1356.49\n",
      "Training Epoch 41  29.8% | batch:        28 of        94\t|\tloss: 1312.02\n",
      "Training Epoch 41  30.9% | batch:        29 of        94\t|\tloss: 966.726\n",
      "Training Epoch 41  31.9% | batch:        30 of        94\t|\tloss: 1534.31\n",
      "Training Epoch 41  33.0% | batch:        31 of        94\t|\tloss: 1080.38\n",
      "Training Epoch 41  34.0% | batch:        32 of        94\t|\tloss: 981.443\n",
      "Training Epoch 41  35.1% | batch:        33 of        94\t|\tloss: 1962.16\n",
      "Training Epoch 41  36.2% | batch:        34 of        94\t|\tloss: 1110.88\n",
      "Training Epoch 41  37.2% | batch:        35 of        94\t|\tloss: 1571.1\n",
      "Training Epoch 41  38.3% | batch:        36 of        94\t|\tloss: 1002.09\n",
      "Training Epoch 41  39.4% | batch:        37 of        94\t|\tloss: 1255.6\n",
      "Training Epoch 41  40.4% | batch:        38 of        94\t|\tloss: 1125.25\n",
      "Training Epoch 41  41.5% | batch:        39 of        94\t|\tloss: 1254.37\n",
      "Training Epoch 41  42.6% | batch:        40 of        94\t|\tloss: 1603.24\n",
      "Training Epoch 41  43.6% | batch:        41 of        94\t|\tloss: 1096.14\n",
      "Training Epoch 41  44.7% | batch:        42 of        94\t|\tloss: 1176.99\n",
      "Training Epoch 41  45.7% | batch:        43 of        94\t|\tloss: 881.595\n",
      "Training Epoch 41  46.8% | batch:        44 of        94\t|\tloss: 1009.82\n",
      "Training Epoch 41  47.9% | batch:        45 of        94\t|\tloss: 1697.51\n",
      "Training Epoch 41  48.9% | batch:        46 of        94\t|\tloss: 1139.57\n",
      "Training Epoch 41  50.0% | batch:        47 of        94\t|\tloss: 1770.04\n",
      "Training Epoch 41  51.1% | batch:        48 of        94\t|\tloss: 1312.86\n",
      "Training Epoch 41  52.1% | batch:        49 of        94\t|\tloss: 999.2\n",
      "Training Epoch 41  53.2% | batch:        50 of        94\t|\tloss: 1397.85\n",
      "Training Epoch 41  54.3% | batch:        51 of        94\t|\tloss: 768.982\n",
      "Training Epoch 41  55.3% | batch:        52 of        94\t|\tloss: 1126.2\n",
      "Training Epoch 41  56.4% | batch:        53 of        94\t|\tloss: 868.369\n",
      "Training Epoch 41  57.4% | batch:        54 of        94\t|\tloss: 2105.25\n",
      "Training Epoch 41  58.5% | batch:        55 of        94\t|\tloss: 2193.94\n",
      "Training Epoch 41  59.6% | batch:        56 of        94\t|\tloss: 975.813\n",
      "Training Epoch 41  60.6% | batch:        57 of        94\t|\tloss: 837.938\n",
      "Training Epoch 41  61.7% | batch:        58 of        94\t|\tloss: 1384.67\n",
      "Training Epoch 41  62.8% | batch:        59 of        94\t|\tloss: 2246.47\n",
      "Training Epoch 41  63.8% | batch:        60 of        94\t|\tloss: 1775.63\n",
      "Training Epoch 41  64.9% | batch:        61 of        94\t|\tloss: 1615.37\n",
      "Training Epoch 41  66.0% | batch:        62 of        94\t|\tloss: 746.378\n",
      "Training Epoch 41  67.0% | batch:        63 of        94\t|\tloss: 1424.21\n",
      "Training Epoch 41  68.1% | batch:        64 of        94\t|\tloss: 772.05\n",
      "Training Epoch 41  69.1% | batch:        65 of        94\t|\tloss: 1846.05\n",
      "Training Epoch 41  70.2% | batch:        66 of        94\t|\tloss: 1383.33\n",
      "Training Epoch 41  71.3% | batch:        67 of        94\t|\tloss: 1319.63\n",
      "Training Epoch 41  72.3% | batch:        68 of        94\t|\tloss: 1397.17\n",
      "Training Epoch 41  73.4% | batch:        69 of        94\t|\tloss: 1545.42\n",
      "Training Epoch 41  74.5% | batch:        70 of        94\t|\tloss: 1802.07\n",
      "Training Epoch 41  75.5% | batch:        71 of        94\t|\tloss: 1329.63\n",
      "Training Epoch 41  76.6% | batch:        72 of        94\t|\tloss: 1023.51\n",
      "Training Epoch 41  77.7% | batch:        73 of        94\t|\tloss: 1288.46\n",
      "Training Epoch 41  78.7% | batch:        74 of        94\t|\tloss: 1601.56\n",
      "Training Epoch 41  79.8% | batch:        75 of        94\t|\tloss: 1022.1\n",
      "Training Epoch 41  80.9% | batch:        76 of        94\t|\tloss: 1626.71\n",
      "Training Epoch 41  81.9% | batch:        77 of        94\t|\tloss: 951.672\n",
      "Training Epoch 41  83.0% | batch:        78 of        94\t|\tloss: 1076.98\n",
      "Training Epoch 41  84.0% | batch:        79 of        94\t|\tloss: 1834.69\n",
      "Training Epoch 41  85.1% | batch:        80 of        94\t|\tloss: 1385.82\n",
      "Training Epoch 41  86.2% | batch:        81 of        94\t|\tloss: 1531.89\n",
      "Training Epoch 41  87.2% | batch:        82 of        94\t|\tloss: 1066.14\n",
      "Training Epoch 41  88.3% | batch:        83 of        94\t|\tloss: 1878.95\n",
      "Training Epoch 41  89.4% | batch:        84 of        94\t|\tloss: 957.766\n",
      "Training Epoch 41  90.4% | batch:        85 of        94\t|\tloss: 1543.8\n",
      "Training Epoch 41  91.5% | batch:        86 of        94\t|\tloss: 977.358\n",
      "Training Epoch 41  92.6% | batch:        87 of        94\t|\tloss: 3489.62\n",
      "Training Epoch 41  93.6% | batch:        88 of        94\t|\tloss: 1889.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:15,264 | INFO : Epoch 41 Training Summary: epoch: 41.000000 | loss: 1422.735049 | \n",
      "2023-05-04 17:00:15,265 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7828755378723145 seconds\n",
      "\n",
      "2023-05-04 17:00:15,266 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.791642642602688 seconds\n",
      "2023-05-04 17:00:15,267 | INFO : Avg batch train. time: 0.01906002811279455 seconds\n",
      "2023-05-04 17:00:15,267 | INFO : Avg sample train. time: 0.00015033081411333177 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 41  94.7% | batch:        89 of        94\t|\tloss: 945.536\n",
      "Training Epoch 41  95.7% | batch:        90 of        94\t|\tloss: 2150\n",
      "Training Epoch 41  96.8% | batch:        91 of        94\t|\tloss: 1514.78\n",
      "Training Epoch 41  97.9% | batch:        92 of        94\t|\tloss: 1398.23\n",
      "Training Epoch 41  98.9% | batch:        93 of        94\t|\tloss: 2117.06\n",
      "\n",
      "Training Epoch 42   0.0% | batch:         0 of        94\t|\tloss: 1217.99\n",
      "Training Epoch 42   1.1% | batch:         1 of        94\t|\tloss: 1488.65\n",
      "Training Epoch 42   2.1% | batch:         2 of        94\t|\tloss: 1315.55\n",
      "Training Epoch 42   3.2% | batch:         3 of        94\t|\tloss: 1036.66\n",
      "Training Epoch 42   4.3% | batch:         4 of        94\t|\tloss: 1129.53\n",
      "Training Epoch 42   5.3% | batch:         5 of        94\t|\tloss: 1788.17\n",
      "Training Epoch 42   6.4% | batch:         6 of        94\t|\tloss: 2475.56\n",
      "Training Epoch 42   7.4% | batch:         7 of        94\t|\tloss: 1355.94\n",
      "Training Epoch 42   8.5% | batch:         8 of        94\t|\tloss: 2169.78\n",
      "Training Epoch 42   9.6% | batch:         9 of        94\t|\tloss: 3218.74\n",
      "Training Epoch 42  10.6% | batch:        10 of        94\t|\tloss: 969.556\n",
      "Training Epoch 42  11.7% | batch:        11 of        94\t|\tloss: 1659.33\n",
      "Training Epoch 42  12.8% | batch:        12 of        94\t|\tloss: 668.405\n",
      "Training Epoch 42  13.8% | batch:        13 of        94\t|\tloss: 849.939\n",
      "Training Epoch 42  14.9% | batch:        14 of        94\t|\tloss: 1234.79\n",
      "Training Epoch 42  16.0% | batch:        15 of        94\t|\tloss: 1055.73\n",
      "Training Epoch 42  17.0% | batch:        16 of        94\t|\tloss: 1079.32\n",
      "Training Epoch 42  18.1% | batch:        17 of        94\t|\tloss: 1582.58\n",
      "Training Epoch 42  19.1% | batch:        18 of        94\t|\tloss: 1364.12\n",
      "Training Epoch 42  20.2% | batch:        19 of        94\t|\tloss: 2712.34\n",
      "Training Epoch 42  21.3% | batch:        20 of        94\t|\tloss: 1463\n",
      "Training Epoch 42  22.3% | batch:        21 of        94\t|\tloss: 744.913\n",
      "Training Epoch 42  23.4% | batch:        22 of        94\t|\tloss: 2107.84\n",
      "Training Epoch 42  24.5% | batch:        23 of        94\t|\tloss: 1249.81\n",
      "Training Epoch 42  25.5% | batch:        24 of        94\t|\tloss: 1218.66\n",
      "Training Epoch 42  26.6% | batch:        25 of        94\t|\tloss: 1151.56\n",
      "Training Epoch 42  27.7% | batch:        26 of        94\t|\tloss: 1297.94\n",
      "Training Epoch 42  28.7% | batch:        27 of        94\t|\tloss: 837.109\n",
      "Training Epoch 42  29.8% | batch:        28 of        94\t|\tloss: 2066.35\n",
      "Training Epoch 42  30.9% | batch:        29 of        94\t|\tloss: 1200.75\n",
      "Training Epoch 42  31.9% | batch:        30 of        94\t|\tloss: 1122.82\n",
      "Training Epoch 42  33.0% | batch:        31 of        94\t|\tloss: 970.591\n",
      "Training Epoch 42  34.0% | batch:        32 of        94\t|\tloss: 1786.78\n",
      "Training Epoch 42  35.1% | batch:        33 of        94\t|\tloss: 1241.19\n",
      "Training Epoch 42  36.2% | batch:        34 of        94\t|\tloss: 1356.41\n",
      "Training Epoch 42  37.2% | batch:        35 of        94\t|\tloss: 1624.36\n",
      "Training Epoch 42  38.3% | batch:        36 of        94\t|\tloss: 1234.72\n",
      "Training Epoch 42  39.4% | batch:        37 of        94\t|\tloss: 896.99\n",
      "Training Epoch 42  40.4% | batch:        38 of        94\t|\tloss: 1144.58\n",
      "Training Epoch 42  41.5% | batch:        39 of        94\t|\tloss: 1234.2\n",
      "Training Epoch 42  42.6% | batch:        40 of        94\t|\tloss: 1377.23\n",
      "Training Epoch 42  43.6% | batch:        41 of        94\t|\tloss: 1209.93\n",
      "Training Epoch 42  44.7% | batch:        42 of        94\t|\tloss: 1403.88\n",
      "Training Epoch 42  45.7% | batch:        43 of        94\t|\tloss: 1523.34\n",
      "Training Epoch 42  46.8% | batch:        44 of        94\t|\tloss: 1074.94\n",
      "Training Epoch 42  47.9% | batch:        45 of        94\t|\tloss: 1518.29\n",
      "Training Epoch 42  48.9% | batch:        46 of        94\t|\tloss: 966.698\n",
      "Training Epoch 42  50.0% | batch:        47 of        94\t|\tloss: 1178.73\n",
      "Training Epoch 42  51.1% | batch:        48 of        94\t|\tloss: 1091.08\n",
      "Training Epoch 42  52.1% | batch:        49 of        94\t|\tloss: 2017.19\n",
      "Training Epoch 42  53.2% | batch:        50 of        94\t|\tloss: 1769.97\n",
      "Training Epoch 42  54.3% | batch:        51 of        94\t|\tloss: 1722.25\n",
      "Training Epoch 42  55.3% | batch:        52 of        94\t|\tloss: 853.87\n",
      "Training Epoch 42  56.4% | batch:        53 of        94\t|\tloss: 1537.07\n",
      "Training Epoch 42  57.4% | batch:        54 of        94\t|\tloss: 2344.13\n",
      "Training Epoch 42  58.5% | batch:        55 of        94\t|\tloss: 786.894\n",
      "Training Epoch 42  59.6% | batch:        56 of        94\t|\tloss: 1775.27\n",
      "Training Epoch 42  60.6% | batch:        57 of        94\t|\tloss: 1644.19\n",
      "Training Epoch 42  61.7% | batch:        58 of        94\t|\tloss: 935.883\n",
      "Training Epoch 42  62.8% | batch:        59 of        94\t|\tloss: 1295.89\n",
      "Training Epoch 42  63.8% | batch:        60 of        94\t|\tloss: 1771.87\n",
      "Training Epoch 42  64.9% | batch:        61 of        94\t|\tloss: 1008.57\n",
      "Training Epoch 42  66.0% | batch:        62 of        94\t|\tloss: 1382.89\n",
      "Training Epoch 42  67.0% | batch:        63 of        94\t|\tloss: 1113.9\n",
      "Training Epoch 42  68.1% | batch:        64 of        94\t|\tloss: 1271.8\n",
      "Training Epoch 42  69.1% | batch:        65 of        94\t|\tloss: 2320.53\n",
      "Training Epoch 42  70.2% | batch:        66 of        94\t|\tloss: 1297.54\n",
      "Training Epoch 42  71.3% | batch:        67 of        94\t|\tloss: 1893.97\n",
      "Training Epoch 42  72.3% | batch:        68 of        94\t|\tloss: 1257.67\n",
      "Training Epoch 42  73.4% | batch:        69 of        94\t|\tloss: 2443.5\n",
      "Training Epoch 42  74.5% | batch:        70 of        94\t|\tloss: 1316.9\n",
      "Training Epoch 42  75.5% | batch:        71 of        94\t|\tloss: 1682.04\n",
      "Training Epoch 42  76.6% | batch:        72 of        94\t|\tloss: 1194.75\n",
      "Training Epoch 42  77.7% | batch:        73 of        94\t|\tloss: 914.555\n",
      "Training Epoch 42  78.7% | batch:        74 of        94\t|\tloss: 1310.32\n",
      "Training Epoch 42  79.8% | batch:        75 of        94\t|\tloss: 1019.85\n",
      "Training Epoch 42  80.9% | batch:        76 of        94\t|\tloss: 924.847\n",
      "Training Epoch 42  81.9% | batch:        77 of        94\t|\tloss: 1094.74\n",
      "Training Epoch 42  83.0% | batch:        78 of        94\t|\tloss: 1189.71\n",
      "Training Epoch 42  84.0% | batch:        79 of        94\t|\tloss: 959.355\n",
      "Training Epoch 42  85.1% | batch:        80 of        94\t|\tloss: 1045.26\n",
      "Training Epoch 42  86.2% | batch:        81 of        94\t|\tloss: 3720.34\n",
      "Training Epoch 42  87.2% | batch:        82 of        94\t|\tloss: 2162.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:17,078 | INFO : Epoch 42 Training Summary: epoch: 42.000000 | loss: 1447.055030 | \n",
      "2023-05-04 17:00:17,079 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7898097038269043 seconds\n",
      "\n",
      "2023-05-04 17:00:17,080 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7915990012032645 seconds\n",
      "2023-05-04 17:00:17,081 | INFO : Avg batch train. time: 0.01905956384258792 seconds\n",
      "2023-05-04 17:00:17,081 | INFO : Avg sample train. time: 0.00015032715230770804 seconds\n",
      "2023-05-04 17:00:17,082 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 42  88.3% | batch:        83 of        94\t|\tloss: 1123.16\n",
      "Training Epoch 42  89.4% | batch:        84 of        94\t|\tloss: 894.841\n",
      "Training Epoch 42  90.4% | batch:        85 of        94\t|\tloss: 1271.74\n",
      "Training Epoch 42  91.5% | batch:        86 of        94\t|\tloss: 1585.82\n",
      "Training Epoch 42  92.6% | batch:        87 of        94\t|\tloss: 2110.02\n",
      "Training Epoch 42  93.6% | batch:        88 of        94\t|\tloss: 1291.56\n",
      "Training Epoch 42  94.7% | batch:        89 of        94\t|\tloss: 1556.62\n",
      "Training Epoch 42  95.7% | batch:        90 of        94\t|\tloss: 2353.34\n",
      "Training Epoch 42  96.8% | batch:        91 of        94\t|\tloss: 1848.27\n",
      "Training Epoch 42  97.9% | batch:        92 of        94\t|\tloss: 1967.08\n",
      "Training Epoch 42  98.9% | batch:        93 of        94\t|\tloss: 772.908\n",
      "\n",
      "Evaluating Epoch 42   0.0% | batch:         0 of        40\t|\tloss: 6163.66\n",
      "Evaluating Epoch 42   2.5% | batch:         1 of        40\t|\tloss: 967.236\n",
      "Evaluating Epoch 42   5.0% | batch:         2 of        40\t|\tloss: 2981.59\n",
      "Evaluating Epoch 42   7.5% | batch:         3 of        40\t|\tloss: 7001\n",
      "Evaluating Epoch 42  10.0% | batch:         4 of        40\t|\tloss: 2539.21\n",
      "Evaluating Epoch 42  12.5% | batch:         5 of        40\t|\tloss: 2647.54\n",
      "Evaluating Epoch 42  15.0% | batch:         6 of        40\t|\tloss: 7332.65\n",
      "Evaluating Epoch 42  17.5% | batch:         7 of        40\t|\tloss: 2709.85\n",
      "Evaluating Epoch 42  20.0% | batch:         8 of        40\t|\tloss: 2668.06\n",
      "Evaluating Epoch 42  22.5% | batch:         9 of        40\t|\tloss: 2110.36\n",
      "Evaluating Epoch 42  25.0% | batch:        10 of        40\t|\tloss: 4038.55\n",
      "Evaluating Epoch 42  27.5% | batch:        11 of        40\t|\tloss: 1260.49\n",
      "Evaluating Epoch 42  30.0% | batch:        12 of        40\t|\tloss: 5659.89\n",
      "Evaluating Epoch 42  32.5% | batch:        13 of        40\t|\tloss: 2376.76\n",
      "Evaluating Epoch 42  35.0% | batch:        14 of        40\t|\tloss: 1637.5\n",
      "Evaluating Epoch 42  37.5% | batch:        15 of        40\t|\tloss: 3193.56\n",
      "Evaluating Epoch 42  40.0% | batch:        16 of        40\t|\tloss: 3083.01\n",
      "Evaluating Epoch 42  42.5% | batch:        17 of        40\t|\tloss: 2194.35\n",
      "Evaluating Epoch 42  45.0% | batch:        18 of        40\t|\tloss: 2336.43\n",
      "Evaluating Epoch 42  47.5% | batch:        19 of        40\t|\tloss: 4046.51\n",
      "Evaluating Epoch 42  50.0% | batch:        20 of        40\t|\tloss: 4247.81\n",
      "Evaluating Epoch 42  52.5% | batch:        21 of        40\t|\tloss: 1009.69\n",
      "Evaluating Epoch 42  55.0% | batch:        22 of        40\t|\tloss: 5087.11\n",
      "Evaluating Epoch 42  57.5% | batch:        23 of        40\t|\tloss: 3062.41\n",
      "Evaluating Epoch 42  60.0% | batch:        24 of        40\t|\tloss: 1719.14\n",
      "Evaluating Epoch 42  62.5% | batch:        25 of        40\t|\tloss: 2805.8\n",
      "Evaluating Epoch 42  65.0% | batch:        26 of        40\t|\tloss: 7964.86\n",
      "Evaluating Epoch 42  67.5% | batch:        27 of        40\t|\tloss: 2073.26\n",
      "Evaluating Epoch 42  70.0% | batch:        28 of        40\t|\tloss: 1999.57\n",
      "Evaluating Epoch 42  72.5% | batch:        29 of        40\t|\tloss: 8664.22\n",
      "Evaluating Epoch 42  75.0% | batch:        30 of        40\t|\tloss: 1739.65\n",
      "Evaluating Epoch 42  77.5% | batch:        31 of        40\t|\tloss: 1812.11\n",
      "Evaluating Epoch 42  80.0% | batch:        32 of        40\t|\tloss: 6772.33\n",
      "Evaluating Epoch 42  82.5% | batch:        33 of        40\t|\tloss: 5304.28\n",
      "Evaluating Epoch 42  85.0% | batch:        34 of        40\t|\tloss: 995.671\n",
      "Evaluating Epoch 42  87.5% | batch:        35 of        40\t|\tloss: 5364.37\n",
      "Evaluating Epoch 42  90.0% | batch:        36 of        40\t|\tloss: 4905.19\n",
      "Evaluating Epoch 42  92.5% | batch:        37 of        40\t|\tloss: 2262.48\n",
      "Evaluating Epoch 42  95.0% | batch:        38 of        40\t|\tloss: 3059.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:17,536 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45350146293640137 seconds\n",
      "\n",
      "2023-05-04 17:00:17,537 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5381232966547427 seconds\n",
      "2023-05-04 17:00:17,537 | INFO : Avg batch val. time: 0.013453082416368566 seconds\n",
      "2023-05-04 17:00:17,538 | INFO : Avg sample val. time: 0.00010660128697597913 seconds\n",
      "2023-05-04 17:00:17,539 | INFO : Epoch 42 Validation Summary: epoch: 42.000000 | loss: 3589.229515 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 42  97.5% | batch:        39 of        40\t|\tloss: 8578.05\n",
      "\n",
      "Training Epoch 43   0.0% | batch:         0 of        94\t|\tloss: 969.988\n",
      "Training Epoch 43   1.1% | batch:         1 of        94\t|\tloss: 1228.79\n",
      "Training Epoch 43   2.1% | batch:         2 of        94\t|\tloss: 1466.04\n",
      "Training Epoch 43   3.2% | batch:         3 of        94\t|\tloss: 1175.75\n",
      "Training Epoch 43   4.3% | batch:         4 of        94\t|\tloss: 1314.96\n",
      "Training Epoch 43   5.3% | batch:         5 of        94\t|\tloss: 1008.71\n",
      "Training Epoch 43   6.4% | batch:         6 of        94\t|\tloss: 1320.95\n",
      "Training Epoch 43   7.4% | batch:         7 of        94\t|\tloss: 1256.31\n",
      "Training Epoch 43   8.5% | batch:         8 of        94\t|\tloss: 2938.03\n",
      "Training Epoch 43   9.6% | batch:         9 of        94\t|\tloss: 681.091\n",
      "Training Epoch 43  10.6% | batch:        10 of        94\t|\tloss: 2129.08\n",
      "Training Epoch 43  11.7% | batch:        11 of        94\t|\tloss: 949.273\n",
      "Training Epoch 43  12.8% | batch:        12 of        94\t|\tloss: 1046.07\n",
      "Training Epoch 43  13.8% | batch:        13 of        94\t|\tloss: 852.926\n",
      "Training Epoch 43  14.9% | batch:        14 of        94\t|\tloss: 637.813\n",
      "Training Epoch 43  16.0% | batch:        15 of        94\t|\tloss: 1001.79\n",
      "Training Epoch 43  17.0% | batch:        16 of        94\t|\tloss: 1494.44\n",
      "Training Epoch 43  18.1% | batch:        17 of        94\t|\tloss: 1151.5\n",
      "Training Epoch 43  19.1% | batch:        18 of        94\t|\tloss: 1630.32\n",
      "Training Epoch 43  20.2% | batch:        19 of        94\t|\tloss: 1412.86\n",
      "Training Epoch 43  21.3% | batch:        20 of        94\t|\tloss: 1783.53\n",
      "Training Epoch 43  22.3% | batch:        21 of        94\t|\tloss: 1265.57\n",
      "Training Epoch 43  23.4% | batch:        22 of        94\t|\tloss: 1419.7\n",
      "Training Epoch 43  24.5% | batch:        23 of        94\t|\tloss: 3229.56\n",
      "Training Epoch 43  25.5% | batch:        24 of        94\t|\tloss: 982.022\n",
      "Training Epoch 43  26.6% | batch:        25 of        94\t|\tloss: 1087.76\n",
      "Training Epoch 43  27.7% | batch:        26 of        94\t|\tloss: 1145.51\n",
      "Training Epoch 43  28.7% | batch:        27 of        94\t|\tloss: 1699.15\n",
      "Training Epoch 43  29.8% | batch:        28 of        94\t|\tloss: 1125.5\n",
      "Training Epoch 43  30.9% | batch:        29 of        94\t|\tloss: 805.054\n",
      "Training Epoch 43  31.9% | batch:        30 of        94\t|\tloss: 1273.86\n",
      "Training Epoch 43  33.0% | batch:        31 of        94\t|\tloss: 982.797\n",
      "Training Epoch 43  34.0% | batch:        32 of        94\t|\tloss: 999.335\n",
      "Training Epoch 43  35.1% | batch:        33 of        94\t|\tloss: 1978.13\n",
      "Training Epoch 43  36.2% | batch:        34 of        94\t|\tloss: 2508.39\n",
      "Training Epoch 43  37.2% | batch:        35 of        94\t|\tloss: 920.593\n",
      "Training Epoch 43  38.3% | batch:        36 of        94\t|\tloss: 1804.05\n",
      "Training Epoch 43  39.4% | batch:        37 of        94\t|\tloss: 2338.84\n",
      "Training Epoch 43  40.4% | batch:        38 of        94\t|\tloss: 1435.41\n",
      "Training Epoch 43  41.5% | batch:        39 of        94\t|\tloss: 1592.29\n",
      "Training Epoch 43  42.6% | batch:        40 of        94\t|\tloss: 1172.03\n",
      "Training Epoch 43  43.6% | batch:        41 of        94\t|\tloss: 1064.81\n",
      "Training Epoch 43  44.7% | batch:        42 of        94\t|\tloss: 3797.39\n",
      "Training Epoch 43  45.7% | batch:        43 of        94\t|\tloss: 1142.57\n",
      "Training Epoch 43  46.8% | batch:        44 of        94\t|\tloss: 1258.08\n",
      "Training Epoch 43  47.9% | batch:        45 of        94\t|\tloss: 869.711\n",
      "Training Epoch 43  48.9% | batch:        46 of        94\t|\tloss: 959.883\n",
      "Training Epoch 43  50.0% | batch:        47 of        94\t|\tloss: 1368.97\n",
      "Training Epoch 43  51.1% | batch:        48 of        94\t|\tloss: 979.181\n",
      "Training Epoch 43  52.1% | batch:        49 of        94\t|\tloss: 1083.53\n",
      "Training Epoch 43  53.2% | batch:        50 of        94\t|\tloss: 1045.02\n",
      "Training Epoch 43  54.3% | batch:        51 of        94\t|\tloss: 686.144\n",
      "Training Epoch 43  55.3% | batch:        52 of        94\t|\tloss: 1164.1\n",
      "Training Epoch 43  56.4% | batch:        53 of        94\t|\tloss: 2121.4\n",
      "Training Epoch 43  57.4% | batch:        54 of        94\t|\tloss: 2752.7\n",
      "Training Epoch 43  58.5% | batch:        55 of        94\t|\tloss: 1700.34\n",
      "Training Epoch 43  59.6% | batch:        56 of        94\t|\tloss: 1046.39\n",
      "Training Epoch 43  60.6% | batch:        57 of        94\t|\tloss: 2172.04\n",
      "Training Epoch 43  61.7% | batch:        58 of        94\t|\tloss: 1352.95\n",
      "Training Epoch 43  62.8% | batch:        59 of        94\t|\tloss: 1414.9\n",
      "Training Epoch 43  63.8% | batch:        60 of        94\t|\tloss: 1079.85\n",
      "Training Epoch 43  64.9% | batch:        61 of        94\t|\tloss: 1781.95\n",
      "Training Epoch 43  66.0% | batch:        62 of        94\t|\tloss: 1493.18\n",
      "Training Epoch 43  67.0% | batch:        63 of        94\t|\tloss: 1273.41\n",
      "Training Epoch 43  68.1% | batch:        64 of        94\t|\tloss: 1257.58\n",
      "Training Epoch 43  69.1% | batch:        65 of        94\t|\tloss: 1406.42\n",
      "Training Epoch 43  70.2% | batch:        66 of        94\t|\tloss: 1512.48\n",
      "Training Epoch 43  71.3% | batch:        67 of        94\t|\tloss: 1391.9\n",
      "Training Epoch 43  72.3% | batch:        68 of        94\t|\tloss: 880.325\n",
      "Training Epoch 43  73.4% | batch:        69 of        94\t|\tloss: 1033.79\n",
      "Training Epoch 43  74.5% | batch:        70 of        94\t|\tloss: 1330.22\n",
      "Training Epoch 43  75.5% | batch:        71 of        94\t|\tloss: 1552.77\n",
      "Training Epoch 43  76.6% | batch:        72 of        94\t|\tloss: 1466.87\n",
      "Training Epoch 43  77.7% | batch:        73 of        94\t|\tloss: 1453.4\n",
      "Training Epoch 43  78.7% | batch:        74 of        94\t|\tloss: 2128.42\n",
      "Training Epoch 43  79.8% | batch:        75 of        94\t|\tloss: 1492.64\n",
      "Training Epoch 43  80.9% | batch:        76 of        94\t|\tloss: 1915.1\n",
      "Training Epoch 43  81.9% | batch:        77 of        94\t|\tloss: 2211.42\n",
      "Training Epoch 43  83.0% | batch:        78 of        94\t|\tloss: 3734.01\n",
      "Training Epoch 43  84.0% | batch:        79 of        94\t|\tloss: 1452.97\n",
      "Training Epoch 43  85.1% | batch:        80 of        94\t|\tloss: 1636.96\n",
      "Training Epoch 43  86.2% | batch:        81 of        94\t|\tloss: 1202.94\n",
      "Training Epoch 43  87.2% | batch:        82 of        94\t|\tloss: 773.514\n",
      "Training Epoch 43  88.3% | batch:        83 of        94\t|\tloss: 1093.16\n",
      "Training Epoch 43  89.4% | batch:        84 of        94\t|\tloss: 2062.14\n",
      "Training Epoch 43  90.4% | batch:        85 of        94\t|\tloss: 1792.54\n",
      "Training Epoch 43  91.5% | batch:        86 of        94\t|\tloss: 2256.23\n",
      "Training Epoch 43  92.6% | batch:        87 of        94\t|\tloss: 1532.16\n",
      "Training Epoch 43  93.6% | batch:        88 of        94\t|\tloss: 1246.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:19,317 | INFO : Epoch 43 Training Summary: epoch: 43.000000 | loss: 1460.165555 | \n",
      "2023-05-04 17:00:19,318 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7566511631011963 seconds\n",
      "\n",
      "2023-05-04 17:00:19,319 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7907862607822862 seconds\n",
      "2023-05-04 17:00:19,319 | INFO : Avg batch train. time: 0.019050917667896662 seconds\n",
      "2023-05-04 17:00:19,320 | INFO : Avg sample train. time: 0.0001502589579444778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 43  94.7% | batch:        89 of        94\t|\tloss: 1477.96\n",
      "Training Epoch 43  95.7% | batch:        90 of        94\t|\tloss: 1285.44\n",
      "Training Epoch 43  96.8% | batch:        91 of        94\t|\tloss: 1084\n",
      "Training Epoch 43  97.9% | batch:        92 of        94\t|\tloss: 1174.82\n",
      "Training Epoch 43  98.9% | batch:        93 of        94\t|\tloss: 2673.25\n",
      "\n",
      "Training Epoch 44   0.0% | batch:         0 of        94\t|\tloss: 891.498\n",
      "Training Epoch 44   1.1% | batch:         1 of        94\t|\tloss: 1460.39\n",
      "Training Epoch 44   2.1% | batch:         2 of        94\t|\tloss: 1520.03\n",
      "Training Epoch 44   3.2% | batch:         3 of        94\t|\tloss: 665.396\n",
      "Training Epoch 44   4.3% | batch:         4 of        94\t|\tloss: 1068.04\n",
      "Training Epoch 44   5.3% | batch:         5 of        94\t|\tloss: 1262.89\n",
      "Training Epoch 44   6.4% | batch:         6 of        94\t|\tloss: 1833.78\n",
      "Training Epoch 44   7.4% | batch:         7 of        94\t|\tloss: 1096.46\n",
      "Training Epoch 44   8.5% | batch:         8 of        94\t|\tloss: 1211.69\n",
      "Training Epoch 44   9.6% | batch:         9 of        94\t|\tloss: 1651.71\n",
      "Training Epoch 44  10.6% | batch:        10 of        94\t|\tloss: 727.427\n",
      "Training Epoch 44  11.7% | batch:        11 of        94\t|\tloss: 1254.67\n",
      "Training Epoch 44  12.8% | batch:        12 of        94\t|\tloss: 1044.76\n",
      "Training Epoch 44  13.8% | batch:        13 of        94\t|\tloss: 1457.08\n",
      "Training Epoch 44  14.9% | batch:        14 of        94\t|\tloss: 1114.91\n",
      "Training Epoch 44  16.0% | batch:        15 of        94\t|\tloss: 1538.78\n",
      "Training Epoch 44  17.0% | batch:        16 of        94\t|\tloss: 3115.4\n",
      "Training Epoch 44  18.1% | batch:        17 of        94\t|\tloss: 1036.84\n",
      "Training Epoch 44  19.1% | batch:        18 of        94\t|\tloss: 1931.99\n",
      "Training Epoch 44  20.2% | batch:        19 of        94\t|\tloss: 868.575\n",
      "Training Epoch 44  21.3% | batch:        20 of        94\t|\tloss: 1524.93\n",
      "Training Epoch 44  22.3% | batch:        21 of        94\t|\tloss: 1472.46\n",
      "Training Epoch 44  23.4% | batch:        22 of        94\t|\tloss: 1815.07\n",
      "Training Epoch 44  24.5% | batch:        23 of        94\t|\tloss: 1880.5\n",
      "Training Epoch 44  25.5% | batch:        24 of        94\t|\tloss: 1211.49\n",
      "Training Epoch 44  26.6% | batch:        25 of        94\t|\tloss: 868.573\n",
      "Training Epoch 44  27.7% | batch:        26 of        94\t|\tloss: 1188.17\n",
      "Training Epoch 44  28.7% | batch:        27 of        94\t|\tloss: 2195.18\n",
      "Training Epoch 44  29.8% | batch:        28 of        94\t|\tloss: 1128.55\n",
      "Training Epoch 44  30.9% | batch:        29 of        94\t|\tloss: 1577.77\n",
      "Training Epoch 44  31.9% | batch:        30 of        94\t|\tloss: 3360.23\n",
      "Training Epoch 44  33.0% | batch:        31 of        94\t|\tloss: 3773.48\n",
      "Training Epoch 44  34.0% | batch:        32 of        94\t|\tloss: 1047.17\n",
      "Training Epoch 44  35.1% | batch:        33 of        94\t|\tloss: 1474.67\n",
      "Training Epoch 44  36.2% | batch:        34 of        94\t|\tloss: 1717.4\n",
      "Training Epoch 44  37.2% | batch:        35 of        94\t|\tloss: 1177.34\n",
      "Training Epoch 44  38.3% | batch:        36 of        94\t|\tloss: 1210.89\n",
      "Training Epoch 44  39.4% | batch:        37 of        94\t|\tloss: 643.995\n",
      "Training Epoch 44  40.4% | batch:        38 of        94\t|\tloss: 1588.87\n",
      "Training Epoch 44  41.5% | batch:        39 of        94\t|\tloss: 990.249\n",
      "Training Epoch 44  42.6% | batch:        40 of        94\t|\tloss: 1001.36\n",
      "Training Epoch 44  43.6% | batch:        41 of        94\t|\tloss: 1390.55\n",
      "Training Epoch 44  44.7% | batch:        42 of        94\t|\tloss: 2042.55\n",
      "Training Epoch 44  45.7% | batch:        43 of        94\t|\tloss: 1034.45\n",
      "Training Epoch 44  46.8% | batch:        44 of        94\t|\tloss: 1801.2\n",
      "Training Epoch 44  47.9% | batch:        45 of        94\t|\tloss: 1859.13\n",
      "Training Epoch 44  48.9% | batch:        46 of        94\t|\tloss: 1786.41\n",
      "Training Epoch 44  50.0% | batch:        47 of        94\t|\tloss: 777.302\n",
      "Training Epoch 44  51.1% | batch:        48 of        94\t|\tloss: 849.284\n",
      "Training Epoch 44  52.1% | batch:        49 of        94\t|\tloss: 1392.97\n",
      "Training Epoch 44  53.2% | batch:        50 of        94\t|\tloss: 1168.08\n",
      "Training Epoch 44  54.3% | batch:        51 of        94\t|\tloss: 1682.96\n",
      "Training Epoch 44  55.3% | batch:        52 of        94\t|\tloss: 1245.76\n",
      "Training Epoch 44  56.4% | batch:        53 of        94\t|\tloss: 993.668\n",
      "Training Epoch 44  57.4% | batch:        54 of        94\t|\tloss: 1374.64\n",
      "Training Epoch 44  58.5% | batch:        55 of        94\t|\tloss: 1096.51\n",
      "Training Epoch 44  59.6% | batch:        56 of        94\t|\tloss: 1043.3\n",
      "Training Epoch 44  60.6% | batch:        57 of        94\t|\tloss: 1248.57\n",
      "Training Epoch 44  61.7% | batch:        58 of        94\t|\tloss: 1562.05\n",
      "Training Epoch 44  62.8% | batch:        59 of        94\t|\tloss: 2083.03\n",
      "Training Epoch 44  63.8% | batch:        60 of        94\t|\tloss: 1228.32\n",
      "Training Epoch 44  64.9% | batch:        61 of        94\t|\tloss: 995.097\n",
      "Training Epoch 44  66.0% | batch:        62 of        94\t|\tloss: 1287.46\n",
      "Training Epoch 44  67.0% | batch:        63 of        94\t|\tloss: 1050.7\n",
      "Training Epoch 44  68.1% | batch:        64 of        94\t|\tloss: 879.012\n",
      "Training Epoch 44  69.1% | batch:        65 of        94\t|\tloss: 1180.37\n",
      "Training Epoch 44  70.2% | batch:        66 of        94\t|\tloss: 796.953\n",
      "Training Epoch 44  71.3% | batch:        67 of        94\t|\tloss: 808.604\n",
      "Training Epoch 44  72.3% | batch:        68 of        94\t|\tloss: 1516.31\n",
      "Training Epoch 44  73.4% | batch:        69 of        94\t|\tloss: 1819.24\n",
      "Training Epoch 44  74.5% | batch:        70 of        94\t|\tloss: 2280.3\n",
      "Training Epoch 44  75.5% | batch:        71 of        94\t|\tloss: 1100.74\n",
      "Training Epoch 44  76.6% | batch:        72 of        94\t|\tloss: 1127.53\n",
      "Training Epoch 44  77.7% | batch:        73 of        94\t|\tloss: 1189.28\n",
      "Training Epoch 44  78.7% | batch:        74 of        94\t|\tloss: 1010.2\n",
      "Training Epoch 44  79.8% | batch:        75 of        94\t|\tloss: 1205.4\n",
      "Training Epoch 44  80.9% | batch:        76 of        94\t|\tloss: 1788.24\n",
      "Training Epoch 44  81.9% | batch:        77 of        94\t|\tloss: 1293.23\n",
      "Training Epoch 44  83.0% | batch:        78 of        94\t|\tloss: 878.965\n",
      "Training Epoch 44  84.0% | batch:        79 of        94\t|\tloss: 1530.83\n",
      "Training Epoch 44  85.1% | batch:        80 of        94\t|\tloss: 1084.25\n",
      "Training Epoch 44  86.2% | batch:        81 of        94\t|\tloss: 843.655\n",
      "Training Epoch 44  87.2% | batch:        82 of        94\t|\tloss: 1265.09\n",
      "Training Epoch 44  88.3% | batch:        83 of        94\t|\tloss: 3818.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:21,122 | INFO : Epoch 44 Training Summary: epoch: 44.000000 | loss: 1399.219375 | \n",
      "2023-05-04 17:00:21,123 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7810547351837158 seconds\n",
      "\n",
      "2023-05-04 17:00:21,124 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.790565089745955 seconds\n",
      "2023-05-04 17:00:21,124 | INFO : Avg batch train. time: 0.019048564784531437 seconds\n",
      "2023-05-04 17:00:21,125 | INFO : Avg sample train. time: 0.00015024040021362268 seconds\n",
      "2023-05-04 17:00:21,125 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 44  89.4% | batch:        84 of        94\t|\tloss: 1137.89\n",
      "Training Epoch 44  90.4% | batch:        85 of        94\t|\tloss: 1103.04\n",
      "Training Epoch 44  91.5% | batch:        86 of        94\t|\tloss: 1218.05\n",
      "Training Epoch 44  92.6% | batch:        87 of        94\t|\tloss: 1934.27\n",
      "Training Epoch 44  93.6% | batch:        88 of        94\t|\tloss: 1950.08\n",
      "Training Epoch 44  94.7% | batch:        89 of        94\t|\tloss: 1008.57\n",
      "Training Epoch 44  95.7% | batch:        90 of        94\t|\tloss: 1113.02\n",
      "Training Epoch 44  96.8% | batch:        91 of        94\t|\tloss: 1345.78\n",
      "Training Epoch 44  97.9% | batch:        92 of        94\t|\tloss: 1358.03\n",
      "Training Epoch 44  98.9% | batch:        93 of        94\t|\tloss: 920.545\n",
      "\n",
      "Evaluating Epoch 44   0.0% | batch:         0 of        40\t|\tloss: 6561.23\n",
      "Evaluating Epoch 44   2.5% | batch:         1 of        40\t|\tloss: 1034.04\n",
      "Evaluating Epoch 44   5.0% | batch:         2 of        40\t|\tloss: 2827.75\n",
      "Evaluating Epoch 44   7.5% | batch:         3 of        40\t|\tloss: 6752.56\n",
      "Evaluating Epoch 44  10.0% | batch:         4 of        40\t|\tloss: 2449.27\n",
      "Evaluating Epoch 44  12.5% | batch:         5 of        40\t|\tloss: 2854.42\n",
      "Evaluating Epoch 44  15.0% | batch:         6 of        40\t|\tloss: 7194.86\n",
      "Evaluating Epoch 44  17.5% | batch:         7 of        40\t|\tloss: 3205.58\n",
      "Evaluating Epoch 44  20.0% | batch:         8 of        40\t|\tloss: 2908.06\n",
      "Evaluating Epoch 44  22.5% | batch:         9 of        40\t|\tloss: 1825.7\n",
      "Evaluating Epoch 44  25.0% | batch:        10 of        40\t|\tloss: 4776.56\n",
      "Evaluating Epoch 44  27.5% | batch:        11 of        40\t|\tloss: 1264.24\n",
      "Evaluating Epoch 44  30.0% | batch:        12 of        40\t|\tloss: 5102.01\n",
      "Evaluating Epoch 44  32.5% | batch:        13 of        40\t|\tloss: 3105.27\n",
      "Evaluating Epoch 44  35.0% | batch:        14 of        40\t|\tloss: 1896.18\n",
      "Evaluating Epoch 44  37.5% | batch:        15 of        40\t|\tloss: 3224.73\n",
      "Evaluating Epoch 44  40.0% | batch:        16 of        40\t|\tloss: 3288.49\n",
      "Evaluating Epoch 44  42.5% | batch:        17 of        40\t|\tloss: 2748.02\n",
      "Evaluating Epoch 44  45.0% | batch:        18 of        40\t|\tloss: 2611.83\n",
      "Evaluating Epoch 44  47.5% | batch:        19 of        40\t|\tloss: 3624.61\n",
      "Evaluating Epoch 44  50.0% | batch:        20 of        40\t|\tloss: 4739.74\n",
      "Evaluating Epoch 44  52.5% | batch:        21 of        40\t|\tloss: 1154.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:21,577 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45109057426452637 seconds\n",
      "\n",
      "2023-05-04 17:00:21,578 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5376528495066875 seconds\n",
      "2023-05-04 17:00:21,578 | INFO : Avg batch val. time: 0.013441321237667187 seconds\n",
      "2023-05-04 17:00:21,579 | INFO : Avg sample val. time: 0.00010650809221606328 seconds\n",
      "2023-05-04 17:00:21,580 | INFO : Epoch 44 Validation Summary: epoch: 44.000000 | loss: 3650.691515 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 44  55.0% | batch:        22 of        40\t|\tloss: 3998.85\n",
      "Evaluating Epoch 44  57.5% | batch:        23 of        40\t|\tloss: 3131.98\n",
      "Evaluating Epoch 44  60.0% | batch:        24 of        40\t|\tloss: 1666.86\n",
      "Evaluating Epoch 44  62.5% | batch:        25 of        40\t|\tloss: 2752.63\n",
      "Evaluating Epoch 44  65.0% | batch:        26 of        40\t|\tloss: 8716.53\n",
      "Evaluating Epoch 44  67.5% | batch:        27 of        40\t|\tloss: 2347.29\n",
      "Evaluating Epoch 44  70.0% | batch:        28 of        40\t|\tloss: 1857\n",
      "Evaluating Epoch 44  72.5% | batch:        29 of        40\t|\tloss: 7775.56\n",
      "Evaluating Epoch 44  75.0% | batch:        30 of        40\t|\tloss: 1493.91\n",
      "Evaluating Epoch 44  77.5% | batch:        31 of        40\t|\tloss: 1567.03\n",
      "Evaluating Epoch 44  80.0% | batch:        32 of        40\t|\tloss: 7003.2\n",
      "Evaluating Epoch 44  82.5% | batch:        33 of        40\t|\tloss: 5682.15\n",
      "Evaluating Epoch 44  85.0% | batch:        34 of        40\t|\tloss: 1062.69\n",
      "Evaluating Epoch 44  87.5% | batch:        35 of        40\t|\tloss: 4341.09\n",
      "Evaluating Epoch 44  90.0% | batch:        36 of        40\t|\tloss: 6088.95\n",
      "Evaluating Epoch 44  92.5% | batch:        37 of        40\t|\tloss: 2383.96\n",
      "Evaluating Epoch 44  95.0% | batch:        38 of        40\t|\tloss: 3247.7\n",
      "Evaluating Epoch 44  97.5% | batch:        39 of        40\t|\tloss: 8472.56\n",
      "\n",
      "Training Epoch 45   0.0% | batch:         0 of        94\t|\tloss: 1346\n",
      "Training Epoch 45   1.1% | batch:         1 of        94\t|\tloss: 1471.45\n",
      "Training Epoch 45   2.1% | batch:         2 of        94\t|\tloss: 934.873\n",
      "Training Epoch 45   3.2% | batch:         3 of        94\t|\tloss: 911.83\n",
      "Training Epoch 45   4.3% | batch:         4 of        94\t|\tloss: 1152.61\n",
      "Training Epoch 45   5.3% | batch:         5 of        94\t|\tloss: 1249.19\n",
      "Training Epoch 45   6.4% | batch:         6 of        94\t|\tloss: 1173.13\n",
      "Training Epoch 45   7.4% | batch:         7 of        94\t|\tloss: 931.588\n",
      "Training Epoch 45   8.5% | batch:         8 of        94\t|\tloss: 725.199\n",
      "Training Epoch 45   9.6% | batch:         9 of        94\t|\tloss: 1514.8\n",
      "Training Epoch 45  10.6% | batch:        10 of        94\t|\tloss: 986.356\n",
      "Training Epoch 45  11.7% | batch:        11 of        94\t|\tloss: 1303.81\n",
      "Training Epoch 45  12.8% | batch:        12 of        94\t|\tloss: 1107.1\n",
      "Training Epoch 45  13.8% | batch:        13 of        94\t|\tloss: 930.271\n",
      "Training Epoch 45  14.9% | batch:        14 of        94\t|\tloss: 923.6\n",
      "Training Epoch 45  16.0% | batch:        15 of        94\t|\tloss: 1231.96\n",
      "Training Epoch 45  17.0% | batch:        16 of        94\t|\tloss: 987.756\n",
      "Training Epoch 45  18.1% | batch:        17 of        94\t|\tloss: 1543.96\n",
      "Training Epoch 45  19.1% | batch:        18 of        94\t|\tloss: 1135.27\n",
      "Training Epoch 45  20.2% | batch:        19 of        94\t|\tloss: 2000.37\n",
      "Training Epoch 45  21.3% | batch:        20 of        94\t|\tloss: 2181.57\n",
      "Training Epoch 45  22.3% | batch:        21 of        94\t|\tloss: 1122.41\n",
      "Training Epoch 45  23.4% | batch:        22 of        94\t|\tloss: 1276.45\n",
      "Training Epoch 45  24.5% | batch:        23 of        94\t|\tloss: 1407.69\n",
      "Training Epoch 45  25.5% | batch:        24 of        94\t|\tloss: 1611.46\n",
      "Training Epoch 45  26.6% | batch:        25 of        94\t|\tloss: 1136.26\n",
      "Training Epoch 45  27.7% | batch:        26 of        94\t|\tloss: 1221.04\n",
      "Training Epoch 45  28.7% | batch:        27 of        94\t|\tloss: 1618.79\n",
      "Training Epoch 45  29.8% | batch:        28 of        94\t|\tloss: 1100.39\n",
      "Training Epoch 45  30.9% | batch:        29 of        94\t|\tloss: 1504.21\n",
      "Training Epoch 45  31.9% | batch:        30 of        94\t|\tloss: 3068.08\n",
      "Training Epoch 45  33.0% | batch:        31 of        94\t|\tloss: 2289.06\n",
      "Training Epoch 45  34.0% | batch:        32 of        94\t|\tloss: 815.588\n",
      "Training Epoch 45  35.1% | batch:        33 of        94\t|\tloss: 999.087\n",
      "Training Epoch 45  36.2% | batch:        34 of        94\t|\tloss: 1152.42\n",
      "Training Epoch 45  37.2% | batch:        35 of        94\t|\tloss: 1190.55\n",
      "Training Epoch 45  38.3% | batch:        36 of        94\t|\tloss: 1238.27\n",
      "Training Epoch 45  39.4% | batch:        37 of        94\t|\tloss: 3371.71\n",
      "Training Epoch 45  40.4% | batch:        38 of        94\t|\tloss: 1197.9\n",
      "Training Epoch 45  41.5% | batch:        39 of        94\t|\tloss: 1150.88\n",
      "Training Epoch 45  42.6% | batch:        40 of        94\t|\tloss: 1297.5\n",
      "Training Epoch 45  43.6% | batch:        41 of        94\t|\tloss: 827.456\n",
      "Training Epoch 45  44.7% | batch:        42 of        94\t|\tloss: 1060.19\n",
      "Training Epoch 45  45.7% | batch:        43 of        94\t|\tloss: 1211.42\n",
      "Training Epoch 45  46.8% | batch:        44 of        94\t|\tloss: 1447.35\n",
      "Training Epoch 45  47.9% | batch:        45 of        94\t|\tloss: 927.497\n",
      "Training Epoch 45  48.9% | batch:        46 of        94\t|\tloss: 1111.74\n",
      "Training Epoch 45  50.0% | batch:        47 of        94\t|\tloss: 1155.84\n",
      "Training Epoch 45  51.1% | batch:        48 of        94\t|\tloss: 1622.36\n",
      "Training Epoch 45  52.1% | batch:        49 of        94\t|\tloss: 1099.25\n",
      "Training Epoch 45  53.2% | batch:        50 of        94\t|\tloss: 1065.51\n",
      "Training Epoch 45  54.3% | batch:        51 of        94\t|\tloss: 1271.94\n",
      "Training Epoch 45  55.3% | batch:        52 of        94\t|\tloss: 1221.13\n",
      "Training Epoch 45  56.4% | batch:        53 of        94\t|\tloss: 1121.6\n",
      "Training Epoch 45  57.4% | batch:        54 of        94\t|\tloss: 951.667\n",
      "Training Epoch 45  58.5% | batch:        55 of        94\t|\tloss: 1061.37\n",
      "Training Epoch 45  59.6% | batch:        56 of        94\t|\tloss: 1481.37\n",
      "Training Epoch 45  60.6% | batch:        57 of        94\t|\tloss: 896.526\n",
      "Training Epoch 45  61.7% | batch:        58 of        94\t|\tloss: 1881.65\n",
      "Training Epoch 45  62.8% | batch:        59 of        94\t|\tloss: 2178.94\n",
      "Training Epoch 45  63.8% | batch:        60 of        94\t|\tloss: 1372.88\n",
      "Training Epoch 45  64.9% | batch:        61 of        94\t|\tloss: 922.358\n",
      "Training Epoch 45  66.0% | batch:        62 of        94\t|\tloss: 1441.81\n",
      "Training Epoch 45  67.0% | batch:        63 of        94\t|\tloss: 1054.43\n",
      "Training Epoch 45  68.1% | batch:        64 of        94\t|\tloss: 1018.74\n",
      "Training Epoch 45  69.1% | batch:        65 of        94\t|\tloss: 1277.38\n",
      "Training Epoch 45  70.2% | batch:        66 of        94\t|\tloss: 3580.55\n",
      "Training Epoch 45  71.3% | batch:        67 of        94\t|\tloss: 855.014\n",
      "Training Epoch 45  72.3% | batch:        68 of        94\t|\tloss: 889.225\n",
      "Training Epoch 45  73.4% | batch:        69 of        94\t|\tloss: 1146.88\n",
      "Training Epoch 45  74.5% | batch:        70 of        94\t|\tloss: 1242.31\n",
      "Training Epoch 45  75.5% | batch:        71 of        94\t|\tloss: 1877.16\n",
      "Training Epoch 45  76.6% | batch:        72 of        94\t|\tloss: 1090.31\n",
      "Training Epoch 45  77.7% | batch:        73 of        94\t|\tloss: 1551.53\n",
      "Training Epoch 45  78.7% | batch:        74 of        94\t|\tloss: 1796.84\n",
      "Training Epoch 45  79.8% | batch:        75 of        94\t|\tloss: 922.781\n",
      "Training Epoch 45  80.9% | batch:        76 of        94\t|\tloss: 1401.24\n",
      "Training Epoch 45  81.9% | batch:        77 of        94\t|\tloss: 1821.6\n",
      "Training Epoch 45  83.0% | batch:        78 of        94\t|\tloss: 1603.27\n",
      "Training Epoch 45  84.0% | batch:        79 of        94\t|\tloss: 1149.33\n",
      "Training Epoch 45  85.1% | batch:        80 of        94\t|\tloss: 954.628\n",
      "Training Epoch 45  86.2% | batch:        81 of        94\t|\tloss: 2299.53\n",
      "Training Epoch 45  87.2% | batch:        82 of        94\t|\tloss: 1215.4\n",
      "Training Epoch 45  88.3% | batch:        83 of        94\t|\tloss: 1440.14\n",
      "Training Epoch 45  89.4% | batch:        84 of        94\t|\tloss: 1189.38\n",
      "Training Epoch 45  90.4% | batch:        85 of        94\t|\tloss: 859.127\n",
      "Training Epoch 45  91.5% | batch:        86 of        94\t|\tloss: 926.253\n",
      "Training Epoch 45  92.6% | batch:        87 of        94\t|\tloss: 1060.96\n",
      "Training Epoch 45  93.6% | batch:        88 of        94\t|\tloss: 2647.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:23,394 | INFO : Epoch 45 Training Summary: epoch: 45.000000 | loss: 1371.056393 | \n",
      "2023-05-04 17:00:23,395 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7929551601409912 seconds\n",
      "\n",
      "2023-05-04 17:00:23,396 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7906182024214004 seconds\n",
      "2023-05-04 17:00:23,396 | INFO : Avg batch train. time: 0.019049129812993622 seconds\n",
      "2023-05-04 17:00:23,397 | INFO : Avg sample train. time: 0.00015024485672272196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 45  94.7% | batch:        89 of        94\t|\tloss: 1690.63\n",
      "Training Epoch 45  95.7% | batch:        90 of        94\t|\tloss: 1662.83\n",
      "Training Epoch 45  96.8% | batch:        91 of        94\t|\tloss: 1772.65\n",
      "Training Epoch 45  97.9% | batch:        92 of        94\t|\tloss: 2675.52\n",
      "Training Epoch 45  98.9% | batch:        93 of        94\t|\tloss: 1285.13\n",
      "\n",
      "Training Epoch 46   0.0% | batch:         0 of        94\t|\tloss: 776.231\n",
      "Training Epoch 46   1.1% | batch:         1 of        94\t|\tloss: 924.237\n",
      "Training Epoch 46   2.1% | batch:         2 of        94\t|\tloss: 1706.48\n",
      "Training Epoch 46   3.2% | batch:         3 of        94\t|\tloss: 1343.78\n",
      "Training Epoch 46   4.3% | batch:         4 of        94\t|\tloss: 1588.79\n",
      "Training Epoch 46   5.3% | batch:         5 of        94\t|\tloss: 1414.77\n",
      "Training Epoch 46   6.4% | batch:         6 of        94\t|\tloss: 988.871\n",
      "Training Epoch 46   7.4% | batch:         7 of        94\t|\tloss: 1400.69\n",
      "Training Epoch 46   8.5% | batch:         8 of        94\t|\tloss: 2215.17\n",
      "Training Epoch 46   9.6% | batch:         9 of        94\t|\tloss: 896.152\n",
      "Training Epoch 46  10.6% | batch:        10 of        94\t|\tloss: 3047.17\n",
      "Training Epoch 46  11.7% | batch:        11 of        94\t|\tloss: 1326.7\n",
      "Training Epoch 46  12.8% | batch:        12 of        94\t|\tloss: 2139.13\n",
      "Training Epoch 46  13.8% | batch:        13 of        94\t|\tloss: 3851.44\n",
      "Training Epoch 46  14.9% | batch:        14 of        94\t|\tloss: 2705.24\n",
      "Training Epoch 46  16.0% | batch:        15 of        94\t|\tloss: 1209.48\n",
      "Training Epoch 46  17.0% | batch:        16 of        94\t|\tloss: 1119.83\n",
      "Training Epoch 46  18.1% | batch:        17 of        94\t|\tloss: 958.267\n",
      "Training Epoch 46  19.1% | batch:        18 of        94\t|\tloss: 1579.59\n",
      "Training Epoch 46  20.2% | batch:        19 of        94\t|\tloss: 903.531\n",
      "Training Epoch 46  21.3% | batch:        20 of        94\t|\tloss: 1332.02\n",
      "Training Epoch 46  22.3% | batch:        21 of        94\t|\tloss: 1057.51\n",
      "Training Epoch 46  23.4% | batch:        22 of        94\t|\tloss: 1249.93\n",
      "Training Epoch 46  24.5% | batch:        23 of        94\t|\tloss: 813.473\n",
      "Training Epoch 46  25.5% | batch:        24 of        94\t|\tloss: 814.01\n",
      "Training Epoch 46  26.6% | batch:        25 of        94\t|\tloss: 1107\n",
      "Training Epoch 46  27.7% | batch:        26 of        94\t|\tloss: 1162.82\n",
      "Training Epoch 46  28.7% | batch:        27 of        94\t|\tloss: 1195.5\n",
      "Training Epoch 46  29.8% | batch:        28 of        94\t|\tloss: 1085.19\n",
      "Training Epoch 46  30.9% | batch:        29 of        94\t|\tloss: 1234.75\n",
      "Training Epoch 46  31.9% | batch:        30 of        94\t|\tloss: 1354.3\n",
      "Training Epoch 46  33.0% | batch:        31 of        94\t|\tloss: 1080.19\n",
      "Training Epoch 46  34.0% | batch:        32 of        94\t|\tloss: 1834.27\n",
      "Training Epoch 46  35.1% | batch:        33 of        94\t|\tloss: 1380.19\n",
      "Training Epoch 46  36.2% | batch:        34 of        94\t|\tloss: 1247.22\n",
      "Training Epoch 46  37.2% | batch:        35 of        94\t|\tloss: 1155.03\n",
      "Training Epoch 46  38.3% | batch:        36 of        94\t|\tloss: 1161.27\n",
      "Training Epoch 46  39.4% | batch:        37 of        94\t|\tloss: 1056.6\n",
      "Training Epoch 46  40.4% | batch:        38 of        94\t|\tloss: 1693.56\n",
      "Training Epoch 46  41.5% | batch:        39 of        94\t|\tloss: 819.615\n",
      "Training Epoch 46  42.6% | batch:        40 of        94\t|\tloss: 1549.84\n",
      "Training Epoch 46  43.6% | batch:        41 of        94\t|\tloss: 1207.5\n",
      "Training Epoch 46  44.7% | batch:        42 of        94\t|\tloss: 928.573\n",
      "Training Epoch 46  45.7% | batch:        43 of        94\t|\tloss: 1087.94\n",
      "Training Epoch 46  46.8% | batch:        44 of        94\t|\tloss: 2169.07\n",
      "Training Epoch 46  47.9% | batch:        45 of        94\t|\tloss: 878.298\n",
      "Training Epoch 46  48.9% | batch:        46 of        94\t|\tloss: 939.128\n",
      "Training Epoch 46  50.0% | batch:        47 of        94\t|\tloss: 1792.88\n",
      "Training Epoch 46  51.1% | batch:        48 of        94\t|\tloss: 1093.4\n",
      "Training Epoch 46  52.1% | batch:        49 of        94\t|\tloss: 1373.79\n",
      "Training Epoch 46  53.2% | batch:        50 of        94\t|\tloss: 998.129\n",
      "Training Epoch 46  54.3% | batch:        51 of        94\t|\tloss: 1104.48\n",
      "Training Epoch 46  55.3% | batch:        52 of        94\t|\tloss: 1197.61\n",
      "Training Epoch 46  56.4% | batch:        53 of        94\t|\tloss: 1097.92\n",
      "Training Epoch 46  57.4% | batch:        54 of        94\t|\tloss: 1212.73\n",
      "Training Epoch 46  58.5% | batch:        55 of        94\t|\tloss: 1361.75\n",
      "Training Epoch 46  59.6% | batch:        56 of        94\t|\tloss: 1050.81\n",
      "Training Epoch 46  60.6% | batch:        57 of        94\t|\tloss: 1369.29\n",
      "Training Epoch 46  61.7% | batch:        58 of        94\t|\tloss: 1065.64\n",
      "Training Epoch 46  62.8% | batch:        59 of        94\t|\tloss: 1199.26\n",
      "Training Epoch 46  63.8% | batch:        60 of        94\t|\tloss: 979.318\n",
      "Training Epoch 46  64.9% | batch:        61 of        94\t|\tloss: 2707.25\n",
      "Training Epoch 46  66.0% | batch:        62 of        94\t|\tloss: 2943.93\n",
      "Training Epoch 46  67.0% | batch:        63 of        94\t|\tloss: 865.847\n",
      "Training Epoch 46  68.1% | batch:        64 of        94\t|\tloss: 1343.24\n",
      "Training Epoch 46  69.1% | batch:        65 of        94\t|\tloss: 1125.71\n",
      "Training Epoch 46  70.2% | batch:        66 of        94\t|\tloss: 1194.19\n",
      "Training Epoch 46  71.3% | batch:        67 of        94\t|\tloss: 1178.37\n",
      "Training Epoch 46  72.3% | batch:        68 of        94\t|\tloss: 968.732\n",
      "Training Epoch 46  73.4% | batch:        69 of        94\t|\tloss: 1575.89\n",
      "Training Epoch 46  74.5% | batch:        70 of        94\t|\tloss: 1401.45\n",
      "Training Epoch 46  75.5% | batch:        71 of        94\t|\tloss: 1886.05\n",
      "Training Epoch 46  76.6% | batch:        72 of        94\t|\tloss: 887.035\n",
      "Training Epoch 46  77.7% | batch:        73 of        94\t|\tloss: 1442.85\n",
      "Training Epoch 46  78.7% | batch:        74 of        94\t|\tloss: 1342.08\n",
      "Training Epoch 46  79.8% | batch:        75 of        94\t|\tloss: 2527.43\n",
      "Training Epoch 46  80.9% | batch:        76 of        94\t|\tloss: 1855.38\n",
      "Training Epoch 46  81.9% | batch:        77 of        94\t|\tloss: 1218.29\n",
      "Training Epoch 46  83.0% | batch:        78 of        94\t|\tloss: 988.871\n",
      "Training Epoch 46  84.0% | batch:        79 of        94\t|\tloss: 1447.18\n",
      "Training Epoch 46  85.1% | batch:        80 of        94\t|\tloss: 1066.16\n",
      "Training Epoch 46  86.2% | batch:        81 of        94\t|\tloss: 1789.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:25,221 | INFO : Epoch 46 Training Summary: epoch: 46.000000 | loss: 1386.699801 | \n",
      "2023-05-04 17:00:25,223 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8039190769195557 seconds\n",
      "\n",
      "2023-05-04 17:00:25,223 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7909073518670124 seconds\n",
      "2023-05-04 17:00:25,224 | INFO : Avg batch train. time: 0.019052205870925664 seconds\n",
      "2023-05-04 17:00:25,225 | INFO : Avg sample train. time: 0.00015026911829728247 seconds\n",
      "2023-05-04 17:00:25,225 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 46  87.2% | batch:        82 of        94\t|\tloss: 1624.11\n",
      "Training Epoch 46  88.3% | batch:        83 of        94\t|\tloss: 2557.88\n",
      "Training Epoch 46  89.4% | batch:        84 of        94\t|\tloss: 868.474\n",
      "Training Epoch 46  90.4% | batch:        85 of        94\t|\tloss: 1692.75\n",
      "Training Epoch 46  91.5% | batch:        86 of        94\t|\tloss: 1252.07\n",
      "Training Epoch 46  92.6% | batch:        87 of        94\t|\tloss: 1162.08\n",
      "Training Epoch 46  93.6% | batch:        88 of        94\t|\tloss: 1346.2\n",
      "Training Epoch 46  94.7% | batch:        89 of        94\t|\tloss: 1356.87\n",
      "Training Epoch 46  95.7% | batch:        90 of        94\t|\tloss: 749.292\n",
      "Training Epoch 46  96.8% | batch:        91 of        94\t|\tloss: 1566.07\n",
      "Training Epoch 46  97.9% | batch:        92 of        94\t|\tloss: 1143.95\n",
      "Training Epoch 46  98.9% | batch:        93 of        94\t|\tloss: 4134.36\n",
      "\n",
      "Evaluating Epoch 46   0.0% | batch:         0 of        40\t|\tloss: 6682.96\n",
      "Evaluating Epoch 46   2.5% | batch:         1 of        40\t|\tloss: 987.118\n",
      "Evaluating Epoch 46   5.0% | batch:         2 of        40\t|\tloss: 2977.2\n",
      "Evaluating Epoch 46   7.5% | batch:         3 of        40\t|\tloss: 6859.81\n",
      "Evaluating Epoch 46  10.0% | batch:         4 of        40\t|\tloss: 2495.18\n",
      "Evaluating Epoch 46  12.5% | batch:         5 of        40\t|\tloss: 2565.46\n",
      "Evaluating Epoch 46  15.0% | batch:         6 of        40\t|\tloss: 7864.99\n",
      "Evaluating Epoch 46  17.5% | batch:         7 of        40\t|\tloss: 2873.55\n",
      "Evaluating Epoch 46  20.0% | batch:         8 of        40\t|\tloss: 2686.24\n",
      "Evaluating Epoch 46  22.5% | batch:         9 of        40\t|\tloss: 2040.98\n",
      "Evaluating Epoch 46  25.0% | batch:        10 of        40\t|\tloss: 4558.01\n",
      "Evaluating Epoch 46  27.5% | batch:        11 of        40\t|\tloss: 1478.24\n",
      "Evaluating Epoch 46  30.0% | batch:        12 of        40\t|\tloss: 7888.54\n",
      "Evaluating Epoch 46  32.5% | batch:        13 of        40\t|\tloss: 3513.27\n",
      "Evaluating Epoch 46  35.0% | batch:        14 of        40\t|\tloss: 1797.32\n",
      "Evaluating Epoch 46  37.5% | batch:        15 of        40\t|\tloss: 4784.2\n",
      "Evaluating Epoch 46  40.0% | batch:        16 of        40\t|\tloss: 4784.16\n",
      "Evaluating Epoch 46  42.5% | batch:        17 of        40\t|\tloss: 2690.78\n",
      "Evaluating Epoch 46  45.0% | batch:        18 of        40\t|\tloss: 2638.03\n",
      "Evaluating Epoch 46  47.5% | batch:        19 of        40\t|\tloss: 5344.52\n",
      "Evaluating Epoch 46  50.0% | batch:        20 of        40\t|\tloss: 4299.96\n",
      "Evaluating Epoch 46  52.5% | batch:        21 of        40\t|\tloss: 1213.78\n",
      "Evaluating Epoch 46  55.0% | batch:        22 of        40\t|\tloss: 3772.77\n",
      "Evaluating Epoch 46  57.5% | batch:        23 of        40\t|\tloss: 3324.73\n",
      "Evaluating Epoch 46  60.0% | batch:        24 of        40\t|\tloss: 1460.32\n",
      "Evaluating Epoch 46  62.5% | batch:        25 of        40\t|\tloss: 4505\n",
      "Evaluating Epoch 46  65.0% | batch:        26 of        40\t|\tloss: 10203.7\n",
      "Evaluating Epoch 46  67.5% | batch:        27 of        40\t|\tloss: 2321.43\n",
      "Evaluating Epoch 46  70.0% | batch:        28 of        40\t|\tloss: 2320.94\n",
      "Evaluating Epoch 46  72.5% | batch:        29 of        40\t|\tloss: 10006.2\n",
      "Evaluating Epoch 46  75.0% | batch:        30 of        40\t|\tloss: 1552.44\n",
      "Evaluating Epoch 46  77.5% | batch:        31 of        40\t|\tloss: 1425.33\n",
      "Evaluating Epoch 46  80.0% | batch:        32 of        40\t|\tloss: 6972.55\n",
      "Evaluating Epoch 46  82.5% | batch:        33 of        40\t|\tloss: 6117.25\n",
      "Evaluating Epoch 46  85.0% | batch:        34 of        40\t|\tloss: 1213.67\n",
      "Evaluating Epoch 46  87.5% | batch:        35 of        40\t|\tloss: 5590.34\n",
      "Evaluating Epoch 46  90.0% | batch:        36 of        40\t|\tloss: 6943.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:25,679 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.453122615814209 seconds\n",
      "\n",
      "2023-05-04 17:00:25,680 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5371983858846849 seconds\n",
      "2023-05-04 17:00:25,680 | INFO : Avg batch val. time: 0.013429959647117124 seconds\n",
      "2023-05-04 17:00:25,681 | INFO : Avg sample val. time: 0.00010641806376479495 seconds\n",
      "2023-05-04 17:00:25,681 | INFO : Epoch 46 Validation Summary: epoch: 46.000000 | loss: 4115.461297 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 46  92.5% | batch:        37 of        40\t|\tloss: 2270.26\n",
      "Evaluating Epoch 46  95.0% | batch:        38 of        40\t|\tloss: 4601.89\n",
      "Evaluating Epoch 46  97.5% | batch:        39 of        40\t|\tloss: 10691\n",
      "\n",
      "Training Epoch 47   0.0% | batch:         0 of        94\t|\tloss: 1089.65\n",
      "Training Epoch 47   1.1% | batch:         1 of        94\t|\tloss: 1313.94\n",
      "Training Epoch 47   2.1% | batch:         2 of        94\t|\tloss: 893.945\n",
      "Training Epoch 47   3.2% | batch:         3 of        94\t|\tloss: 1319.87\n",
      "Training Epoch 47   4.3% | batch:         4 of        94\t|\tloss: 668.928\n",
      "Training Epoch 47   5.3% | batch:         5 of        94\t|\tloss: 1266.73\n",
      "Training Epoch 47   6.4% | batch:         6 of        94\t|\tloss: 879.454\n",
      "Training Epoch 47   7.4% | batch:         7 of        94\t|\tloss: 2804.44\n",
      "Training Epoch 47   8.5% | batch:         8 of        94\t|\tloss: 1910.06\n",
      "Training Epoch 47   9.6% | batch:         9 of        94\t|\tloss: 1306.19\n",
      "Training Epoch 47  10.6% | batch:        10 of        94\t|\tloss: 987.925\n",
      "Training Epoch 47  11.7% | batch:        11 of        94\t|\tloss: 1000.69\n",
      "Training Epoch 47  12.8% | batch:        12 of        94\t|\tloss: 1394.05\n",
      "Training Epoch 47  13.8% | batch:        13 of        94\t|\tloss: 1084.33\n",
      "Training Epoch 47  14.9% | batch:        14 of        94\t|\tloss: 1861.75\n",
      "Training Epoch 47  16.0% | batch:        15 of        94\t|\tloss: 1393.96\n",
      "Training Epoch 47  17.0% | batch:        16 of        94\t|\tloss: 1458.12\n",
      "Training Epoch 47  18.1% | batch:        17 of        94\t|\tloss: 1404.18\n",
      "Training Epoch 47  19.1% | batch:        18 of        94\t|\tloss: 970.593\n",
      "Training Epoch 47  20.2% | batch:        19 of        94\t|\tloss: 1583.47\n",
      "Training Epoch 47  21.3% | batch:        20 of        94\t|\tloss: 1455.59\n",
      "Training Epoch 47  22.3% | batch:        21 of        94\t|\tloss: 1594.19\n",
      "Training Epoch 47  23.4% | batch:        22 of        94\t|\tloss: 1134.22\n",
      "Training Epoch 47  24.5% | batch:        23 of        94\t|\tloss: 1017.63\n",
      "Training Epoch 47  25.5% | batch:        24 of        94\t|\tloss: 1072.68\n",
      "Training Epoch 47  26.6% | batch:        25 of        94\t|\tloss: 2530.77\n",
      "Training Epoch 47  27.7% | batch:        26 of        94\t|\tloss: 1053.11\n",
      "Training Epoch 47  28.7% | batch:        27 of        94\t|\tloss: 1429.2\n",
      "Training Epoch 47  29.8% | batch:        28 of        94\t|\tloss: 899.91\n",
      "Training Epoch 47  30.9% | batch:        29 of        94\t|\tloss: 777.091\n",
      "Training Epoch 47  31.9% | batch:        30 of        94\t|\tloss: 1505.31\n",
      "Training Epoch 47  33.0% | batch:        31 of        94\t|\tloss: 1082.24\n",
      "Training Epoch 47  34.0% | batch:        32 of        94\t|\tloss: 1437.21\n",
      "Training Epoch 47  35.1% | batch:        33 of        94\t|\tloss: 2523.08\n",
      "Training Epoch 47  36.2% | batch:        34 of        94\t|\tloss: 1194.63\n",
      "Training Epoch 47  37.2% | batch:        35 of        94\t|\tloss: 2345.97\n",
      "Training Epoch 47  38.3% | batch:        36 of        94\t|\tloss: 1448.35\n",
      "Training Epoch 47  39.4% | batch:        37 of        94\t|\tloss: 1261.07\n",
      "Training Epoch 47  40.4% | batch:        38 of        94\t|\tloss: 1175.39\n",
      "Training Epoch 47  41.5% | batch:        39 of        94\t|\tloss: 1200.24\n",
      "Training Epoch 47  42.6% | batch:        40 of        94\t|\tloss: 1408.37\n",
      "Training Epoch 47  43.6% | batch:        41 of        94\t|\tloss: 1920.35\n",
      "Training Epoch 47  44.7% | batch:        42 of        94\t|\tloss: 1357.4\n",
      "Training Epoch 47  45.7% | batch:        43 of        94\t|\tloss: 843.44\n",
      "Training Epoch 47  46.8% | batch:        44 of        94\t|\tloss: 2661.69\n",
      "Training Epoch 47  47.9% | batch:        45 of        94\t|\tloss: 793.162\n",
      "Training Epoch 47  48.9% | batch:        46 of        94\t|\tloss: 871.188\n",
      "Training Epoch 47  50.0% | batch:        47 of        94\t|\tloss: 1157.57\n",
      "Training Epoch 47  51.1% | batch:        48 of        94\t|\tloss: 1115.2\n",
      "Training Epoch 47  52.1% | batch:        49 of        94\t|\tloss: 1210.39\n",
      "Training Epoch 47  53.2% | batch:        50 of        94\t|\tloss: 935.923\n",
      "Training Epoch 47  54.3% | batch:        51 of        94\t|\tloss: 1265.98\n",
      "Training Epoch 47  55.3% | batch:        52 of        94\t|\tloss: 1630.39\n",
      "Training Epoch 47  56.4% | batch:        53 of        94\t|\tloss: 1391.18\n",
      "Training Epoch 47  57.4% | batch:        54 of        94\t|\tloss: 1090.74\n",
      "Training Epoch 47  58.5% | batch:        55 of        94\t|\tloss: 1327.15\n",
      "Training Epoch 47  59.6% | batch:        56 of        94\t|\tloss: 1247.83\n",
      "Training Epoch 47  60.6% | batch:        57 of        94\t|\tloss: 996.883\n",
      "Training Epoch 47  61.7% | batch:        58 of        94\t|\tloss: 1255.57\n",
      "Training Epoch 47  62.8% | batch:        59 of        94\t|\tloss: 1156.26\n",
      "Training Epoch 47  63.8% | batch:        60 of        94\t|\tloss: 934.164\n",
      "Training Epoch 47  64.9% | batch:        61 of        94\t|\tloss: 1282.19\n",
      "Training Epoch 47  66.0% | batch:        62 of        94\t|\tloss: 1204.73\n",
      "Training Epoch 47  67.0% | batch:        63 of        94\t|\tloss: 1051.28\n",
      "Training Epoch 47  68.1% | batch:        64 of        94\t|\tloss: 1461.14\n",
      "Training Epoch 47  69.1% | batch:        65 of        94\t|\tloss: 1168.47\n",
      "Training Epoch 47  70.2% | batch:        66 of        94\t|\tloss: 1058.77\n",
      "Training Epoch 47  71.3% | batch:        67 of        94\t|\tloss: 2298.94\n",
      "Training Epoch 47  72.3% | batch:        68 of        94\t|\tloss: 909.414\n",
      "Training Epoch 47  73.4% | batch:        69 of        94\t|\tloss: 972.912\n",
      "Training Epoch 47  74.5% | batch:        70 of        94\t|\tloss: 1473.74\n",
      "Training Epoch 47  75.5% | batch:        71 of        94\t|\tloss: 1132.5\n",
      "Training Epoch 47  76.6% | batch:        72 of        94\t|\tloss: 894.564\n",
      "Training Epoch 47  77.7% | batch:        73 of        94\t|\tloss: 1721.05\n",
      "Training Epoch 47  78.7% | batch:        74 of        94\t|\tloss: 1170.11\n",
      "Training Epoch 47  79.8% | batch:        75 of        94\t|\tloss: 1143.52\n",
      "Training Epoch 47  80.9% | batch:        76 of        94\t|\tloss: 1116.3\n",
      "Training Epoch 47  81.9% | batch:        77 of        94\t|\tloss: 2672.48\n",
      "Training Epoch 47  83.0% | batch:        78 of        94\t|\tloss: 2006.68\n",
      "Training Epoch 47  84.0% | batch:        79 of        94\t|\tloss: 946.382\n",
      "Training Epoch 47  85.1% | batch:        80 of        94\t|\tloss: 1282.75\n",
      "Training Epoch 47  86.2% | batch:        81 of        94\t|\tloss: 1693.64\n",
      "Training Epoch 47  87.2% | batch:        82 of        94\t|\tloss: 1225.01\n",
      "Training Epoch 47  88.3% | batch:        83 of        94\t|\tloss: 1709.41\n",
      "Training Epoch 47  89.4% | batch:        84 of        94\t|\tloss: 1927.12\n",
      "Training Epoch 47  90.4% | batch:        85 of        94\t|\tloss: 1087.83\n",
      "Training Epoch 47  91.5% | batch:        86 of        94\t|\tloss: 1184.84\n",
      "Training Epoch 47  92.6% | batch:        87 of        94\t|\tloss: 1126.31\n",
      "Training Epoch 47  93.6% | batch:        88 of        94\t|\tloss: 1192.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:27,441 | INFO : Epoch 47 Training Summary: epoch: 47.000000 | loss: 1338.657383 | \n",
      "2023-05-04 17:00:27,442 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7381155490875244 seconds\n",
      "\n",
      "2023-05-04 17:00:27,442 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7897841220206403 seconds\n",
      "2023-05-04 17:00:27,443 | INFO : Avg batch train. time: 0.019040256617240854 seconds\n",
      "2023-05-04 17:00:27,444 | INFO : Avg sample train. time: 0.00015017487179230075 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 47  94.7% | batch:        89 of        94\t|\tloss: 1005.6\n",
      "Training Epoch 47  95.7% | batch:        90 of        94\t|\tloss: 1436.25\n",
      "Training Epoch 47  96.8% | batch:        91 of        94\t|\tloss: 1160.93\n",
      "Training Epoch 47  97.9% | batch:        92 of        94\t|\tloss: 1514.15\n",
      "Training Epoch 47  98.9% | batch:        93 of        94\t|\tloss: 998.886\n",
      "\n",
      "Training Epoch 48   0.0% | batch:         0 of        94\t|\tloss: 860.01\n",
      "Training Epoch 48   1.1% | batch:         1 of        94\t|\tloss: 1216.76\n",
      "Training Epoch 48   2.1% | batch:         2 of        94\t|\tloss: 682.072\n",
      "Training Epoch 48   3.2% | batch:         3 of        94\t|\tloss: 1173.26\n",
      "Training Epoch 48   4.3% | batch:         4 of        94\t|\tloss: 1952.51\n",
      "Training Epoch 48   5.3% | batch:         5 of        94\t|\tloss: 874.596\n",
      "Training Epoch 48   6.4% | batch:         6 of        94\t|\tloss: 1330.76\n",
      "Training Epoch 48   7.4% | batch:         7 of        94\t|\tloss: 1004.44\n",
      "Training Epoch 48   8.5% | batch:         8 of        94\t|\tloss: 1094.65\n",
      "Training Epoch 48   9.6% | batch:         9 of        94\t|\tloss: 1036.46\n",
      "Training Epoch 48  10.6% | batch:        10 of        94\t|\tloss: 2984.58\n",
      "Training Epoch 48  11.7% | batch:        11 of        94\t|\tloss: 2478.2\n",
      "Training Epoch 48  12.8% | batch:        12 of        94\t|\tloss: 924.662\n",
      "Training Epoch 48  13.8% | batch:        13 of        94\t|\tloss: 944.181\n",
      "Training Epoch 48  14.9% | batch:        14 of        94\t|\tloss: 1757.48\n",
      "Training Epoch 48  16.0% | batch:        15 of        94\t|\tloss: 1066.8\n",
      "Training Epoch 48  17.0% | batch:        16 of        94\t|\tloss: 1196.99\n",
      "Training Epoch 48  18.1% | batch:        17 of        94\t|\tloss: 1099.41\n",
      "Training Epoch 48  19.1% | batch:        18 of        94\t|\tloss: 938.702\n",
      "Training Epoch 48  20.2% | batch:        19 of        94\t|\tloss: 1131.25\n",
      "Training Epoch 48  21.3% | batch:        20 of        94\t|\tloss: 1109.04\n",
      "Training Epoch 48  22.3% | batch:        21 of        94\t|\tloss: 1163.78\n",
      "Training Epoch 48  23.4% | batch:        22 of        94\t|\tloss: 1005.88\n",
      "Training Epoch 48  24.5% | batch:        23 of        94\t|\tloss: 1107.66\n",
      "Training Epoch 48  25.5% | batch:        24 of        94\t|\tloss: 1110.44\n",
      "Training Epoch 48  26.6% | batch:        25 of        94\t|\tloss: 1304.03\n",
      "Training Epoch 48  27.7% | batch:        26 of        94\t|\tloss: 2306.15\n",
      "Training Epoch 48  28.7% | batch:        27 of        94\t|\tloss: 1466.59\n",
      "Training Epoch 48  29.8% | batch:        28 of        94\t|\tloss: 1130.58\n",
      "Training Epoch 48  30.9% | batch:        29 of        94\t|\tloss: 1378.05\n",
      "Training Epoch 48  31.9% | batch:        30 of        94\t|\tloss: 1045.58\n",
      "Training Epoch 48  33.0% | batch:        31 of        94\t|\tloss: 2174.97\n",
      "Training Epoch 48  34.0% | batch:        32 of        94\t|\tloss: 1688.93\n",
      "Training Epoch 48  35.1% | batch:        33 of        94\t|\tloss: 1537\n",
      "Training Epoch 48  36.2% | batch:        34 of        94\t|\tloss: 1285.41\n",
      "Training Epoch 48  37.2% | batch:        35 of        94\t|\tloss: 1060.76\n",
      "Training Epoch 48  38.3% | batch:        36 of        94\t|\tloss: 832.856\n",
      "Training Epoch 48  39.4% | batch:        37 of        94\t|\tloss: 1090.76\n",
      "Training Epoch 48  40.4% | batch:        38 of        94\t|\tloss: 980.636\n",
      "Training Epoch 48  41.5% | batch:        39 of        94\t|\tloss: 1252.39\n",
      "Training Epoch 48  42.6% | batch:        40 of        94\t|\tloss: 1107.09\n",
      "Training Epoch 48  43.6% | batch:        41 of        94\t|\tloss: 1190.19\n",
      "Training Epoch 48  44.7% | batch:        42 of        94\t|\tloss: 874.482\n",
      "Training Epoch 48  45.7% | batch:        43 of        94\t|\tloss: 1297.46\n",
      "Training Epoch 48  46.8% | batch:        44 of        94\t|\tloss: 1281.91\n",
      "Training Epoch 48  47.9% | batch:        45 of        94\t|\tloss: 1233.25\n",
      "Training Epoch 48  48.9% | batch:        46 of        94\t|\tloss: 1459\n",
      "Training Epoch 48  50.0% | batch:        47 of        94\t|\tloss: 1230.41\n",
      "Training Epoch 48  51.1% | batch:        48 of        94\t|\tloss: 2828.63\n",
      "Training Epoch 48  52.1% | batch:        49 of        94\t|\tloss: 1308.89\n",
      "Training Epoch 48  53.2% | batch:        50 of        94\t|\tloss: 1349.39\n",
      "Training Epoch 48  54.3% | batch:        51 of        94\t|\tloss: 1182.92\n",
      "Training Epoch 48  55.3% | batch:        52 of        94\t|\tloss: 1312.57\n",
      "Training Epoch 48  56.4% | batch:        53 of        94\t|\tloss: 1100.39\n",
      "Training Epoch 48  57.4% | batch:        54 of        94\t|\tloss: 1238.14\n",
      "Training Epoch 48  58.5% | batch:        55 of        94\t|\tloss: 1475.92\n",
      "Training Epoch 48  59.6% | batch:        56 of        94\t|\tloss: 1124.22\n",
      "Training Epoch 48  60.6% | batch:        57 of        94\t|\tloss: 1117.14\n",
      "Training Epoch 48  61.7% | batch:        58 of        94\t|\tloss: 1095.26\n",
      "Training Epoch 48  62.8% | batch:        59 of        94\t|\tloss: 1249.71\n",
      "Training Epoch 48  63.8% | batch:        60 of        94\t|\tloss: 2433.93\n",
      "Training Epoch 48  64.9% | batch:        61 of        94\t|\tloss: 1653.22\n",
      "Training Epoch 48  66.0% | batch:        62 of        94\t|\tloss: 889.029\n",
      "Training Epoch 48  67.0% | batch:        63 of        94\t|\tloss: 1184.75\n",
      "Training Epoch 48  68.1% | batch:        64 of        94\t|\tloss: 1242.97\n",
      "Training Epoch 48  69.1% | batch:        65 of        94\t|\tloss: 821.69\n",
      "Training Epoch 48  70.2% | batch:        66 of        94\t|\tloss: 1011.69\n",
      "Training Epoch 48  71.3% | batch:        67 of        94\t|\tloss: 1446.22\n",
      "Training Epoch 48  72.3% | batch:        68 of        94\t|\tloss: 1151.84\n",
      "Training Epoch 48  73.4% | batch:        69 of        94\t|\tloss: 1307.64\n",
      "Training Epoch 48  74.5% | batch:        70 of        94\t|\tloss: 1629.47\n",
      "Training Epoch 48  75.5% | batch:        71 of        94\t|\tloss: 1568.43\n",
      "Training Epoch 48  76.6% | batch:        72 of        94\t|\tloss: 2583.68\n",
      "Training Epoch 48  77.7% | batch:        73 of        94\t|\tloss: 1178.32\n",
      "Training Epoch 48  78.7% | batch:        74 of        94\t|\tloss: 1258.16\n",
      "Training Epoch 48  79.8% | batch:        75 of        94\t|\tloss: 1709.97\n",
      "Training Epoch 48  80.9% | batch:        76 of        94\t|\tloss: 1023.24\n",
      "Training Epoch 48  81.9% | batch:        77 of        94\t|\tloss: 2194.17\n",
      "Training Epoch 48  83.0% | batch:        78 of        94\t|\tloss: 1722.67\n",
      "Training Epoch 48  84.0% | batch:        79 of        94\t|\tloss: 1203.21\n",
      "Training Epoch 48  85.1% | batch:        80 of        94\t|\tloss: 1475.39\n",
      "Training Epoch 48  86.2% | batch:        81 of        94\t|\tloss: 1397.6\n",
      "Training Epoch 48  87.2% | batch:        82 of        94\t|\tloss: 1221.55\n",
      "Training Epoch 48  88.3% | batch:        83 of        94\t|\tloss: 2155.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:29,237 | INFO : Epoch 48 Training Summary: epoch: 48.000000 | loss: 1330.628957 | \n",
      "2023-05-04 17:00:29,238 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7728419303894043 seconds\n",
      "\n",
      "2023-05-04 17:00:29,239 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7894311596949894 seconds\n",
      "2023-05-04 17:00:29,239 | INFO : Avg batch train. time: 0.019036501698882866 seconds\n",
      "2023-05-04 17:00:29,240 | INFO : Avg sample train. time: 0.00015014525588982964 seconds\n",
      "2023-05-04 17:00:29,241 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 48  89.4% | batch:        84 of        94\t|\tloss: 1169.46\n",
      "Training Epoch 48  90.4% | batch:        85 of        94\t|\tloss: 1136.36\n",
      "Training Epoch 48  91.5% | batch:        86 of        94\t|\tloss: 997.337\n",
      "Training Epoch 48  92.6% | batch:        87 of        94\t|\tloss: 824.056\n",
      "Training Epoch 48  93.6% | batch:        88 of        94\t|\tloss: 1067.65\n",
      "Training Epoch 48  94.7% | batch:        89 of        94\t|\tloss: 959.04\n",
      "Training Epoch 48  95.7% | batch:        90 of        94\t|\tloss: 1244.53\n",
      "Training Epoch 48  96.8% | batch:        91 of        94\t|\tloss: 1262.79\n",
      "Training Epoch 48  97.9% | batch:        92 of        94\t|\tloss: 1852.23\n",
      "Training Epoch 48  98.9% | batch:        93 of        94\t|\tloss: 733.407\n",
      "\n",
      "Evaluating Epoch 48   0.0% | batch:         0 of        40\t|\tloss: 7171.36\n",
      "Evaluating Epoch 48   2.5% | batch:         1 of        40\t|\tloss: 1154.61\n",
      "Evaluating Epoch 48   5.0% | batch:         2 of        40\t|\tloss: 4570.63\n",
      "Evaluating Epoch 48   7.5% | batch:         3 of        40\t|\tloss: 7601.02\n",
      "Evaluating Epoch 48  10.0% | batch:         4 of        40\t|\tloss: 2418.63\n",
      "Evaluating Epoch 48  12.5% | batch:         5 of        40\t|\tloss: 2906.55\n",
      "Evaluating Epoch 48  15.0% | batch:         6 of        40\t|\tloss: 9052.77\n",
      "Evaluating Epoch 48  17.5% | batch:         7 of        40\t|\tloss: 3246.83\n",
      "Evaluating Epoch 48  20.0% | batch:         8 of        40\t|\tloss: 2759.55\n",
      "Evaluating Epoch 48  22.5% | batch:         9 of        40\t|\tloss: 2284.05\n",
      "Evaluating Epoch 48  25.0% | batch:        10 of        40\t|\tloss: 5248.96\n",
      "Evaluating Epoch 48  27.5% | batch:        11 of        40\t|\tloss: 1479.59\n",
      "Evaluating Epoch 48  30.0% | batch:        12 of        40\t|\tloss: 6676.82\n",
      "Evaluating Epoch 48  32.5% | batch:        13 of        40\t|\tloss: 3616.82\n",
      "Evaluating Epoch 48  35.0% | batch:        14 of        40\t|\tloss: 1961.27\n",
      "Evaluating Epoch 48  37.5% | batch:        15 of        40\t|\tloss: 3710.83\n",
      "Evaluating Epoch 48  40.0% | batch:        16 of        40\t|\tloss: 4789.65\n",
      "Evaluating Epoch 48  42.5% | batch:        17 of        40\t|\tloss: 2879.69\n",
      "Evaluating Epoch 48  45.0% | batch:        18 of        40\t|\tloss: 2199.68\n",
      "Evaluating Epoch 48  47.5% | batch:        19 of        40\t|\tloss: 6024.81\n",
      "Evaluating Epoch 48  50.0% | batch:        20 of        40\t|\tloss: 5436.87\n",
      "Evaluating Epoch 48  52.5% | batch:        21 of        40\t|\tloss: 1108.94\n",
      "Evaluating Epoch 48  55.0% | batch:        22 of        40\t|\tloss: 4454.01\n",
      "Evaluating Epoch 48  57.5% | batch:        23 of        40\t|\tloss: 3270.74\n",
      "Evaluating Epoch 48  60.0% | batch:        24 of        40\t|\tloss: 1751.89\n",
      "Evaluating Epoch 48  62.5% | batch:        25 of        40\t|\tloss: 3963.27\n",
      "Evaluating Epoch 48  65.0% | batch:        26 of        40\t|\tloss: 10648.6\n",
      "Evaluating Epoch 48  67.5% | batch:        27 of        40\t|\tloss: 2703\n",
      "Evaluating Epoch 48  70.0% | batch:        28 of        40\t|\tloss: 2498.29\n",
      "Evaluating Epoch 48  72.5% | batch:        29 of        40\t|\tloss: 9077.08\n",
      "Evaluating Epoch 48  75.0% | batch:        30 of        40\t|\tloss: 1656.61\n",
      "Evaluating Epoch 48  77.5% | batch:        31 of        40\t|\tloss: 2026.19\n",
      "Evaluating Epoch 48  80.0% | batch:        32 of        40\t|\tloss: 9093.73\n",
      "Evaluating Epoch 48  82.5% | batch:        33 of        40\t|\tloss: 6382.29\n",
      "Evaluating Epoch 48  85.0% | batch:        34 of        40\t|\tloss: 1083.2\n",
      "Evaluating Epoch 48  87.5% | batch:        35 of        40\t|\tloss: 6908.39\n",
      "Evaluating Epoch 48  90.0% | batch:        36 of        40\t|\tloss: 6862.2\n",
      "Evaluating Epoch 48  92.5% | batch:        37 of        40\t|\tloss: 2436.31\n",
      "Evaluating Epoch 48  95.0% | batch:        38 of        40\t|\tloss: 4336.46\n",
      "Evaluating Epoch 48  97.5% | batch:        39 of        40\t|\tloss: 11988.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:29,694 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4524998664855957 seconds\n",
      "\n",
      "2023-05-04 17:00:29,695 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5367454526258663 seconds\n",
      "2023-05-04 17:00:29,695 | INFO : Avg batch val. time: 0.013418636315646656 seconds\n",
      "2023-05-04 17:00:29,696 | INFO : Avg sample val. time: 0.00010632833847580552 seconds\n",
      "2023-05-04 17:00:29,697 | INFO : Epoch 48 Validation Summary: epoch: 48.000000 | loss: 4379.011131 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 49   0.0% | batch:         0 of        94\t|\tloss: 3022.62\n",
      "Training Epoch 49   1.1% | batch:         1 of        94\t|\tloss: 1055.71\n",
      "Training Epoch 49   2.1% | batch:         2 of        94\t|\tloss: 856.083\n",
      "Training Epoch 49   3.2% | batch:         3 of        94\t|\tloss: 928.779\n",
      "Training Epoch 49   4.3% | batch:         4 of        94\t|\tloss: 1189.49\n",
      "Training Epoch 49   5.3% | batch:         5 of        94\t|\tloss: 1007.55\n",
      "Training Epoch 49   6.4% | batch:         6 of        94\t|\tloss: 1596.82\n",
      "Training Epoch 49   7.4% | batch:         7 of        94\t|\tloss: 3472.1\n",
      "Training Epoch 49   8.5% | batch:         8 of        94\t|\tloss: 1268.37\n",
      "Training Epoch 49   9.6% | batch:         9 of        94\t|\tloss: 752.333\n",
      "Training Epoch 49  10.6% | batch:        10 of        94\t|\tloss: 795.836\n",
      "Training Epoch 49  11.7% | batch:        11 of        94\t|\tloss: 1432.37\n",
      "Training Epoch 49  12.8% | batch:        12 of        94\t|\tloss: 1536.27\n",
      "Training Epoch 49  13.8% | batch:        13 of        94\t|\tloss: 877.214\n",
      "Training Epoch 49  14.9% | batch:        14 of        94\t|\tloss: 1152.34\n",
      "Training Epoch 49  16.0% | batch:        15 of        94\t|\tloss: 977.522\n",
      "Training Epoch 49  17.0% | batch:        16 of        94\t|\tloss: 1503.45\n",
      "Training Epoch 49  18.1% | batch:        17 of        94\t|\tloss: 944.04\n",
      "Training Epoch 49  19.1% | batch:        18 of        94\t|\tloss: 2378\n",
      "Training Epoch 49  20.2% | batch:        19 of        94\t|\tloss: 1188.36\n",
      "Training Epoch 49  21.3% | batch:        20 of        94\t|\tloss: 1341.95\n",
      "Training Epoch 49  22.3% | batch:        21 of        94\t|\tloss: 1452.23\n",
      "Training Epoch 49  23.4% | batch:        22 of        94\t|\tloss: 699.14\n",
      "Training Epoch 49  24.5% | batch:        23 of        94\t|\tloss: 815.037\n",
      "Training Epoch 49  25.5% | batch:        24 of        94\t|\tloss: 1133.7\n",
      "Training Epoch 49  26.6% | batch:        25 of        94\t|\tloss: 1524.87\n",
      "Training Epoch 49  27.7% | batch:        26 of        94\t|\tloss: 1503.97\n",
      "Training Epoch 49  28.7% | batch:        27 of        94\t|\tloss: 1458.91\n",
      "Training Epoch 49  29.8% | batch:        28 of        94\t|\tloss: 2555.8\n",
      "Training Epoch 49  30.9% | batch:        29 of        94\t|\tloss: 1117.64\n",
      "Training Epoch 49  31.9% | batch:        30 of        94\t|\tloss: 1005.83\n",
      "Training Epoch 49  33.0% | batch:        31 of        94\t|\tloss: 1140.49\n",
      "Training Epoch 49  34.0% | batch:        32 of        94\t|\tloss: 1503.19\n",
      "Training Epoch 49  35.1% | batch:        33 of        94\t|\tloss: 1729.07\n",
      "Training Epoch 49  36.2% | batch:        34 of        94\t|\tloss: 1375.92\n",
      "Training Epoch 49  37.2% | batch:        35 of        94\t|\tloss: 952.116\n",
      "Training Epoch 49  38.3% | batch:        36 of        94\t|\tloss: 2635.69\n",
      "Training Epoch 49  39.4% | batch:        37 of        94\t|\tloss: 989.647\n",
      "Training Epoch 49  40.4% | batch:        38 of        94\t|\tloss: 1120.15\n",
      "Training Epoch 49  41.5% | batch:        39 of        94\t|\tloss: 1940.61\n",
      "Training Epoch 49  42.6% | batch:        40 of        94\t|\tloss: 965.407\n",
      "Training Epoch 49  43.6% | batch:        41 of        94\t|\tloss: 1690\n",
      "Training Epoch 49  44.7% | batch:        42 of        94\t|\tloss: 1826.29\n",
      "Training Epoch 49  45.7% | batch:        43 of        94\t|\tloss: 732.482\n",
      "Training Epoch 49  46.8% | batch:        44 of        94\t|\tloss: 1587.23\n",
      "Training Epoch 49  47.9% | batch:        45 of        94\t|\tloss: 1551.77\n",
      "Training Epoch 49  48.9% | batch:        46 of        94\t|\tloss: 969.24\n",
      "Training Epoch 49  50.0% | batch:        47 of        94\t|\tloss: 1102.4\n",
      "Training Epoch 49  51.1% | batch:        48 of        94\t|\tloss: 1393.59\n",
      "Training Epoch 49  52.1% | batch:        49 of        94\t|\tloss: 1365.76\n",
      "Training Epoch 49  53.2% | batch:        50 of        94\t|\tloss: 1875.97\n",
      "Training Epoch 49  54.3% | batch:        51 of        94\t|\tloss: 1038.68\n",
      "Training Epoch 49  55.3% | batch:        52 of        94\t|\tloss: 2292.46\n",
      "Training Epoch 49  56.4% | batch:        53 of        94\t|\tloss: 1178.39\n",
      "Training Epoch 49  57.4% | batch:        54 of        94\t|\tloss: 1047.9\n",
      "Training Epoch 49  58.5% | batch:        55 of        94\t|\tloss: 1642.82\n",
      "Training Epoch 49  59.6% | batch:        56 of        94\t|\tloss: 1731.57\n",
      "Training Epoch 49  60.6% | batch:        57 of        94\t|\tloss: 1070.68\n",
      "Training Epoch 49  61.7% | batch:        58 of        94\t|\tloss: 1124.28\n",
      "Training Epoch 49  62.8% | batch:        59 of        94\t|\tloss: 1174.09\n",
      "Training Epoch 49  63.8% | batch:        60 of        94\t|\tloss: 1290.45\n",
      "Training Epoch 49  64.9% | batch:        61 of        94\t|\tloss: 1477.25\n",
      "Training Epoch 49  66.0% | batch:        62 of        94\t|\tloss: 1343.34\n",
      "Training Epoch 49  67.0% | batch:        63 of        94\t|\tloss: 1082\n",
      "Training Epoch 49  68.1% | batch:        64 of        94\t|\tloss: 1593.19\n",
      "Training Epoch 49  69.1% | batch:        65 of        94\t|\tloss: 1337.03\n",
      "Training Epoch 49  70.2% | batch:        66 of        94\t|\tloss: 1607.66\n",
      "Training Epoch 49  71.3% | batch:        67 of        94\t|\tloss: 1911.81\n",
      "Training Epoch 49  72.3% | batch:        68 of        94\t|\tloss: 1239.76\n",
      "Training Epoch 49  73.4% | batch:        69 of        94\t|\tloss: 1378.74\n",
      "Training Epoch 49  74.5% | batch:        70 of        94\t|\tloss: 1078.2\n",
      "Training Epoch 49  75.5% | batch:        71 of        94\t|\tloss: 1036.28\n",
      "Training Epoch 49  76.6% | batch:        72 of        94\t|\tloss: 1143.37\n",
      "Training Epoch 49  77.7% | batch:        73 of        94\t|\tloss: 1200.54\n",
      "Training Epoch 49  78.7% | batch:        74 of        94\t|\tloss: 1369.27\n",
      "Training Epoch 49  79.8% | batch:        75 of        94\t|\tloss: 1195.58\n",
      "Training Epoch 49  80.9% | batch:        76 of        94\t|\tloss: 1471.64\n",
      "Training Epoch 49  81.9% | batch:        77 of        94\t|\tloss: 1006.28\n",
      "Training Epoch 49  83.0% | batch:        78 of        94\t|\tloss: 2171.24\n",
      "Training Epoch 49  84.0% | batch:        79 of        94\t|\tloss: 1764.86\n",
      "Training Epoch 49  85.1% | batch:        80 of        94\t|\tloss: 982.09\n",
      "Training Epoch 49  86.2% | batch:        81 of        94\t|\tloss: 1559.18\n",
      "Training Epoch 49  87.2% | batch:        82 of        94\t|\tloss: 1214.04\n",
      "Training Epoch 49  88.3% | batch:        83 of        94\t|\tloss: 1447.61\n",
      "Training Epoch 49  89.4% | batch:        84 of        94\t|\tloss: 1034.46\n",
      "Training Epoch 49  90.4% | batch:        85 of        94\t|\tloss: 1512.63\n",
      "Training Epoch 49  91.5% | batch:        86 of        94\t|\tloss: 2396.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:31,500 | INFO : Epoch 49 Training Summary: epoch: 49.000000 | loss: 1395.817274 | \n",
      "2023-05-04 17:00:31,501 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7824759483337402 seconds\n",
      "\n",
      "2023-05-04 17:00:31,502 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7892892166059844 seconds\n",
      "2023-05-04 17:00:31,503 | INFO : Avg batch train. time: 0.01903499166602111 seconds\n",
      "2023-05-04 17:00:31,503 | INFO : Avg sample train. time: 0.00015013334591424605 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 49  92.6% | batch:        87 of        94\t|\tloss: 1792.79\n",
      "Training Epoch 49  93.6% | batch:        88 of        94\t|\tloss: 2283.95\n",
      "Training Epoch 49  94.7% | batch:        89 of        94\t|\tloss: 1060.3\n",
      "Training Epoch 49  95.7% | batch:        90 of        94\t|\tloss: 1423.57\n",
      "Training Epoch 49  96.8% | batch:        91 of        94\t|\tloss: 799.234\n",
      "Training Epoch 49  97.9% | batch:        92 of        94\t|\tloss: 1347.14\n",
      "Training Epoch 49  98.9% | batch:        93 of        94\t|\tloss: 1090.35\n",
      "\n",
      "Training Epoch 50   0.0% | batch:         0 of        94\t|\tloss: 1074.64\n",
      "Training Epoch 50   1.1% | batch:         1 of        94\t|\tloss: 925.764\n",
      "Training Epoch 50   2.1% | batch:         2 of        94\t|\tloss: 1084\n",
      "Training Epoch 50   3.2% | batch:         3 of        94\t|\tloss: 1279.33\n",
      "Training Epoch 50   4.3% | batch:         4 of        94\t|\tloss: 1285.3\n",
      "Training Epoch 50   5.3% | batch:         5 of        94\t|\tloss: 1399.92\n",
      "Training Epoch 50   6.4% | batch:         6 of        94\t|\tloss: 1147.38\n",
      "Training Epoch 50   7.4% | batch:         7 of        94\t|\tloss: 1017.13\n",
      "Training Epoch 50   8.5% | batch:         8 of        94\t|\tloss: 1839.83\n",
      "Training Epoch 50   9.6% | batch:         9 of        94\t|\tloss: 1269.32\n",
      "Training Epoch 50  10.6% | batch:        10 of        94\t|\tloss: 1003.78\n",
      "Training Epoch 50  11.7% | batch:        11 of        94\t|\tloss: 1128.99\n",
      "Training Epoch 50  12.8% | batch:        12 of        94\t|\tloss: 1251.8\n",
      "Training Epoch 50  13.8% | batch:        13 of        94\t|\tloss: 815.748\n",
      "Training Epoch 50  14.9% | batch:        14 of        94\t|\tloss: 697.302\n",
      "Training Epoch 50  16.0% | batch:        15 of        94\t|\tloss: 855.256\n",
      "Training Epoch 50  17.0% | batch:        16 of        94\t|\tloss: 1282.79\n",
      "Training Epoch 50  18.1% | batch:        17 of        94\t|\tloss: 1275.13\n",
      "Training Epoch 50  19.1% | batch:        18 of        94\t|\tloss: 800.184\n",
      "Training Epoch 50  20.2% | batch:        19 of        94\t|\tloss: 902.934\n",
      "Training Epoch 50  21.3% | batch:        20 of        94\t|\tloss: 978.402\n",
      "Training Epoch 50  22.3% | batch:        21 of        94\t|\tloss: 1341.01\n",
      "Training Epoch 50  23.4% | batch:        22 of        94\t|\tloss: 829.269\n",
      "Training Epoch 50  24.5% | batch:        23 of        94\t|\tloss: 1371.17\n",
      "Training Epoch 50  25.5% | batch:        24 of        94\t|\tloss: 2508.11\n",
      "Training Epoch 50  26.6% | batch:        25 of        94\t|\tloss: 1082.4\n",
      "Training Epoch 50  27.7% | batch:        26 of        94\t|\tloss: 1903.21\n",
      "Training Epoch 50  28.7% | batch:        27 of        94\t|\tloss: 1178.23\n",
      "Training Epoch 50  29.8% | batch:        28 of        94\t|\tloss: 2092.55\n",
      "Training Epoch 50  30.9% | batch:        29 of        94\t|\tloss: 1054.87\n",
      "Training Epoch 50  31.9% | batch:        30 of        94\t|\tloss: 1493.55\n",
      "Training Epoch 50  33.0% | batch:        31 of        94\t|\tloss: 1219.94\n",
      "Training Epoch 50  34.0% | batch:        32 of        94\t|\tloss: 1745.13\n",
      "Training Epoch 50  35.1% | batch:        33 of        94\t|\tloss: 994.729\n",
      "Training Epoch 50  36.2% | batch:        34 of        94\t|\tloss: 2034.91\n",
      "Training Epoch 50  37.2% | batch:        35 of        94\t|\tloss: 1094.28\n",
      "Training Epoch 50  38.3% | batch:        36 of        94\t|\tloss: 1022.01\n",
      "Training Epoch 50  39.4% | batch:        37 of        94\t|\tloss: 1086.03\n",
      "Training Epoch 50  40.4% | batch:        38 of        94\t|\tloss: 2996.11\n",
      "Training Epoch 50  41.5% | batch:        39 of        94\t|\tloss: 1009.51\n",
      "Training Epoch 50  42.6% | batch:        40 of        94\t|\tloss: 1335.26\n",
      "Training Epoch 50  43.6% | batch:        41 of        94\t|\tloss: 1281.19\n",
      "Training Epoch 50  44.7% | batch:        42 of        94\t|\tloss: 1157.02\n",
      "Training Epoch 50  45.7% | batch:        43 of        94\t|\tloss: 942.169\n",
      "Training Epoch 50  46.8% | batch:        44 of        94\t|\tloss: 2878.78\n",
      "Training Epoch 50  47.9% | batch:        45 of        94\t|\tloss: 991.801\n",
      "Training Epoch 50  48.9% | batch:        46 of        94\t|\tloss: 1330.21\n",
      "Training Epoch 50  50.0% | batch:        47 of        94\t|\tloss: 1195.66\n",
      "Training Epoch 50  51.1% | batch:        48 of        94\t|\tloss: 1090.96\n",
      "Training Epoch 50  52.1% | batch:        49 of        94\t|\tloss: 1585.41\n",
      "Training Epoch 50  53.2% | batch:        50 of        94\t|\tloss: 1558.42\n",
      "Training Epoch 50  54.3% | batch:        51 of        94\t|\tloss: 1236.18\n",
      "Training Epoch 50  55.3% | batch:        52 of        94\t|\tloss: 1115.51\n",
      "Training Epoch 50  56.4% | batch:        53 of        94\t|\tloss: 1541.2\n",
      "Training Epoch 50  57.4% | batch:        54 of        94\t|\tloss: 1576.27\n",
      "Training Epoch 50  58.5% | batch:        55 of        94\t|\tloss: 1289.77\n",
      "Training Epoch 50  59.6% | batch:        56 of        94\t|\tloss: 904.5\n",
      "Training Epoch 50  60.6% | batch:        57 of        94\t|\tloss: 999.513\n",
      "Training Epoch 50  61.7% | batch:        58 of        94\t|\tloss: 1166.91\n",
      "Training Epoch 50  62.8% | batch:        59 of        94\t|\tloss: 2492.4\n",
      "Training Epoch 50  63.8% | batch:        60 of        94\t|\tloss: 940.215\n",
      "Training Epoch 50  64.9% | batch:        61 of        94\t|\tloss: 1663.54\n",
      "Training Epoch 50  66.0% | batch:        62 of        94\t|\tloss: 1302.2\n",
      "Training Epoch 50  67.0% | batch:        63 of        94\t|\tloss: 1305.44\n",
      "Training Epoch 50  68.1% | batch:        64 of        94\t|\tloss: 1494.95\n",
      "Training Epoch 50  69.1% | batch:        65 of        94\t|\tloss: 1245.71\n",
      "Training Epoch 50  70.2% | batch:        66 of        94\t|\tloss: 981.969\n",
      "Training Epoch 50  71.3% | batch:        67 of        94\t|\tloss: 710.149\n",
      "Training Epoch 50  72.3% | batch:        68 of        94\t|\tloss: 3564.02\n",
      "Training Epoch 50  73.4% | batch:        69 of        94\t|\tloss: 1129.12\n",
      "Training Epoch 50  74.5% | batch:        70 of        94\t|\tloss: 1030.89\n",
      "Training Epoch 50  75.5% | batch:        71 of        94\t|\tloss: 1115.03\n",
      "Training Epoch 50  76.6% | batch:        72 of        94\t|\tloss: 1127.7\n",
      "Training Epoch 50  77.7% | batch:        73 of        94\t|\tloss: 1122.96\n",
      "Training Epoch 50  78.7% | batch:        74 of        94\t|\tloss: 1527.27\n",
      "Training Epoch 50  79.8% | batch:        75 of        94\t|\tloss: 1641.76\n",
      "Training Epoch 50  80.9% | batch:        76 of        94\t|\tloss: 1213.79\n",
      "Training Epoch 50  81.9% | batch:        77 of        94\t|\tloss: 1488.33\n",
      "Training Epoch 50  83.0% | batch:        78 of        94\t|\tloss: 1252.93\n",
      "Training Epoch 50  84.0% | batch:        79 of        94\t|\tloss: 1526.23\n",
      "Training Epoch 50  85.1% | batch:        80 of        94\t|\tloss: 1029.05\n",
      "Training Epoch 50  86.2% | batch:        81 of        94\t|\tloss: 872.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:33,294 | INFO : Epoch 50 Training Summary: epoch: 50.000000 | loss: 1332.544898 | \n",
      "2023-05-04 17:00:33,294 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7694642543792725 seconds\n",
      "\n",
      "2023-05-04 17:00:33,295 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7888927173614502 seconds\n",
      "2023-05-04 17:00:33,296 | INFO : Avg batch train. time: 0.019030773588951597 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 50  87.2% | batch:        82 of        94\t|\tloss: 1592.39\n",
      "Training Epoch 50  88.3% | batch:        83 of        94\t|\tloss: 1040.03\n",
      "Training Epoch 50  89.4% | batch:        84 of        94\t|\tloss: 2145.93\n",
      "Training Epoch 50  90.4% | batch:        85 of        94\t|\tloss: 1364.74\n",
      "Training Epoch 50  91.5% | batch:        86 of        94\t|\tloss: 1936.84\n",
      "Training Epoch 50  92.6% | batch:        87 of        94\t|\tloss: 1285.2\n",
      "Training Epoch 50  93.6% | batch:        88 of        94\t|\tloss: 1273.17\n",
      "Training Epoch 50  94.7% | batch:        89 of        94\t|\tloss: 905.399\n",
      "Training Epoch 50  95.7% | batch:        90 of        94\t|\tloss: 1632.46\n",
      "Training Epoch 50  96.8% | batch:        91 of        94\t|\tloss: 902.886\n",
      "Training Epoch 50  97.9% | batch:        92 of        94\t|\tloss: 1602.71\n",
      "Training Epoch 50  98.9% | batch:        93 of        94\t|\tloss: 585.492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:33,297 | INFO : Avg sample train. time: 0.0001501000769727681 seconds\n",
      "2023-05-04 17:00:33,298 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 50   0.0% | batch:         0 of        40\t|\tloss: 6790.37\n",
      "Evaluating Epoch 50   2.5% | batch:         1 of        40\t|\tloss: 1324.65\n",
      "Evaluating Epoch 50   5.0% | batch:         2 of        40\t|\tloss: 3492.05\n",
      "Evaluating Epoch 50   7.5% | batch:         3 of        40\t|\tloss: 7314.7\n",
      "Evaluating Epoch 50  10.0% | batch:         4 of        40\t|\tloss: 2311.47\n",
      "Evaluating Epoch 50  12.5% | batch:         5 of        40\t|\tloss: 2211.63\n",
      "Evaluating Epoch 50  15.0% | batch:         6 of        40\t|\tloss: 8934.32\n",
      "Evaluating Epoch 50  17.5% | batch:         7 of        40\t|\tloss: 3512.06\n",
      "Evaluating Epoch 50  20.0% | batch:         8 of        40\t|\tloss: 3162.98\n",
      "Evaluating Epoch 50  22.5% | batch:         9 of        40\t|\tloss: 2297.35\n",
      "Evaluating Epoch 50  25.0% | batch:        10 of        40\t|\tloss: 4867.91\n",
      "Evaluating Epoch 50  27.5% | batch:        11 of        40\t|\tloss: 1477.32\n",
      "Evaluating Epoch 50  30.0% | batch:        12 of        40\t|\tloss: 6777.62\n",
      "Evaluating Epoch 50  32.5% | batch:        13 of        40\t|\tloss: 3370.41\n",
      "Evaluating Epoch 50  35.0% | batch:        14 of        40\t|\tloss: 1997.67\n",
      "Evaluating Epoch 50  37.5% | batch:        15 of        40\t|\tloss: 3601.29\n",
      "Evaluating Epoch 50  40.0% | batch:        16 of        40\t|\tloss: 4894.23\n",
      "Evaluating Epoch 50  42.5% | batch:        17 of        40\t|\tloss: 2875.79\n",
      "Evaluating Epoch 50  45.0% | batch:        18 of        40\t|\tloss: 2545.7\n",
      "Evaluating Epoch 50  47.5% | batch:        19 of        40\t|\tloss: 6021.68\n",
      "Evaluating Epoch 50  50.0% | batch:        20 of        40\t|\tloss: 5811.1\n",
      "Evaluating Epoch 50  52.5% | batch:        21 of        40\t|\tloss: 1298.84\n",
      "Evaluating Epoch 50  55.0% | batch:        22 of        40\t|\tloss: 3984.9\n",
      "Evaluating Epoch 50  57.5% | batch:        23 of        40\t|\tloss: 2953.18\n",
      "Evaluating Epoch 50  60.0% | batch:        24 of        40\t|\tloss: 1626.17\n",
      "Evaluating Epoch 50  62.5% | batch:        25 of        40\t|\tloss: 3789.57\n",
      "Evaluating Epoch 50  65.0% | batch:        26 of        40\t|\tloss: 10132.1\n",
      "Evaluating Epoch 50  67.5% | batch:        27 of        40\t|\tloss: 2801.43\n",
      "Evaluating Epoch 50  70.0% | batch:        28 of        40\t|\tloss: 2017.49\n",
      "Evaluating Epoch 50  72.5% | batch:        29 of        40\t|\tloss: 9057.76\n",
      "Evaluating Epoch 50  75.0% | batch:        30 of        40\t|\tloss: 1689.39\n",
      "Evaluating Epoch 50  77.5% | batch:        31 of        40\t|\tloss: 1968.52\n",
      "Evaluating Epoch 50  80.0% | batch:        32 of        40\t|\tloss: 8577.17\n",
      "Evaluating Epoch 50  82.5% | batch:        33 of        40\t|\tloss: 6143.14\n",
      "Evaluating Epoch 50  85.0% | batch:        34 of        40\t|\tloss: 1396.45\n",
      "Evaluating Epoch 50  87.5% | batch:        35 of        40\t|\tloss: 5693.8\n",
      "Evaluating Epoch 50  90.0% | batch:        36 of        40\t|\tloss: 6790.27\n",
      "Evaluating Epoch 50  92.5% | batch:        37 of        40\t|\tloss: 2565.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:33,737 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4381847381591797 seconds\n",
      "\n",
      "2023-05-04 17:00:33,737 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5362211935063625 seconds\n",
      "2023-05-04 17:00:33,738 | INFO : Avg batch val. time: 0.013405529837659063 seconds\n",
      "2023-05-04 17:00:33,739 | INFO : Avg sample val. time: 0.00010622448365815424 seconds\n",
      "2023-05-04 17:00:33,739 | INFO : Epoch 50 Validation Summary: epoch: 50.000000 | loss: 4239.482614 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 50  95.0% | batch:        38 of        40\t|\tloss: 3862.1\n",
      "Evaluating Epoch 50  97.5% | batch:        39 of        40\t|\tloss: 12009.7\n",
      "\n",
      "Training Epoch 51   0.0% | batch:         0 of        94\t|\tloss: 982.866\n",
      "Training Epoch 51   1.1% | batch:         1 of        94\t|\tloss: 1565.03\n",
      "Training Epoch 51   2.1% | batch:         2 of        94\t|\tloss: 916.852\n",
      "Training Epoch 51   3.2% | batch:         3 of        94\t|\tloss: 1360.32\n",
      "Training Epoch 51   4.3% | batch:         4 of        94\t|\tloss: 1158.89\n",
      "Training Epoch 51   5.3% | batch:         5 of        94\t|\tloss: 1634.03\n",
      "Training Epoch 51   6.4% | batch:         6 of        94\t|\tloss: 3119.69\n",
      "Training Epoch 51   7.4% | batch:         7 of        94\t|\tloss: 1537.43\n",
      "Training Epoch 51   8.5% | batch:         8 of        94\t|\tloss: 916.489\n",
      "Training Epoch 51   9.6% | batch:         9 of        94\t|\tloss: 1039.85\n",
      "Training Epoch 51  10.6% | batch:        10 of        94\t|\tloss: 1078.53\n",
      "Training Epoch 51  11.7% | batch:        11 of        94\t|\tloss: 1553.8\n",
      "Training Epoch 51  12.8% | batch:        12 of        94\t|\tloss: 2644.02\n",
      "Training Epoch 51  13.8% | batch:        13 of        94\t|\tloss: 1121.75\n",
      "Training Epoch 51  14.9% | batch:        14 of        94\t|\tloss: 1314.21\n",
      "Training Epoch 51  16.0% | batch:        15 of        94\t|\tloss: 1734.55\n",
      "Training Epoch 51  17.0% | batch:        16 of        94\t|\tloss: 1158.71\n",
      "Training Epoch 51  18.1% | batch:        17 of        94\t|\tloss: 1167.52\n",
      "Training Epoch 51  19.1% | batch:        18 of        94\t|\tloss: 920.325\n",
      "Training Epoch 51  20.2% | batch:        19 of        94\t|\tloss: 1178.26\n",
      "Training Epoch 51  21.3% | batch:        20 of        94\t|\tloss: 1000.92\n",
      "Training Epoch 51  22.3% | batch:        21 of        94\t|\tloss: 778.509\n",
      "Training Epoch 51  23.4% | batch:        22 of        94\t|\tloss: 1014.82\n",
      "Training Epoch 51  24.5% | batch:        23 of        94\t|\tloss: 661.564\n",
      "Training Epoch 51  25.5% | batch:        24 of        94\t|\tloss: 830.182\n",
      "Training Epoch 51  26.6% | batch:        25 of        94\t|\tloss: 1093.23\n",
      "Training Epoch 51  27.7% | batch:        26 of        94\t|\tloss: 883.01\n",
      "Training Epoch 51  28.7% | batch:        27 of        94\t|\tloss: 2316.16\n",
      "Training Epoch 51  29.8% | batch:        28 of        94\t|\tloss: 994.101\n",
      "Training Epoch 51  30.9% | batch:        29 of        94\t|\tloss: 754.111\n",
      "Training Epoch 51  31.9% | batch:        30 of        94\t|\tloss: 1396.96\n",
      "Training Epoch 51  33.0% | batch:        31 of        94\t|\tloss: 1105.5\n",
      "Training Epoch 51  34.0% | batch:        32 of        94\t|\tloss: 1644.24\n",
      "Training Epoch 51  35.1% | batch:        33 of        94\t|\tloss: 841.238\n",
      "Training Epoch 51  36.2% | batch:        34 of        94\t|\tloss: 905.208\n",
      "Training Epoch 51  37.2% | batch:        35 of        94\t|\tloss: 1779.41\n",
      "Training Epoch 51  38.3% | batch:        36 of        94\t|\tloss: 2351.19\n",
      "Training Epoch 51  39.4% | batch:        37 of        94\t|\tloss: 907.917\n",
      "Training Epoch 51  40.4% | batch:        38 of        94\t|\tloss: 857.488\n",
      "Training Epoch 51  41.5% | batch:        39 of        94\t|\tloss: 2363.4\n",
      "Training Epoch 51  42.6% | batch:        40 of        94\t|\tloss: 1034.73\n",
      "Training Epoch 51  43.6% | batch:        41 of        94\t|\tloss: 1931.18\n",
      "Training Epoch 51  44.7% | batch:        42 of        94\t|\tloss: 955.622\n",
      "Training Epoch 51  45.7% | batch:        43 of        94\t|\tloss: 1779.18\n",
      "Training Epoch 51  46.8% | batch:        44 of        94\t|\tloss: 846.985\n",
      "Training Epoch 51  47.9% | batch:        45 of        94\t|\tloss: 1291.15\n",
      "Training Epoch 51  48.9% | batch:        46 of        94\t|\tloss: 1304.07\n",
      "Training Epoch 51  50.0% | batch:        47 of        94\t|\tloss: 1260.13\n",
      "Training Epoch 51  51.1% | batch:        48 of        94\t|\tloss: 2465.43\n",
      "Training Epoch 51  52.1% | batch:        49 of        94\t|\tloss: 889.843\n",
      "Training Epoch 51  53.2% | batch:        50 of        94\t|\tloss: 1621.69\n",
      "Training Epoch 51  54.3% | batch:        51 of        94\t|\tloss: 1327.68\n",
      "Training Epoch 51  55.3% | batch:        52 of        94\t|\tloss: 1336.29\n",
      "Training Epoch 51  56.4% | batch:        53 of        94\t|\tloss: 1398.31\n",
      "Training Epoch 51  57.4% | batch:        54 of        94\t|\tloss: 1228.05\n",
      "Training Epoch 51  58.5% | batch:        55 of        94\t|\tloss: 1145.92\n",
      "Training Epoch 51  59.6% | batch:        56 of        94\t|\tloss: 1375.4\n",
      "Training Epoch 51  60.6% | batch:        57 of        94\t|\tloss: 1098.58\n",
      "Training Epoch 51  61.7% | batch:        58 of        94\t|\tloss: 886.641\n",
      "Training Epoch 51  62.8% | batch:        59 of        94\t|\tloss: 1168.51\n",
      "Training Epoch 51  63.8% | batch:        60 of        94\t|\tloss: 1133.25\n",
      "Training Epoch 51  64.9% | batch:        61 of        94\t|\tloss: 963.421\n",
      "Training Epoch 51  66.0% | batch:        62 of        94\t|\tloss: 1591.81\n",
      "Training Epoch 51  67.0% | batch:        63 of        94\t|\tloss: 1343.2\n",
      "Training Epoch 51  68.1% | batch:        64 of        94\t|\tloss: 861.367\n",
      "Training Epoch 51  69.1% | batch:        65 of        94\t|\tloss: 1797.12\n",
      "Training Epoch 51  70.2% | batch:        66 of        94\t|\tloss: 1225.93\n",
      "Training Epoch 51  71.3% | batch:        67 of        94\t|\tloss: 1648.44\n",
      "Training Epoch 51  72.3% | batch:        68 of        94\t|\tloss: 1445.58\n",
      "Training Epoch 51  73.4% | batch:        69 of        94\t|\tloss: 1119.74\n",
      "Training Epoch 51  74.5% | batch:        70 of        94\t|\tloss: 1846.49\n",
      "Training Epoch 51  75.5% | batch:        71 of        94\t|\tloss: 2198.43\n",
      "Training Epoch 51  76.6% | batch:        72 of        94\t|\tloss: 1080.25\n",
      "Training Epoch 51  77.7% | batch:        73 of        94\t|\tloss: 1297.16\n",
      "Training Epoch 51  78.7% | batch:        74 of        94\t|\tloss: 1796.26\n",
      "Training Epoch 51  79.8% | batch:        75 of        94\t|\tloss: 1087.27\n",
      "Training Epoch 51  80.9% | batch:        76 of        94\t|\tloss: 838.685\n",
      "Training Epoch 51  81.9% | batch:        77 of        94\t|\tloss: 1463.13\n",
      "Training Epoch 51  83.0% | batch:        78 of        94\t|\tloss: 1458.89\n",
      "Training Epoch 51  84.0% | batch:        79 of        94\t|\tloss: 1338.24\n",
      "Training Epoch 51  85.1% | batch:        80 of        94\t|\tloss: 817.836\n",
      "Training Epoch 51  86.2% | batch:        81 of        94\t|\tloss: 1224.5\n",
      "Training Epoch 51  87.2% | batch:        82 of        94\t|\tloss: 1155.1\n",
      "Training Epoch 51  88.3% | batch:        83 of        94\t|\tloss: 1188.79\n",
      "Training Epoch 51  89.4% | batch:        84 of        94\t|\tloss: 959.076\n",
      "Training Epoch 51  90.4% | batch:        85 of        94\t|\tloss: 1390.86\n",
      "Training Epoch 51  91.5% | batch:        86 of        94\t|\tloss: 2748.88\n",
      "Training Epoch 51  92.6% | batch:        87 of        94\t|\tloss: 1172.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:35,553 | INFO : Epoch 51 Training Summary: epoch: 51.000000 | loss: 1315.179498 | \n",
      "2023-05-04 17:00:35,554 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7924823760986328 seconds\n",
      "\n",
      "2023-05-04 17:00:35,555 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.788963102826885 seconds\n",
      "2023-05-04 17:00:35,555 | INFO : Avg batch train. time: 0.019031522370498776 seconds\n",
      "2023-05-04 17:00:35,556 | INFO : Avg sample train. time: 0.00015010598278460187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 51  93.6% | batch:        88 of        94\t|\tloss: 1184.75\n",
      "Training Epoch 51  94.7% | batch:        89 of        94\t|\tloss: 974.87\n",
      "Training Epoch 51  95.7% | batch:        90 of        94\t|\tloss: 1336.61\n",
      "Training Epoch 51  96.8% | batch:        91 of        94\t|\tloss: 804.38\n",
      "Training Epoch 51  97.9% | batch:        92 of        94\t|\tloss: 805.061\n",
      "Training Epoch 51  98.9% | batch:        93 of        94\t|\tloss: 2099.97\n",
      "\n",
      "Training Epoch 52   0.0% | batch:         0 of        94\t|\tloss: 1154.14\n",
      "Training Epoch 52   1.1% | batch:         1 of        94\t|\tloss: 1725.76\n",
      "Training Epoch 52   2.1% | batch:         2 of        94\t|\tloss: 921.024\n",
      "Training Epoch 52   3.2% | batch:         3 of        94\t|\tloss: 814.632\n",
      "Training Epoch 52   4.3% | batch:         4 of        94\t|\tloss: 1078.77\n",
      "Training Epoch 52   5.3% | batch:         5 of        94\t|\tloss: 1734.47\n",
      "Training Epoch 52   6.4% | batch:         6 of        94\t|\tloss: 854.357\n",
      "Training Epoch 52   7.4% | batch:         7 of        94\t|\tloss: 1394.14\n",
      "Training Epoch 52   8.5% | batch:         8 of        94\t|\tloss: 1224.23\n",
      "Training Epoch 52   9.6% | batch:         9 of        94\t|\tloss: 812.098\n",
      "Training Epoch 52  10.6% | batch:        10 of        94\t|\tloss: 1018.39\n",
      "Training Epoch 52  11.7% | batch:        11 of        94\t|\tloss: 869.248\n",
      "Training Epoch 52  12.8% | batch:        12 of        94\t|\tloss: 1374.92\n",
      "Training Epoch 52  13.8% | batch:        13 of        94\t|\tloss: 2129.54\n",
      "Training Epoch 52  14.9% | batch:        14 of        94\t|\tloss: 780.237\n",
      "Training Epoch 52  16.0% | batch:        15 of        94\t|\tloss: 1263.46\n",
      "Training Epoch 52  17.0% | batch:        16 of        94\t|\tloss: 957.682\n",
      "Training Epoch 52  18.1% | batch:        17 of        94\t|\tloss: 1347.03\n",
      "Training Epoch 52  19.1% | batch:        18 of        94\t|\tloss: 922.683\n",
      "Training Epoch 52  20.2% | batch:        19 of        94\t|\tloss: 2176.69\n",
      "Training Epoch 52  21.3% | batch:        20 of        94\t|\tloss: 1288.41\n",
      "Training Epoch 52  22.3% | batch:        21 of        94\t|\tloss: 1400.16\n",
      "Training Epoch 52  23.4% | batch:        22 of        94\t|\tloss: 1274.1\n",
      "Training Epoch 52  24.5% | batch:        23 of        94\t|\tloss: 863.709\n",
      "Training Epoch 52  25.5% | batch:        24 of        94\t|\tloss: 992.384\n",
      "Training Epoch 52  26.6% | batch:        25 of        94\t|\tloss: 2979.07\n",
      "Training Epoch 52  27.7% | batch:        26 of        94\t|\tloss: 998.359\n",
      "Training Epoch 52  28.7% | batch:        27 of        94\t|\tloss: 936.154\n",
      "Training Epoch 52  29.8% | batch:        28 of        94\t|\tloss: 1447.91\n",
      "Training Epoch 52  30.9% | batch:        29 of        94\t|\tloss: 1045.66\n",
      "Training Epoch 52  31.9% | batch:        30 of        94\t|\tloss: 1310.95\n",
      "Training Epoch 52  33.0% | batch:        31 of        94\t|\tloss: 1672.35\n",
      "Training Epoch 52  34.0% | batch:        32 of        94\t|\tloss: 765.243\n",
      "Training Epoch 52  35.1% | batch:        33 of        94\t|\tloss: 1205.33\n",
      "Training Epoch 52  36.2% | batch:        34 of        94\t|\tloss: 1112.5\n",
      "Training Epoch 52  37.2% | batch:        35 of        94\t|\tloss: 780.507\n",
      "Training Epoch 52  38.3% | batch:        36 of        94\t|\tloss: 1456.41\n",
      "Training Epoch 52  39.4% | batch:        37 of        94\t|\tloss: 1448.38\n",
      "Training Epoch 52  40.4% | batch:        38 of        94\t|\tloss: 1097.88\n",
      "Training Epoch 52  41.5% | batch:        39 of        94\t|\tloss: 1154.61\n",
      "Training Epoch 52  42.6% | batch:        40 of        94\t|\tloss: 788.635\n",
      "Training Epoch 52  43.6% | batch:        41 of        94\t|\tloss: 1073.63\n",
      "Training Epoch 52  44.7% | batch:        42 of        94\t|\tloss: 800.302\n",
      "Training Epoch 52  45.7% | batch:        43 of        94\t|\tloss: 855.773\n",
      "Training Epoch 52  46.8% | batch:        44 of        94\t|\tloss: 1464.56\n",
      "Training Epoch 52  47.9% | batch:        45 of        94\t|\tloss: 1003.99\n",
      "Training Epoch 52  48.9% | batch:        46 of        94\t|\tloss: 2011.44\n",
      "Training Epoch 52  50.0% | batch:        47 of        94\t|\tloss: 1138.98\n",
      "Training Epoch 52  51.1% | batch:        48 of        94\t|\tloss: 1462.61\n",
      "Training Epoch 52  52.1% | batch:        49 of        94\t|\tloss: 843.094\n",
      "Training Epoch 52  53.2% | batch:        50 of        94\t|\tloss: 764.024\n",
      "Training Epoch 52  54.3% | batch:        51 of        94\t|\tloss: 1566.12\n",
      "Training Epoch 52  55.3% | batch:        52 of        94\t|\tloss: 1045.64\n",
      "Training Epoch 52  56.4% | batch:        53 of        94\t|\tloss: 1313.11\n",
      "Training Epoch 52  57.4% | batch:        54 of        94\t|\tloss: 1274.74\n",
      "Training Epoch 52  58.5% | batch:        55 of        94\t|\tloss: 1165.5\n",
      "Training Epoch 52  59.6% | batch:        56 of        94\t|\tloss: 2360.68\n",
      "Training Epoch 52  60.6% | batch:        57 of        94\t|\tloss: 1219.98\n",
      "Training Epoch 52  61.7% | batch:        58 of        94\t|\tloss: 988.282\n",
      "Training Epoch 52  62.8% | batch:        59 of        94\t|\tloss: 1574.71\n",
      "Training Epoch 52  63.8% | batch:        60 of        94\t|\tloss: 1227.49\n",
      "Training Epoch 52  64.9% | batch:        61 of        94\t|\tloss: 1299.79\n",
      "Training Epoch 52  66.0% | batch:        62 of        94\t|\tloss: 1219.6\n",
      "Training Epoch 52  67.0% | batch:        63 of        94\t|\tloss: 1397.84\n",
      "Training Epoch 52  68.1% | batch:        64 of        94\t|\tloss: 1962.63\n",
      "Training Epoch 52  69.1% | batch:        65 of        94\t|\tloss: 1061.92\n",
      "Training Epoch 52  70.2% | batch:        66 of        94\t|\tloss: 1399.21\n",
      "Training Epoch 52  71.3% | batch:        67 of        94\t|\tloss: 1023.02\n",
      "Training Epoch 52  72.3% | batch:        68 of        94\t|\tloss: 1320.72\n",
      "Training Epoch 52  73.4% | batch:        69 of        94\t|\tloss: 1114.59\n",
      "Training Epoch 52  74.5% | batch:        70 of        94\t|\tloss: 1528.63\n",
      "Training Epoch 52  75.5% | batch:        71 of        94\t|\tloss: 2298.09\n",
      "Training Epoch 52  76.6% | batch:        72 of        94\t|\tloss: 1045.78\n",
      "Training Epoch 52  77.7% | batch:        73 of        94\t|\tloss: 995.911\n",
      "Training Epoch 52  78.7% | batch:        74 of        94\t|\tloss: 1701.46\n",
      "Training Epoch 52  79.8% | batch:        75 of        94\t|\tloss: 1338.87\n",
      "Training Epoch 52  80.9% | batch:        76 of        94\t|\tloss: 1154.92\n",
      "Training Epoch 52  81.9% | batch:        77 of        94\t|\tloss: 1064.51\n",
      "Training Epoch 52  83.0% | batch:        78 of        94\t|\tloss: 932.401\n",
      "Training Epoch 52  84.0% | batch:        79 of        94\t|\tloss: 1012.88\n",
      "Training Epoch 52  85.1% | batch:        80 of        94\t|\tloss: 3426.74\n",
      "Training Epoch 52  86.2% | batch:        81 of        94\t|\tloss: 1566.44\n",
      "Training Epoch 52  87.2% | batch:        82 of        94\t|\tloss: 979.106\n",
      "Training Epoch 52  88.3% | batch:        83 of        94\t|\tloss: 1110.47\n",
      "Training Epoch 52  89.4% | batch:        84 of        94\t|\tloss: 1027.52\n",
      "Training Epoch 52  90.4% | batch:        85 of        94\t|\tloss: 1660.54\n",
      "Training Epoch 52  91.5% | batch:        86 of        94\t|\tloss: 1668.72\n",
      "Training Epoch 52  92.6% | batch:        87 of        94\t|\tloss: 1096.62\n",
      "Training Epoch 52  93.6% | batch:        88 of        94\t|\tloss: 864.916\n",
      "Training Epoch 52  94.7% | batch:        89 of        94\t|\tloss: 1080.07\n",
      "Training Epoch 52  95.7% | batch:        90 of        94\t|\tloss: 1160.27\n",
      "Training Epoch 52  96.8% | batch:        91 of        94\t|\tloss: 1024.83\n",
      "Training Epoch 52  97.9% | batch:        92 of        94\t|\tloss: 896.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:37,374 | INFO : Epoch 52 Training Summary: epoch: 52.000000 | loss: 1270.706703 | \n",
      "2023-05-04 17:00:37,376 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7975950241088867 seconds\n",
      "\n",
      "2023-05-04 17:00:37,376 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7891291013130775 seconds\n",
      "2023-05-04 17:00:37,377 | INFO : Avg batch train. time: 0.01903328831184125 seconds\n",
      "2023-05-04 17:00:37,378 | INFO : Avg sample train. time: 0.0001501199111690785 seconds\n",
      "2023-05-04 17:00:37,379 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 52  98.9% | batch:        93 of        94\t|\tloss: 1394.48\n",
      "\n",
      "Evaluating Epoch 52   0.0% | batch:         0 of        40\t|\tloss: 6739.25\n",
      "Evaluating Epoch 52   2.5% | batch:         1 of        40\t|\tloss: 1141.86\n",
      "Evaluating Epoch 52   5.0% | batch:         2 of        40\t|\tloss: 3046.07\n",
      "Evaluating Epoch 52   7.5% | batch:         3 of        40\t|\tloss: 6270.29\n",
      "Evaluating Epoch 52  10.0% | batch:         4 of        40\t|\tloss: 2290.35\n",
      "Evaluating Epoch 52  12.5% | batch:         5 of        40\t|\tloss: 2353.84\n",
      "Evaluating Epoch 52  15.0% | batch:         6 of        40\t|\tloss: 8152.64\n",
      "Evaluating Epoch 52  17.5% | batch:         7 of        40\t|\tloss: 3207.5\n",
      "Evaluating Epoch 52  20.0% | batch:         8 of        40\t|\tloss: 2687.59\n",
      "Evaluating Epoch 52  22.5% | batch:         9 of        40\t|\tloss: 2262.4\n",
      "Evaluating Epoch 52  25.0% | batch:        10 of        40\t|\tloss: 4320.24\n",
      "Evaluating Epoch 52  27.5% | batch:        11 of        40\t|\tloss: 1335.07\n",
      "Evaluating Epoch 52  30.0% | batch:        12 of        40\t|\tloss: 6121.52\n",
      "Evaluating Epoch 52  32.5% | batch:        13 of        40\t|\tloss: 3050.5\n",
      "Evaluating Epoch 52  35.0% | batch:        14 of        40\t|\tloss: 2001.72\n",
      "Evaluating Epoch 52  37.5% | batch:        15 of        40\t|\tloss: 3335.38\n",
      "Evaluating Epoch 52  40.0% | batch:        16 of        40\t|\tloss: 3823.42\n",
      "Evaluating Epoch 52  42.5% | batch:        17 of        40\t|\tloss: 3089.71\n",
      "Evaluating Epoch 52  45.0% | batch:        18 of        40\t|\tloss: 2305.06\n",
      "Evaluating Epoch 52  47.5% | batch:        19 of        40\t|\tloss: 4571.22\n",
      "Evaluating Epoch 52  50.0% | batch:        20 of        40\t|\tloss: 4522.95\n",
      "Evaluating Epoch 52  52.5% | batch:        21 of        40\t|\tloss: 1056.39\n",
      "Evaluating Epoch 52  55.0% | batch:        22 of        40\t|\tloss: 4288.08\n",
      "Evaluating Epoch 52  57.5% | batch:        23 of        40\t|\tloss: 2813.91\n",
      "Evaluating Epoch 52  60.0% | batch:        24 of        40\t|\tloss: 1634.29\n",
      "Evaluating Epoch 52  62.5% | batch:        25 of        40\t|\tloss: 3302.28\n",
      "Evaluating Epoch 52  65.0% | batch:        26 of        40\t|\tloss: 9503.47\n",
      "Evaluating Epoch 52  67.5% | batch:        27 of        40\t|\tloss: 2695.24\n",
      "Evaluating Epoch 52  70.0% | batch:        28 of        40\t|\tloss: 2177.26\n",
      "Evaluating Epoch 52  72.5% | batch:        29 of        40\t|\tloss: 7622.63\n",
      "Evaluating Epoch 52  75.0% | batch:        30 of        40\t|\tloss: 1733.92\n",
      "Evaluating Epoch 52  77.5% | batch:        31 of        40\t|\tloss: 1607.51\n",
      "Evaluating Epoch 52  80.0% | batch:        32 of        40\t|\tloss: 7152.76\n",
      "Evaluating Epoch 52  82.5% | batch:        33 of        40\t|\tloss: 5537\n",
      "Evaluating Epoch 52  85.0% | batch:        34 of        40\t|\tloss: 1102.82\n",
      "Evaluating Epoch 52  87.5% | batch:        35 of        40\t|\tloss: 5557.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:37,828 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4483511447906494 seconds\n",
      "\n",
      "2023-05-04 17:00:37,829 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5357562726136869 seconds\n",
      "2023-05-04 17:00:37,829 | INFO : Avg batch val. time: 0.013393906815342171 seconds\n",
      "2023-05-04 17:00:37,830 | INFO : Avg sample val. time: 0.00010613238363979534 seconds\n",
      "2023-05-04 17:00:37,831 | INFO : Epoch 52 Validation Summary: epoch: 52.000000 | loss: 3855.688008 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 52  90.0% | batch:        36 of        40\t|\tloss: 6390.4\n",
      "Evaluating Epoch 52  92.5% | batch:        37 of        40\t|\tloss: 2470.68\n",
      "Evaluating Epoch 52  95.0% | batch:        38 of        40\t|\tloss: 3672.9\n",
      "Evaluating Epoch 52  97.5% | batch:        39 of        40\t|\tloss: 11681.7\n",
      "\n",
      "Training Epoch 53   0.0% | batch:         0 of        94\t|\tloss: 986.091\n",
      "Training Epoch 53   1.1% | batch:         1 of        94\t|\tloss: 785.435\n",
      "Training Epoch 53   2.1% | batch:         2 of        94\t|\tloss: 994.452\n",
      "Training Epoch 53   3.2% | batch:         3 of        94\t|\tloss: 802.551\n",
      "Training Epoch 53   4.3% | batch:         4 of        94\t|\tloss: 1004.51\n",
      "Training Epoch 53   5.3% | batch:         5 of        94\t|\tloss: 1247.95\n",
      "Training Epoch 53   6.4% | batch:         6 of        94\t|\tloss: 1159.92\n",
      "Training Epoch 53   7.4% | batch:         7 of        94\t|\tloss: 820.511\n",
      "Training Epoch 53   8.5% | batch:         8 of        94\t|\tloss: 966.7\n",
      "Training Epoch 53   9.6% | batch:         9 of        94\t|\tloss: 895.277\n",
      "Training Epoch 53  10.6% | batch:        10 of        94\t|\tloss: 1674.71\n",
      "Training Epoch 53  11.7% | batch:        11 of        94\t|\tloss: 792.153\n",
      "Training Epoch 53  12.8% | batch:        12 of        94\t|\tloss: 1068.01\n",
      "Training Epoch 53  13.8% | batch:        13 of        94\t|\tloss: 1026.93\n",
      "Training Epoch 53  14.9% | batch:        14 of        94\t|\tloss: 1007.98\n",
      "Training Epoch 53  16.0% | batch:        15 of        94\t|\tloss: 1905.62\n",
      "Training Epoch 53  17.0% | batch:        16 of        94\t|\tloss: 1045.59\n",
      "Training Epoch 53  18.1% | batch:        17 of        94\t|\tloss: 1222.44\n",
      "Training Epoch 53  19.1% | batch:        18 of        94\t|\tloss: 721.398\n",
      "Training Epoch 53  20.2% | batch:        19 of        94\t|\tloss: 796.244\n",
      "Training Epoch 53  21.3% | batch:        20 of        94\t|\tloss: 1135.59\n",
      "Training Epoch 53  22.3% | batch:        21 of        94\t|\tloss: 1007.21\n",
      "Training Epoch 53  23.4% | batch:        22 of        94\t|\tloss: 875.03\n",
      "Training Epoch 53  24.5% | batch:        23 of        94\t|\tloss: 810.807\n",
      "Training Epoch 53  25.5% | batch:        24 of        94\t|\tloss: 910.786\n",
      "Training Epoch 53  26.6% | batch:        25 of        94\t|\tloss: 1801.22\n",
      "Training Epoch 53  27.7% | batch:        26 of        94\t|\tloss: 872.768\n",
      "Training Epoch 53  28.7% | batch:        27 of        94\t|\tloss: 2696.22\n",
      "Training Epoch 53  29.8% | batch:        28 of        94\t|\tloss: 1148.98\n",
      "Training Epoch 53  30.9% | batch:        29 of        94\t|\tloss: 1293.37\n",
      "Training Epoch 53  31.9% | batch:        30 of        94\t|\tloss: 1149.16\n",
      "Training Epoch 53  33.0% | batch:        31 of        94\t|\tloss: 1483.87\n",
      "Training Epoch 53  34.0% | batch:        32 of        94\t|\tloss: 772.758\n",
      "Training Epoch 53  35.1% | batch:        33 of        94\t|\tloss: 1119.18\n",
      "Training Epoch 53  36.2% | batch:        34 of        94\t|\tloss: 739.762\n",
      "Training Epoch 53  37.2% | batch:        35 of        94\t|\tloss: 1116.58\n",
      "Training Epoch 53  38.3% | batch:        36 of        94\t|\tloss: 1019.99\n",
      "Training Epoch 53  39.4% | batch:        37 of        94\t|\tloss: 816.797\n",
      "Training Epoch 53  40.4% | batch:        38 of        94\t|\tloss: 733.812\n",
      "Training Epoch 53  41.5% | batch:        39 of        94\t|\tloss: 1121.28\n",
      "Training Epoch 53  42.6% | batch:        40 of        94\t|\tloss: 2231.43\n",
      "Training Epoch 53  43.6% | batch:        41 of        94\t|\tloss: 3511.48\n",
      "Training Epoch 53  44.7% | batch:        42 of        94\t|\tloss: 862.146\n",
      "Training Epoch 53  45.7% | batch:        43 of        94\t|\tloss: 1331.87\n",
      "Training Epoch 53  46.8% | batch:        44 of        94\t|\tloss: 1818.36\n",
      "Training Epoch 53  47.9% | batch:        45 of        94\t|\tloss: 1623.35\n",
      "Training Epoch 53  48.9% | batch:        46 of        94\t|\tloss: 1114.43\n",
      "Training Epoch 53  50.0% | batch:        47 of        94\t|\tloss: 880.685\n",
      "Training Epoch 53  51.1% | batch:        48 of        94\t|\tloss: 1095.81\n",
      "Training Epoch 53  52.1% | batch:        49 of        94\t|\tloss: 1407.19\n",
      "Training Epoch 53  53.2% | batch:        50 of        94\t|\tloss: 1128.22\n",
      "Training Epoch 53  54.3% | batch:        51 of        94\t|\tloss: 1462.57\n",
      "Training Epoch 53  55.3% | batch:        52 of        94\t|\tloss: 1157.95\n",
      "Training Epoch 53  56.4% | batch:        53 of        94\t|\tloss: 1136.17\n",
      "Training Epoch 53  57.4% | batch:        54 of        94\t|\tloss: 753.607\n",
      "Training Epoch 53  58.5% | batch:        55 of        94\t|\tloss: 1789.13\n",
      "Training Epoch 53  59.6% | batch:        56 of        94\t|\tloss: 958.539\n",
      "Training Epoch 53  60.6% | batch:        57 of        94\t|\tloss: 1121.25\n",
      "Training Epoch 53  61.7% | batch:        58 of        94\t|\tloss: 1261.25\n",
      "Training Epoch 53  62.8% | batch:        59 of        94\t|\tloss: 1224.96\n",
      "Training Epoch 53  63.8% | batch:        60 of        94\t|\tloss: 1182\n",
      "Training Epoch 53  64.9% | batch:        61 of        94\t|\tloss: 1011.83\n",
      "Training Epoch 53  66.0% | batch:        62 of        94\t|\tloss: 1529.16\n",
      "Training Epoch 53  67.0% | batch:        63 of        94\t|\tloss: 1338.29\n",
      "Training Epoch 53  68.1% | batch:        64 of        94\t|\tloss: 2538.91\n",
      "Training Epoch 53  69.1% | batch:        65 of        94\t|\tloss: 1027.06\n",
      "Training Epoch 53  70.2% | batch:        66 of        94\t|\tloss: 838.504\n",
      "Training Epoch 53  71.3% | batch:        67 of        94\t|\tloss: 1816.31\n",
      "Training Epoch 53  72.3% | batch:        68 of        94\t|\tloss: 2496.15\n",
      "Training Epoch 53  73.4% | batch:        69 of        94\t|\tloss: 999.076\n",
      "Training Epoch 53  74.5% | batch:        70 of        94\t|\tloss: 1405.78\n",
      "Training Epoch 53  75.5% | batch:        71 of        94\t|\tloss: 814.312\n",
      "Training Epoch 53  76.6% | batch:        72 of        94\t|\tloss: 1156.88\n",
      "Training Epoch 53  77.7% | batch:        73 of        94\t|\tloss: 1697.61\n",
      "Training Epoch 53  78.7% | batch:        74 of        94\t|\tloss: 1438.29\n",
      "Training Epoch 53  79.8% | batch:        75 of        94\t|\tloss: 3018.02\n",
      "Training Epoch 53  80.9% | batch:        76 of        94\t|\tloss: 896.243\n",
      "Training Epoch 53  81.9% | batch:        77 of        94\t|\tloss: 965.336\n",
      "Training Epoch 53  83.0% | batch:        78 of        94\t|\tloss: 1964.37\n",
      "Training Epoch 53  84.0% | batch:        79 of        94\t|\tloss: 995.84\n",
      "Training Epoch 53  85.1% | batch:        80 of        94\t|\tloss: 788.494\n",
      "Training Epoch 53  86.2% | batch:        81 of        94\t|\tloss: 1247.68\n",
      "Training Epoch 53  87.2% | batch:        82 of        94\t|\tloss: 1779.46\n",
      "Training Epoch 53  88.3% | batch:        83 of        94\t|\tloss: 820.16\n",
      "Training Epoch 53  89.4% | batch:        84 of        94\t|\tloss: 1061.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:39,650 | INFO : Epoch 53 Training Summary: epoch: 53.000000 | loss: 1255.727803 | \n",
      "2023-05-04 17:00:39,651 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7976653575897217 seconds\n",
      "\n",
      "2023-05-04 17:00:39,652 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7892901627522595 seconds\n",
      "2023-05-04 17:00:39,652 | INFO : Avg batch train. time: 0.019035001731407018 seconds\n",
      "2023-05-04 17:00:39,653 | INFO : Avg sample train. time: 0.0001501334253022537 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 53  90.4% | batch:        85 of        94\t|\tloss: 1138.84\n",
      "Training Epoch 53  91.5% | batch:        86 of        94\t|\tloss: 1500.45\n",
      "Training Epoch 53  92.6% | batch:        87 of        94\t|\tloss: 1241.12\n",
      "Training Epoch 53  93.6% | batch:        88 of        94\t|\tloss: 1329.79\n",
      "Training Epoch 53  94.7% | batch:        89 of        94\t|\tloss: 1548.18\n",
      "Training Epoch 53  95.7% | batch:        90 of        94\t|\tloss: 1305.29\n",
      "Training Epoch 53  96.8% | batch:        91 of        94\t|\tloss: 1412.07\n",
      "Training Epoch 53  97.9% | batch:        92 of        94\t|\tloss: 837.126\n",
      "Training Epoch 53  98.9% | batch:        93 of        94\t|\tloss: 3291.48\n",
      "\n",
      "Training Epoch 54   0.0% | batch:         0 of        94\t|\tloss: 1276.9\n",
      "Training Epoch 54   1.1% | batch:         1 of        94\t|\tloss: 1015.64\n",
      "Training Epoch 54   2.1% | batch:         2 of        94\t|\tloss: 818.794\n",
      "Training Epoch 54   3.2% | batch:         3 of        94\t|\tloss: 3224.72\n",
      "Training Epoch 54   4.3% | batch:         4 of        94\t|\tloss: 1191.91\n",
      "Training Epoch 54   5.3% | batch:         5 of        94\t|\tloss: 884.941\n",
      "Training Epoch 54   6.4% | batch:         6 of        94\t|\tloss: 1325.9\n",
      "Training Epoch 54   7.4% | batch:         7 of        94\t|\tloss: 1015.92\n",
      "Training Epoch 54   8.5% | batch:         8 of        94\t|\tloss: 1026.6\n",
      "Training Epoch 54   9.6% | batch:         9 of        94\t|\tloss: 825.503\n",
      "Training Epoch 54  10.6% | batch:        10 of        94\t|\tloss: 892.99\n",
      "Training Epoch 54  11.7% | batch:        11 of        94\t|\tloss: 750.855\n",
      "Training Epoch 54  12.8% | batch:        12 of        94\t|\tloss: 1112.54\n",
      "Training Epoch 54  13.8% | batch:        13 of        94\t|\tloss: 1624.83\n",
      "Training Epoch 54  14.9% | batch:        14 of        94\t|\tloss: 1657.96\n",
      "Training Epoch 54  16.0% | batch:        15 of        94\t|\tloss: 967.521\n",
      "Training Epoch 54  17.0% | batch:        16 of        94\t|\tloss: 1002.39\n",
      "Training Epoch 54  18.1% | batch:        17 of        94\t|\tloss: 702.31\n",
      "Training Epoch 54  19.1% | batch:        18 of        94\t|\tloss: 1211.6\n",
      "Training Epoch 54  20.2% | batch:        19 of        94\t|\tloss: 1141.71\n",
      "Training Epoch 54  21.3% | batch:        20 of        94\t|\tloss: 764.988\n",
      "Training Epoch 54  22.3% | batch:        21 of        94\t|\tloss: 1751.56\n",
      "Training Epoch 54  23.4% | batch:        22 of        94\t|\tloss: 2195.25\n",
      "Training Epoch 54  24.5% | batch:        23 of        94\t|\tloss: 962.911\n",
      "Training Epoch 54  25.5% | batch:        24 of        94\t|\tloss: 1144.47\n",
      "Training Epoch 54  26.6% | batch:        25 of        94\t|\tloss: 982.205\n",
      "Training Epoch 54  27.7% | batch:        26 of        94\t|\tloss: 1026.42\n",
      "Training Epoch 54  28.7% | batch:        27 of        94\t|\tloss: 1606.44\n",
      "Training Epoch 54  29.8% | batch:        28 of        94\t|\tloss: 1714.79\n",
      "Training Epoch 54  30.9% | batch:        29 of        94\t|\tloss: 1743.09\n",
      "Training Epoch 54  31.9% | batch:        30 of        94\t|\tloss: 682.111\n",
      "Training Epoch 54  33.0% | batch:        31 of        94\t|\tloss: 987.952\n",
      "Training Epoch 54  34.0% | batch:        32 of        94\t|\tloss: 3043.7\n",
      "Training Epoch 54  35.1% | batch:        33 of        94\t|\tloss: 1084.55\n",
      "Training Epoch 54  36.2% | batch:        34 of        94\t|\tloss: 1391.28\n",
      "Training Epoch 54  37.2% | batch:        35 of        94\t|\tloss: 1415.11\n",
      "Training Epoch 54  38.3% | batch:        36 of        94\t|\tloss: 1201.44\n",
      "Training Epoch 54  39.4% | batch:        37 of        94\t|\tloss: 2220.41\n",
      "Training Epoch 54  40.4% | batch:        38 of        94\t|\tloss: 756.797\n",
      "Training Epoch 54  41.5% | batch:        39 of        94\t|\tloss: 921.035\n",
      "Training Epoch 54  42.6% | batch:        40 of        94\t|\tloss: 1153.96\n",
      "Training Epoch 54  43.6% | batch:        41 of        94\t|\tloss: 1063.37\n",
      "Training Epoch 54  44.7% | batch:        42 of        94\t|\tloss: 1148.76\n",
      "Training Epoch 54  45.7% | batch:        43 of        94\t|\tloss: 1037.33\n",
      "Training Epoch 54  46.8% | batch:        44 of        94\t|\tloss: 899.122\n",
      "Training Epoch 54  47.9% | batch:        45 of        94\t|\tloss: 1186.83\n",
      "Training Epoch 54  48.9% | batch:        46 of        94\t|\tloss: 785.483\n",
      "Training Epoch 54  50.0% | batch:        47 of        94\t|\tloss: 1609.87\n",
      "Training Epoch 54  51.1% | batch:        48 of        94\t|\tloss: 1052\n",
      "Training Epoch 54  52.1% | batch:        49 of        94\t|\tloss: 788.706\n",
      "Training Epoch 54  53.2% | batch:        50 of        94\t|\tloss: 1373.79\n",
      "Training Epoch 54  54.3% | batch:        51 of        94\t|\tloss: 936.478\n",
      "Training Epoch 54  55.3% | batch:        52 of        94\t|\tloss: 1132.31\n",
      "Training Epoch 54  56.4% | batch:        53 of        94\t|\tloss: 696.019\n",
      "Training Epoch 54  57.4% | batch:        54 of        94\t|\tloss: 2486.03\n",
      "Training Epoch 54  58.5% | batch:        55 of        94\t|\tloss: 989.282\n",
      "Training Epoch 54  59.6% | batch:        56 of        94\t|\tloss: 2770.14\n",
      "Training Epoch 54  60.6% | batch:        57 of        94\t|\tloss: 1142.71\n",
      "Training Epoch 54  61.7% | batch:        58 of        94\t|\tloss: 933.897\n",
      "Training Epoch 54  62.8% | batch:        59 of        94\t|\tloss: 1176.13\n",
      "Training Epoch 54  63.8% | batch:        60 of        94\t|\tloss: 1753.62\n",
      "Training Epoch 54  64.9% | batch:        61 of        94\t|\tloss: 1056.91\n",
      "Training Epoch 54  66.0% | batch:        62 of        94\t|\tloss: 2144.99\n",
      "Training Epoch 54  67.0% | batch:        63 of        94\t|\tloss: 1110.58\n",
      "Training Epoch 54  68.1% | batch:        64 of        94\t|\tloss: 1064.64\n",
      "Training Epoch 54  69.1% | batch:        65 of        94\t|\tloss: 949.953\n",
      "Training Epoch 54  70.2% | batch:        66 of        94\t|\tloss: 1811.81\n",
      "Training Epoch 54  71.3% | batch:        67 of        94\t|\tloss: 1002.48\n",
      "Training Epoch 54  72.3% | batch:        68 of        94\t|\tloss: 2081.01\n",
      "Training Epoch 54  73.4% | batch:        69 of        94\t|\tloss: 1941.82\n",
      "Training Epoch 54  74.5% | batch:        70 of        94\t|\tloss: 782.904\n",
      "Training Epoch 54  75.5% | batch:        71 of        94\t|\tloss: 924.323\n",
      "Training Epoch 54  76.6% | batch:        72 of        94\t|\tloss: 981.749\n",
      "Training Epoch 54  77.7% | batch:        73 of        94\t|\tloss: 1339.45\n",
      "Training Epoch 54  78.7% | batch:        74 of        94\t|\tloss: 1827.29\n",
      "Training Epoch 54  79.8% | batch:        75 of        94\t|\tloss: 1006.82\n",
      "Training Epoch 54  80.9% | batch:        76 of        94\t|\tloss: 1264.4\n",
      "Training Epoch 54  81.9% | batch:        77 of        94\t|\tloss: 1608.35\n",
      "Training Epoch 54  83.0% | batch:        78 of        94\t|\tloss: 1696.35\n",
      "Training Epoch 54  84.0% | batch:        79 of        94\t|\tloss: 1366.11\n",
      "Training Epoch 54  85.1% | batch:        80 of        94\t|\tloss: 940.957\n",
      "Training Epoch 54  86.2% | batch:        81 of        94\t|\tloss: 971.731\n",
      "Training Epoch 54  87.2% | batch:        82 of        94\t|\tloss: 1289.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:41,394 | INFO : Epoch 54 Training Summary: epoch: 54.000000 | loss: 1277.660749 | \n",
      "2023-05-04 17:00:41,395 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7211370468139648 seconds\n",
      "\n",
      "2023-05-04 17:00:41,396 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7880280680126615 seconds\n",
      "2023-05-04 17:00:41,396 | INFO : Avg batch train. time: 0.01902157519162406 seconds\n",
      "2023-05-04 17:00:41,397 | INFO : Avg sample train. time: 0.00015002752710292511 seconds\n",
      "2023-05-04 17:00:41,398 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 54  88.3% | batch:        83 of        94\t|\tloss: 1893.46\n",
      "Training Epoch 54  89.4% | batch:        84 of        94\t|\tloss: 1197.51\n",
      "Training Epoch 54  90.4% | batch:        85 of        94\t|\tloss: 1255.04\n",
      "Training Epoch 54  91.5% | batch:        86 of        94\t|\tloss: 861.965\n",
      "Training Epoch 54  92.6% | batch:        87 of        94\t|\tloss: 1616.99\n",
      "Training Epoch 54  93.6% | batch:        88 of        94\t|\tloss: 886.781\n",
      "Training Epoch 54  94.7% | batch:        89 of        94\t|\tloss: 1111.72\n",
      "Training Epoch 54  95.7% | batch:        90 of        94\t|\tloss: 945.429\n",
      "Training Epoch 54  96.8% | batch:        91 of        94\t|\tloss: 952.396\n",
      "Training Epoch 54  97.9% | batch:        92 of        94\t|\tloss: 1561.67\n",
      "Training Epoch 54  98.9% | batch:        93 of        94\t|\tloss: 1199.07\n",
      "\n",
      "Evaluating Epoch 54   0.0% | batch:         0 of        40\t|\tloss: 6973.59\n",
      "Evaluating Epoch 54   2.5% | batch:         1 of        40\t|\tloss: 1233.75\n",
      "Evaluating Epoch 54   5.0% | batch:         2 of        40\t|\tloss: 2369.59\n",
      "Evaluating Epoch 54   7.5% | batch:         3 of        40\t|\tloss: 7168.92\n",
      "Evaluating Epoch 54  10.0% | batch:         4 of        40\t|\tloss: 2382.68\n",
      "Evaluating Epoch 54  12.5% | batch:         5 of        40\t|\tloss: 2254.31\n",
      "Evaluating Epoch 54  15.0% | batch:         6 of        40\t|\tloss: 8040.01\n",
      "Evaluating Epoch 54  17.5% | batch:         7 of        40\t|\tloss: 3285.85\n",
      "Evaluating Epoch 54  20.0% | batch:         8 of        40\t|\tloss: 2567.03\n",
      "Evaluating Epoch 54  22.5% | batch:         9 of        40\t|\tloss: 1864.42\n",
      "Evaluating Epoch 54  25.0% | batch:        10 of        40\t|\tloss: 4613\n",
      "Evaluating Epoch 54  27.5% | batch:        11 of        40\t|\tloss: 1270.69\n",
      "Evaluating Epoch 54  30.0% | batch:        12 of        40\t|\tloss: 5945.19\n",
      "Evaluating Epoch 54  32.5% | batch:        13 of        40\t|\tloss: 2756.94\n",
      "Evaluating Epoch 54  35.0% | batch:        14 of        40\t|\tloss: 1860.73\n",
      "Evaluating Epoch 54  37.5% | batch:        15 of        40\t|\tloss: 2942.23\n",
      "Evaluating Epoch 54  40.0% | batch:        16 of        40\t|\tloss: 4507.47\n",
      "Evaluating Epoch 54  42.5% | batch:        17 of        40\t|\tloss: 3008.47\n",
      "Evaluating Epoch 54  45.0% | batch:        18 of        40\t|\tloss: 2129.05\n",
      "Evaluating Epoch 54  47.5% | batch:        19 of        40\t|\tloss: 4277.4\n",
      "Evaluating Epoch 54  50.0% | batch:        20 of        40\t|\tloss: 5079.87\n",
      "Evaluating Epoch 54  52.5% | batch:        21 of        40\t|\tloss: 1033.97\n",
      "Evaluating Epoch 54  55.0% | batch:        22 of        40\t|\tloss: 3632.12\n",
      "Evaluating Epoch 54  57.5% | batch:        23 of        40\t|\tloss: 3271.54\n",
      "Evaluating Epoch 54  60.0% | batch:        24 of        40\t|\tloss: 1641.1\n",
      "Evaluating Epoch 54  62.5% | batch:        25 of        40\t|\tloss: 2855.24\n",
      "Evaluating Epoch 54  65.0% | batch:        26 of        40\t|\tloss: 9597.3\n",
      "Evaluating Epoch 54  67.5% | batch:        27 of        40\t|\tloss: 2752.9\n",
      "Evaluating Epoch 54  70.0% | batch:        28 of        40\t|\tloss: 1845.49\n",
      "Evaluating Epoch 54  72.5% | batch:        29 of        40\t|\tloss: 8125.32\n",
      "Evaluating Epoch 54  75.0% | batch:        30 of        40\t|\tloss: 1858.69\n",
      "Evaluating Epoch 54  77.5% | batch:        31 of        40\t|\tloss: 1354.39\n",
      "Evaluating Epoch 54  80.0% | batch:        32 of        40\t|\tloss: 7128.25\n",
      "Evaluating Epoch 54  82.5% | batch:        33 of        40\t|\tloss: 6029.98\n",
      "Evaluating Epoch 54  85.0% | batch:        34 of        40\t|\tloss: 1016.58\n",
      "Evaluating Epoch 54  87.5% | batch:        35 of        40\t|\tloss: 4884.55\n",
      "Evaluating Epoch 54  90.0% | batch:        36 of        40\t|\tloss: 5467.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:41,849 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45015954971313477 seconds\n",
      "\n",
      "2023-05-04 17:00:41,849 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5353057635457892 seconds\n",
      "2023-05-04 17:00:41,850 | INFO : Avg batch val. time: 0.01338264408864473 seconds\n",
      "2023-05-04 17:00:41,850 | INFO : Avg sample val. time: 0.00010604313857880135 seconds\n",
      "2023-05-04 17:00:41,851 | INFO : Epoch 54 Validation Summary: epoch: 54.000000 | loss: 3793.144160 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 54  92.5% | batch:        37 of        40\t|\tloss: 2635.82\n",
      "Evaluating Epoch 54  95.0% | batch:        38 of        40\t|\tloss: 2818.6\n",
      "Evaluating Epoch 54  97.5% | batch:        39 of        40\t|\tloss: 11683.3\n",
      "\n",
      "Training Epoch 55   0.0% | batch:         0 of        94\t|\tloss: 794.932\n",
      "Training Epoch 55   1.1% | batch:         1 of        94\t|\tloss: 1212.37\n",
      "Training Epoch 55   2.1% | batch:         2 of        94\t|\tloss: 974.512\n",
      "Training Epoch 55   3.2% | batch:         3 of        94\t|\tloss: 1397.55\n",
      "Training Epoch 55   4.3% | batch:         4 of        94\t|\tloss: 1077.08\n",
      "Training Epoch 55   5.3% | batch:         5 of        94\t|\tloss: 925.965\n",
      "Training Epoch 55   6.4% | batch:         6 of        94\t|\tloss: 1030.1\n",
      "Training Epoch 55   7.4% | batch:         7 of        94\t|\tloss: 1407.27\n",
      "Training Epoch 55   8.5% | batch:         8 of        94\t|\tloss: 939.089\n",
      "Training Epoch 55   9.6% | batch:         9 of        94\t|\tloss: 1281.21\n",
      "Training Epoch 55  10.6% | batch:        10 of        94\t|\tloss: 2023.33\n",
      "Training Epoch 55  11.7% | batch:        11 of        94\t|\tloss: 743.629\n",
      "Training Epoch 55  12.8% | batch:        12 of        94\t|\tloss: 1196.39\n",
      "Training Epoch 55  13.8% | batch:        13 of        94\t|\tloss: 1998.12\n",
      "Training Epoch 55  14.9% | batch:        14 of        94\t|\tloss: 1015.38\n",
      "Training Epoch 55  16.0% | batch:        15 of        94\t|\tloss: 736.268\n",
      "Training Epoch 55  17.0% | batch:        16 of        94\t|\tloss: 2228.48\n",
      "Training Epoch 55  18.1% | batch:        17 of        94\t|\tloss: 1186.48\n",
      "Training Epoch 55  19.1% | batch:        18 of        94\t|\tloss: 1482.6\n",
      "Training Epoch 55  20.2% | batch:        19 of        94\t|\tloss: 1310.62\n",
      "Training Epoch 55  21.3% | batch:        20 of        94\t|\tloss: 1069.93\n",
      "Training Epoch 55  22.3% | batch:        21 of        94\t|\tloss: 1221.31\n",
      "Training Epoch 55  23.4% | batch:        22 of        94\t|\tloss: 1565.75\n",
      "Training Epoch 55  24.5% | batch:        23 of        94\t|\tloss: 932.935\n",
      "Training Epoch 55  25.5% | batch:        24 of        94\t|\tloss: 878.324\n",
      "Training Epoch 55  26.6% | batch:        25 of        94\t|\tloss: 1175.33\n",
      "Training Epoch 55  27.7% | batch:        26 of        94\t|\tloss: 876.676\n",
      "Training Epoch 55  28.7% | batch:        27 of        94\t|\tloss: 1731.35\n",
      "Training Epoch 55  29.8% | batch:        28 of        94\t|\tloss: 837.9\n",
      "Training Epoch 55  30.9% | batch:        29 of        94\t|\tloss: 883.901\n",
      "Training Epoch 55  31.9% | batch:        30 of        94\t|\tloss: 916.49\n",
      "Training Epoch 55  33.0% | batch:        31 of        94\t|\tloss: 949.942\n",
      "Training Epoch 55  34.0% | batch:        32 of        94\t|\tloss: 1152.51\n",
      "Training Epoch 55  35.1% | batch:        33 of        94\t|\tloss: 828.748\n",
      "Training Epoch 55  36.2% | batch:        34 of        94\t|\tloss: 967.583\n",
      "Training Epoch 55  37.2% | batch:        35 of        94\t|\tloss: 1627.02\n",
      "Training Epoch 55  38.3% | batch:        36 of        94\t|\tloss: 759.243\n",
      "Training Epoch 55  39.4% | batch:        37 of        94\t|\tloss: 949.839\n",
      "Training Epoch 55  40.4% | batch:        38 of        94\t|\tloss: 1308.18\n",
      "Training Epoch 55  41.5% | batch:        39 of        94\t|\tloss: 1068.47\n",
      "Training Epoch 55  42.6% | batch:        40 of        94\t|\tloss: 1521.61\n",
      "Training Epoch 55  43.6% | batch:        41 of        94\t|\tloss: 1141.22\n",
      "Training Epoch 55  44.7% | batch:        42 of        94\t|\tloss: 722.885\n",
      "Training Epoch 55  45.7% | batch:        43 of        94\t|\tloss: 1397.63\n",
      "Training Epoch 55  46.8% | batch:        44 of        94\t|\tloss: 1127.31\n",
      "Training Epoch 55  47.9% | batch:        45 of        94\t|\tloss: 3840.1\n",
      "Training Epoch 55  48.9% | batch:        46 of        94\t|\tloss: 998.363\n",
      "Training Epoch 55  50.0% | batch:        47 of        94\t|\tloss: 1339.64\n",
      "Training Epoch 55  51.1% | batch:        48 of        94\t|\tloss: 1351.1\n",
      "Training Epoch 55  52.1% | batch:        49 of        94\t|\tloss: 958.749\n",
      "Training Epoch 55  53.2% | batch:        50 of        94\t|\tloss: 2498.76\n",
      "Training Epoch 55  54.3% | batch:        51 of        94\t|\tloss: 1248.63\n",
      "Training Epoch 55  55.3% | batch:        52 of        94\t|\tloss: 1145.42\n",
      "Training Epoch 55  56.4% | batch:        53 of        94\t|\tloss: 1824.7\n",
      "Training Epoch 55  57.4% | batch:        54 of        94\t|\tloss: 1240.79\n",
      "Training Epoch 55  58.5% | batch:        55 of        94\t|\tloss: 906.007\n",
      "Training Epoch 55  59.6% | batch:        56 of        94\t|\tloss: 1085.51\n",
      "Training Epoch 55  60.6% | batch:        57 of        94\t|\tloss: 741.322\n",
      "Training Epoch 55  61.7% | batch:        58 of        94\t|\tloss: 1176.1\n",
      "Training Epoch 55  62.8% | batch:        59 of        94\t|\tloss: 1595.47\n",
      "Training Epoch 55  63.8% | batch:        60 of        94\t|\tloss: 1355.22\n",
      "Training Epoch 55  64.9% | batch:        61 of        94\t|\tloss: 1582.94\n",
      "Training Epoch 55  66.0% | batch:        62 of        94\t|\tloss: 1609.05\n",
      "Training Epoch 55  67.0% | batch:        63 of        94\t|\tloss: 1376.17\n",
      "Training Epoch 55  68.1% | batch:        64 of        94\t|\tloss: 811.976\n",
      "Training Epoch 55  69.1% | batch:        65 of        94\t|\tloss: 825.177\n",
      "Training Epoch 55  70.2% | batch:        66 of        94\t|\tloss: 787.335\n",
      "Training Epoch 55  71.3% | batch:        67 of        94\t|\tloss: 1296.58\n",
      "Training Epoch 55  72.3% | batch:        68 of        94\t|\tloss: 1288.32\n",
      "Training Epoch 55  73.4% | batch:        69 of        94\t|\tloss: 832.329\n",
      "Training Epoch 55  74.5% | batch:        70 of        94\t|\tloss: 756.146\n",
      "Training Epoch 55  75.5% | batch:        71 of        94\t|\tloss: 1744\n",
      "Training Epoch 55  76.6% | batch:        72 of        94\t|\tloss: 1691.62\n",
      "Training Epoch 55  77.7% | batch:        73 of        94\t|\tloss: 1148.49\n",
      "Training Epoch 55  78.7% | batch:        74 of        94\t|\tloss: 951.216\n",
      "Training Epoch 55  79.8% | batch:        75 of        94\t|\tloss: 849.865\n",
      "Training Epoch 55  80.9% | batch:        76 of        94\t|\tloss: 1268.39\n",
      "Training Epoch 55  81.9% | batch:        77 of        94\t|\tloss: 727.606\n",
      "Training Epoch 55  83.0% | batch:        78 of        94\t|\tloss: 1028.4\n",
      "Training Epoch 55  84.0% | batch:        79 of        94\t|\tloss: 947.564\n",
      "Training Epoch 55  85.1% | batch:        80 of        94\t|\tloss: 1487.67\n",
      "Training Epoch 55  86.2% | batch:        81 of        94\t|\tloss: 781.595\n",
      "Training Epoch 55  87.2% | batch:        82 of        94\t|\tloss: 912.307\n",
      "Training Epoch 55  88.3% | batch:        83 of        94\t|\tloss: 739.053\n",
      "Training Epoch 55  89.4% | batch:        84 of        94\t|\tloss: 821.284\n",
      "Training Epoch 55  90.4% | batch:        85 of        94\t|\tloss: 1836.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:43,665 | INFO : Epoch 55 Training Summary: epoch: 55.000000 | loss: 1231.085934 | \n",
      "2023-05-04 17:00:43,666 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7920458316802979 seconds\n",
      "\n",
      "2023-05-04 17:00:43,667 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.788101118261164 seconds\n",
      "2023-05-04 17:00:43,668 | INFO : Avg batch train. time: 0.019022352321927276 seconds\n",
      "2023-05-04 17:00:43,669 | INFO : Avg sample train. time: 0.00015003365650790099 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 55  91.5% | batch:        86 of        94\t|\tloss: 794.173\n",
      "Training Epoch 55  92.6% | batch:        87 of        94\t|\tloss: 693.003\n",
      "Training Epoch 55  93.6% | batch:        88 of        94\t|\tloss: 1750.24\n",
      "Training Epoch 55  94.7% | batch:        89 of        94\t|\tloss: 3189.06\n",
      "Training Epoch 55  95.7% | batch:        90 of        94\t|\tloss: 955.23\n",
      "Training Epoch 55  96.8% | batch:        91 of        94\t|\tloss: 1036.82\n",
      "Training Epoch 55  97.9% | batch:        92 of        94\t|\tloss: 1952.49\n",
      "Training Epoch 55  98.9% | batch:        93 of        94\t|\tloss: 2498.04\n",
      "\n",
      "Training Epoch 56   0.0% | batch:         0 of        94\t|\tloss: 854.151\n",
      "Training Epoch 56   1.1% | batch:         1 of        94\t|\tloss: 1080.22\n",
      "Training Epoch 56   2.1% | batch:         2 of        94\t|\tloss: 1142.98\n",
      "Training Epoch 56   3.2% | batch:         3 of        94\t|\tloss: 1340.96\n",
      "Training Epoch 56   4.3% | batch:         4 of        94\t|\tloss: 786.893\n",
      "Training Epoch 56   5.3% | batch:         5 of        94\t|\tloss: 940.497\n",
      "Training Epoch 56   6.4% | batch:         6 of        94\t|\tloss: 802.125\n",
      "Training Epoch 56   7.4% | batch:         7 of        94\t|\tloss: 942.332\n",
      "Training Epoch 56   8.5% | batch:         8 of        94\t|\tloss: 990.759\n",
      "Training Epoch 56   9.6% | batch:         9 of        94\t|\tloss: 945.746\n",
      "Training Epoch 56  10.6% | batch:        10 of        94\t|\tloss: 840.422\n",
      "Training Epoch 56  11.7% | batch:        11 of        94\t|\tloss: 1579.13\n",
      "Training Epoch 56  12.8% | batch:        12 of        94\t|\tloss: 1110.23\n",
      "Training Epoch 56  13.8% | batch:        13 of        94\t|\tloss: 768\n",
      "Training Epoch 56  14.9% | batch:        14 of        94\t|\tloss: 1257.94\n",
      "Training Epoch 56  16.0% | batch:        15 of        94\t|\tloss: 799.382\n",
      "Training Epoch 56  17.0% | batch:        16 of        94\t|\tloss: 720.812\n",
      "Training Epoch 56  18.1% | batch:        17 of        94\t|\tloss: 1160.29\n",
      "Training Epoch 56  19.1% | batch:        18 of        94\t|\tloss: 775.026\n",
      "Training Epoch 56  20.2% | batch:        19 of        94\t|\tloss: 1711.37\n",
      "Training Epoch 56  21.3% | batch:        20 of        94\t|\tloss: 1639.9\n",
      "Training Epoch 56  22.3% | batch:        21 of        94\t|\tloss: 1049.53\n",
      "Training Epoch 56  23.4% | batch:        22 of        94\t|\tloss: 1182.07\n",
      "Training Epoch 56  24.5% | batch:        23 of        94\t|\tloss: 1056.72\n",
      "Training Epoch 56  25.5% | batch:        24 of        94\t|\tloss: 2309.56\n",
      "Training Epoch 56  26.6% | batch:        25 of        94\t|\tloss: 1002.55\n",
      "Training Epoch 56  27.7% | batch:        26 of        94\t|\tloss: 1000.44\n",
      "Training Epoch 56  28.7% | batch:        27 of        94\t|\tloss: 646.792\n",
      "Training Epoch 56  29.8% | batch:        28 of        94\t|\tloss: 774.957\n",
      "Training Epoch 56  30.9% | batch:        29 of        94\t|\tloss: 1201.7\n",
      "Training Epoch 56  31.9% | batch:        30 of        94\t|\tloss: 745.563\n",
      "Training Epoch 56  33.0% | batch:        31 of        94\t|\tloss: 1306.88\n",
      "Training Epoch 56  34.0% | batch:        32 of        94\t|\tloss: 1172.47\n",
      "Training Epoch 56  35.1% | batch:        33 of        94\t|\tloss: 1724.17\n",
      "Training Epoch 56  36.2% | batch:        34 of        94\t|\tloss: 1264.8\n",
      "Training Epoch 56  37.2% | batch:        35 of        94\t|\tloss: 1000.03\n",
      "Training Epoch 56  38.3% | batch:        36 of        94\t|\tloss: 1699.41\n",
      "Training Epoch 56  39.4% | batch:        37 of        94\t|\tloss: 1382.82\n",
      "Training Epoch 56  40.4% | batch:        38 of        94\t|\tloss: 1053.49\n",
      "Training Epoch 56  41.5% | batch:        39 of        94\t|\tloss: 928.832\n",
      "Training Epoch 56  42.6% | batch:        40 of        94\t|\tloss: 784.23\n",
      "Training Epoch 56  43.6% | batch:        41 of        94\t|\tloss: 856.686\n",
      "Training Epoch 56  44.7% | batch:        42 of        94\t|\tloss: 1429.25\n",
      "Training Epoch 56  45.7% | batch:        43 of        94\t|\tloss: 928.893\n",
      "Training Epoch 56  46.8% | batch:        44 of        94\t|\tloss: 1228.56\n",
      "Training Epoch 56  47.9% | batch:        45 of        94\t|\tloss: 966.14\n",
      "Training Epoch 56  48.9% | batch:        46 of        94\t|\tloss: 987.578\n",
      "Training Epoch 56  50.0% | batch:        47 of        94\t|\tloss: 1972.07\n",
      "Training Epoch 56  51.1% | batch:        48 of        94\t|\tloss: 805.845\n",
      "Training Epoch 56  52.1% | batch:        49 of        94\t|\tloss: 1546.74\n",
      "Training Epoch 56  53.2% | batch:        50 of        94\t|\tloss: 1198.66\n",
      "Training Epoch 56  54.3% | batch:        51 of        94\t|\tloss: 732.284\n",
      "Training Epoch 56  55.3% | batch:        52 of        94\t|\tloss: 853.424\n",
      "Training Epoch 56  56.4% | batch:        53 of        94\t|\tloss: 1135.16\n",
      "Training Epoch 56  57.4% | batch:        54 of        94\t|\tloss: 1286.23\n",
      "Training Epoch 56  58.5% | batch:        55 of        94\t|\tloss: 1199.34\n",
      "Training Epoch 56  59.6% | batch:        56 of        94\t|\tloss: 1100.01\n",
      "Training Epoch 56  60.6% | batch:        57 of        94\t|\tloss: 1358.97\n",
      "Training Epoch 56  61.7% | batch:        58 of        94\t|\tloss: 1403.3\n",
      "Training Epoch 56  62.8% | batch:        59 of        94\t|\tloss: 861.913\n",
      "Training Epoch 56  63.8% | batch:        60 of        94\t|\tloss: 823.936\n",
      "Training Epoch 56  64.9% | batch:        61 of        94\t|\tloss: 2368.12\n",
      "Training Epoch 56  66.0% | batch:        62 of        94\t|\tloss: 1539.79\n",
      "Training Epoch 56  67.0% | batch:        63 of        94\t|\tloss: 787.641\n",
      "Training Epoch 56  68.1% | batch:        64 of        94\t|\tloss: 2363.21\n",
      "Training Epoch 56  69.1% | batch:        65 of        94\t|\tloss: 1415.31\n",
      "Training Epoch 56  70.2% | batch:        66 of        94\t|\tloss: 696.697\n",
      "Training Epoch 56  71.3% | batch:        67 of        94\t|\tloss: 1524.76\n",
      "Training Epoch 56  72.3% | batch:        68 of        94\t|\tloss: 1576.79\n",
      "Training Epoch 56  73.4% | batch:        69 of        94\t|\tloss: 1191.14\n",
      "Training Epoch 56  74.5% | batch:        70 of        94\t|\tloss: 2132.8\n",
      "Training Epoch 56  75.5% | batch:        71 of        94\t|\tloss: 1226.09\n",
      "Training Epoch 56  76.6% | batch:        72 of        94\t|\tloss: 1058.82\n",
      "Training Epoch 56  77.7% | batch:        73 of        94\t|\tloss: 1043.83\n",
      "Training Epoch 56  78.7% | batch:        74 of        94\t|\tloss: 1176.26\n",
      "Training Epoch 56  79.8% | batch:        75 of        94\t|\tloss: 1398.93\n",
      "Training Epoch 56  80.9% | batch:        76 of        94\t|\tloss: 804.804\n",
      "Training Epoch 56  81.9% | batch:        77 of        94\t|\tloss: 2294.83\n",
      "Training Epoch 56  83.0% | batch:        78 of        94\t|\tloss: 927.732\n",
      "Training Epoch 56  84.0% | batch:        79 of        94\t|\tloss: 1103.59\n",
      "Training Epoch 56  85.1% | batch:        80 of        94\t|\tloss: 917.882\n",
      "Training Epoch 56  86.2% | batch:        81 of        94\t|\tloss: 1379.68\n",
      "Training Epoch 56  87.2% | batch:        82 of        94\t|\tloss: 1390.87\n",
      "Training Epoch 56  88.3% | batch:        83 of        94\t|\tloss: 983.912\n",
      "Training Epoch 56  89.4% | batch:        84 of        94\t|\tloss: 898.147\n",
      "Training Epoch 56  90.4% | batch:        85 of        94\t|\tloss: 881.518\n",
      "Training Epoch 56  91.5% | batch:        86 of        94\t|\tloss: 2040.68\n",
      "Training Epoch 56  92.6% | batch:        87 of        94\t|\tloss: 1487.34\n",
      "Training Epoch 56  93.6% | batch:        88 of        94\t|\tloss: 1796.01\n",
      "Training Epoch 56  94.7% | batch:        89 of        94\t|\tloss: 2735.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:45,494 | INFO : Epoch 56 Training Summary: epoch: 56.000000 | loss: 1225.474227 | \n",
      "2023-05-04 17:00:45,495 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8042182922363281 seconds\n",
      "\n",
      "2023-05-04 17:00:45,495 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.788388924939292 seconds\n",
      "2023-05-04 17:00:45,496 | INFO : Avg batch train. time: 0.01902541409509885 seconds\n",
      "2023-05-04 17:00:45,497 | INFO : Avg sample train. time: 0.00015005780541527873 seconds\n",
      "2023-05-04 17:00:45,498 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 56  95.7% | batch:        90 of        94\t|\tloss: 1347.05\n",
      "Training Epoch 56  96.8% | batch:        91 of        94\t|\tloss: 1527.52\n",
      "Training Epoch 56  97.9% | batch:        92 of        94\t|\tloss: 1837.24\n",
      "Training Epoch 56  98.9% | batch:        93 of        94\t|\tloss: 892.209\n",
      "\n",
      "Evaluating Epoch 56   0.0% | batch:         0 of        40\t|\tloss: 6711.18\n",
      "Evaluating Epoch 56   2.5% | batch:         1 of        40\t|\tloss: 1305.94\n",
      "Evaluating Epoch 56   5.0% | batch:         2 of        40\t|\tloss: 2659.97\n",
      "Evaluating Epoch 56   7.5% | batch:         3 of        40\t|\tloss: 6569.44\n",
      "Evaluating Epoch 56  10.0% | batch:         4 of        40\t|\tloss: 2299.64\n",
      "Evaluating Epoch 56  12.5% | batch:         5 of        40\t|\tloss: 2733.19\n",
      "Evaluating Epoch 56  15.0% | batch:         6 of        40\t|\tloss: 8806.01\n",
      "Evaluating Epoch 56  17.5% | batch:         7 of        40\t|\tloss: 3080.6\n",
      "Evaluating Epoch 56  20.0% | batch:         8 of        40\t|\tloss: 2754.81\n",
      "Evaluating Epoch 56  22.5% | batch:         9 of        40\t|\tloss: 2095.73\n",
      "Evaluating Epoch 56  25.0% | batch:        10 of        40\t|\tloss: 4350.13\n",
      "Evaluating Epoch 56  27.5% | batch:        11 of        40\t|\tloss: 1388.25\n",
      "Evaluating Epoch 56  30.0% | batch:        12 of        40\t|\tloss: 6360.63\n",
      "Evaluating Epoch 56  32.5% | batch:        13 of        40\t|\tloss: 2432.26\n",
      "Evaluating Epoch 56  35.0% | batch:        14 of        40\t|\tloss: 2016.53\n",
      "Evaluating Epoch 56  37.5% | batch:        15 of        40\t|\tloss: 3328.5\n",
      "Evaluating Epoch 56  40.0% | batch:        16 of        40\t|\tloss: 4069.88\n",
      "Evaluating Epoch 56  42.5% | batch:        17 of        40\t|\tloss: 2676.21\n",
      "Evaluating Epoch 56  45.0% | batch:        18 of        40\t|\tloss: 2477.3\n",
      "Evaluating Epoch 56  47.5% | batch:        19 of        40\t|\tloss: 5353.51\n",
      "Evaluating Epoch 56  50.0% | batch:        20 of        40\t|\tloss: 4648.37\n",
      "Evaluating Epoch 56  52.5% | batch:        21 of        40\t|\tloss: 1055.73\n",
      "Evaluating Epoch 56  55.0% | batch:        22 of        40\t|\tloss: 4052.86\n",
      "Evaluating Epoch 56  57.5% | batch:        23 of        40\t|\tloss: 2742.32\n",
      "Evaluating Epoch 56  60.0% | batch:        24 of        40\t|\tloss: 1712.77\n",
      "Evaluating Epoch 56  62.5% | batch:        25 of        40\t|\tloss: 3417.34\n",
      "Evaluating Epoch 56  65.0% | batch:        26 of        40\t|\tloss: 10002.1\n",
      "Evaluating Epoch 56  67.5% | batch:        27 of        40\t|\tloss: 2800.65\n",
      "Evaluating Epoch 56  70.0% | batch:        28 of        40\t|\tloss: 2000.09\n",
      "Evaluating Epoch 56  72.5% | batch:        29 of        40\t|\tloss: 9056.8\n",
      "Evaluating Epoch 56  75.0% | batch:        30 of        40\t|\tloss: 1723.9\n",
      "Evaluating Epoch 56  77.5% | batch:        31 of        40\t|\tloss: 1641.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:45,949 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4495522975921631 seconds\n",
      "\n",
      "2023-05-04 17:00:45,949 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.534856792519854 seconds\n",
      "2023-05-04 17:00:45,950 | INFO : Avg batch val. time: 0.01337141981299635 seconds\n",
      "2023-05-04 17:00:45,951 | INFO : Avg sample val. time: 0.0001059541982012389 seconds\n",
      "2023-05-04 17:00:45,951 | INFO : Epoch 56 Validation Summary: epoch: 56.000000 | loss: 3903.036181 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 56  80.0% | batch:        32 of        40\t|\tloss: 7582.99\n",
      "Evaluating Epoch 56  82.5% | batch:        33 of        40\t|\tloss: 6107.83\n",
      "Evaluating Epoch 56  85.0% | batch:        34 of        40\t|\tloss: 1152.25\n",
      "Evaluating Epoch 56  87.5% | batch:        35 of        40\t|\tloss: 4384.62\n",
      "Evaluating Epoch 56  90.0% | batch:        36 of        40\t|\tloss: 5093.18\n",
      "Evaluating Epoch 56  92.5% | batch:        37 of        40\t|\tloss: 2650.27\n",
      "Evaluating Epoch 56  95.0% | batch:        38 of        40\t|\tloss: 3437.96\n",
      "Evaluating Epoch 56  97.5% | batch:        39 of        40\t|\tloss: 11870.1\n",
      "\n",
      "Training Epoch 57   0.0% | batch:         0 of        94\t|\tloss: 1025.89\n",
      "Training Epoch 57   1.1% | batch:         1 of        94\t|\tloss: 839.226\n",
      "Training Epoch 57   2.1% | batch:         2 of        94\t|\tloss: 1186.66\n",
      "Training Epoch 57   3.2% | batch:         3 of        94\t|\tloss: 1267.28\n",
      "Training Epoch 57   4.3% | batch:         4 of        94\t|\tloss: 825.892\n",
      "Training Epoch 57   5.3% | batch:         5 of        94\t|\tloss: 825.314\n",
      "Training Epoch 57   6.4% | batch:         6 of        94\t|\tloss: 1711.89\n",
      "Training Epoch 57   7.4% | batch:         7 of        94\t|\tloss: 1123.02\n",
      "Training Epoch 57   8.5% | batch:         8 of        94\t|\tloss: 963.176\n",
      "Training Epoch 57   9.6% | batch:         9 of        94\t|\tloss: 1158.28\n",
      "Training Epoch 57  10.6% | batch:        10 of        94\t|\tloss: 1037.43\n",
      "Training Epoch 57  11.7% | batch:        11 of        94\t|\tloss: 1015.57\n",
      "Training Epoch 57  12.8% | batch:        12 of        94\t|\tloss: 738.352\n",
      "Training Epoch 57  13.8% | batch:        13 of        94\t|\tloss: 1107.54\n",
      "Training Epoch 57  14.9% | batch:        14 of        94\t|\tloss: 776.148\n",
      "Training Epoch 57  16.0% | batch:        15 of        94\t|\tloss: 1013.61\n",
      "Training Epoch 57  17.0% | batch:        16 of        94\t|\tloss: 833.445\n",
      "Training Epoch 57  18.1% | batch:        17 of        94\t|\tloss: 1004.67\n",
      "Training Epoch 57  19.1% | batch:        18 of        94\t|\tloss: 786.952\n",
      "Training Epoch 57  20.2% | batch:        19 of        94\t|\tloss: 682.456\n",
      "Training Epoch 57  21.3% | batch:        20 of        94\t|\tloss: 3311\n",
      "Training Epoch 57  22.3% | batch:        21 of        94\t|\tloss: 1810.84\n",
      "Training Epoch 57  23.4% | batch:        22 of        94\t|\tloss: 740.324\n",
      "Training Epoch 57  24.5% | batch:        23 of        94\t|\tloss: 1142.31\n",
      "Training Epoch 57  25.5% | batch:        24 of        94\t|\tloss: 1168.85\n",
      "Training Epoch 57  26.6% | batch:        25 of        94\t|\tloss: 915.597\n",
      "Training Epoch 57  27.7% | batch:        26 of        94\t|\tloss: 1476.97\n",
      "Training Epoch 57  28.7% | batch:        27 of        94\t|\tloss: 992.169\n",
      "Training Epoch 57  29.8% | batch:        28 of        94\t|\tloss: 1413.5\n",
      "Training Epoch 57  30.9% | batch:        29 of        94\t|\tloss: 977.108\n",
      "Training Epoch 57  31.9% | batch:        30 of        94\t|\tloss: 698.647\n",
      "Training Epoch 57  33.0% | batch:        31 of        94\t|\tloss: 1259.53\n",
      "Training Epoch 57  34.0% | batch:        32 of        94\t|\tloss: 1066.58\n",
      "Training Epoch 57  35.1% | batch:        33 of        94\t|\tloss: 919.172\n",
      "Training Epoch 57  36.2% | batch:        34 of        94\t|\tloss: 1071.11\n",
      "Training Epoch 57  37.2% | batch:        35 of        94\t|\tloss: 1792.17\n",
      "Training Epoch 57  38.3% | batch:        36 of        94\t|\tloss: 1142.46\n",
      "Training Epoch 57  39.4% | batch:        37 of        94\t|\tloss: 2025.58\n",
      "Training Epoch 57  40.4% | batch:        38 of        94\t|\tloss: 738.55\n",
      "Training Epoch 57  41.5% | batch:        39 of        94\t|\tloss: 1293.48\n",
      "Training Epoch 57  42.6% | batch:        40 of        94\t|\tloss: 1137.37\n",
      "Training Epoch 57  43.6% | batch:        41 of        94\t|\tloss: 2370.75\n",
      "Training Epoch 57  44.7% | batch:        42 of        94\t|\tloss: 1355.85\n",
      "Training Epoch 57  45.7% | batch:        43 of        94\t|\tloss: 1409.32\n",
      "Training Epoch 57  46.8% | batch:        44 of        94\t|\tloss: 1278.07\n",
      "Training Epoch 57  47.9% | batch:        45 of        94\t|\tloss: 1341.74\n",
      "Training Epoch 57  48.9% | batch:        46 of        94\t|\tloss: 1161.66\n",
      "Training Epoch 57  50.0% | batch:        47 of        94\t|\tloss: 1703.79\n",
      "Training Epoch 57  51.1% | batch:        48 of        94\t|\tloss: 854.18\n",
      "Training Epoch 57  52.1% | batch:        49 of        94\t|\tloss: 1020.49\n",
      "Training Epoch 57  53.2% | batch:        50 of        94\t|\tloss: 944.865\n",
      "Training Epoch 57  54.3% | batch:        51 of        94\t|\tloss: 910.385\n",
      "Training Epoch 57  55.3% | batch:        52 of        94\t|\tloss: 1402.38\n",
      "Training Epoch 57  56.4% | batch:        53 of        94\t|\tloss: 2414.85\n",
      "Training Epoch 57  57.4% | batch:        54 of        94\t|\tloss: 1394.71\n",
      "Training Epoch 57  58.5% | batch:        55 of        94\t|\tloss: 1613.34\n",
      "Training Epoch 57  59.6% | batch:        56 of        94\t|\tloss: 1336.68\n",
      "Training Epoch 57  60.6% | batch:        57 of        94\t|\tloss: 1182.91\n",
      "Training Epoch 57  61.7% | batch:        58 of        94\t|\tloss: 1123.28\n",
      "Training Epoch 57  62.8% | batch:        59 of        94\t|\tloss: 1021.61\n",
      "Training Epoch 57  63.8% | batch:        60 of        94\t|\tloss: 1075.56\n",
      "Training Epoch 57  64.9% | batch:        61 of        94\t|\tloss: 915.389\n",
      "Training Epoch 57  66.0% | batch:        62 of        94\t|\tloss: 1352.66\n",
      "Training Epoch 57  67.0% | batch:        63 of        94\t|\tloss: 1073.05\n",
      "Training Epoch 57  68.1% | batch:        64 of        94\t|\tloss: 2999.47\n",
      "Training Epoch 57  69.1% | batch:        65 of        94\t|\tloss: 837.079\n",
      "Training Epoch 57  70.2% | batch:        66 of        94\t|\tloss: 1053.81\n",
      "Training Epoch 57  71.3% | batch:        67 of        94\t|\tloss: 1121.81\n",
      "Training Epoch 57  72.3% | batch:        68 of        94\t|\tloss: 1136.54\n",
      "Training Epoch 57  73.4% | batch:        69 of        94\t|\tloss: 1646.63\n",
      "Training Epoch 57  74.5% | batch:        70 of        94\t|\tloss: 1111.87\n",
      "Training Epoch 57  75.5% | batch:        71 of        94\t|\tloss: 987.508\n",
      "Training Epoch 57  76.6% | batch:        72 of        94\t|\tloss: 1549.62\n",
      "Training Epoch 57  77.7% | batch:        73 of        94\t|\tloss: 1630.66\n",
      "Training Epoch 57  78.7% | batch:        74 of        94\t|\tloss: 1079.23\n",
      "Training Epoch 57  79.8% | batch:        75 of        94\t|\tloss: 950.509\n",
      "Training Epoch 57  80.9% | batch:        76 of        94\t|\tloss: 1134.7\n",
      "Training Epoch 57  81.9% | batch:        77 of        94\t|\tloss: 887.447\n",
      "Training Epoch 57  83.0% | batch:        78 of        94\t|\tloss: 1155.99\n",
      "Training Epoch 57  84.0% | batch:        79 of        94\t|\tloss: 1136.6\n",
      "Training Epoch 57  85.1% | batch:        80 of        94\t|\tloss: 1239.99\n",
      "Training Epoch 57  86.2% | batch:        81 of        94\t|\tloss: 1623.54\n",
      "Training Epoch 57  87.2% | batch:        82 of        94\t|\tloss: 2150.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:47,753 | INFO : Epoch 57 Training Summary: epoch: 57.000000 | loss: 1265.026592 | \n",
      "2023-05-04 17:00:47,754 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.780440330505371 seconds\n",
      "\n",
      "2023-05-04 17:00:47,755 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7882494759141354 seconds\n",
      "2023-05-04 17:00:47,755 | INFO : Avg batch train. time: 0.019023930594831227 seconds\n",
      "2023-05-04 17:00:47,756 | INFO : Avg sample train. time: 0.0001500461047083517 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 57  88.3% | batch:        83 of        94\t|\tloss: 2174.14\n",
      "Training Epoch 57  89.4% | batch:        84 of        94\t|\tloss: 1161.25\n",
      "Training Epoch 57  90.4% | batch:        85 of        94\t|\tloss: 1207.38\n",
      "Training Epoch 57  91.5% | batch:        86 of        94\t|\tloss: 1958.98\n",
      "Training Epoch 57  92.6% | batch:        87 of        94\t|\tloss: 841.639\n",
      "Training Epoch 57  93.6% | batch:        88 of        94\t|\tloss: 1610.61\n",
      "Training Epoch 57  94.7% | batch:        89 of        94\t|\tloss: 2161.74\n",
      "Training Epoch 57  95.7% | batch:        90 of        94\t|\tloss: 1176.73\n",
      "Training Epoch 57  96.8% | batch:        91 of        94\t|\tloss: 1422.89\n",
      "Training Epoch 57  97.9% | batch:        92 of        94\t|\tloss: 1243.25\n",
      "Training Epoch 57  98.9% | batch:        93 of        94\t|\tloss: 1099.7\n",
      "\n",
      "Training Epoch 58   0.0% | batch:         0 of        94\t|\tloss: 860.226\n",
      "Training Epoch 58   1.1% | batch:         1 of        94\t|\tloss: 1215.24\n",
      "Training Epoch 58   2.1% | batch:         2 of        94\t|\tloss: 1485.65\n",
      "Training Epoch 58   3.2% | batch:         3 of        94\t|\tloss: 1661.8\n",
      "Training Epoch 58   4.3% | batch:         4 of        94\t|\tloss: 1762.71\n",
      "Training Epoch 58   5.3% | batch:         5 of        94\t|\tloss: 1154.48\n",
      "Training Epoch 58   6.4% | batch:         6 of        94\t|\tloss: 1937.97\n",
      "Training Epoch 58   7.4% | batch:         7 of        94\t|\tloss: 1118.43\n",
      "Training Epoch 58   8.5% | batch:         8 of        94\t|\tloss: 1178.94\n",
      "Training Epoch 58   9.6% | batch:         9 of        94\t|\tloss: 1497.81\n",
      "Training Epoch 58  10.6% | batch:        10 of        94\t|\tloss: 1213.02\n",
      "Training Epoch 58  11.7% | batch:        11 of        94\t|\tloss: 1714.24\n",
      "Training Epoch 58  12.8% | batch:        12 of        94\t|\tloss: 2043.44\n",
      "Training Epoch 58  13.8% | batch:        13 of        94\t|\tloss: 1155.58\n",
      "Training Epoch 58  14.9% | batch:        14 of        94\t|\tloss: 1150.11\n",
      "Training Epoch 58  16.0% | batch:        15 of        94\t|\tloss: 1578.15\n",
      "Training Epoch 58  17.0% | batch:        16 of        94\t|\tloss: 964\n",
      "Training Epoch 58  18.1% | batch:        17 of        94\t|\tloss: 1165.86\n",
      "Training Epoch 58  19.1% | batch:        18 of        94\t|\tloss: 1125.73\n",
      "Training Epoch 58  20.2% | batch:        19 of        94\t|\tloss: 872.816\n",
      "Training Epoch 58  21.3% | batch:        20 of        94\t|\tloss: 822.596\n",
      "Training Epoch 58  22.3% | batch:        21 of        94\t|\tloss: 854.526\n",
      "Training Epoch 58  23.4% | batch:        22 of        94\t|\tloss: 979.261\n",
      "Training Epoch 58  24.5% | batch:        23 of        94\t|\tloss: 1305.14\n",
      "Training Epoch 58  25.5% | batch:        24 of        94\t|\tloss: 689.228\n",
      "Training Epoch 58  26.6% | batch:        25 of        94\t|\tloss: 919.551\n",
      "Training Epoch 58  27.7% | batch:        26 of        94\t|\tloss: 1359.61\n",
      "Training Epoch 58  28.7% | batch:        27 of        94\t|\tloss: 1046.55\n",
      "Training Epoch 58  29.8% | batch:        28 of        94\t|\tloss: 860.673\n",
      "Training Epoch 58  30.9% | batch:        29 of        94\t|\tloss: 782.302\n",
      "Training Epoch 58  31.9% | batch:        30 of        94\t|\tloss: 808.298\n",
      "Training Epoch 58  33.0% | batch:        31 of        94\t|\tloss: 1056.79\n",
      "Training Epoch 58  34.0% | batch:        32 of        94\t|\tloss: 1560.28\n",
      "Training Epoch 58  35.1% | batch:        33 of        94\t|\tloss: 1278.4\n",
      "Training Epoch 58  36.2% | batch:        34 of        94\t|\tloss: 1140.58\n",
      "Training Epoch 58  37.2% | batch:        35 of        94\t|\tloss: 801.073\n",
      "Training Epoch 58  38.3% | batch:        36 of        94\t|\tloss: 722.908\n",
      "Training Epoch 58  39.4% | batch:        37 of        94\t|\tloss: 716.729\n",
      "Training Epoch 58  40.4% | batch:        38 of        94\t|\tloss: 792.847\n",
      "Training Epoch 58  41.5% | batch:        39 of        94\t|\tloss: 829.159\n",
      "Training Epoch 58  42.6% | batch:        40 of        94\t|\tloss: 758.547\n",
      "Training Epoch 58  43.6% | batch:        41 of        94\t|\tloss: 777.316\n",
      "Training Epoch 58  44.7% | batch:        42 of        94\t|\tloss: 722.566\n",
      "Training Epoch 58  45.7% | batch:        43 of        94\t|\tloss: 956.703\n",
      "Training Epoch 58  46.8% | batch:        44 of        94\t|\tloss: 1949.79\n",
      "Training Epoch 58  47.9% | batch:        45 of        94\t|\tloss: 892.038\n",
      "Training Epoch 58  48.9% | batch:        46 of        94\t|\tloss: 1238.27\n",
      "Training Epoch 58  50.0% | batch:        47 of        94\t|\tloss: 1253.25\n",
      "Training Epoch 58  51.1% | batch:        48 of        94\t|\tloss: 1157.78\n",
      "Training Epoch 58  52.1% | batch:        49 of        94\t|\tloss: 1247.9\n",
      "Training Epoch 58  53.2% | batch:        50 of        94\t|\tloss: 793.672\n",
      "Training Epoch 58  54.3% | batch:        51 of        94\t|\tloss: 1227.62\n",
      "Training Epoch 58  55.3% | batch:        52 of        94\t|\tloss: 736.396\n",
      "Training Epoch 58  56.4% | batch:        53 of        94\t|\tloss: 1539.41\n",
      "Training Epoch 58  57.4% | batch:        54 of        94\t|\tloss: 693.444\n",
      "Training Epoch 58  58.5% | batch:        55 of        94\t|\tloss: 1168.37\n",
      "Training Epoch 58  59.6% | batch:        56 of        94\t|\tloss: 1318.39\n",
      "Training Epoch 58  60.6% | batch:        57 of        94\t|\tloss: 1622.91\n",
      "Training Epoch 58  61.7% | batch:        58 of        94\t|\tloss: 924.874\n",
      "Training Epoch 58  62.8% | batch:        59 of        94\t|\tloss: 1210.52\n",
      "Training Epoch 58  63.8% | batch:        60 of        94\t|\tloss: 1880.43\n",
      "Training Epoch 58  64.9% | batch:        61 of        94\t|\tloss: 982.924\n",
      "Training Epoch 58  66.0% | batch:        62 of        94\t|\tloss: 990.544\n",
      "Training Epoch 58  67.0% | batch:        63 of        94\t|\tloss: 2433.65\n",
      "Training Epoch 58  68.1% | batch:        64 of        94\t|\tloss: 644.994\n",
      "Training Epoch 58  69.1% | batch:        65 of        94\t|\tloss: 975.917\n",
      "Training Epoch 58  70.2% | batch:        66 of        94\t|\tloss: 1327.38\n",
      "Training Epoch 58  71.3% | batch:        67 of        94\t|\tloss: 1543.37\n",
      "Training Epoch 58  72.3% | batch:        68 of        94\t|\tloss: 1178.89\n",
      "Training Epoch 58  73.4% | batch:        69 of        94\t|\tloss: 1235.35\n",
      "Training Epoch 58  74.5% | batch:        70 of        94\t|\tloss: 926.057\n",
      "Training Epoch 58  75.5% | batch:        71 of        94\t|\tloss: 1234.7\n",
      "Training Epoch 58  76.6% | batch:        72 of        94\t|\tloss: 1464.43\n",
      "Training Epoch 58  77.7% | batch:        73 of        94\t|\tloss: 1082.19\n",
      "Training Epoch 58  78.7% | batch:        74 of        94\t|\tloss: 1496.1\n",
      "Training Epoch 58  79.8% | batch:        75 of        94\t|\tloss: 1786.69\n",
      "Training Epoch 58  80.9% | batch:        76 of        94\t|\tloss: 1371.1\n",
      "Training Epoch 58  81.9% | batch:        77 of        94\t|\tloss: 1052.28\n",
      "Training Epoch 58  83.0% | batch:        78 of        94\t|\tloss: 1085.11\n",
      "Training Epoch 58  84.0% | batch:        79 of        94\t|\tloss: 1206.82\n",
      "Training Epoch 58  85.1% | batch:        80 of        94\t|\tloss: 774.786\n",
      "Training Epoch 58  86.2% | batch:        81 of        94\t|\tloss: 720.553\n",
      "Training Epoch 58  87.2% | batch:        82 of        94\t|\tloss: 1317.33\n",
      "Training Epoch 58  88.3% | batch:        83 of        94\t|\tloss: 1370.26\n",
      "Training Epoch 58  89.4% | batch:        84 of        94\t|\tloss: 2605.64\n",
      "Training Epoch 58  90.4% | batch:        85 of        94\t|\tloss: 2893.84\n",
      "Training Epoch 58  91.5% | batch:        86 of        94\t|\tloss: 1640.95\n",
      "Training Epoch 58  92.6% | batch:        87 of        94\t|\tloss: 1435.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:49,575 | INFO : Epoch 58 Training Summary: epoch: 58.000000 | loss: 1216.078617 | \n",
      "2023-05-04 17:00:49,575 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7965803146362305 seconds\n",
      "\n",
      "2023-05-04 17:00:49,576 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7883931110645164 seconds\n",
      "2023-05-04 17:00:49,576 | INFO : Avg batch train. time: 0.01902545862834592 seconds\n",
      "2023-05-04 17:00:49,577 | INFO : Avg sample train. time: 0.00015005815665921433 seconds\n",
      "2023-05-04 17:00:49,577 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 58  93.6% | batch:        88 of        94\t|\tloss: 1275.67\n",
      "Training Epoch 58  94.7% | batch:        89 of        94\t|\tloss: 1411.01\n",
      "Training Epoch 58  95.7% | batch:        90 of        94\t|\tloss: 1387.39\n",
      "Training Epoch 58  96.8% | batch:        91 of        94\t|\tloss: 1245.78\n",
      "Training Epoch 58  97.9% | batch:        92 of        94\t|\tloss: 740.416\n",
      "Training Epoch 58  98.9% | batch:        93 of        94\t|\tloss: 1262.28\n",
      "\n",
      "Evaluating Epoch 58   0.0% | batch:         0 of        40\t|\tloss: 7111.75\n",
      "Evaluating Epoch 58   2.5% | batch:         1 of        40\t|\tloss: 1178.75\n",
      "Evaluating Epoch 58   5.0% | batch:         2 of        40\t|\tloss: 2631.64\n",
      "Evaluating Epoch 58   7.5% | batch:         3 of        40\t|\tloss: 6519.34\n",
      "Evaluating Epoch 58  10.0% | batch:         4 of        40\t|\tloss: 2666.98\n",
      "Evaluating Epoch 58  12.5% | batch:         5 of        40\t|\tloss: 3064.56\n",
      "Evaluating Epoch 58  15.0% | batch:         6 of        40\t|\tloss: 8319.22\n",
      "Evaluating Epoch 58  17.5% | batch:         7 of        40\t|\tloss: 2943.31\n",
      "Evaluating Epoch 58  20.0% | batch:         8 of        40\t|\tloss: 2711.97\n",
      "Evaluating Epoch 58  22.5% | batch:         9 of        40\t|\tloss: 1841.87\n",
      "Evaluating Epoch 58  25.0% | batch:        10 of        40\t|\tloss: 4739.56\n",
      "Evaluating Epoch 58  27.5% | batch:        11 of        40\t|\tloss: 1410.86\n",
      "Evaluating Epoch 58  30.0% | batch:        12 of        40\t|\tloss: 6828.42\n",
      "Evaluating Epoch 58  32.5% | batch:        13 of        40\t|\tloss: 3141.32\n",
      "Evaluating Epoch 58  35.0% | batch:        14 of        40\t|\tloss: 1832.23\n",
      "Evaluating Epoch 58  37.5% | batch:        15 of        40\t|\tloss: 3851.85\n",
      "Evaluating Epoch 58  40.0% | batch:        16 of        40\t|\tloss: 3766.48\n",
      "Evaluating Epoch 58  42.5% | batch:        17 of        40\t|\tloss: 2731.34\n",
      "Evaluating Epoch 58  45.0% | batch:        18 of        40\t|\tloss: 2298.21\n",
      "Evaluating Epoch 58  47.5% | batch:        19 of        40\t|\tloss: 4002.44\n",
      "Evaluating Epoch 58  50.0% | batch:        20 of        40\t|\tloss: 4609.8\n",
      "Evaluating Epoch 58  52.5% | batch:        21 of        40\t|\tloss: 1182.26\n",
      "Evaluating Epoch 58  55.0% | batch:        22 of        40\t|\tloss: 3789.43\n",
      "Evaluating Epoch 58  57.5% | batch:        23 of        40\t|\tloss: 2707.27\n",
      "Evaluating Epoch 58  60.0% | batch:        24 of        40\t|\tloss: 1548.56\n",
      "Evaluating Epoch 58  62.5% | batch:        25 of        40\t|\tloss: 3727.85\n",
      "Evaluating Epoch 58  65.0% | batch:        26 of        40\t|\tloss: 9236.58\n",
      "Evaluating Epoch 58  67.5% | batch:        27 of        40\t|\tloss: 2541.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:50,026 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4488544464111328 seconds\n",
      "\n",
      "2023-05-04 17:00:50,028 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5344088636338711 seconds\n",
      "2023-05-04 17:00:50,028 | INFO : Avg batch val. time: 0.013360221590846776 seconds\n",
      "2023-05-04 17:00:50,028 | INFO : Avg sample val. time: 0.00010586546426978428 seconds\n",
      "2023-05-04 17:00:50,029 | INFO : Epoch 58 Validation Summary: epoch: 58.000000 | loss: 3866.178716 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 58  70.0% | batch:        28 of        40\t|\tloss: 1741.67\n",
      "Evaluating Epoch 58  72.5% | batch:        29 of        40\t|\tloss: 7732.94\n",
      "Evaluating Epoch 58  75.0% | batch:        30 of        40\t|\tloss: 1498.98\n",
      "Evaluating Epoch 58  77.5% | batch:        31 of        40\t|\tloss: 1585.88\n",
      "Evaluating Epoch 58  80.0% | batch:        32 of        40\t|\tloss: 7274.78\n",
      "Evaluating Epoch 58  82.5% | batch:        33 of        40\t|\tloss: 5764.41\n",
      "Evaluating Epoch 58  85.0% | batch:        34 of        40\t|\tloss: 1136.68\n",
      "Evaluating Epoch 58  87.5% | batch:        35 of        40\t|\tloss: 4833.75\n",
      "Evaluating Epoch 58  90.0% | batch:        36 of        40\t|\tloss: 6403.56\n",
      "Evaluating Epoch 58  92.5% | batch:        37 of        40\t|\tloss: 2277.31\n",
      "Evaluating Epoch 58  95.0% | batch:        38 of        40\t|\tloss: 3886.71\n",
      "Evaluating Epoch 58  97.5% | batch:        39 of        40\t|\tloss: 12343.5\n",
      "\n",
      "Training Epoch 59   0.0% | batch:         0 of        94\t|\tloss: 934.517\n",
      "Training Epoch 59   1.1% | batch:         1 of        94\t|\tloss: 1307.8\n",
      "Training Epoch 59   2.1% | batch:         2 of        94\t|\tloss: 1186.41\n",
      "Training Epoch 59   3.2% | batch:         3 of        94\t|\tloss: 1701.94\n",
      "Training Epoch 59   4.3% | batch:         4 of        94\t|\tloss: 970.196\n",
      "Training Epoch 59   5.3% | batch:         5 of        94\t|\tloss: 837.094\n",
      "Training Epoch 59   6.4% | batch:         6 of        94\t|\tloss: 870.705\n",
      "Training Epoch 59   7.4% | batch:         7 of        94\t|\tloss: 847.265\n",
      "Training Epoch 59   8.5% | batch:         8 of        94\t|\tloss: 886.829\n",
      "Training Epoch 59   9.6% | batch:         9 of        94\t|\tloss: 731.035\n",
      "Training Epoch 59  10.6% | batch:        10 of        94\t|\tloss: 1311.3\n",
      "Training Epoch 59  11.7% | batch:        11 of        94\t|\tloss: 1165.79\n",
      "Training Epoch 59  12.8% | batch:        12 of        94\t|\tloss: 1008.81\n",
      "Training Epoch 59  13.8% | batch:        13 of        94\t|\tloss: 962.831\n",
      "Training Epoch 59  14.9% | batch:        14 of        94\t|\tloss: 2776.37\n",
      "Training Epoch 59  16.0% | batch:        15 of        94\t|\tloss: 1444.02\n",
      "Training Epoch 59  17.0% | batch:        16 of        94\t|\tloss: 1172.6\n",
      "Training Epoch 59  18.1% | batch:        17 of        94\t|\tloss: 619.885\n",
      "Training Epoch 59  19.1% | batch:        18 of        94\t|\tloss: 1115.45\n",
      "Training Epoch 59  20.2% | batch:        19 of        94\t|\tloss: 940.743\n",
      "Training Epoch 59  21.3% | batch:        20 of        94\t|\tloss: 1853.74\n",
      "Training Epoch 59  22.3% | batch:        21 of        94\t|\tloss: 1015.61\n",
      "Training Epoch 59  23.4% | batch:        22 of        94\t|\tloss: 1503.47\n",
      "Training Epoch 59  24.5% | batch:        23 of        94\t|\tloss: 1481.72\n",
      "Training Epoch 59  25.5% | batch:        24 of        94\t|\tloss: 1257.95\n",
      "Training Epoch 59  26.6% | batch:        25 of        94\t|\tloss: 986.553\n",
      "Training Epoch 59  27.7% | batch:        26 of        94\t|\tloss: 1951.35\n",
      "Training Epoch 59  28.7% | batch:        27 of        94\t|\tloss: 1033.55\n",
      "Training Epoch 59  29.8% | batch:        28 of        94\t|\tloss: 805.25\n",
      "Training Epoch 59  30.9% | batch:        29 of        94\t|\tloss: 1243.71\n",
      "Training Epoch 59  31.9% | batch:        30 of        94\t|\tloss: 849.686\n",
      "Training Epoch 59  33.0% | batch:        31 of        94\t|\tloss: 1077.8\n",
      "Training Epoch 59  34.0% | batch:        32 of        94\t|\tloss: 851.142\n",
      "Training Epoch 59  35.1% | batch:        33 of        94\t|\tloss: 1563.74\n",
      "Training Epoch 59  36.2% | batch:        34 of        94\t|\tloss: 1085.37\n",
      "Training Epoch 59  37.2% | batch:        35 of        94\t|\tloss: 965.864\n",
      "Training Epoch 59  38.3% | batch:        36 of        94\t|\tloss: 1080.55\n",
      "Training Epoch 59  39.4% | batch:        37 of        94\t|\tloss: 1469.31\n",
      "Training Epoch 59  40.4% | batch:        38 of        94\t|\tloss: 1387.63\n",
      "Training Epoch 59  41.5% | batch:        39 of        94\t|\tloss: 882.713\n",
      "Training Epoch 59  42.6% | batch:        40 of        94\t|\tloss: 1511.79\n",
      "Training Epoch 59  43.6% | batch:        41 of        94\t|\tloss: 854.926\n",
      "Training Epoch 59  44.7% | batch:        42 of        94\t|\tloss: 1800.42\n",
      "Training Epoch 59  45.7% | batch:        43 of        94\t|\tloss: 1366.02\n",
      "Training Epoch 59  46.8% | batch:        44 of        94\t|\tloss: 878.058\n",
      "Training Epoch 59  47.9% | batch:        45 of        94\t|\tloss: 1336.88\n",
      "Training Epoch 59  48.9% | batch:        46 of        94\t|\tloss: 1382.25\n",
      "Training Epoch 59  50.0% | batch:        47 of        94\t|\tloss: 1032.43\n",
      "Training Epoch 59  51.1% | batch:        48 of        94\t|\tloss: 1247.49\n",
      "Training Epoch 59  52.1% | batch:        49 of        94\t|\tloss: 1142.63\n",
      "Training Epoch 59  53.2% | batch:        50 of        94\t|\tloss: 1077.22\n",
      "Training Epoch 59  54.3% | batch:        51 of        94\t|\tloss: 2463.61\n",
      "Training Epoch 59  55.3% | batch:        52 of        94\t|\tloss: 1976.2\n",
      "Training Epoch 59  56.4% | batch:        53 of        94\t|\tloss: 1704.32\n",
      "Training Epoch 59  57.4% | batch:        54 of        94\t|\tloss: 1175.19\n",
      "Training Epoch 59  58.5% | batch:        55 of        94\t|\tloss: 1497.45\n",
      "Training Epoch 59  59.6% | batch:        56 of        94\t|\tloss: 984.228\n",
      "Training Epoch 59  60.6% | batch:        57 of        94\t|\tloss: 855.462\n",
      "Training Epoch 59  61.7% | batch:        58 of        94\t|\tloss: 1168.59\n",
      "Training Epoch 59  62.8% | batch:        59 of        94\t|\tloss: 1029.9\n",
      "Training Epoch 59  63.8% | batch:        60 of        94\t|\tloss: 803.747\n",
      "Training Epoch 59  64.9% | batch:        61 of        94\t|\tloss: 1362.74\n",
      "Training Epoch 59  66.0% | batch:        62 of        94\t|\tloss: 1342.32\n",
      "Training Epoch 59  67.0% | batch:        63 of        94\t|\tloss: 692.559\n",
      "Training Epoch 59  68.1% | batch:        64 of        94\t|\tloss: 1091.22\n",
      "Training Epoch 59  69.1% | batch:        65 of        94\t|\tloss: 2073.45\n",
      "Training Epoch 59  70.2% | batch:        66 of        94\t|\tloss: 1209.59\n",
      "Training Epoch 59  71.3% | batch:        67 of        94\t|\tloss: 1958.02\n",
      "Training Epoch 59  72.3% | batch:        68 of        94\t|\tloss: 894.775\n",
      "Training Epoch 59  73.4% | batch:        69 of        94\t|\tloss: 1085.94\n",
      "Training Epoch 59  74.5% | batch:        70 of        94\t|\tloss: 1419.19\n",
      "Training Epoch 59  75.5% | batch:        71 of        94\t|\tloss: 805.958\n",
      "Training Epoch 59  76.6% | batch:        72 of        94\t|\tloss: 1066.61\n",
      "Training Epoch 59  77.7% | batch:        73 of        94\t|\tloss: 950.811\n",
      "Training Epoch 59  78.7% | batch:        74 of        94\t|\tloss: 839.399\n",
      "Training Epoch 59  79.8% | batch:        75 of        94\t|\tloss: 873.983\n",
      "Training Epoch 59  80.9% | batch:        76 of        94\t|\tloss: 825.917\n",
      "Training Epoch 59  81.9% | batch:        77 of        94\t|\tloss: 1249.14\n",
      "Training Epoch 59  83.0% | batch:        78 of        94\t|\tloss: 757.568\n",
      "Training Epoch 59  84.0% | batch:        79 of        94\t|\tloss: 1296.33\n",
      "Training Epoch 59  85.1% | batch:        80 of        94\t|\tloss: 1766.39\n",
      "Training Epoch 59  86.2% | batch:        81 of        94\t|\tloss: 1007.59\n",
      "Training Epoch 59  87.2% | batch:        82 of        94\t|\tloss: 1458.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:51,783 | INFO : Epoch 59 Training Summary: epoch: 59.000000 | loss: 1205.817130 | \n",
      "2023-05-04 17:00:51,784 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7325496673583984 seconds\n",
      "\n",
      "2023-05-04 17:00:51,785 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7874466120186498 seconds\n",
      "2023-05-04 17:00:51,785 | INFO : Avg batch train. time: 0.019015389489560105 seconds\n",
      "2023-05-04 17:00:51,786 | INFO : Avg sample train. time: 0.00014997873905174105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 59  88.3% | batch:        83 of        94\t|\tloss: 1043.01\n",
      "Training Epoch 59  89.4% | batch:        84 of        94\t|\tloss: 1297.17\n",
      "Training Epoch 59  90.4% | batch:        85 of        94\t|\tloss: 1066.58\n",
      "Training Epoch 59  91.5% | batch:        86 of        94\t|\tloss: 1280.19\n",
      "Training Epoch 59  92.6% | batch:        87 of        94\t|\tloss: 1015.38\n",
      "Training Epoch 59  93.6% | batch:        88 of        94\t|\tloss: 1130.73\n",
      "Training Epoch 59  94.7% | batch:        89 of        94\t|\tloss: 1902.3\n",
      "Training Epoch 59  95.7% | batch:        90 of        94\t|\tloss: 1095.25\n",
      "Training Epoch 59  96.8% | batch:        91 of        94\t|\tloss: 1102.92\n",
      "Training Epoch 59  97.9% | batch:        92 of        94\t|\tloss: 714.728\n",
      "Training Epoch 59  98.9% | batch:        93 of        94\t|\tloss: 1547.03\n",
      "\n",
      "Training Epoch 60   0.0% | batch:         0 of        94\t|\tloss: 1144.24\n",
      "Training Epoch 60   1.1% | batch:         1 of        94\t|\tloss: 2694.84\n",
      "Training Epoch 60   2.1% | batch:         2 of        94\t|\tloss: 1338.49\n",
      "Training Epoch 60   3.2% | batch:         3 of        94\t|\tloss: 2488.12\n",
      "Training Epoch 60   4.3% | batch:         4 of        94\t|\tloss: 820.711\n",
      "Training Epoch 60   5.3% | batch:         5 of        94\t|\tloss: 2940.32\n",
      "Training Epoch 60   6.4% | batch:         6 of        94\t|\tloss: 782.782\n",
      "Training Epoch 60   7.4% | batch:         7 of        94\t|\tloss: 917.684\n",
      "Training Epoch 60   8.5% | batch:         8 of        94\t|\tloss: 899.058\n",
      "Training Epoch 60   9.6% | batch:         9 of        94\t|\tloss: 665.367\n",
      "Training Epoch 60  10.6% | batch:        10 of        94\t|\tloss: 808.633\n",
      "Training Epoch 60  11.7% | batch:        11 of        94\t|\tloss: 702.35\n",
      "Training Epoch 60  12.8% | batch:        12 of        94\t|\tloss: 938.083\n",
      "Training Epoch 60  13.8% | batch:        13 of        94\t|\tloss: 1004.84\n",
      "Training Epoch 60  14.9% | batch:        14 of        94\t|\tloss: 884.655\n",
      "Training Epoch 60  16.0% | batch:        15 of        94\t|\tloss: 1083.76\n",
      "Training Epoch 60  17.0% | batch:        16 of        94\t|\tloss: 977.682\n",
      "Training Epoch 60  18.1% | batch:        17 of        94\t|\tloss: 1708.35\n",
      "Training Epoch 60  19.1% | batch:        18 of        94\t|\tloss: 1446.22\n",
      "Training Epoch 60  20.2% | batch:        19 of        94\t|\tloss: 1323.55\n",
      "Training Epoch 60  21.3% | batch:        20 of        94\t|\tloss: 1344.45\n",
      "Training Epoch 60  22.3% | batch:        21 of        94\t|\tloss: 1291.15\n",
      "Training Epoch 60  23.4% | batch:        22 of        94\t|\tloss: 940.618\n",
      "Training Epoch 60  24.5% | batch:        23 of        94\t|\tloss: 1659.22\n",
      "Training Epoch 60  25.5% | batch:        24 of        94\t|\tloss: 1103.57\n",
      "Training Epoch 60  26.6% | batch:        25 of        94\t|\tloss: 968.164\n",
      "Training Epoch 60  27.7% | batch:        26 of        94\t|\tloss: 820.37\n",
      "Training Epoch 60  28.7% | batch:        27 of        94\t|\tloss: 1111.29\n",
      "Training Epoch 60  29.8% | batch:        28 of        94\t|\tloss: 1027.53\n",
      "Training Epoch 60  30.9% | batch:        29 of        94\t|\tloss: 1210.35\n",
      "Training Epoch 60  31.9% | batch:        30 of        94\t|\tloss: 1686.54\n",
      "Training Epoch 60  33.0% | batch:        31 of        94\t|\tloss: 1266.89\n",
      "Training Epoch 60  34.0% | batch:        32 of        94\t|\tloss: 924.814\n",
      "Training Epoch 60  35.1% | batch:        33 of        94\t|\tloss: 915.063\n",
      "Training Epoch 60  36.2% | batch:        34 of        94\t|\tloss: 1743.5\n",
      "Training Epoch 60  37.2% | batch:        35 of        94\t|\tloss: 1099.38\n",
      "Training Epoch 60  38.3% | batch:        36 of        94\t|\tloss: 1176.14\n",
      "Training Epoch 60  39.4% | batch:        37 of        94\t|\tloss: 1134.59\n",
      "Training Epoch 60  40.4% | batch:        38 of        94\t|\tloss: 607.385\n",
      "Training Epoch 60  41.5% | batch:        39 of        94\t|\tloss: 891.823\n",
      "Training Epoch 60  42.6% | batch:        40 of        94\t|\tloss: 1963.58\n",
      "Training Epoch 60  43.6% | batch:        41 of        94\t|\tloss: 1145.93\n",
      "Training Epoch 60  44.7% | batch:        42 of        94\t|\tloss: 1230.57\n",
      "Training Epoch 60  45.7% | batch:        43 of        94\t|\tloss: 1005.26\n",
      "Training Epoch 60  46.8% | batch:        44 of        94\t|\tloss: 1097.68\n",
      "Training Epoch 60  47.9% | batch:        45 of        94\t|\tloss: 1107.63\n",
      "Training Epoch 60  48.9% | batch:        46 of        94\t|\tloss: 1060.35\n",
      "Training Epoch 60  50.0% | batch:        47 of        94\t|\tloss: 712.682\n",
      "Training Epoch 60  51.1% | batch:        48 of        94\t|\tloss: 1614.58\n",
      "Training Epoch 60  52.1% | batch:        49 of        94\t|\tloss: 1650.31\n",
      "Training Epoch 60  53.2% | batch:        50 of        94\t|\tloss: 1157.49\n",
      "Training Epoch 60  54.3% | batch:        51 of        94\t|\tloss: 1301.89\n",
      "Training Epoch 60  55.3% | batch:        52 of        94\t|\tloss: 1372.11\n",
      "Training Epoch 60  56.4% | batch:        53 of        94\t|\tloss: 718.767\n",
      "Training Epoch 60  57.4% | batch:        54 of        94\t|\tloss: 859.454\n",
      "Training Epoch 60  58.5% | batch:        55 of        94\t|\tloss: 1006.88\n",
      "Training Epoch 60  59.6% | batch:        56 of        94\t|\tloss: 782.288\n",
      "Training Epoch 60  60.6% | batch:        57 of        94\t|\tloss: 890.845\n",
      "Training Epoch 60  61.7% | batch:        58 of        94\t|\tloss: 1481.67\n",
      "Training Epoch 60  62.8% | batch:        59 of        94\t|\tloss: 1793.37\n",
      "Training Epoch 60  63.8% | batch:        60 of        94\t|\tloss: 1077.01\n",
      "Training Epoch 60  64.9% | batch:        61 of        94\t|\tloss: 1171.4\n",
      "Training Epoch 60  66.0% | batch:        62 of        94\t|\tloss: 647.315\n",
      "Training Epoch 60  67.0% | batch:        63 of        94\t|\tloss: 1315.34\n",
      "Training Epoch 60  68.1% | batch:        64 of        94\t|\tloss: 889.181\n",
      "Training Epoch 60  69.1% | batch:        65 of        94\t|\tloss: 1827.92\n",
      "Training Epoch 60  70.2% | batch:        66 of        94\t|\tloss: 1315.62\n",
      "Training Epoch 60  71.3% | batch:        67 of        94\t|\tloss: 1404.46\n",
      "Training Epoch 60  72.3% | batch:        68 of        94\t|\tloss: 1107.62\n",
      "Training Epoch 60  73.4% | batch:        69 of        94\t|\tloss: 1216.11\n",
      "Training Epoch 60  74.5% | batch:        70 of        94\t|\tloss: 1091.19\n",
      "Training Epoch 60  75.5% | batch:        71 of        94\t|\tloss: 1039.28\n",
      "Training Epoch 60  76.6% | batch:        72 of        94\t|\tloss: 1062.55\n",
      "Training Epoch 60  77.7% | batch:        73 of        94\t|\tloss: 1075.1\n",
      "Training Epoch 60  78.7% | batch:        74 of        94\t|\tloss: 1206.39\n",
      "Training Epoch 60  79.8% | batch:        75 of        94\t|\tloss: 1558.13\n",
      "Training Epoch 60  80.9% | batch:        76 of        94\t|\tloss: 1900.49\n",
      "Training Epoch 60  81.9% | batch:        77 of        94\t|\tloss: 1112.42\n",
      "Training Epoch 60  83.0% | batch:        78 of        94\t|\tloss: 677.959\n",
      "Training Epoch 60  84.0% | batch:        79 of        94\t|\tloss: 924.706\n",
      "Training Epoch 60  85.1% | batch:        80 of        94\t|\tloss: 1230.4\n",
      "Training Epoch 60  86.2% | batch:        81 of        94\t|\tloss: 2610.12\n",
      "Training Epoch 60  87.2% | batch:        82 of        94\t|\tloss: 1104.12\n",
      "Training Epoch 60  88.3% | batch:        83 of        94\t|\tloss: 1232.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:53,456 | INFO : Epoch 60 Training Summary: epoch: 60.000000 | loss: 1217.068234 | \n",
      "2023-05-04 17:00:53,457 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6494567394256592 seconds\n",
      "\n",
      "2023-05-04 17:00:53,458 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7851467808087667 seconds\n",
      "2023-05-04 17:00:53,458 | INFO : Avg batch train. time: 0.01899092320009326 seconds\n",
      "2023-05-04 17:00:53,459 | INFO : Avg sample train. time: 0.0001497857678141271 seconds\n",
      "2023-05-04 17:00:53,460 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 60  89.4% | batch:        84 of        94\t|\tloss: 1934.85\n",
      "Training Epoch 60  90.4% | batch:        85 of        94\t|\tloss: 903.39\n",
      "Training Epoch 60  91.5% | batch:        86 of        94\t|\tloss: 1305.25\n",
      "Training Epoch 60  92.6% | batch:        87 of        94\t|\tloss: 1249.74\n",
      "Training Epoch 60  93.6% | batch:        88 of        94\t|\tloss: 1216.16\n",
      "Training Epoch 60  94.7% | batch:        89 of        94\t|\tloss: 1044.9\n",
      "Training Epoch 60  95.7% | batch:        90 of        94\t|\tloss: 1774.7\n",
      "Training Epoch 60  96.8% | batch:        91 of        94\t|\tloss: 899.498\n",
      "Training Epoch 60  97.9% | batch:        92 of        94\t|\tloss: 589.587\n",
      "Training Epoch 60  98.9% | batch:        93 of        94\t|\tloss: 1454.22\n",
      "\n",
      "Evaluating Epoch 60   0.0% | batch:         0 of        40\t|\tloss: 7345.64\n",
      "Evaluating Epoch 60   2.5% | batch:         1 of        40\t|\tloss: 1040.2\n",
      "Evaluating Epoch 60   5.0% | batch:         2 of        40\t|\tloss: 2353.31\n",
      "Evaluating Epoch 60   7.5% | batch:         3 of        40\t|\tloss: 6402.71\n",
      "Evaluating Epoch 60  10.0% | batch:         4 of        40\t|\tloss: 2517.04\n",
      "Evaluating Epoch 60  12.5% | batch:         5 of        40\t|\tloss: 2413.73\n",
      "Evaluating Epoch 60  15.0% | batch:         6 of        40\t|\tloss: 7952.51\n",
      "Evaluating Epoch 60  17.5% | batch:         7 of        40\t|\tloss: 3146.42\n",
      "Evaluating Epoch 60  20.0% | batch:         8 of        40\t|\tloss: 2561.23\n",
      "Evaluating Epoch 60  22.5% | batch:         9 of        40\t|\tloss: 1699.96\n",
      "Evaluating Epoch 60  25.0% | batch:        10 of        40\t|\tloss: 4875.25\n",
      "Evaluating Epoch 60  27.5% | batch:        11 of        40\t|\tloss: 1209.14\n",
      "Evaluating Epoch 60  30.0% | batch:        12 of        40\t|\tloss: 5814.8\n",
      "Evaluating Epoch 60  32.5% | batch:        13 of        40\t|\tloss: 3048.83\n",
      "Evaluating Epoch 60  35.0% | batch:        14 of        40\t|\tloss: 1885.56\n",
      "Evaluating Epoch 60  37.5% | batch:        15 of        40\t|\tloss: 3266.76\n",
      "Evaluating Epoch 60  40.0% | batch:        16 of        40\t|\tloss: 4173.06\n",
      "Evaluating Epoch 60  42.5% | batch:        17 of        40\t|\tloss: 2906.49\n",
      "Evaluating Epoch 60  45.0% | batch:        18 of        40\t|\tloss: 2432.94\n",
      "Evaluating Epoch 60  47.5% | batch:        19 of        40\t|\tloss: 3799.84\n",
      "Evaluating Epoch 60  50.0% | batch:        20 of        40\t|\tloss: 4954.34\n",
      "Evaluating Epoch 60  52.5% | batch:        21 of        40\t|\tloss: 1277.94\n",
      "Evaluating Epoch 60  55.0% | batch:        22 of        40\t|\tloss: 3166.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:53,907 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44738125801086426 seconds\n",
      "\n",
      "2023-05-04 17:00:53,908 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5339579433974825 seconds\n",
      "2023-05-04 17:00:53,909 | INFO : Avg batch val. time: 0.013348948584937062 seconds\n",
      "2023-05-04 17:00:53,909 | INFO : Avg sample val. time: 0.00010577613775702902 seconds\n",
      "2023-05-04 17:00:53,910 | INFO : Epoch 60 Validation Summary: epoch: 60.000000 | loss: 3770.824562 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 60  57.5% | batch:        23 of        40\t|\tloss: 3100.71\n",
      "Evaluating Epoch 60  60.0% | batch:        24 of        40\t|\tloss: 1635.85\n",
      "Evaluating Epoch 60  62.5% | batch:        25 of        40\t|\tloss: 3031.1\n",
      "Evaluating Epoch 60  65.0% | batch:        26 of        40\t|\tloss: 9428.79\n",
      "Evaluating Epoch 60  67.5% | batch:        27 of        40\t|\tloss: 2675.68\n",
      "Evaluating Epoch 60  70.0% | batch:        28 of        40\t|\tloss: 1573.82\n",
      "Evaluating Epoch 60  72.5% | batch:        29 of        40\t|\tloss: 8640.49\n",
      "Evaluating Epoch 60  75.0% | batch:        30 of        40\t|\tloss: 1557.06\n",
      "Evaluating Epoch 60  77.5% | batch:        31 of        40\t|\tloss: 1425.27\n",
      "Evaluating Epoch 60  80.0% | batch:        32 of        40\t|\tloss: 6538.16\n",
      "Evaluating Epoch 60  82.5% | batch:        33 of        40\t|\tloss: 6249.28\n",
      "Evaluating Epoch 60  85.0% | batch:        34 of        40\t|\tloss: 963.887\n",
      "Evaluating Epoch 60  87.5% | batch:        35 of        40\t|\tloss: 4499.33\n",
      "Evaluating Epoch 60  90.0% | batch:        36 of        40\t|\tloss: 6560\n",
      "Evaluating Epoch 60  92.5% | batch:        37 of        40\t|\tloss: 2389.08\n",
      "Evaluating Epoch 60  95.0% | batch:        38 of        40\t|\tloss: 3027.41\n",
      "Evaluating Epoch 60  97.5% | batch:        39 of        40\t|\tloss: 11821.5\n",
      "\n",
      "Training Epoch 61   0.0% | batch:         0 of        94\t|\tloss: 1380.27\n",
      "Training Epoch 61   1.1% | batch:         1 of        94\t|\tloss: 2220.46\n",
      "Training Epoch 61   2.1% | batch:         2 of        94\t|\tloss: 1081.68\n",
      "Training Epoch 61   3.2% | batch:         3 of        94\t|\tloss: 1430.72\n",
      "Training Epoch 61   4.3% | batch:         4 of        94\t|\tloss: 1044.75\n",
      "Training Epoch 61   5.3% | batch:         5 of        94\t|\tloss: 916.63\n",
      "Training Epoch 61   6.4% | batch:         6 of        94\t|\tloss: 1235.14\n",
      "Training Epoch 61   7.4% | batch:         7 of        94\t|\tloss: 884.165\n",
      "Training Epoch 61   8.5% | batch:         8 of        94\t|\tloss: 926.934\n",
      "Training Epoch 61   9.6% | batch:         9 of        94\t|\tloss: 1315.23\n",
      "Training Epoch 61  10.6% | batch:        10 of        94\t|\tloss: 1111.96\n",
      "Training Epoch 61  11.7% | batch:        11 of        94\t|\tloss: 961.694\n",
      "Training Epoch 61  12.8% | batch:        12 of        94\t|\tloss: 1090.84\n",
      "Training Epoch 61  13.8% | batch:        13 of        94\t|\tloss: 1253.54\n",
      "Training Epoch 61  14.9% | batch:        14 of        94\t|\tloss: 1317.59\n",
      "Training Epoch 61  16.0% | batch:        15 of        94\t|\tloss: 1277.77\n",
      "Training Epoch 61  17.0% | batch:        16 of        94\t|\tloss: 663.639\n",
      "Training Epoch 61  18.1% | batch:        17 of        94\t|\tloss: 756.164\n",
      "Training Epoch 61  19.1% | batch:        18 of        94\t|\tloss: 1120.81\n",
      "Training Epoch 61  20.2% | batch:        19 of        94\t|\tloss: 973.047\n",
      "Training Epoch 61  21.3% | batch:        20 of        94\t|\tloss: 798.775\n",
      "Training Epoch 61  22.3% | batch:        21 of        94\t|\tloss: 1380.65\n",
      "Training Epoch 61  23.4% | batch:        22 of        94\t|\tloss: 1318.34\n",
      "Training Epoch 61  24.5% | batch:        23 of        94\t|\tloss: 1063.56\n",
      "Training Epoch 61  25.5% | batch:        24 of        94\t|\tloss: 898.995\n",
      "Training Epoch 61  26.6% | batch:        25 of        94\t|\tloss: 877.627\n",
      "Training Epoch 61  27.7% | batch:        26 of        94\t|\tloss: 1463.53\n",
      "Training Epoch 61  28.7% | batch:        27 of        94\t|\tloss: 1100.04\n",
      "Training Epoch 61  29.8% | batch:        28 of        94\t|\tloss: 773.451\n",
      "Training Epoch 61  30.9% | batch:        29 of        94\t|\tloss: 1484.61\n",
      "Training Epoch 61  31.9% | batch:        30 of        94\t|\tloss: 1152.35\n",
      "Training Epoch 61  33.0% | batch:        31 of        94\t|\tloss: 3311.42\n",
      "Training Epoch 61  34.0% | batch:        32 of        94\t|\tloss: 679.631\n",
      "Training Epoch 61  35.1% | batch:        33 of        94\t|\tloss: 797.882\n",
      "Training Epoch 61  36.2% | batch:        34 of        94\t|\tloss: 1220.7\n",
      "Training Epoch 61  37.2% | batch:        35 of        94\t|\tloss: 859.663\n",
      "Training Epoch 61  38.3% | batch:        36 of        94\t|\tloss: 1291.72\n",
      "Training Epoch 61  39.4% | batch:        37 of        94\t|\tloss: 1408.38\n",
      "Training Epoch 61  40.4% | batch:        38 of        94\t|\tloss: 1851.13\n",
      "Training Epoch 61  41.5% | batch:        39 of        94\t|\tloss: 2128.33\n",
      "Training Epoch 61  42.6% | batch:        40 of        94\t|\tloss: 925.314\n",
      "Training Epoch 61  43.6% | batch:        41 of        94\t|\tloss: 1336.35\n",
      "Training Epoch 61  44.7% | batch:        42 of        94\t|\tloss: 1413.42\n",
      "Training Epoch 61  45.7% | batch:        43 of        94\t|\tloss: 1065.93\n",
      "Training Epoch 61  46.8% | batch:        44 of        94\t|\tloss: 1264.46\n",
      "Training Epoch 61  47.9% | batch:        45 of        94\t|\tloss: 1174.07\n",
      "Training Epoch 61  48.9% | batch:        46 of        94\t|\tloss: 972.931\n",
      "Training Epoch 61  50.0% | batch:        47 of        94\t|\tloss: 1087.59\n",
      "Training Epoch 61  51.1% | batch:        48 of        94\t|\tloss: 974.906\n",
      "Training Epoch 61  52.1% | batch:        49 of        94\t|\tloss: 3244.09\n",
      "Training Epoch 61  53.2% | batch:        50 of        94\t|\tloss: 1097.6\n",
      "Training Epoch 61  54.3% | batch:        51 of        94\t|\tloss: 2412.88\n",
      "Training Epoch 61  55.3% | batch:        52 of        94\t|\tloss: 1430.39\n",
      "Training Epoch 61  56.4% | batch:        53 of        94\t|\tloss: 2802.57\n",
      "Training Epoch 61  57.4% | batch:        54 of        94\t|\tloss: 1095.57\n",
      "Training Epoch 61  58.5% | batch:        55 of        94\t|\tloss: 1126.5\n",
      "Training Epoch 61  59.6% | batch:        56 of        94\t|\tloss: 919.669\n",
      "Training Epoch 61  60.6% | batch:        57 of        94\t|\tloss: 1154.09\n",
      "Training Epoch 61  61.7% | batch:        58 of        94\t|\tloss: 1171.29\n",
      "Training Epoch 61  62.8% | batch:        59 of        94\t|\tloss: 811.334\n",
      "Training Epoch 61  63.8% | batch:        60 of        94\t|\tloss: 803.48\n",
      "Training Epoch 61  64.9% | batch:        61 of        94\t|\tloss: 1056.42\n",
      "Training Epoch 61  66.0% | batch:        62 of        94\t|\tloss: 984.495\n",
      "Training Epoch 61  67.0% | batch:        63 of        94\t|\tloss: 937.043\n",
      "Training Epoch 61  68.1% | batch:        64 of        94\t|\tloss: 1178.3\n",
      "Training Epoch 61  69.1% | batch:        65 of        94\t|\tloss: 807.676\n",
      "Training Epoch 61  70.2% | batch:        66 of        94\t|\tloss: 1211.65\n",
      "Training Epoch 61  71.3% | batch:        67 of        94\t|\tloss: 885.588\n",
      "Training Epoch 61  72.3% | batch:        68 of        94\t|\tloss: 632.339\n",
      "Training Epoch 61  73.4% | batch:        69 of        94\t|\tloss: 783.429\n",
      "Training Epoch 61  74.5% | batch:        70 of        94\t|\tloss: 767.362\n",
      "Training Epoch 61  75.5% | batch:        71 of        94\t|\tloss: 671.436\n",
      "Training Epoch 61  76.6% | batch:        72 of        94\t|\tloss: 932.072\n",
      "Training Epoch 61  77.7% | batch:        73 of        94\t|\tloss: 1293.56\n",
      "Training Epoch 61  78.7% | batch:        74 of        94\t|\tloss: 1460.79\n",
      "Training Epoch 61  79.8% | batch:        75 of        94\t|\tloss: 1111.84\n",
      "Training Epoch 61  80.9% | batch:        76 of        94\t|\tloss: 982.054\n",
      "Training Epoch 61  81.9% | batch:        77 of        94\t|\tloss: 798.926\n",
      "Training Epoch 61  83.0% | batch:        78 of        94\t|\tloss: 1108.37\n",
      "Training Epoch 61  84.0% | batch:        79 of        94\t|\tloss: 857.755\n",
      "Training Epoch 61  85.1% | batch:        80 of        94\t|\tloss: 865.296\n",
      "Training Epoch 61  86.2% | batch:        81 of        94\t|\tloss: 955.714\n",
      "Training Epoch 61  87.2% | batch:        82 of        94\t|\tloss: 1055.28\n",
      "Training Epoch 61  88.3% | batch:        83 of        94\t|\tloss: 862.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:55,582 | INFO : Epoch 61 Training Summary: epoch: 61.000000 | loss: 1201.185676 | \n",
      "2023-05-04 17:00:55,583 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6514017581939697 seconds\n",
      "\n",
      "2023-05-04 17:00:55,584 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7829542394544258 seconds\n",
      "2023-05-04 17:00:55,585 | INFO : Avg batch train. time: 0.018967598292068358 seconds\n",
      "2023-05-04 17:00:55,585 | INFO : Avg sample train. time: 0.00014960179891377963 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 61  89.4% | batch:        84 of        94\t|\tloss: 1065.92\n",
      "Training Epoch 61  90.4% | batch:        85 of        94\t|\tloss: 1751.32\n",
      "Training Epoch 61  91.5% | batch:        86 of        94\t|\tloss: 1177.53\n",
      "Training Epoch 61  92.6% | batch:        87 of        94\t|\tloss: 1719.44\n",
      "Training Epoch 61  93.6% | batch:        88 of        94\t|\tloss: 1149.21\n",
      "Training Epoch 61  94.7% | batch:        89 of        94\t|\tloss: 1648.88\n",
      "Training Epoch 61  95.7% | batch:        90 of        94\t|\tloss: 1191.97\n",
      "Training Epoch 61  96.8% | batch:        91 of        94\t|\tloss: 1116.3\n",
      "Training Epoch 61  97.9% | batch:        92 of        94\t|\tloss: 1195.24\n",
      "Training Epoch 61  98.9% | batch:        93 of        94\t|\tloss: 4729.61\n",
      "\n",
      "Training Epoch 62   0.0% | batch:         0 of        94\t|\tloss: 1084.01\n",
      "Training Epoch 62   1.1% | batch:         1 of        94\t|\tloss: 1051.49\n",
      "Training Epoch 62   2.1% | batch:         2 of        94\t|\tloss: 920.493\n",
      "Training Epoch 62   3.2% | batch:         3 of        94\t|\tloss: 1730.99\n",
      "Training Epoch 62   4.3% | batch:         4 of        94\t|\tloss: 865.597\n",
      "Training Epoch 62   5.3% | batch:         5 of        94\t|\tloss: 1082.23\n",
      "Training Epoch 62   6.4% | batch:         6 of        94\t|\tloss: 1014.96\n",
      "Training Epoch 62   7.4% | batch:         7 of        94\t|\tloss: 952.429\n",
      "Training Epoch 62   8.5% | batch:         8 of        94\t|\tloss: 615.887\n",
      "Training Epoch 62   9.6% | batch:         9 of        94\t|\tloss: 2050.64\n",
      "Training Epoch 62  10.6% | batch:        10 of        94\t|\tloss: 1367.89\n",
      "Training Epoch 62  11.7% | batch:        11 of        94\t|\tloss: 902.702\n",
      "Training Epoch 62  12.8% | batch:        12 of        94\t|\tloss: 925.827\n",
      "Training Epoch 62  13.8% | batch:        13 of        94\t|\tloss: 836.767\n",
      "Training Epoch 62  14.9% | batch:        14 of        94\t|\tloss: 711.217\n",
      "Training Epoch 62  16.0% | batch:        15 of        94\t|\tloss: 864.664\n",
      "Training Epoch 62  17.0% | batch:        16 of        94\t|\tloss: 841.853\n",
      "Training Epoch 62  18.1% | batch:        17 of        94\t|\tloss: 2488.92\n",
      "Training Epoch 62  19.1% | batch:        18 of        94\t|\tloss: 1172.74\n",
      "Training Epoch 62  20.2% | batch:        19 of        94\t|\tloss: 1749.37\n",
      "Training Epoch 62  21.3% | batch:        20 of        94\t|\tloss: 844.578\n",
      "Training Epoch 62  22.3% | batch:        21 of        94\t|\tloss: 1136.87\n",
      "Training Epoch 62  23.4% | batch:        22 of        94\t|\tloss: 1190.71\n",
      "Training Epoch 62  24.5% | batch:        23 of        94\t|\tloss: 1242.35\n",
      "Training Epoch 62  25.5% | batch:        24 of        94\t|\tloss: 1194.35\n",
      "Training Epoch 62  26.6% | batch:        25 of        94\t|\tloss: 1711.58\n",
      "Training Epoch 62  27.7% | batch:        26 of        94\t|\tloss: 944.022\n",
      "Training Epoch 62  28.7% | batch:        27 of        94\t|\tloss: 921.135\n",
      "Training Epoch 62  29.8% | batch:        28 of        94\t|\tloss: 998.572\n",
      "Training Epoch 62  30.9% | batch:        29 of        94\t|\tloss: 1082.97\n",
      "Training Epoch 62  31.9% | batch:        30 of        94\t|\tloss: 911.57\n",
      "Training Epoch 62  33.0% | batch:        31 of        94\t|\tloss: 897.816\n",
      "Training Epoch 62  34.0% | batch:        32 of        94\t|\tloss: 1194.92\n",
      "Training Epoch 62  35.1% | batch:        33 of        94\t|\tloss: 1623.32\n",
      "Training Epoch 62  36.2% | batch:        34 of        94\t|\tloss: 1072.5\n",
      "Training Epoch 62  37.2% | batch:        35 of        94\t|\tloss: 1260.65\n",
      "Training Epoch 62  38.3% | batch:        36 of        94\t|\tloss: 1642.38\n",
      "Training Epoch 62  39.4% | batch:        37 of        94\t|\tloss: 949.417\n",
      "Training Epoch 62  40.4% | batch:        38 of        94\t|\tloss: 1071.1\n",
      "Training Epoch 62  41.5% | batch:        39 of        94\t|\tloss: 1012.55\n",
      "Training Epoch 62  42.6% | batch:        40 of        94\t|\tloss: 1202.75\n",
      "Training Epoch 62  43.6% | batch:        41 of        94\t|\tloss: 1067.97\n",
      "Training Epoch 62  44.7% | batch:        42 of        94\t|\tloss: 763.01\n",
      "Training Epoch 62  45.7% | batch:        43 of        94\t|\tloss: 1043.67\n",
      "Training Epoch 62  46.8% | batch:        44 of        94\t|\tloss: 1407.48\n",
      "Training Epoch 62  47.9% | batch:        45 of        94\t|\tloss: 1645.01\n",
      "Training Epoch 62  48.9% | batch:        46 of        94\t|\tloss: 1760.95\n",
      "Training Epoch 62  50.0% | batch:        47 of        94\t|\tloss: 883.409\n",
      "Training Epoch 62  51.1% | batch:        48 of        94\t|\tloss: 2018.76\n",
      "Training Epoch 62  52.1% | batch:        49 of        94\t|\tloss: 963.058\n",
      "Training Epoch 62  53.2% | batch:        50 of        94\t|\tloss: 854.585\n",
      "Training Epoch 62  54.3% | batch:        51 of        94\t|\tloss: 977.799\n",
      "Training Epoch 62  55.3% | batch:        52 of        94\t|\tloss: 898.108\n",
      "Training Epoch 62  56.4% | batch:        53 of        94\t|\tloss: 954.045\n",
      "Training Epoch 62  57.4% | batch:        54 of        94\t|\tloss: 2227.4\n",
      "Training Epoch 62  58.5% | batch:        55 of        94\t|\tloss: 1340.77\n",
      "Training Epoch 62  59.6% | batch:        56 of        94\t|\tloss: 932.921\n",
      "Training Epoch 62  60.6% | batch:        57 of        94\t|\tloss: 1592.88\n",
      "Training Epoch 62  61.7% | batch:        58 of        94\t|\tloss: 726.709\n",
      "Training Epoch 62  62.8% | batch:        59 of        94\t|\tloss: 947.722\n",
      "Training Epoch 62  63.8% | batch:        60 of        94\t|\tloss: 1777.12\n",
      "Training Epoch 62  64.9% | batch:        61 of        94\t|\tloss: 789.608\n",
      "Training Epoch 62  66.0% | batch:        62 of        94\t|\tloss: 796.585\n",
      "Training Epoch 62  67.0% | batch:        63 of        94\t|\tloss: 1130.08\n",
      "Training Epoch 62  68.1% | batch:        64 of        94\t|\tloss: 1180.95\n",
      "Training Epoch 62  69.1% | batch:        65 of        94\t|\tloss: 2689.91\n",
      "Training Epoch 62  70.2% | batch:        66 of        94\t|\tloss: 1540.38\n",
      "Training Epoch 62  71.3% | batch:        67 of        94\t|\tloss: 1216.63\n",
      "Training Epoch 62  72.3% | batch:        68 of        94\t|\tloss: 1355\n",
      "Training Epoch 62  73.4% | batch:        69 of        94\t|\tloss: 948.059\n",
      "Training Epoch 62  74.5% | batch:        70 of        94\t|\tloss: 1041.01\n",
      "Training Epoch 62  75.5% | batch:        71 of        94\t|\tloss: 1190.35\n",
      "Training Epoch 62  76.6% | batch:        72 of        94\t|\tloss: 1026.56\n",
      "Training Epoch 62  77.7% | batch:        73 of        94\t|\tloss: 685.253\n",
      "Training Epoch 62  78.7% | batch:        74 of        94\t|\tloss: 1184.49\n",
      "Training Epoch 62  79.8% | batch:        75 of        94\t|\tloss: 1542.73\n",
      "Training Epoch 62  80.9% | batch:        76 of        94\t|\tloss: 1272.15\n",
      "Training Epoch 62  81.9% | batch:        77 of        94\t|\tloss: 1106.92\n",
      "Training Epoch 62  83.0% | batch:        78 of        94\t|\tloss: 1114.69\n",
      "Training Epoch 62  84.0% | batch:        79 of        94\t|\tloss: 963.631\n",
      "Training Epoch 62  85.1% | batch:        80 of        94\t|\tloss: 988.845\n",
      "Training Epoch 62  86.2% | batch:        81 of        94\t|\tloss: 1675.27\n",
      "Training Epoch 62  87.2% | batch:        82 of        94\t|\tloss: 1188.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:57,311 | INFO : Epoch 62 Training Summary: epoch: 62.000000 | loss: 1182.034569 | \n",
      "2023-05-04 17:00:57,312 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7047429084777832 seconds\n",
      "\n",
      "2023-05-04 17:00:57,313 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7816927663741573 seconds\n",
      "2023-05-04 17:00:57,313 | INFO : Avg batch train. time: 0.018954178365682525 seconds\n",
      "2023-05-04 17:00:57,314 | INFO : Avg sample train. time: 0.00014949595287583128 seconds\n",
      "2023-05-04 17:00:57,314 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 62  88.3% | batch:        83 of        94\t|\tloss: 1683.04\n",
      "Training Epoch 62  89.4% | batch:        84 of        94\t|\tloss: 962.021\n",
      "Training Epoch 62  90.4% | batch:        85 of        94\t|\tloss: 934.477\n",
      "Training Epoch 62  91.5% | batch:        86 of        94\t|\tloss: 1303.88\n",
      "Training Epoch 62  92.6% | batch:        87 of        94\t|\tloss: 1223.92\n",
      "Training Epoch 62  93.6% | batch:        88 of        94\t|\tloss: 1234.59\n",
      "Training Epoch 62  94.7% | batch:        89 of        94\t|\tloss: 855.508\n",
      "Training Epoch 62  95.7% | batch:        90 of        94\t|\tloss: 964.915\n",
      "Training Epoch 62  96.8% | batch:        91 of        94\t|\tloss: 1124.21\n",
      "Training Epoch 62  97.9% | batch:        92 of        94\t|\tloss: 909.633\n",
      "Training Epoch 62  98.9% | batch:        93 of        94\t|\tloss: 1044.23\n",
      "\n",
      "Evaluating Epoch 62   0.0% | batch:         0 of        40\t|\tloss: 7435.27\n",
      "Evaluating Epoch 62   2.5% | batch:         1 of        40\t|\tloss: 1055.75\n",
      "Evaluating Epoch 62   5.0% | batch:         2 of        40\t|\tloss: 3224.1\n",
      "Evaluating Epoch 62   7.5% | batch:         3 of        40\t|\tloss: 6897.01\n",
      "Evaluating Epoch 62  10.0% | batch:         4 of        40\t|\tloss: 2320.98\n",
      "Evaluating Epoch 62  12.5% | batch:         5 of        40\t|\tloss: 2347.01\n",
      "Evaluating Epoch 62  15.0% | batch:         6 of        40\t|\tloss: 8545.06\n",
      "Evaluating Epoch 62  17.5% | batch:         7 of        40\t|\tloss: 3371.2\n",
      "Evaluating Epoch 62  20.0% | batch:         8 of        40\t|\tloss: 2953.91\n",
      "Evaluating Epoch 62  22.5% | batch:         9 of        40\t|\tloss: 2108.29\n",
      "Evaluating Epoch 62  25.0% | batch:        10 of        40\t|\tloss: 4820.9\n",
      "Evaluating Epoch 62  27.5% | batch:        11 of        40\t|\tloss: 1293.84\n",
      "Evaluating Epoch 62  30.0% | batch:        12 of        40\t|\tloss: 5636.12\n",
      "Evaluating Epoch 62  32.5% | batch:        13 of        40\t|\tloss: 2698.24\n",
      "Evaluating Epoch 62  35.0% | batch:        14 of        40\t|\tloss: 1879.58\n",
      "Evaluating Epoch 62  37.5% | batch:        15 of        40\t|\tloss: 2753.48\n",
      "Evaluating Epoch 62  40.0% | batch:        16 of        40\t|\tloss: 4523.94\n",
      "Evaluating Epoch 62  42.5% | batch:        17 of        40\t|\tloss: 2923.22\n",
      "Evaluating Epoch 62  45.0% | batch:        18 of        40\t|\tloss: 2309.94\n",
      "Evaluating Epoch 62  47.5% | batch:        19 of        40\t|\tloss: 4249.11\n",
      "Evaluating Epoch 62  50.0% | batch:        20 of        40\t|\tloss: 5222.66\n",
      "Evaluating Epoch 62  52.5% | batch:        21 of        40\t|\tloss: 1143.51\n",
      "Evaluating Epoch 62  55.0% | batch:        22 of        40\t|\tloss: 4128.17\n",
      "Evaluating Epoch 62  57.5% | batch:        23 of        40\t|\tloss: 2953.45\n",
      "Evaluating Epoch 62  60.0% | batch:        24 of        40\t|\tloss: 1555.78\n",
      "Evaluating Epoch 62  62.5% | batch:        25 of        40\t|\tloss: 3304.97\n",
      "Evaluating Epoch 62  65.0% | batch:        26 of        40\t|\tloss: 8777.98\n",
      "Evaluating Epoch 62  67.5% | batch:        27 of        40\t|\tloss: 2700.84\n",
      "Evaluating Epoch 62  70.0% | batch:        28 of        40\t|\tloss: 1985.19\n",
      "Evaluating Epoch 62  72.5% | batch:        29 of        40\t|\tloss: 9056.81\n",
      "Evaluating Epoch 62  75.0% | batch:        30 of        40\t|\tloss: 1701.47\n",
      "Evaluating Epoch 62  77.5% | batch:        31 of        40\t|\tloss: 1744.21\n",
      "Evaluating Epoch 62  80.0% | batch:        32 of        40\t|\tloss: 7576.33\n",
      "Evaluating Epoch 62  82.5% | batch:        33 of        40\t|\tloss: 5971.96\n",
      "Evaluating Epoch 62  85.0% | batch:        34 of        40\t|\tloss: 1220.46\n",
      "Evaluating Epoch 62  87.5% | batch:        35 of        40\t|\tloss: 5260.48\n",
      "Evaluating Epoch 62  90.0% | batch:        36 of        40\t|\tloss: 5831.68\n",
      "Evaluating Epoch 62  92.5% | batch:        37 of        40\t|\tloss: 2527.4\n",
      "Evaluating Epoch 62  95.0% | batch:        38 of        40\t|\tloss: 3253.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:57,769 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4534115791320801 seconds\n",
      "\n",
      "2023-05-04 17:00:57,769 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5335427559528154 seconds\n",
      "2023-05-04 17:00:57,770 | INFO : Avg batch val. time: 0.013338568898820385 seconds\n",
      "2023-05-04 17:00:57,770 | INFO : Avg sample val. time: 0.00010569388984802207 seconds\n",
      "2023-05-04 17:00:57,771 | INFO : Epoch 62 Validation Summary: epoch: 62.000000 | loss: 3907.877498 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 62  97.5% | batch:        39 of        40\t|\tloss: 11092.9\n",
      "\n",
      "Training Epoch 63   0.0% | batch:         0 of        94\t|\tloss: 723.759\n",
      "Training Epoch 63   1.1% | batch:         1 of        94\t|\tloss: 797.24\n",
      "Training Epoch 63   2.1% | batch:         2 of        94\t|\tloss: 747.855\n",
      "Training Epoch 63   3.2% | batch:         3 of        94\t|\tloss: 1231.85\n",
      "Training Epoch 63   4.3% | batch:         4 of        94\t|\tloss: 910.881\n",
      "Training Epoch 63   5.3% | batch:         5 of        94\t|\tloss: 997.534\n",
      "Training Epoch 63   6.4% | batch:         6 of        94\t|\tloss: 1525.45\n",
      "Training Epoch 63   7.4% | batch:         7 of        94\t|\tloss: 887.389\n",
      "Training Epoch 63   8.5% | batch:         8 of        94\t|\tloss: 1034.44\n",
      "Training Epoch 63   9.6% | batch:         9 of        94\t|\tloss: 2999.54\n",
      "Training Epoch 63  10.6% | batch:        10 of        94\t|\tloss: 1215.93\n",
      "Training Epoch 63  11.7% | batch:        11 of        94\t|\tloss: 997.732\n",
      "Training Epoch 63  12.8% | batch:        12 of        94\t|\tloss: 1806.93\n",
      "Training Epoch 63  13.8% | batch:        13 of        94\t|\tloss: 1157.29\n",
      "Training Epoch 63  14.9% | batch:        14 of        94\t|\tloss: 988.702\n",
      "Training Epoch 63  16.0% | batch:        15 of        94\t|\tloss: 894.102\n",
      "Training Epoch 63  17.0% | batch:        16 of        94\t|\tloss: 1352.54\n",
      "Training Epoch 63  18.1% | batch:        17 of        94\t|\tloss: 1416.66\n",
      "Training Epoch 63  19.1% | batch:        18 of        94\t|\tloss: 808.583\n",
      "Training Epoch 63  20.2% | batch:        19 of        94\t|\tloss: 759.751\n",
      "Training Epoch 63  21.3% | batch:        20 of        94\t|\tloss: 906.56\n",
      "Training Epoch 63  22.3% | batch:        21 of        94\t|\tloss: 1458.02\n",
      "Training Epoch 63  23.4% | batch:        22 of        94\t|\tloss: 1083\n",
      "Training Epoch 63  24.5% | batch:        23 of        94\t|\tloss: 832.806\n",
      "Training Epoch 63  25.5% | batch:        24 of        94\t|\tloss: 881.34\n",
      "Training Epoch 63  26.6% | batch:        25 of        94\t|\tloss: 752.204\n",
      "Training Epoch 63  27.7% | batch:        26 of        94\t|\tloss: 896.766\n",
      "Training Epoch 63  28.7% | batch:        27 of        94\t|\tloss: 998.299\n",
      "Training Epoch 63  29.8% | batch:        28 of        94\t|\tloss: 886.114\n",
      "Training Epoch 63  30.9% | batch:        29 of        94\t|\tloss: 984.753\n",
      "Training Epoch 63  31.9% | batch:        30 of        94\t|\tloss: 1494.31\n",
      "Training Epoch 63  33.0% | batch:        31 of        94\t|\tloss: 867.33\n",
      "Training Epoch 63  34.0% | batch:        32 of        94\t|\tloss: 769.828\n",
      "Training Epoch 63  35.1% | batch:        33 of        94\t|\tloss: 1397.74\n",
      "Training Epoch 63  36.2% | batch:        34 of        94\t|\tloss: 1094.27\n",
      "Training Epoch 63  37.2% | batch:        35 of        94\t|\tloss: 1001.48\n",
      "Training Epoch 63  38.3% | batch:        36 of        94\t|\tloss: 903.661\n",
      "Training Epoch 63  39.4% | batch:        37 of        94\t|\tloss: 943.785\n",
      "Training Epoch 63  40.4% | batch:        38 of        94\t|\tloss: 1108.67\n",
      "Training Epoch 63  41.5% | batch:        39 of        94\t|\tloss: 992.388\n",
      "Training Epoch 63  42.6% | batch:        40 of        94\t|\tloss: 1384.25\n",
      "Training Epoch 63  43.6% | batch:        41 of        94\t|\tloss: 1026.78\n",
      "Training Epoch 63  44.7% | batch:        42 of        94\t|\tloss: 1264.85\n",
      "Training Epoch 63  45.7% | batch:        43 of        94\t|\tloss: 1027.6\n",
      "Training Epoch 63  46.8% | batch:        44 of        94\t|\tloss: 1594.63\n",
      "Training Epoch 63  47.9% | batch:        45 of        94\t|\tloss: 1061.82\n",
      "Training Epoch 63  48.9% | batch:        46 of        94\t|\tloss: 1108.98\n",
      "Training Epoch 63  50.0% | batch:        47 of        94\t|\tloss: 1130.62\n",
      "Training Epoch 63  51.1% | batch:        48 of        94\t|\tloss: 1597.01\n",
      "Training Epoch 63  52.1% | batch:        49 of        94\t|\tloss: 1137.74\n",
      "Training Epoch 63  53.2% | batch:        50 of        94\t|\tloss: 864.172\n",
      "Training Epoch 63  54.3% | batch:        51 of        94\t|\tloss: 1329.25\n",
      "Training Epoch 63  55.3% | batch:        52 of        94\t|\tloss: 840.279\n",
      "Training Epoch 63  56.4% | batch:        53 of        94\t|\tloss: 804.216\n",
      "Training Epoch 63  57.4% | batch:        54 of        94\t|\tloss: 1091.7\n",
      "Training Epoch 63  58.5% | batch:        55 of        94\t|\tloss: 1764.55\n",
      "Training Epoch 63  59.6% | batch:        56 of        94\t|\tloss: 1010.29\n",
      "Training Epoch 63  60.6% | batch:        57 of        94\t|\tloss: 1417.68\n",
      "Training Epoch 63  61.7% | batch:        58 of        94\t|\tloss: 1102.18\n",
      "Training Epoch 63  62.8% | batch:        59 of        94\t|\tloss: 1604.9\n",
      "Training Epoch 63  63.8% | batch:        60 of        94\t|\tloss: 1150.64\n",
      "Training Epoch 63  64.9% | batch:        61 of        94\t|\tloss: 1202.96\n",
      "Training Epoch 63  66.0% | batch:        62 of        94\t|\tloss: 1492.11\n",
      "Training Epoch 63  67.0% | batch:        63 of        94\t|\tloss: 1262.33\n",
      "Training Epoch 63  68.1% | batch:        64 of        94\t|\tloss: 1182.48\n",
      "Training Epoch 63  69.1% | batch:        65 of        94\t|\tloss: 1372.55\n",
      "Training Epoch 63  70.2% | batch:        66 of        94\t|\tloss: 1567.54\n",
      "Training Epoch 63  71.3% | batch:        67 of        94\t|\tloss: 881.148\n",
      "Training Epoch 63  72.3% | batch:        68 of        94\t|\tloss: 937.213\n",
      "Training Epoch 63  73.4% | batch:        69 of        94\t|\tloss: 739.509\n",
      "Training Epoch 63  74.5% | batch:        70 of        94\t|\tloss: 845.688\n",
      "Training Epoch 63  75.5% | batch:        71 of        94\t|\tloss: 1015.51\n",
      "Training Epoch 63  76.6% | batch:        72 of        94\t|\tloss: 778.075\n",
      "Training Epoch 63  77.7% | batch:        73 of        94\t|\tloss: 1109.21\n",
      "Training Epoch 63  78.7% | batch:        74 of        94\t|\tloss: 1138.54\n",
      "Training Epoch 63  79.8% | batch:        75 of        94\t|\tloss: 1083.49\n",
      "Training Epoch 63  80.9% | batch:        76 of        94\t|\tloss: 915.134\n",
      "Training Epoch 63  81.9% | batch:        77 of        94\t|\tloss: 1203.27\n",
      "Training Epoch 63  83.0% | batch:        78 of        94\t|\tloss: 1661.32\n",
      "Training Epoch 63  84.0% | batch:        79 of        94\t|\tloss: 1160.49\n",
      "Training Epoch 63  85.1% | batch:        80 of        94\t|\tloss: 957.415\n",
      "Training Epoch 63  86.2% | batch:        81 of        94\t|\tloss: 3270.79\n",
      "Training Epoch 63  87.2% | batch:        82 of        94\t|\tloss: 1286.75\n",
      "Training Epoch 63  88.3% | batch:        83 of        94\t|\tloss: 965.363\n",
      "Training Epoch 63  89.4% | batch:        84 of        94\t|\tloss: 803.051\n",
      "Training Epoch 63  90.4% | batch:        85 of        94\t|\tloss: 1068.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:00:59,589 | INFO : Epoch 63 Training Summary: epoch: 63.000000 | loss: 1144.774520 | \n",
      "2023-05-04 17:00:59,590 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.796623706817627 seconds\n",
      "\n",
      "2023-05-04 17:00:59,590 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7819297654288155 seconds\n",
      "2023-05-04 17:00:59,591 | INFO : Avg batch train. time: 0.018956699632221442 seconds\n",
      "2023-05-04 17:00:59,592 | INFO : Avg sample train. time: 0.00014951583868340457 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 63  91.5% | batch:        86 of        94\t|\tloss: 927.823\n",
      "Training Epoch 63  92.6% | batch:        87 of        94\t|\tloss: 1022.66\n",
      "Training Epoch 63  93.6% | batch:        88 of        94\t|\tloss: 1630.21\n",
      "Training Epoch 63  94.7% | batch:        89 of        94\t|\tloss: 952.933\n",
      "Training Epoch 63  95.7% | batch:        90 of        94\t|\tloss: 1288.03\n",
      "Training Epoch 63  96.8% | batch:        91 of        94\t|\tloss: 1016.01\n",
      "Training Epoch 63  97.9% | batch:        92 of        94\t|\tloss: 820.103\n",
      "Training Epoch 63  98.9% | batch:        93 of        94\t|\tloss: 1914.81\n",
      "\n",
      "Training Epoch 64   0.0% | batch:         0 of        94\t|\tloss: 625.95\n",
      "Training Epoch 64   1.1% | batch:         1 of        94\t|\tloss: 1357.15\n",
      "Training Epoch 64   2.1% | batch:         2 of        94\t|\tloss: 1421.49\n",
      "Training Epoch 64   3.2% | batch:         3 of        94\t|\tloss: 878.157\n",
      "Training Epoch 64   4.3% | batch:         4 of        94\t|\tloss: 1118.8\n",
      "Training Epoch 64   5.3% | batch:         5 of        94\t|\tloss: 1389.84\n",
      "Training Epoch 64   6.4% | batch:         6 of        94\t|\tloss: 726.256\n",
      "Training Epoch 64   7.4% | batch:         7 of        94\t|\tloss: 1115.55\n",
      "Training Epoch 64   8.5% | batch:         8 of        94\t|\tloss: 805.82\n",
      "Training Epoch 64   9.6% | batch:         9 of        94\t|\tloss: 1000.89\n",
      "Training Epoch 64  10.6% | batch:        10 of        94\t|\tloss: 1041.55\n",
      "Training Epoch 64  11.7% | batch:        11 of        94\t|\tloss: 721.408\n",
      "Training Epoch 64  12.8% | batch:        12 of        94\t|\tloss: 1049.3\n",
      "Training Epoch 64  13.8% | batch:        13 of        94\t|\tloss: 656.258\n",
      "Training Epoch 64  14.9% | batch:        14 of        94\t|\tloss: 1034.61\n",
      "Training Epoch 64  16.0% | batch:        15 of        94\t|\tloss: 985.561\n",
      "Training Epoch 64  17.0% | batch:        16 of        94\t|\tloss: 1052.34\n",
      "Training Epoch 64  18.1% | batch:        17 of        94\t|\tloss: 726.44\n",
      "Training Epoch 64  19.1% | batch:        18 of        94\t|\tloss: 1033.23\n",
      "Training Epoch 64  20.2% | batch:        19 of        94\t|\tloss: 1413.82\n",
      "Training Epoch 64  21.3% | batch:        20 of        94\t|\tloss: 1440.24\n",
      "Training Epoch 64  22.3% | batch:        21 of        94\t|\tloss: 1169.26\n",
      "Training Epoch 64  23.4% | batch:        22 of        94\t|\tloss: 870.249\n",
      "Training Epoch 64  24.5% | batch:        23 of        94\t|\tloss: 940.931\n",
      "Training Epoch 64  25.5% | batch:        24 of        94\t|\tloss: 1160.57\n",
      "Training Epoch 64  26.6% | batch:        25 of        94\t|\tloss: 879.676\n",
      "Training Epoch 64  27.7% | batch:        26 of        94\t|\tloss: 1147.76\n",
      "Training Epoch 64  28.7% | batch:        27 of        94\t|\tloss: 1571.87\n",
      "Training Epoch 64  29.8% | batch:        28 of        94\t|\tloss: 1128.67\n",
      "Training Epoch 64  30.9% | batch:        29 of        94\t|\tloss: 1376.33\n",
      "Training Epoch 64  31.9% | batch:        30 of        94\t|\tloss: 922.55\n",
      "Training Epoch 64  33.0% | batch:        31 of        94\t|\tloss: 1296.64\n",
      "Training Epoch 64  34.0% | batch:        32 of        94\t|\tloss: 993.52\n",
      "Training Epoch 64  35.1% | batch:        33 of        94\t|\tloss: 936.745\n",
      "Training Epoch 64  36.2% | batch:        34 of        94\t|\tloss: 1123.85\n",
      "Training Epoch 64  37.2% | batch:        35 of        94\t|\tloss: 720.211\n",
      "Training Epoch 64  38.3% | batch:        36 of        94\t|\tloss: 1652.07\n",
      "Training Epoch 64  39.4% | batch:        37 of        94\t|\tloss: 1652.45\n",
      "Training Epoch 64  40.4% | batch:        38 of        94\t|\tloss: 1013.44\n",
      "Training Epoch 64  41.5% | batch:        39 of        94\t|\tloss: 1707.97\n",
      "Training Epoch 64  42.6% | batch:        40 of        94\t|\tloss: 916.727\n",
      "Training Epoch 64  43.6% | batch:        41 of        94\t|\tloss: 2036.91\n",
      "Training Epoch 64  44.7% | batch:        42 of        94\t|\tloss: 1288.25\n",
      "Training Epoch 64  45.7% | batch:        43 of        94\t|\tloss: 1138.76\n",
      "Training Epoch 64  46.8% | batch:        44 of        94\t|\tloss: 1223.04\n",
      "Training Epoch 64  47.9% | batch:        45 of        94\t|\tloss: 834.38\n",
      "Training Epoch 64  48.9% | batch:        46 of        94\t|\tloss: 692.425\n",
      "Training Epoch 64  50.0% | batch:        47 of        94\t|\tloss: 632.678\n",
      "Training Epoch 64  51.1% | batch:        48 of        94\t|\tloss: 820.415\n",
      "Training Epoch 64  52.1% | batch:        49 of        94\t|\tloss: 721.389\n",
      "Training Epoch 64  53.2% | batch:        50 of        94\t|\tloss: 946.683\n",
      "Training Epoch 64  54.3% | batch:        51 of        94\t|\tloss: 944.317\n",
      "Training Epoch 64  55.3% | batch:        52 of        94\t|\tloss: 870.464\n",
      "Training Epoch 64  56.4% | batch:        53 of        94\t|\tloss: 2018.19\n",
      "Training Epoch 64  57.4% | batch:        54 of        94\t|\tloss: 882.865\n",
      "Training Epoch 64  58.5% | batch:        55 of        94\t|\tloss: 1048.67\n",
      "Training Epoch 64  59.6% | batch:        56 of        94\t|\tloss: 1583.22\n",
      "Training Epoch 64  60.6% | batch:        57 of        94\t|\tloss: 905.093\n",
      "Training Epoch 64  61.7% | batch:        58 of        94\t|\tloss: 1598.14\n",
      "Training Epoch 64  62.8% | batch:        59 of        94\t|\tloss: 1055.41\n",
      "Training Epoch 64  63.8% | batch:        60 of        94\t|\tloss: 1540.7\n",
      "Training Epoch 64  64.9% | batch:        61 of        94\t|\tloss: 998.444\n",
      "Training Epoch 64  66.0% | batch:        62 of        94\t|\tloss: 1392.51\n",
      "Training Epoch 64  67.0% | batch:        63 of        94\t|\tloss: 1223.32\n",
      "Training Epoch 64  68.1% | batch:        64 of        94\t|\tloss: 913.181\n",
      "Training Epoch 64  69.1% | batch:        65 of        94\t|\tloss: 1122.91\n",
      "Training Epoch 64  70.2% | batch:        66 of        94\t|\tloss: 1176.33\n",
      "Training Epoch 64  71.3% | batch:        67 of        94\t|\tloss: 1518.88\n",
      "Training Epoch 64  72.3% | batch:        68 of        94\t|\tloss: 1319.79\n",
      "Training Epoch 64  73.4% | batch:        69 of        94\t|\tloss: 1133.48\n",
      "Training Epoch 64  74.5% | batch:        70 of        94\t|\tloss: 887.693\n",
      "Training Epoch 64  75.5% | batch:        71 of        94\t|\tloss: 1375.08\n",
      "Training Epoch 64  76.6% | batch:        72 of        94\t|\tloss: 795.347\n",
      "Training Epoch 64  77.7% | batch:        73 of        94\t|\tloss: 984.56\n",
      "Training Epoch 64  78.7% | batch:        74 of        94\t|\tloss: 3473.69\n",
      "Training Epoch 64  79.8% | batch:        75 of        94\t|\tloss: 897.72\n",
      "Training Epoch 64  80.9% | batch:        76 of        94\t|\tloss: 2993.68\n",
      "Training Epoch 64  81.9% | batch:        77 of        94\t|\tloss: 676.72\n",
      "Training Epoch 64  83.0% | batch:        78 of        94\t|\tloss: 1062.6\n",
      "Training Epoch 64  84.0% | batch:        79 of        94\t|\tloss: 910.875\n",
      "Training Epoch 64  85.1% | batch:        80 of        94\t|\tloss: 821.706\n",
      "Training Epoch 64  86.2% | batch:        81 of        94\t|\tloss: 2375.96\n",
      "Training Epoch 64  87.2% | batch:        82 of        94\t|\tloss: 914.864\n",
      "Training Epoch 64  88.3% | batch:        83 of        94\t|\tloss: 984.674\n",
      "Training Epoch 64  89.4% | batch:        84 of        94\t|\tloss: 1123.3\n",
      "Training Epoch 64  90.4% | batch:        85 of        94\t|\tloss: 927.601\n",
      "Training Epoch 64  91.5% | batch:        86 of        94\t|\tloss: 825.884\n",
      "Training Epoch 64  92.6% | batch:        87 of        94\t|\tloss: 914.286\n",
      "Training Epoch 64  93.6% | batch:        88 of        94\t|\tloss: 1096.7\n",
      "Training Epoch 64  94.7% | batch:        89 of        94\t|\tloss: 871.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:01,409 | INFO : Epoch 64 Training Summary: epoch: 64.000000 | loss: 1157.101938 | \n",
      "2023-05-04 17:01:01,410 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7965607643127441 seconds\n",
      "\n",
      "2023-05-04 17:01:01,410 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.782158374786377 seconds\n",
      "2023-05-04 17:01:01,411 | INFO : Avg batch train. time: 0.018959131646663584 seconds\n",
      "2023-05-04 17:01:01,412 | INFO : Avg sample train. time: 0.00014953502053921606 seconds\n",
      "2023-05-04 17:01:01,412 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 64  95.7% | batch:        90 of        94\t|\tloss: 1229.37\n",
      "Training Epoch 64  96.8% | batch:        91 of        94\t|\tloss: 769.216\n",
      "Training Epoch 64  97.9% | batch:        92 of        94\t|\tloss: 2391.84\n",
      "Training Epoch 64  98.9% | batch:        93 of        94\t|\tloss: 690.925\n",
      "\n",
      "Evaluating Epoch 64   0.0% | batch:         0 of        40\t|\tloss: 6590.24\n",
      "Evaluating Epoch 64   2.5% | batch:         1 of        40\t|\tloss: 970.105\n",
      "Evaluating Epoch 64   5.0% | batch:         2 of        40\t|\tloss: 3019.22\n",
      "Evaluating Epoch 64   7.5% | batch:         3 of        40\t|\tloss: 6644.6\n",
      "Evaluating Epoch 64  10.0% | batch:         4 of        40\t|\tloss: 2641.28\n",
      "Evaluating Epoch 64  12.5% | batch:         5 of        40\t|\tloss: 2622.72\n",
      "Evaluating Epoch 64  15.0% | batch:         6 of        40\t|\tloss: 7866.02\n",
      "Evaluating Epoch 64  17.5% | batch:         7 of        40\t|\tloss: 3234.68\n",
      "Evaluating Epoch 64  20.0% | batch:         8 of        40\t|\tloss: 2721.59\n",
      "Evaluating Epoch 64  22.5% | batch:         9 of        40\t|\tloss: 1697.84\n",
      "Evaluating Epoch 64  25.0% | batch:        10 of        40\t|\tloss: 4306.16\n",
      "Evaluating Epoch 64  27.5% | batch:        11 of        40\t|\tloss: 1226.02\n",
      "Evaluating Epoch 64  30.0% | batch:        12 of        40\t|\tloss: 7026.42\n",
      "Evaluating Epoch 64  32.5% | batch:        13 of        40\t|\tloss: 2667.74\n",
      "Evaluating Epoch 64  35.0% | batch:        14 of        40\t|\tloss: 1919.82\n",
      "Evaluating Epoch 64  37.5% | batch:        15 of        40\t|\tloss: 3500.97\n",
      "Evaluating Epoch 64  40.0% | batch:        16 of        40\t|\tloss: 5115.22\n",
      "Evaluating Epoch 64  42.5% | batch:        17 of        40\t|\tloss: 2843.65\n",
      "Evaluating Epoch 64  45.0% | batch:        18 of        40\t|\tloss: 2242.69\n",
      "Evaluating Epoch 64  47.5% | batch:        19 of        40\t|\tloss: 4572.67\n",
      "Evaluating Epoch 64  50.0% | batch:        20 of        40\t|\tloss: 4597.94\n",
      "Evaluating Epoch 64  52.5% | batch:        21 of        40\t|\tloss: 987.453\n",
      "Evaluating Epoch 64  55.0% | batch:        22 of        40\t|\tloss: 3607.11\n",
      "Evaluating Epoch 64  57.5% | batch:        23 of        40\t|\tloss: 2605.27\n",
      "Evaluating Epoch 64  60.0% | batch:        24 of        40\t|\tloss: 1587.79\n",
      "Evaluating Epoch 64  62.5% | batch:        25 of        40\t|\tloss: 3371.55\n",
      "Evaluating Epoch 64  65.0% | batch:        26 of        40\t|\tloss: 10470.7\n",
      "Evaluating Epoch 64  67.5% | batch:        27 of        40\t|\tloss: 2531.58\n",
      "Evaluating Epoch 64  70.0% | batch:        28 of        40\t|\tloss: 2139.19\n",
      "Evaluating Epoch 64  72.5% | batch:        29 of        40\t|\tloss: 8351.65\n",
      "Evaluating Epoch 64  75.0% | batch:        30 of        40\t|\tloss: 1656.47\n",
      "Evaluating Epoch 64  77.5% | batch:        31 of        40\t|\tloss: 1751.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:01,861 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44835972785949707 seconds\n",
      "\n",
      "2023-05-04 17:01:01,862 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5331059199113112 seconds\n",
      "2023-05-04 17:01:01,862 | INFO : Avg batch val. time: 0.01332764799778278 seconds\n",
      "2023-05-04 17:01:01,863 | INFO : Avg sample val. time: 0.00010560735338972091 seconds\n",
      "2023-05-04 17:01:01,863 | INFO : Epoch 64 Validation Summary: epoch: 64.000000 | loss: 3927.666698 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 64  80.0% | batch:        32 of        40\t|\tloss: 7244.06\n",
      "Evaluating Epoch 64  82.5% | batch:        33 of        40\t|\tloss: 5885.98\n",
      "Evaluating Epoch 64  85.0% | batch:        34 of        40\t|\tloss: 1084.69\n",
      "Evaluating Epoch 64  87.5% | batch:        35 of        40\t|\tloss: 5745.95\n",
      "Evaluating Epoch 64  90.0% | batch:        36 of        40\t|\tloss: 5687.56\n",
      "Evaluating Epoch 64  92.5% | batch:        37 of        40\t|\tloss: 2425.35\n",
      "Evaluating Epoch 64  95.0% | batch:        38 of        40\t|\tloss: 3893.33\n",
      "Evaluating Epoch 64  97.5% | batch:        39 of        40\t|\tloss: 13353.8\n",
      "\n",
      "Training Epoch 65   0.0% | batch:         0 of        94\t|\tloss: 1153.47\n",
      "Training Epoch 65   1.1% | batch:         1 of        94\t|\tloss: 1023.46\n",
      "Training Epoch 65   2.1% | batch:         2 of        94\t|\tloss: 1115.79\n",
      "Training Epoch 65   3.2% | batch:         3 of        94\t|\tloss: 938.379\n",
      "Training Epoch 65   4.3% | batch:         4 of        94\t|\tloss: 722.675\n",
      "Training Epoch 65   5.3% | batch:         5 of        94\t|\tloss: 905.691\n",
      "Training Epoch 65   6.4% | batch:         6 of        94\t|\tloss: 1398.72\n",
      "Training Epoch 65   7.4% | batch:         7 of        94\t|\tloss: 1354.21\n",
      "Training Epoch 65   8.5% | batch:         8 of        94\t|\tloss: 1302.91\n",
      "Training Epoch 65   9.6% | batch:         9 of        94\t|\tloss: 681.33\n",
      "Training Epoch 65  10.6% | batch:        10 of        94\t|\tloss: 630.876\n",
      "Training Epoch 65  11.7% | batch:        11 of        94\t|\tloss: 863.275\n",
      "Training Epoch 65  12.8% | batch:        12 of        94\t|\tloss: 823.375\n",
      "Training Epoch 65  13.8% | batch:        13 of        94\t|\tloss: 685.6\n",
      "Training Epoch 65  14.9% | batch:        14 of        94\t|\tloss: 1111.93\n",
      "Training Epoch 65  16.0% | batch:        15 of        94\t|\tloss: 840.647\n",
      "Training Epoch 65  17.0% | batch:        16 of        94\t|\tloss: 1237.23\n",
      "Training Epoch 65  18.1% | batch:        17 of        94\t|\tloss: 1213.75\n",
      "Training Epoch 65  19.1% | batch:        18 of        94\t|\tloss: 1246.71\n",
      "Training Epoch 65  20.2% | batch:        19 of        94\t|\tloss: 2547.92\n",
      "Training Epoch 65  21.3% | batch:        20 of        94\t|\tloss: 790.108\n",
      "Training Epoch 65  22.3% | batch:        21 of        94\t|\tloss: 1526.22\n",
      "Training Epoch 65  23.4% | batch:        22 of        94\t|\tloss: 986.531\n",
      "Training Epoch 65  24.5% | batch:        23 of        94\t|\tloss: 776.434\n",
      "Training Epoch 65  25.5% | batch:        24 of        94\t|\tloss: 834.309\n",
      "Training Epoch 65  26.6% | batch:        25 of        94\t|\tloss: 1316.68\n",
      "Training Epoch 65  27.7% | batch:        26 of        94\t|\tloss: 740.031\n",
      "Training Epoch 65  28.7% | batch:        27 of        94\t|\tloss: 878.208\n",
      "Training Epoch 65  29.8% | batch:        28 of        94\t|\tloss: 1472.69\n",
      "Training Epoch 65  30.9% | batch:        29 of        94\t|\tloss: 1158.97\n",
      "Training Epoch 65  31.9% | batch:        30 of        94\t|\tloss: 900.654\n",
      "Training Epoch 65  33.0% | batch:        31 of        94\t|\tloss: 2950.4\n",
      "Training Epoch 65  34.0% | batch:        32 of        94\t|\tloss: 912.462\n",
      "Training Epoch 65  35.1% | batch:        33 of        94\t|\tloss: 1040.32\n",
      "Training Epoch 65  36.2% | batch:        34 of        94\t|\tloss: 750.588\n",
      "Training Epoch 65  37.2% | batch:        35 of        94\t|\tloss: 2762.24\n",
      "Training Epoch 65  38.3% | batch:        36 of        94\t|\tloss: 873.419\n",
      "Training Epoch 65  39.4% | batch:        37 of        94\t|\tloss: 1330.09\n",
      "Training Epoch 65  40.4% | batch:        38 of        94\t|\tloss: 935.277\n",
      "Training Epoch 65  41.5% | batch:        39 of        94\t|\tloss: 806.623\n",
      "Training Epoch 65  42.6% | batch:        40 of        94\t|\tloss: 1509.76\n",
      "Training Epoch 65  43.6% | batch:        41 of        94\t|\tloss: 976.886\n",
      "Training Epoch 65  44.7% | batch:        42 of        94\t|\tloss: 1405.94\n",
      "Training Epoch 65  45.7% | batch:        43 of        94\t|\tloss: 1812.7\n",
      "Training Epoch 65  46.8% | batch:        44 of        94\t|\tloss: 738.382\n",
      "Training Epoch 65  47.9% | batch:        45 of        94\t|\tloss: 1459.09\n",
      "Training Epoch 65  48.9% | batch:        46 of        94\t|\tloss: 1182.99\n",
      "Training Epoch 65  50.0% | batch:        47 of        94\t|\tloss: 1411.86\n",
      "Training Epoch 65  51.1% | batch:        48 of        94\t|\tloss: 975.195\n",
      "Training Epoch 65  52.1% | batch:        49 of        94\t|\tloss: 1591.39\n",
      "Training Epoch 65  53.2% | batch:        50 of        94\t|\tloss: 740.265\n",
      "Training Epoch 65  54.3% | batch:        51 of        94\t|\tloss: 1647.63\n",
      "Training Epoch 65  55.3% | batch:        52 of        94\t|\tloss: 989.322\n",
      "Training Epoch 65  56.4% | batch:        53 of        94\t|\tloss: 826.039\n",
      "Training Epoch 65  57.4% | batch:        54 of        94\t|\tloss: 2463.87\n",
      "Training Epoch 65  58.5% | batch:        55 of        94\t|\tloss: 1025.22\n",
      "Training Epoch 65  59.6% | batch:        56 of        94\t|\tloss: 2066.91\n",
      "Training Epoch 65  60.6% | batch:        57 of        94\t|\tloss: 989.055\n",
      "Training Epoch 65  61.7% | batch:        58 of        94\t|\tloss: 716.376\n",
      "Training Epoch 65  62.8% | batch:        59 of        94\t|\tloss: 1040.59\n",
      "Training Epoch 65  63.8% | batch:        60 of        94\t|\tloss: 957.787\n",
      "Training Epoch 65  64.9% | batch:        61 of        94\t|\tloss: 1029.53\n",
      "Training Epoch 65  66.0% | batch:        62 of        94\t|\tloss: 1108.91\n",
      "Training Epoch 65  67.0% | batch:        63 of        94\t|\tloss: 1352.06\n",
      "Training Epoch 65  68.1% | batch:        64 of        94\t|\tloss: 2302.7\n",
      "Training Epoch 65  69.1% | batch:        65 of        94\t|\tloss: 1567.77\n",
      "Training Epoch 65  70.2% | batch:        66 of        94\t|\tloss: 930.244\n",
      "Training Epoch 65  71.3% | batch:        67 of        94\t|\tloss: 1114.76\n",
      "Training Epoch 65  72.3% | batch:        68 of        94\t|\tloss: 1259.86\n",
      "Training Epoch 65  73.4% | batch:        69 of        94\t|\tloss: 918.349\n",
      "Training Epoch 65  74.5% | batch:        70 of        94\t|\tloss: 1036.57\n",
      "Training Epoch 65  75.5% | batch:        71 of        94\t|\tloss: 890.709\n",
      "Training Epoch 65  76.6% | batch:        72 of        94\t|\tloss: 749.084\n",
      "Training Epoch 65  77.7% | batch:        73 of        94\t|\tloss: 790.24\n",
      "Training Epoch 65  78.7% | batch:        74 of        94\t|\tloss: 840.771\n",
      "Training Epoch 65  79.8% | batch:        75 of        94\t|\tloss: 3500.57\n",
      "Training Epoch 65  80.9% | batch:        76 of        94\t|\tloss: 759.352\n",
      "Training Epoch 65  81.9% | batch:        77 of        94\t|\tloss: 1411.51\n",
      "Training Epoch 65  83.0% | batch:        78 of        94\t|\tloss: 1070.54\n",
      "Training Epoch 65  84.0% | batch:        79 of        94\t|\tloss: 1049.51\n",
      "Training Epoch 65  85.1% | batch:        80 of        94\t|\tloss: 1187.2\n",
      "Training Epoch 65  86.2% | batch:        81 of        94\t|\tloss: 1232.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:03,679 | INFO : Epoch 65 Training Summary: epoch: 65.000000 | loss: 1184.917074 | \n",
      "2023-05-04 17:01:03,680 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7948768138885498 seconds\n",
      "\n",
      "2023-05-04 17:01:03,681 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7823540430802565 seconds\n",
      "2023-05-04 17:01:03,682 | INFO : Avg batch train. time: 0.018961213224258047 seconds\n",
      "2023-05-04 17:01:03,682 | INFO : Avg sample train. time: 0.00014955143841921938 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 65  87.2% | batch:        82 of        94\t|\tloss: 855.121\n",
      "Training Epoch 65  88.3% | batch:        83 of        94\t|\tloss: 688.671\n",
      "Training Epoch 65  89.4% | batch:        84 of        94\t|\tloss: 967.417\n",
      "Training Epoch 65  90.4% | batch:        85 of        94\t|\tloss: 1172.13\n",
      "Training Epoch 65  91.5% | batch:        86 of        94\t|\tloss: 872.225\n",
      "Training Epoch 65  92.6% | batch:        87 of        94\t|\tloss: 1090.87\n",
      "Training Epoch 65  93.6% | batch:        88 of        94\t|\tloss: 1002.96\n",
      "Training Epoch 65  94.7% | batch:        89 of        94\t|\tloss: 1285.1\n",
      "Training Epoch 65  95.7% | batch:        90 of        94\t|\tloss: 1743.37\n",
      "Training Epoch 65  96.8% | batch:        91 of        94\t|\tloss: 1287.32\n",
      "Training Epoch 65  97.9% | batch:        92 of        94\t|\tloss: 1035.27\n",
      "Training Epoch 65  98.9% | batch:        93 of        94\t|\tloss: 1426.31\n",
      "\n",
      "Training Epoch 66   0.0% | batch:         0 of        94\t|\tloss: 662.155\n",
      "Training Epoch 66   1.1% | batch:         1 of        94\t|\tloss: 1347.22\n",
      "Training Epoch 66   2.1% | batch:         2 of        94\t|\tloss: 1116.66\n",
      "Training Epoch 66   3.2% | batch:         3 of        94\t|\tloss: 916.114\n",
      "Training Epoch 66   4.3% | batch:         4 of        94\t|\tloss: 853.907\n",
      "Training Epoch 66   5.3% | batch:         5 of        94\t|\tloss: 1533.19\n",
      "Training Epoch 66   6.4% | batch:         6 of        94\t|\tloss: 679.738\n",
      "Training Epoch 66   7.4% | batch:         7 of        94\t|\tloss: 1156.05\n",
      "Training Epoch 66   8.5% | batch:         8 of        94\t|\tloss: 943.108\n",
      "Training Epoch 66   9.6% | batch:         9 of        94\t|\tloss: 1374.8\n",
      "Training Epoch 66  10.6% | batch:        10 of        94\t|\tloss: 1030.06\n",
      "Training Epoch 66  11.7% | batch:        11 of        94\t|\tloss: 892.086\n",
      "Training Epoch 66  12.8% | batch:        12 of        94\t|\tloss: 813.752\n",
      "Training Epoch 66  13.8% | batch:        13 of        94\t|\tloss: 1173.93\n",
      "Training Epoch 66  14.9% | batch:        14 of        94\t|\tloss: 1533.3\n",
      "Training Epoch 66  16.0% | batch:        15 of        94\t|\tloss: 1205.6\n",
      "Training Epoch 66  17.0% | batch:        16 of        94\t|\tloss: 858.486\n",
      "Training Epoch 66  18.1% | batch:        17 of        94\t|\tloss: 873.52\n",
      "Training Epoch 66  19.1% | batch:        18 of        94\t|\tloss: 1123.55\n",
      "Training Epoch 66  20.2% | batch:        19 of        94\t|\tloss: 809.095\n",
      "Training Epoch 66  21.3% | batch:        20 of        94\t|\tloss: 879.399\n",
      "Training Epoch 66  22.3% | batch:        21 of        94\t|\tloss: 806.88\n",
      "Training Epoch 66  23.4% | batch:        22 of        94\t|\tloss: 917.98\n",
      "Training Epoch 66  24.5% | batch:        23 of        94\t|\tloss: 907.592\n",
      "Training Epoch 66  25.5% | batch:        24 of        94\t|\tloss: 791.028\n",
      "Training Epoch 66  26.6% | batch:        25 of        94\t|\tloss: 1155.11\n",
      "Training Epoch 66  27.7% | batch:        26 of        94\t|\tloss: 808.445\n",
      "Training Epoch 66  28.7% | batch:        27 of        94\t|\tloss: 1847.26\n",
      "Training Epoch 66  29.8% | batch:        28 of        94\t|\tloss: 917.991\n",
      "Training Epoch 66  30.9% | batch:        29 of        94\t|\tloss: 847.012\n",
      "Training Epoch 66  31.9% | batch:        30 of        94\t|\tloss: 729.762\n",
      "Training Epoch 66  33.0% | batch:        31 of        94\t|\tloss: 1048.86\n",
      "Training Epoch 66  34.0% | batch:        32 of        94\t|\tloss: 1235.71\n",
      "Training Epoch 66  35.1% | batch:        33 of        94\t|\tloss: 1104.68\n",
      "Training Epoch 66  36.2% | batch:        34 of        94\t|\tloss: 1032.6\n",
      "Training Epoch 66  37.2% | batch:        35 of        94\t|\tloss: 3308.25\n",
      "Training Epoch 66  38.3% | batch:        36 of        94\t|\tloss: 1681.15\n",
      "Training Epoch 66  39.4% | batch:        37 of        94\t|\tloss: 1112.97\n",
      "Training Epoch 66  40.4% | batch:        38 of        94\t|\tloss: 849.632\n",
      "Training Epoch 66  41.5% | batch:        39 of        94\t|\tloss: 1074.33\n",
      "Training Epoch 66  42.6% | batch:        40 of        94\t|\tloss: 1068.42\n",
      "Training Epoch 66  43.6% | batch:        41 of        94\t|\tloss: 1433.52\n",
      "Training Epoch 66  44.7% | batch:        42 of        94\t|\tloss: 2383.08\n",
      "Training Epoch 66  45.7% | batch:        43 of        94\t|\tloss: 792.367\n",
      "Training Epoch 66  46.8% | batch:        44 of        94\t|\tloss: 1793.29\n",
      "Training Epoch 66  47.9% | batch:        45 of        94\t|\tloss: 1483.41\n",
      "Training Epoch 66  48.9% | batch:        46 of        94\t|\tloss: 1034.53\n",
      "Training Epoch 66  50.0% | batch:        47 of        94\t|\tloss: 870.239\n",
      "Training Epoch 66  51.1% | batch:        48 of        94\t|\tloss: 904.001\n",
      "Training Epoch 66  52.1% | batch:        49 of        94\t|\tloss: 1179.65\n",
      "Training Epoch 66  53.2% | batch:        50 of        94\t|\tloss: 931.785\n",
      "Training Epoch 66  54.3% | batch:        51 of        94\t|\tloss: 1632.86\n",
      "Training Epoch 66  55.3% | batch:        52 of        94\t|\tloss: 1503.8\n",
      "Training Epoch 66  56.4% | batch:        53 of        94\t|\tloss: 1245.89\n",
      "Training Epoch 66  57.4% | batch:        54 of        94\t|\tloss: 882.481\n",
      "Training Epoch 66  58.5% | batch:        55 of        94\t|\tloss: 990.628\n",
      "Training Epoch 66  59.6% | batch:        56 of        94\t|\tloss: 860.088\n",
      "Training Epoch 66  60.6% | batch:        57 of        94\t|\tloss: 1186.38\n",
      "Training Epoch 66  61.7% | batch:        58 of        94\t|\tloss: 1030.13\n",
      "Training Epoch 66  62.8% | batch:        59 of        94\t|\tloss: 1277.94\n",
      "Training Epoch 66  63.8% | batch:        60 of        94\t|\tloss: 788.089\n",
      "Training Epoch 66  64.9% | batch:        61 of        94\t|\tloss: 1484.15\n",
      "Training Epoch 66  66.0% | batch:        62 of        94\t|\tloss: 1149.82\n",
      "Training Epoch 66  67.0% | batch:        63 of        94\t|\tloss: 1165.38\n",
      "Training Epoch 66  68.1% | batch:        64 of        94\t|\tloss: 1071.08\n",
      "Training Epoch 66  69.1% | batch:        65 of        94\t|\tloss: 1172.47\n",
      "Training Epoch 66  70.2% | batch:        66 of        94\t|\tloss: 1235.17\n",
      "Training Epoch 66  71.3% | batch:        67 of        94\t|\tloss: 919.78\n",
      "Training Epoch 66  72.3% | batch:        68 of        94\t|\tloss: 919.335\n",
      "Training Epoch 66  73.4% | batch:        69 of        94\t|\tloss: 903.786\n",
      "Training Epoch 66  74.5% | batch:        70 of        94\t|\tloss: 1206.39\n",
      "Training Epoch 66  75.5% | batch:        71 of        94\t|\tloss: 761.585\n",
      "Training Epoch 66  76.6% | batch:        72 of        94\t|\tloss: 752.103\n",
      "Training Epoch 66  77.7% | batch:        73 of        94\t|\tloss: 802.882\n",
      "Training Epoch 66  78.7% | batch:        74 of        94\t|\tloss: 1196.38\n",
      "Training Epoch 66  79.8% | batch:        75 of        94\t|\tloss: 895.116\n",
      "Training Epoch 66  80.9% | batch:        76 of        94\t|\tloss: 861.088\n",
      "Training Epoch 66  81.9% | batch:        77 of        94\t|\tloss: 1459.95\n",
      "Training Epoch 66  83.0% | batch:        78 of        94\t|\tloss: 913.701\n",
      "Training Epoch 66  84.0% | batch:        79 of        94\t|\tloss: 969.801\n",
      "Training Epoch 66  85.1% | batch:        80 of        94\t|\tloss: 974.338\n",
      "Training Epoch 66  86.2% | batch:        81 of        94\t|\tloss: 595.099\n",
      "Training Epoch 66  87.2% | batch:        82 of        94\t|\tloss: 829.525\n",
      "Training Epoch 66  88.3% | batch:        83 of        94\t|\tloss: 1800.48\n",
      "Training Epoch 66  89.4% | batch:        84 of        94\t|\tloss: 1741.29\n",
      "Training Epoch 66  90.4% | batch:        85 of        94\t|\tloss: 1077.25\n",
      "Training Epoch 66  91.5% | batch:        86 of        94\t|\tloss: 1869.3\n",
      "Training Epoch 66  92.6% | batch:        87 of        94\t|\tloss: 1289.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:05,510 | INFO : Epoch 66 Training Summary: epoch: 66.000000 | loss: 1152.226706 | \n",
      "2023-05-04 17:01:05,511 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.806917667388916 seconds\n",
      "\n",
      "2023-05-04 17:01:05,511 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7827262192061453 seconds\n",
      "2023-05-04 17:01:05,512 | INFO : Avg batch train. time: 0.018965172544746226 seconds\n",
      "2023-05-04 17:01:05,513 | INFO : Avg sample train. time: 0.00014958266648818134 seconds\n",
      "2023-05-04 17:01:05,513 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 66  93.6% | batch:        88 of        94\t|\tloss: 1296.28\n",
      "Training Epoch 66  94.7% | batch:        89 of        94\t|\tloss: 1437.79\n",
      "Training Epoch 66  95.7% | batch:        90 of        94\t|\tloss: 1589.25\n",
      "Training Epoch 66  96.8% | batch:        91 of        94\t|\tloss: 1469.84\n",
      "Training Epoch 66  97.9% | batch:        92 of        94\t|\tloss: 1973.06\n",
      "Training Epoch 66  98.9% | batch:        93 of        94\t|\tloss: 2508.37\n",
      "\n",
      "Evaluating Epoch 66   0.0% | batch:         0 of        40\t|\tloss: 7340\n",
      "Evaluating Epoch 66   2.5% | batch:         1 of        40\t|\tloss: 1066.38\n",
      "Evaluating Epoch 66   5.0% | batch:         2 of        40\t|\tloss: 2923.29\n",
      "Evaluating Epoch 66   7.5% | batch:         3 of        40\t|\tloss: 6947.63\n",
      "Evaluating Epoch 66  10.0% | batch:         4 of        40\t|\tloss: 2829.16\n",
      "Evaluating Epoch 66  12.5% | batch:         5 of        40\t|\tloss: 2136.62\n",
      "Evaluating Epoch 66  15.0% | batch:         6 of        40\t|\tloss: 8115.48\n",
      "Evaluating Epoch 66  17.5% | batch:         7 of        40\t|\tloss: 3825.13\n",
      "Evaluating Epoch 66  20.0% | batch:         8 of        40\t|\tloss: 2786.14\n",
      "Evaluating Epoch 66  22.5% | batch:         9 of        40\t|\tloss: 1976.72\n",
      "Evaluating Epoch 66  25.0% | batch:        10 of        40\t|\tloss: 4685.08\n",
      "Evaluating Epoch 66  27.5% | batch:        11 of        40\t|\tloss: 1302.15\n",
      "Evaluating Epoch 66  30.0% | batch:        12 of        40\t|\tloss: 6751.13\n",
      "Evaluating Epoch 66  32.5% | batch:        13 of        40\t|\tloss: 3451.1\n",
      "Evaluating Epoch 66  35.0% | batch:        14 of        40\t|\tloss: 1774.17\n",
      "Evaluating Epoch 66  37.5% | batch:        15 of        40\t|\tloss: 3607.6\n",
      "Evaluating Epoch 66  40.0% | batch:        16 of        40\t|\tloss: 5115.65\n",
      "Evaluating Epoch 66  42.5% | batch:        17 of        40\t|\tloss: 2902.12\n",
      "Evaluating Epoch 66  45.0% | batch:        18 of        40\t|\tloss: 2470.24\n",
      "Evaluating Epoch 66  47.5% | batch:        19 of        40\t|\tloss: 5955.8\n",
      "Evaluating Epoch 66  50.0% | batch:        20 of        40\t|\tloss: 5738.49\n",
      "Evaluating Epoch 66  52.5% | batch:        21 of        40\t|\tloss: 894.319\n",
      "Evaluating Epoch 66  55.0% | batch:        22 of        40\t|\tloss: 3589.35\n",
      "Evaluating Epoch 66  57.5% | batch:        23 of        40\t|\tloss: 2926.82\n",
      "Evaluating Epoch 66  60.0% | batch:        24 of        40\t|\tloss: 1533.77\n",
      "Evaluating Epoch 66  62.5% | batch:        25 of        40\t|\tloss: 3722.37\n",
      "Evaluating Epoch 66  65.0% | batch:        26 of        40\t|\tloss: 11563.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:05,964 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45004892349243164 seconds\n",
      "\n",
      "2023-05-04 17:01:05,965 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5326821597255006 seconds\n",
      "2023-05-04 17:01:05,965 | INFO : Avg batch val. time: 0.013317053993137516 seconds\n",
      "2023-05-04 17:01:05,966 | INFO : Avg sample val. time: 0.00010552340723563799 seconds\n",
      "2023-05-04 17:01:05,967 | INFO : Epoch 66 Validation Summary: epoch: 66.000000 | loss: 4155.714448 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 66  67.5% | batch:        27 of        40\t|\tloss: 2499.31\n",
      "Evaluating Epoch 66  70.0% | batch:        28 of        40\t|\tloss: 2137.78\n",
      "Evaluating Epoch 66  72.5% | batch:        29 of        40\t|\tloss: 8997.14\n",
      "Evaluating Epoch 66  75.0% | batch:        30 of        40\t|\tloss: 1619.73\n",
      "Evaluating Epoch 66  77.5% | batch:        31 of        40\t|\tloss: 1493.81\n",
      "Evaluating Epoch 66  80.0% | batch:        32 of        40\t|\tloss: 7649.12\n",
      "Evaluating Epoch 66  82.5% | batch:        33 of        40\t|\tloss: 6657.99\n",
      "Evaluating Epoch 66  85.0% | batch:        34 of        40\t|\tloss: 950.365\n",
      "Evaluating Epoch 66  87.5% | batch:        35 of        40\t|\tloss: 5207.96\n",
      "Evaluating Epoch 66  90.0% | batch:        36 of        40\t|\tloss: 6313.28\n",
      "Evaluating Epoch 66  92.5% | batch:        37 of        40\t|\tloss: 2357.29\n",
      "Evaluating Epoch 66  95.0% | batch:        38 of        40\t|\tloss: 3875.29\n",
      "Evaluating Epoch 66  97.5% | batch:        39 of        40\t|\tloss: 14174.7\n",
      "\n",
      "Training Epoch 67   0.0% | batch:         0 of        94\t|\tloss: 1155.88\n",
      "Training Epoch 67   1.1% | batch:         1 of        94\t|\tloss: 1112.54\n",
      "Training Epoch 67   2.1% | batch:         2 of        94\t|\tloss: 985.851\n",
      "Training Epoch 67   3.2% | batch:         3 of        94\t|\tloss: 1078.98\n",
      "Training Epoch 67   4.3% | batch:         4 of        94\t|\tloss: 1082.11\n",
      "Training Epoch 67   5.3% | batch:         5 of        94\t|\tloss: 1024.11\n",
      "Training Epoch 67   6.4% | batch:         6 of        94\t|\tloss: 1108.89\n",
      "Training Epoch 67   7.4% | batch:         7 of        94\t|\tloss: 899.172\n",
      "Training Epoch 67   8.5% | batch:         8 of        94\t|\tloss: 1011.23\n",
      "Training Epoch 67   9.6% | batch:         9 of        94\t|\tloss: 693.786\n",
      "Training Epoch 67  10.6% | batch:        10 of        94\t|\tloss: 1190\n",
      "Training Epoch 67  11.7% | batch:        11 of        94\t|\tloss: 814.811\n",
      "Training Epoch 67  12.8% | batch:        12 of        94\t|\tloss: 1049.87\n",
      "Training Epoch 67  13.8% | batch:        13 of        94\t|\tloss: 692.098\n",
      "Training Epoch 67  14.9% | batch:        14 of        94\t|\tloss: 830.865\n",
      "Training Epoch 67  16.0% | batch:        15 of        94\t|\tloss: 2942.51\n",
      "Training Epoch 67  17.0% | batch:        16 of        94\t|\tloss: 1880.13\n",
      "Training Epoch 67  18.1% | batch:        17 of        94\t|\tloss: 987.676\n",
      "Training Epoch 67  19.1% | batch:        18 of        94\t|\tloss: 891.416\n",
      "Training Epoch 67  20.2% | batch:        19 of        94\t|\tloss: 868.323\n",
      "Training Epoch 67  21.3% | batch:        20 of        94\t|\tloss: 743.216\n",
      "Training Epoch 67  22.3% | batch:        21 of        94\t|\tloss: 835.472\n",
      "Training Epoch 67  23.4% | batch:        22 of        94\t|\tloss: 822.118\n",
      "Training Epoch 67  24.5% | batch:        23 of        94\t|\tloss: 1116.37\n",
      "Training Epoch 67  25.5% | batch:        24 of        94\t|\tloss: 952.715\n",
      "Training Epoch 67  26.6% | batch:        25 of        94\t|\tloss: 1893.71\n",
      "Training Epoch 67  27.7% | batch:        26 of        94\t|\tloss: 1087.17\n",
      "Training Epoch 67  28.7% | batch:        27 of        94\t|\tloss: 1206.23\n",
      "Training Epoch 67  29.8% | batch:        28 of        94\t|\tloss: 2275.9\n",
      "Training Epoch 67  30.9% | batch:        29 of        94\t|\tloss: 950.987\n",
      "Training Epoch 67  31.9% | batch:        30 of        94\t|\tloss: 1019.28\n",
      "Training Epoch 67  33.0% | batch:        31 of        94\t|\tloss: 761.764\n",
      "Training Epoch 67  34.0% | batch:        32 of        94\t|\tloss: 800.43\n",
      "Training Epoch 67  35.1% | batch:        33 of        94\t|\tloss: 913.717\n",
      "Training Epoch 67  36.2% | batch:        34 of        94\t|\tloss: 1528.07\n",
      "Training Epoch 67  37.2% | batch:        35 of        94\t|\tloss: 864.329\n",
      "Training Epoch 67  38.3% | batch:        36 of        94\t|\tloss: 1350.3\n",
      "Training Epoch 67  39.4% | batch:        37 of        94\t|\tloss: 739.369\n",
      "Training Epoch 67  40.4% | batch:        38 of        94\t|\tloss: 2383.81\n",
      "Training Epoch 67  41.5% | batch:        39 of        94\t|\tloss: 1030.01\n",
      "Training Epoch 67  42.6% | batch:        40 of        94\t|\tloss: 1214.93\n",
      "Training Epoch 67  43.6% | batch:        41 of        94\t|\tloss: 879.895\n",
      "Training Epoch 67  44.7% | batch:        42 of        94\t|\tloss: 683.762\n",
      "Training Epoch 67  45.7% | batch:        43 of        94\t|\tloss: 1006.91\n",
      "Training Epoch 67  46.8% | batch:        44 of        94\t|\tloss: 856.21\n",
      "Training Epoch 67  47.9% | batch:        45 of        94\t|\tloss: 671.469\n",
      "Training Epoch 67  48.9% | batch:        46 of        94\t|\tloss: 951.434\n",
      "Training Epoch 67  50.0% | batch:        47 of        94\t|\tloss: 1527.27\n",
      "Training Epoch 67  51.1% | batch:        48 of        94\t|\tloss: 1952.61\n",
      "Training Epoch 67  52.1% | batch:        49 of        94\t|\tloss: 1798.95\n",
      "Training Epoch 67  53.2% | batch:        50 of        94\t|\tloss: 1021.47\n",
      "Training Epoch 67  54.3% | batch:        51 of        94\t|\tloss: 1699.75\n",
      "Training Epoch 67  55.3% | batch:        52 of        94\t|\tloss: 1021.33\n",
      "Training Epoch 67  56.4% | batch:        53 of        94\t|\tloss: 1405.76\n",
      "Training Epoch 67  57.4% | batch:        54 of        94\t|\tloss: 1495.39\n",
      "Training Epoch 67  58.5% | batch:        55 of        94\t|\tloss: 1334.27\n",
      "Training Epoch 67  59.6% | batch:        56 of        94\t|\tloss: 842.226\n",
      "Training Epoch 67  60.6% | batch:        57 of        94\t|\tloss: 1001.5\n",
      "Training Epoch 67  61.7% | batch:        58 of        94\t|\tloss: 1428.96\n",
      "Training Epoch 67  62.8% | batch:        59 of        94\t|\tloss: 1272.83\n",
      "Training Epoch 67  63.8% | batch:        60 of        94\t|\tloss: 988.755\n",
      "Training Epoch 67  64.9% | batch:        61 of        94\t|\tloss: 1295.21\n",
      "Training Epoch 67  66.0% | batch:        62 of        94\t|\tloss: 1288.72\n",
      "Training Epoch 67  67.0% | batch:        63 of        94\t|\tloss: 930.099\n",
      "Training Epoch 67  68.1% | batch:        64 of        94\t|\tloss: 1122.02\n",
      "Training Epoch 67  69.1% | batch:        65 of        94\t|\tloss: 806.578\n",
      "Training Epoch 67  70.2% | batch:        66 of        94\t|\tloss: 990.562\n",
      "Training Epoch 67  71.3% | batch:        67 of        94\t|\tloss: 1297.51\n",
      "Training Epoch 67  72.3% | batch:        68 of        94\t|\tloss: 893.688\n",
      "Training Epoch 67  73.4% | batch:        69 of        94\t|\tloss: 768.177\n",
      "Training Epoch 67  74.5% | batch:        70 of        94\t|\tloss: 1428.79\n",
      "Training Epoch 67  75.5% | batch:        71 of        94\t|\tloss: 1098.59\n",
      "Training Epoch 67  76.6% | batch:        72 of        94\t|\tloss: 1217.29\n",
      "Training Epoch 67  77.7% | batch:        73 of        94\t|\tloss: 1105.3\n",
      "Training Epoch 67  78.7% | batch:        74 of        94\t|\tloss: 1700.76\n",
      "Training Epoch 67  79.8% | batch:        75 of        94\t|\tloss: 1575.96\n",
      "Training Epoch 67  80.9% | batch:        76 of        94\t|\tloss: 1098.66\n",
      "Training Epoch 67  81.9% | batch:        77 of        94\t|\tloss: 1100.07\n",
      "Training Epoch 67  83.0% | batch:        78 of        94\t|\tloss: 1136.86\n",
      "Training Epoch 67  84.0% | batch:        79 of        94\t|\tloss: 881.366\n",
      "Training Epoch 67  85.1% | batch:        80 of        94\t|\tloss: 870.176\n",
      "Training Epoch 67  86.2% | batch:        81 of        94\t|\tloss: 961.598\n",
      "Training Epoch 67  87.2% | batch:        82 of        94\t|\tloss: 1562.29\n",
      "Training Epoch 67  88.3% | batch:        83 of        94\t|\tloss: 1203.25\n",
      "Training Epoch 67  89.4% | batch:        84 of        94\t|\tloss: 966.317\n",
      "Training Epoch 67  90.4% | batch:        85 of        94\t|\tloss: 1029.17\n",
      "Training Epoch 67  91.5% | batch:        86 of        94\t|\tloss: 1264.22\n",
      "Training Epoch 67  92.6% | batch:        87 of        94\t|\tloss: 898.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:07,814 | INFO : Epoch 67 Training Summary: epoch: 67.000000 | loss: 1132.813212 | \n",
      "2023-05-04 17:01:07,815 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8258042335510254 seconds\n",
      "\n",
      "2023-05-04 17:01:07,815 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7833691746441287 seconds\n",
      "2023-05-04 17:01:07,816 | INFO : Avg batch train. time: 0.018972012496214136 seconds\n",
      "2023-05-04 17:01:07,817 | INFO : Avg sample train. time: 0.0001496366147544998 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 67  93.6% | batch:        88 of        94\t|\tloss: 780.074\n",
      "Training Epoch 67  94.7% | batch:        89 of        94\t|\tloss: 914.817\n",
      "Training Epoch 67  95.7% | batch:        90 of        94\t|\tloss: 879.07\n",
      "Training Epoch 67  96.8% | batch:        91 of        94\t|\tloss: 970.03\n",
      "Training Epoch 67  97.9% | batch:        92 of        94\t|\tloss: 744.012\n",
      "Training Epoch 67  98.9% | batch:        93 of        94\t|\tloss: 589.779\n",
      "\n",
      "Training Epoch 68   0.0% | batch:         0 of        94\t|\tloss: 770.493\n",
      "Training Epoch 68   1.1% | batch:         1 of        94\t|\tloss: 1495.62\n",
      "Training Epoch 68   2.1% | batch:         2 of        94\t|\tloss: 936.011\n",
      "Training Epoch 68   3.2% | batch:         3 of        94\t|\tloss: 928.608\n",
      "Training Epoch 68   4.3% | batch:         4 of        94\t|\tloss: 986.975\n",
      "Training Epoch 68   5.3% | batch:         5 of        94\t|\tloss: 1165.24\n",
      "Training Epoch 68   6.4% | batch:         6 of        94\t|\tloss: 1177.95\n",
      "Training Epoch 68   7.4% | batch:         7 of        94\t|\tloss: 1656.48\n",
      "Training Epoch 68   8.5% | batch:         8 of        94\t|\tloss: 982.218\n",
      "Training Epoch 68   9.6% | batch:         9 of        94\t|\tloss: 1448.97\n",
      "Training Epoch 68  10.6% | batch:        10 of        94\t|\tloss: 859.254\n",
      "Training Epoch 68  11.7% | batch:        11 of        94\t|\tloss: 2074.59\n",
      "Training Epoch 68  12.8% | batch:        12 of        94\t|\tloss: 1517.13\n",
      "Training Epoch 68  13.8% | batch:        13 of        94\t|\tloss: 791.109\n",
      "Training Epoch 68  14.9% | batch:        14 of        94\t|\tloss: 1615.96\n",
      "Training Epoch 68  16.0% | batch:        15 of        94\t|\tloss: 1698.25\n",
      "Training Epoch 68  17.0% | batch:        16 of        94\t|\tloss: 1137.02\n",
      "Training Epoch 68  18.1% | batch:        17 of        94\t|\tloss: 1105.24\n",
      "Training Epoch 68  19.1% | batch:        18 of        94\t|\tloss: 951.031\n",
      "Training Epoch 68  20.2% | batch:        19 of        94\t|\tloss: 1402.48\n",
      "Training Epoch 68  21.3% | batch:        20 of        94\t|\tloss: 896.953\n",
      "Training Epoch 68  22.3% | batch:        21 of        94\t|\tloss: 735.718\n",
      "Training Epoch 68  23.4% | batch:        22 of        94\t|\tloss: 768.654\n",
      "Training Epoch 68  24.5% | batch:        23 of        94\t|\tloss: 1557.03\n",
      "Training Epoch 68  25.5% | batch:        24 of        94\t|\tloss: 758.594\n",
      "Training Epoch 68  26.6% | batch:        25 of        94\t|\tloss: 943.032\n",
      "Training Epoch 68  27.7% | batch:        26 of        94\t|\tloss: 746.047\n",
      "Training Epoch 68  28.7% | batch:        27 of        94\t|\tloss: 773.982\n",
      "Training Epoch 68  29.8% | batch:        28 of        94\t|\tloss: 813.506\n",
      "Training Epoch 68  30.9% | batch:        29 of        94\t|\tloss: 918.133\n",
      "Training Epoch 68  31.9% | batch:        30 of        94\t|\tloss: 877.224\n",
      "Training Epoch 68  33.0% | batch:        31 of        94\t|\tloss: 849.852\n",
      "Training Epoch 68  34.0% | batch:        32 of        94\t|\tloss: 1043.23\n",
      "Training Epoch 68  35.1% | batch:        33 of        94\t|\tloss: 1901.1\n",
      "Training Epoch 68  36.2% | batch:        34 of        94\t|\tloss: 981.346\n",
      "Training Epoch 68  37.2% | batch:        35 of        94\t|\tloss: 1001.51\n",
      "Training Epoch 68  38.3% | batch:        36 of        94\t|\tloss: 1117.12\n",
      "Training Epoch 68  39.4% | batch:        37 of        94\t|\tloss: 913.214\n",
      "Training Epoch 68  40.4% | batch:        38 of        94\t|\tloss: 1237.09\n",
      "Training Epoch 68  41.5% | batch:        39 of        94\t|\tloss: 1064.36\n",
      "Training Epoch 68  42.6% | batch:        40 of        94\t|\tloss: 1010.27\n",
      "Training Epoch 68  43.6% | batch:        41 of        94\t|\tloss: 2992.65\n",
      "Training Epoch 68  44.7% | batch:        42 of        94\t|\tloss: 1120.27\n",
      "Training Epoch 68  45.7% | batch:        43 of        94\t|\tloss: 1544.63\n",
      "Training Epoch 68  46.8% | batch:        44 of        94\t|\tloss: 988.562\n",
      "Training Epoch 68  47.9% | batch:        45 of        94\t|\tloss: 1122.89\n",
      "Training Epoch 68  48.9% | batch:        46 of        94\t|\tloss: 1218.41\n",
      "Training Epoch 68  50.0% | batch:        47 of        94\t|\tloss: 1452.48\n",
      "Training Epoch 68  51.1% | batch:        48 of        94\t|\tloss: 703.436\n",
      "Training Epoch 68  52.1% | batch:        49 of        94\t|\tloss: 766.18\n",
      "Training Epoch 68  53.2% | batch:        50 of        94\t|\tloss: 952.097\n",
      "Training Epoch 68  54.3% | batch:        51 of        94\t|\tloss: 686.342\n",
      "Training Epoch 68  55.3% | batch:        52 of        94\t|\tloss: 1058.13\n",
      "Training Epoch 68  56.4% | batch:        53 of        94\t|\tloss: 700.292\n",
      "Training Epoch 68  57.4% | batch:        54 of        94\t|\tloss: 611.903\n",
      "Training Epoch 68  58.5% | batch:        55 of        94\t|\tloss: 840.132\n",
      "Training Epoch 68  59.6% | batch:        56 of        94\t|\tloss: 647.381\n",
      "Training Epoch 68  60.6% | batch:        57 of        94\t|\tloss: 2268.21\n",
      "Training Epoch 68  61.7% | batch:        58 of        94\t|\tloss: 941.62\n",
      "Training Epoch 68  62.8% | batch:        59 of        94\t|\tloss: 1068.78\n",
      "Training Epoch 68  63.8% | batch:        60 of        94\t|\tloss: 672.045\n",
      "Training Epoch 68  64.9% | batch:        61 of        94\t|\tloss: 947.13\n",
      "Training Epoch 68  66.0% | batch:        62 of        94\t|\tloss: 1031.25\n",
      "Training Epoch 68  67.0% | batch:        63 of        94\t|\tloss: 677.51\n",
      "Training Epoch 68  68.1% | batch:        64 of        94\t|\tloss: 978.777\n",
      "Training Epoch 68  69.1% | batch:        65 of        94\t|\tloss: 1329.35\n",
      "Training Epoch 68  70.2% | batch:        66 of        94\t|\tloss: 1571.72\n",
      "Training Epoch 68  71.3% | batch:        67 of        94\t|\tloss: 1299.5\n",
      "Training Epoch 68  72.3% | batch:        68 of        94\t|\tloss: 1158.06\n",
      "Training Epoch 68  73.4% | batch:        69 of        94\t|\tloss: 803.596\n",
      "Training Epoch 68  74.5% | batch:        70 of        94\t|\tloss: 1289.34\n",
      "Training Epoch 68  75.5% | batch:        71 of        94\t|\tloss: 1809.46\n",
      "Training Epoch 68  76.6% | batch:        72 of        94\t|\tloss: 1130.16\n",
      "Training Epoch 68  77.7% | batch:        73 of        94\t|\tloss: 735.813\n",
      "Training Epoch 68  78.7% | batch:        74 of        94\t|\tloss: 1744.83\n",
      "Training Epoch 68  79.8% | batch:        75 of        94\t|\tloss: 836.063\n",
      "Training Epoch 68  80.9% | batch:        76 of        94\t|\tloss: 1289.82\n",
      "Training Epoch 68  81.9% | batch:        77 of        94\t|\tloss: 1009.18\n",
      "Training Epoch 68  83.0% | batch:        78 of        94\t|\tloss: 677.786\n",
      "Training Epoch 68  84.0% | batch:        79 of        94\t|\tloss: 1381.1\n",
      "Training Epoch 68  85.1% | batch:        80 of        94\t|\tloss: 1202.78\n",
      "Training Epoch 68  86.2% | batch:        81 of        94\t|\tloss: 629.451\n",
      "Training Epoch 68  87.2% | batch:        82 of        94\t|\tloss: 1941.89\n",
      "Training Epoch 68  88.3% | batch:        83 of        94\t|\tloss: 889.62\n",
      "Training Epoch 68  89.4% | batch:        84 of        94\t|\tloss: 847.129\n",
      "Training Epoch 68  90.4% | batch:        85 of        94\t|\tloss: 718.621\n",
      "Training Epoch 68  91.5% | batch:        86 of        94\t|\tloss: 655.212\n",
      "Training Epoch 68  92.6% | batch:        87 of        94\t|\tloss: 680.197\n",
      "Training Epoch 68  93.6% | batch:        88 of        94\t|\tloss: 845.106\n",
      "Training Epoch 68  94.7% | batch:        89 of        94\t|\tloss: 1782.9\n",
      "Training Epoch 68  95.7% | batch:        90 of        94\t|\tloss: 836.431\n",
      "Training Epoch 68  96.8% | batch:        91 of        94\t|\tloss: 1230.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:09,635 | INFO : Epoch 68 Training Summary: epoch: 68.000000 | loss: 1108.815489 | \n",
      "2023-05-04 17:01:09,636 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7971060276031494 seconds\n",
      "\n",
      "2023-05-04 17:01:09,636 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7835711871876436 seconds\n",
      "2023-05-04 17:01:09,637 | INFO : Avg batch train. time: 0.018974161565825997 seconds\n",
      "2023-05-04 17:01:09,637 | INFO : Avg sample train. time: 0.00014965356495952708 seconds\n",
      "2023-05-04 17:01:09,638 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 68  97.9% | batch:        92 of        94\t|\tloss: 1204.55\n",
      "Training Epoch 68  98.9% | batch:        93 of        94\t|\tloss: 1013.91\n",
      "\n",
      "Evaluating Epoch 68   0.0% | batch:         0 of        40\t|\tloss: 7555.12\n",
      "Evaluating Epoch 68   2.5% | batch:         1 of        40\t|\tloss: 995.94\n",
      "Evaluating Epoch 68   5.0% | batch:         2 of        40\t|\tloss: 2672.61\n",
      "Evaluating Epoch 68   7.5% | batch:         3 of        40\t|\tloss: 6583.45\n",
      "Evaluating Epoch 68  10.0% | batch:         4 of        40\t|\tloss: 3086.05\n",
      "Evaluating Epoch 68  12.5% | batch:         5 of        40\t|\tloss: 2714.5\n",
      "Evaluating Epoch 68  15.0% | batch:         6 of        40\t|\tloss: 8268.2\n",
      "Evaluating Epoch 68  17.5% | batch:         7 of        40\t|\tloss: 3601.83\n",
      "Evaluating Epoch 68  20.0% | batch:         8 of        40\t|\tloss: 2882.05\n",
      "Evaluating Epoch 68  22.5% | batch:         9 of        40\t|\tloss: 1948.14\n",
      "Evaluating Epoch 68  25.0% | batch:        10 of        40\t|\tloss: 5074.5\n",
      "Evaluating Epoch 68  27.5% | batch:        11 of        40\t|\tloss: 1528.75\n",
      "Evaluating Epoch 68  30.0% | batch:        12 of        40\t|\tloss: 7346.64\n",
      "Evaluating Epoch 68  32.5% | batch:        13 of        40\t|\tloss: 3203.02\n",
      "Evaluating Epoch 68  35.0% | batch:        14 of        40\t|\tloss: 2199.22\n",
      "Evaluating Epoch 68  37.5% | batch:        15 of        40\t|\tloss: 3359.61\n",
      "Evaluating Epoch 68  40.0% | batch:        16 of        40\t|\tloss: 4228.54\n",
      "Evaluating Epoch 68  42.5% | batch:        17 of        40\t|\tloss: 3100.18\n",
      "Evaluating Epoch 68  45.0% | batch:        18 of        40\t|\tloss: 2387.85\n",
      "Evaluating Epoch 68  47.5% | batch:        19 of        40\t|\tloss: 4524.66\n",
      "Evaluating Epoch 68  50.0% | batch:        20 of        40\t|\tloss: 5232.54\n",
      "Evaluating Epoch 68  52.5% | batch:        21 of        40\t|\tloss: 1246.57\n",
      "Evaluating Epoch 68  55.0% | batch:        22 of        40\t|\tloss: 3098.74\n",
      "Evaluating Epoch 68  57.5% | batch:        23 of        40\t|\tloss: 3260.42\n",
      "Evaluating Epoch 68  60.0% | batch:        24 of        40\t|\tloss: 1732.04\n",
      "Evaluating Epoch 68  62.5% | batch:        25 of        40\t|\tloss: 3841.63\n",
      "Evaluating Epoch 68  65.0% | batch:        26 of        40\t|\tloss: 11090.8\n",
      "Evaluating Epoch 68  67.5% | batch:        27 of        40\t|\tloss: 3234.1\n",
      "Evaluating Epoch 68  70.0% | batch:        28 of        40\t|\tloss: 2150.06\n",
      "Evaluating Epoch 68  72.5% | batch:        29 of        40\t|\tloss: 8369.52\n",
      "Evaluating Epoch 68  75.0% | batch:        30 of        40\t|\tloss: 2020.59\n",
      "Evaluating Epoch 68  77.5% | batch:        31 of        40\t|\tloss: 1557.87\n",
      "Evaluating Epoch 68  80.0% | batch:        32 of        40\t|\tloss: 7183.09\n",
      "Evaluating Epoch 68  82.5% | batch:        33 of        40\t|\tloss: 6180.26\n",
      "Evaluating Epoch 68  85.0% | batch:        34 of        40\t|\tloss: 1247.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:10,087 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4482095241546631 seconds\n",
      "\n",
      "2023-05-04 17:01:10,088 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5322533646210801 seconds\n",
      "2023-05-04 17:01:10,088 | INFO : Avg batch val. time: 0.013306334115527002 seconds\n",
      "2023-05-04 17:01:10,089 | INFO : Avg sample val. time: 0.00010543846367295564 seconds\n",
      "2023-05-04 17:01:10,090 | INFO : Epoch 68 Validation Summary: epoch: 68.000000 | loss: 4106.189159 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 68  87.5% | batch:        35 of        40\t|\tloss: 4811.13\n",
      "Evaluating Epoch 68  90.0% | batch:        36 of        40\t|\tloss: 6299.5\n",
      "Evaluating Epoch 68  92.5% | batch:        37 of        40\t|\tloss: 2880.08\n",
      "Evaluating Epoch 68  95.0% | batch:        38 of        40\t|\tloss: 3597.61\n",
      "Evaluating Epoch 68  97.5% | batch:        39 of        40\t|\tloss: 12898.5\n",
      "\n",
      "Training Epoch 69   0.0% | batch:         0 of        94\t|\tloss: 1466.84\n",
      "Training Epoch 69   1.1% | batch:         1 of        94\t|\tloss: 1134.61\n",
      "Training Epoch 69   2.1% | batch:         2 of        94\t|\tloss: 1034.54\n",
      "Training Epoch 69   3.2% | batch:         3 of        94\t|\tloss: 944.92\n",
      "Training Epoch 69   4.3% | batch:         4 of        94\t|\tloss: 2045.02\n",
      "Training Epoch 69   5.3% | batch:         5 of        94\t|\tloss: 1086.71\n",
      "Training Epoch 69   6.4% | batch:         6 of        94\t|\tloss: 1579.8\n",
      "Training Epoch 69   7.4% | batch:         7 of        94\t|\tloss: 1073.8\n",
      "Training Epoch 69   8.5% | batch:         8 of        94\t|\tloss: 972.03\n",
      "Training Epoch 69   9.6% | batch:         9 of        94\t|\tloss: 910.722\n",
      "Training Epoch 69  10.6% | batch:        10 of        94\t|\tloss: 829.407\n",
      "Training Epoch 69  11.7% | batch:        11 of        94\t|\tloss: 973.204\n",
      "Training Epoch 69  12.8% | batch:        12 of        94\t|\tloss: 893.08\n",
      "Training Epoch 69  13.8% | batch:        13 of        94\t|\tloss: 584.478\n",
      "Training Epoch 69  14.9% | batch:        14 of        94\t|\tloss: 1030.09\n",
      "Training Epoch 69  16.0% | batch:        15 of        94\t|\tloss: 648.411\n",
      "Training Epoch 69  17.0% | batch:        16 of        94\t|\tloss: 840.669\n",
      "Training Epoch 69  18.1% | batch:        17 of        94\t|\tloss: 827.818\n",
      "Training Epoch 69  19.1% | batch:        18 of        94\t|\tloss: 753.11\n",
      "Training Epoch 69  20.2% | batch:        19 of        94\t|\tloss: 1074.96\n",
      "Training Epoch 69  21.3% | batch:        20 of        94\t|\tloss: 1339.9\n",
      "Training Epoch 69  22.3% | batch:        21 of        94\t|\tloss: 2160.16\n",
      "Training Epoch 69  23.4% | batch:        22 of        94\t|\tloss: 867.559\n",
      "Training Epoch 69  24.5% | batch:        23 of        94\t|\tloss: 1111.21\n",
      "Training Epoch 69  25.5% | batch:        24 of        94\t|\tloss: 669.432\n",
      "Training Epoch 69  26.6% | batch:        25 of        94\t|\tloss: 882.91\n",
      "Training Epoch 69  27.7% | batch:        26 of        94\t|\tloss: 2143.68\n",
      "Training Epoch 69  28.7% | batch:        27 of        94\t|\tloss: 910.113\n",
      "Training Epoch 69  29.8% | batch:        28 of        94\t|\tloss: 2123.26\n",
      "Training Epoch 69  30.9% | batch:        29 of        94\t|\tloss: 1145.22\n",
      "Training Epoch 69  31.9% | batch:        30 of        94\t|\tloss: 1891.8\n",
      "Training Epoch 69  33.0% | batch:        31 of        94\t|\tloss: 1915.78\n",
      "Training Epoch 69  34.0% | batch:        32 of        94\t|\tloss: 2057.39\n",
      "Training Epoch 69  35.1% | batch:        33 of        94\t|\tloss: 902.329\n",
      "Training Epoch 69  36.2% | batch:        34 of        94\t|\tloss: 830.737\n",
      "Training Epoch 69  37.2% | batch:        35 of        94\t|\tloss: 1433.08\n",
      "Training Epoch 69  38.3% | batch:        36 of        94\t|\tloss: 697.464\n",
      "Training Epoch 69  39.4% | batch:        37 of        94\t|\tloss: 585.513\n",
      "Training Epoch 69  40.4% | batch:        38 of        94\t|\tloss: 856.894\n",
      "Training Epoch 69  41.5% | batch:        39 of        94\t|\tloss: 911.758\n",
      "Training Epoch 69  42.6% | batch:        40 of        94\t|\tloss: 1069.68\n",
      "Training Epoch 69  43.6% | batch:        41 of        94\t|\tloss: 968.728\n",
      "Training Epoch 69  44.7% | batch:        42 of        94\t|\tloss: 1094.65\n",
      "Training Epoch 69  45.7% | batch:        43 of        94\t|\tloss: 980.916\n",
      "Training Epoch 69  46.8% | batch:        44 of        94\t|\tloss: 982.161\n",
      "Training Epoch 69  47.9% | batch:        45 of        94\t|\tloss: 845.325\n",
      "Training Epoch 69  48.9% | batch:        46 of        94\t|\tloss: 1315.59\n",
      "Training Epoch 69  50.0% | batch:        47 of        94\t|\tloss: 766.89\n",
      "Training Epoch 69  51.1% | batch:        48 of        94\t|\tloss: 729.678\n",
      "Training Epoch 69  52.1% | batch:        49 of        94\t|\tloss: 848.482\n",
      "Training Epoch 69  53.2% | batch:        50 of        94\t|\tloss: 1727.14\n",
      "Training Epoch 69  54.3% | batch:        51 of        94\t|\tloss: 1007.72\n",
      "Training Epoch 69  55.3% | batch:        52 of        94\t|\tloss: 812.622\n",
      "Training Epoch 69  56.4% | batch:        53 of        94\t|\tloss: 936.932\n",
      "Training Epoch 69  57.4% | batch:        54 of        94\t|\tloss: 775.779\n",
      "Training Epoch 69  58.5% | batch:        55 of        94\t|\tloss: 832.987\n",
      "Training Epoch 69  59.6% | batch:        56 of        94\t|\tloss: 1691.13\n",
      "Training Epoch 69  60.6% | batch:        57 of        94\t|\tloss: 770.931\n",
      "Training Epoch 69  61.7% | batch:        58 of        94\t|\tloss: 1458.38\n",
      "Training Epoch 69  62.8% | batch:        59 of        94\t|\tloss: 946.867\n",
      "Training Epoch 69  63.8% | batch:        60 of        94\t|\tloss: 2737.63\n",
      "Training Epoch 69  64.9% | batch:        61 of        94\t|\tloss: 685.975\n",
      "Training Epoch 69  66.0% | batch:        62 of        94\t|\tloss: 1351.05\n",
      "Training Epoch 69  67.0% | batch:        63 of        94\t|\tloss: 878.983\n",
      "Training Epoch 69  68.1% | batch:        64 of        94\t|\tloss: 812.038\n",
      "Training Epoch 69  69.1% | batch:        65 of        94\t|\tloss: 830.99\n",
      "Training Epoch 69  70.2% | batch:        66 of        94\t|\tloss: 987.133\n",
      "Training Epoch 69  71.3% | batch:        67 of        94\t|\tloss: 980.943\n",
      "Training Epoch 69  72.3% | batch:        68 of        94\t|\tloss: 1475.55\n",
      "Training Epoch 69  73.4% | batch:        69 of        94\t|\tloss: 820.247\n",
      "Training Epoch 69  74.5% | batch:        70 of        94\t|\tloss: 1846.53\n",
      "Training Epoch 69  75.5% | batch:        71 of        94\t|\tloss: 882.11\n",
      "Training Epoch 69  76.6% | batch:        72 of        94\t|\tloss: 1498.8\n",
      "Training Epoch 69  77.7% | batch:        73 of        94\t|\tloss: 1003.25\n",
      "Training Epoch 69  78.7% | batch:        74 of        94\t|\tloss: 859.239\n",
      "Training Epoch 69  79.8% | batch:        75 of        94\t|\tloss: 1233.62\n",
      "Training Epoch 69  80.9% | batch:        76 of        94\t|\tloss: 1299.51\n",
      "Training Epoch 69  81.9% | batch:        77 of        94\t|\tloss: 1060.25\n",
      "Training Epoch 69  83.0% | batch:        78 of        94\t|\tloss: 1743.25\n",
      "Training Epoch 69  84.0% | batch:        79 of        94\t|\tloss: 1048.94\n",
      "Training Epoch 69  85.1% | batch:        80 of        94\t|\tloss: 1646.49\n",
      "Training Epoch 69  86.2% | batch:        81 of        94\t|\tloss: 1071.21\n",
      "Training Epoch 69  87.2% | batch:        82 of        94\t|\tloss: 1292.09\n",
      "Training Epoch 69  88.3% | batch:        83 of        94\t|\tloss: 1049.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:11,881 | INFO : Epoch 69 Training Summary: epoch: 69.000000 | loss: 1123.373223 | \n",
      "2023-05-04 17:01:11,882 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7701663970947266 seconds\n",
      "\n",
      "2023-05-04 17:01:11,882 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7833769148674563 seconds\n",
      "2023-05-04 17:01:11,883 | INFO : Avg batch train. time: 0.018972094839015494 seconds\n",
      "2023-05-04 17:01:11,884 | INFO : Avg sample train. time: 0.00014963726421106364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 69  89.4% | batch:        84 of        94\t|\tloss: 978.106\n",
      "Training Epoch 69  90.4% | batch:        85 of        94\t|\tloss: 1103.54\n",
      "Training Epoch 69  91.5% | batch:        86 of        94\t|\tloss: 1221.06\n",
      "Training Epoch 69  92.6% | batch:        87 of        94\t|\tloss: 957.952\n",
      "Training Epoch 69  93.6% | batch:        88 of        94\t|\tloss: 1061.55\n",
      "Training Epoch 69  94.7% | batch:        89 of        94\t|\tloss: 1017.24\n",
      "Training Epoch 69  95.7% | batch:        90 of        94\t|\tloss: 762.427\n",
      "Training Epoch 69  96.8% | batch:        91 of        94\t|\tloss: 748.197\n",
      "Training Epoch 69  97.9% | batch:        92 of        94\t|\tloss: 674.808\n",
      "Training Epoch 69  98.9% | batch:        93 of        94\t|\tloss: 2497.9\n",
      "\n",
      "Training Epoch 70   0.0% | batch:         0 of        94\t|\tloss: 1337\n",
      "Training Epoch 70   1.1% | batch:         1 of        94\t|\tloss: 785.629\n",
      "Training Epoch 70   2.1% | batch:         2 of        94\t|\tloss: 853.988\n",
      "Training Epoch 70   3.2% | batch:         3 of        94\t|\tloss: 1259.7\n",
      "Training Epoch 70   4.3% | batch:         4 of        94\t|\tloss: 2561.51\n",
      "Training Epoch 70   5.3% | batch:         5 of        94\t|\tloss: 1585.09\n",
      "Training Epoch 70   6.4% | batch:         6 of        94\t|\tloss: 1287.38\n",
      "Training Epoch 70   7.4% | batch:         7 of        94\t|\tloss: 1411.91\n",
      "Training Epoch 70   8.5% | batch:         8 of        94\t|\tloss: 967.246\n",
      "Training Epoch 70   9.6% | batch:         9 of        94\t|\tloss: 1153.82\n",
      "Training Epoch 70  10.6% | batch:        10 of        94\t|\tloss: 923.338\n",
      "Training Epoch 70  11.7% | batch:        11 of        94\t|\tloss: 1628.15\n",
      "Training Epoch 70  12.8% | batch:        12 of        94\t|\tloss: 1349.24\n",
      "Training Epoch 70  13.8% | batch:        13 of        94\t|\tloss: 1101.32\n",
      "Training Epoch 70  14.9% | batch:        14 of        94\t|\tloss: 1360.96\n",
      "Training Epoch 70  16.0% | batch:        15 of        94\t|\tloss: 810.769\n",
      "Training Epoch 70  17.0% | batch:        16 of        94\t|\tloss: 1775.02\n",
      "Training Epoch 70  18.1% | batch:        17 of        94\t|\tloss: 948.742\n",
      "Training Epoch 70  19.1% | batch:        18 of        94\t|\tloss: 1288.13\n",
      "Training Epoch 70  20.2% | batch:        19 of        94\t|\tloss: 1085.1\n",
      "Training Epoch 70  21.3% | batch:        20 of        94\t|\tloss: 733.08\n",
      "Training Epoch 70  22.3% | batch:        21 of        94\t|\tloss: 1356.02\n",
      "Training Epoch 70  23.4% | batch:        22 of        94\t|\tloss: 1041.26\n",
      "Training Epoch 70  24.5% | batch:        23 of        94\t|\tloss: 1053.74\n",
      "Training Epoch 70  25.5% | batch:        24 of        94\t|\tloss: 1070.92\n",
      "Training Epoch 70  26.6% | batch:        25 of        94\t|\tloss: 954.618\n",
      "Training Epoch 70  27.7% | batch:        26 of        94\t|\tloss: 1055.1\n",
      "Training Epoch 70  28.7% | batch:        27 of        94\t|\tloss: 697.516\n",
      "Training Epoch 70  29.8% | batch:        28 of        94\t|\tloss: 1108.21\n",
      "Training Epoch 70  30.9% | batch:        29 of        94\t|\tloss: 1001.01\n",
      "Training Epoch 70  31.9% | batch:        30 of        94\t|\tloss: 831.385\n",
      "Training Epoch 70  33.0% | batch:        31 of        94\t|\tloss: 799.744\n",
      "Training Epoch 70  34.0% | batch:        32 of        94\t|\tloss: 1611.78\n",
      "Training Epoch 70  35.1% | batch:        33 of        94\t|\tloss: 1211.52\n",
      "Training Epoch 70  36.2% | batch:        34 of        94\t|\tloss: 933.604\n",
      "Training Epoch 70  37.2% | batch:        35 of        94\t|\tloss: 774.917\n",
      "Training Epoch 70  38.3% | batch:        36 of        94\t|\tloss: 1052.67\n",
      "Training Epoch 70  39.4% | batch:        37 of        94\t|\tloss: 972.44\n",
      "Training Epoch 70  40.4% | batch:        38 of        94\t|\tloss: 742.073\n",
      "Training Epoch 70  41.5% | batch:        39 of        94\t|\tloss: 800.939\n",
      "Training Epoch 70  42.6% | batch:        40 of        94\t|\tloss: 883.325\n",
      "Training Epoch 70  43.6% | batch:        41 of        94\t|\tloss: 913.592\n",
      "Training Epoch 70  44.7% | batch:        42 of        94\t|\tloss: 1163.97\n",
      "Training Epoch 70  45.7% | batch:        43 of        94\t|\tloss: 942.734\n",
      "Training Epoch 70  46.8% | batch:        44 of        94\t|\tloss: 797.348\n",
      "Training Epoch 70  47.9% | batch:        45 of        94\t|\tloss: 819.597\n",
      "Training Epoch 70  48.9% | batch:        46 of        94\t|\tloss: 959.762\n",
      "Training Epoch 70  50.0% | batch:        47 of        94\t|\tloss: 809.242\n",
      "Training Epoch 70  51.1% | batch:        48 of        94\t|\tloss: 902.708\n",
      "Training Epoch 70  52.1% | batch:        49 of        94\t|\tloss: 1636.59\n",
      "Training Epoch 70  53.2% | batch:        50 of        94\t|\tloss: 1094.96\n",
      "Training Epoch 70  54.3% | batch:        51 of        94\t|\tloss: 1858.16\n",
      "Training Epoch 70  55.3% | batch:        52 of        94\t|\tloss: 856.04\n",
      "Training Epoch 70  56.4% | batch:        53 of        94\t|\tloss: 1453.32\n",
      "Training Epoch 70  57.4% | batch:        54 of        94\t|\tloss: 1886.44\n",
      "Training Epoch 70  58.5% | batch:        55 of        94\t|\tloss: 1351.37\n",
      "Training Epoch 70  59.6% | batch:        56 of        94\t|\tloss: 1137.28\n",
      "Training Epoch 70  60.6% | batch:        57 of        94\t|\tloss: 974.082\n",
      "Training Epoch 70  61.7% | batch:        58 of        94\t|\tloss: 1277.23\n",
      "Training Epoch 70  62.8% | batch:        59 of        94\t|\tloss: 1005.37\n",
      "Training Epoch 70  63.8% | batch:        60 of        94\t|\tloss: 857.681\n",
      "Training Epoch 70  64.9% | batch:        61 of        94\t|\tloss: 875.041\n",
      "Training Epoch 70  66.0% | batch:        62 of        94\t|\tloss: 935.911\n",
      "Training Epoch 70  67.0% | batch:        63 of        94\t|\tloss: 1426.18\n",
      "Training Epoch 70  68.1% | batch:        64 of        94\t|\tloss: 981.225\n",
      "Training Epoch 70  69.1% | batch:        65 of        94\t|\tloss: 1500.89\n",
      "Training Epoch 70  70.2% | batch:        66 of        94\t|\tloss: 808.837\n",
      "Training Epoch 70  71.3% | batch:        67 of        94\t|\tloss: 717.113\n",
      "Training Epoch 70  72.3% | batch:        68 of        94\t|\tloss: 798.155\n",
      "Training Epoch 70  73.4% | batch:        69 of        94\t|\tloss: 1195.03\n",
      "Training Epoch 70  74.5% | batch:        70 of        94\t|\tloss: 1006.15\n",
      "Training Epoch 70  75.5% | batch:        71 of        94\t|\tloss: 1266.06\n",
      "Training Epoch 70  76.6% | batch:        72 of        94\t|\tloss: 934.743\n",
      "Training Epoch 70  77.7% | batch:        73 of        94\t|\tloss: 1168.06\n",
      "Training Epoch 70  78.7% | batch:        74 of        94\t|\tloss: 908.786\n",
      "Training Epoch 70  79.8% | batch:        75 of        94\t|\tloss: 988.746\n",
      "Training Epoch 70  80.9% | batch:        76 of        94\t|\tloss: 1020.38\n",
      "Training Epoch 70  81.9% | batch:        77 of        94\t|\tloss: 2835.15\n",
      "Training Epoch 70  83.0% | batch:        78 of        94\t|\tloss: 1074.15\n",
      "Training Epoch 70  84.0% | batch:        79 of        94\t|\tloss: 1004.08\n",
      "Training Epoch 70  85.1% | batch:        80 of        94\t|\tloss: 2625.69\n",
      "Training Epoch 70  86.2% | batch:        81 of        94\t|\tloss: 845.62\n",
      "Training Epoch 70  87.2% | batch:        82 of        94\t|\tloss: 1315.99\n",
      "Training Epoch 70  88.3% | batch:        83 of        94\t|\tloss: 902.966\n",
      "Training Epoch 70  89.4% | batch:        84 of        94\t|\tloss: 936.816\n",
      "Training Epoch 70  90.4% | batch:        85 of        94\t|\tloss: 1028.18\n",
      "Training Epoch 70  91.5% | batch:        86 of        94\t|\tloss: 1089.52\n",
      "Training Epoch 70  92.6% | batch:        87 of        94\t|\tloss: 1179.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:13,710 | INFO : Epoch 70 Training Summary: epoch: 70.000000 | loss: 1133.711289 | \n",
      "2023-05-04 17:01:13,711 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8053092956542969 seconds\n",
      "\n",
      "2023-05-04 17:01:13,712 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7836902345929826 seconds\n",
      "2023-05-04 17:01:13,712 | INFO : Avg batch train. time: 0.01897542802758492 seconds\n",
      "2023-05-04 17:01:13,713 | INFO : Avg sample train. time: 0.00014966355383394718 seconds\n",
      "2023-05-04 17:01:13,713 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 70  93.6% | batch:        88 of        94\t|\tloss: 894.658\n",
      "Training Epoch 70  94.7% | batch:        89 of        94\t|\tloss: 1131.05\n",
      "Training Epoch 70  95.7% | batch:        90 of        94\t|\tloss: 943.192\n",
      "Training Epoch 70  96.8% | batch:        91 of        94\t|\tloss: 1258.26\n",
      "Training Epoch 70  97.9% | batch:        92 of        94\t|\tloss: 1020.49\n",
      "Training Epoch 70  98.9% | batch:        93 of        94\t|\tloss: 776.438\n",
      "\n",
      "Evaluating Epoch 70   0.0% | batch:         0 of        40\t|\tloss: 7088.93\n",
      "Evaluating Epoch 70   2.5% | batch:         1 of        40\t|\tloss: 1030.59\n",
      "Evaluating Epoch 70   5.0% | batch:         2 of        40\t|\tloss: 3828.47\n",
      "Evaluating Epoch 70   7.5% | batch:         3 of        40\t|\tloss: 6272.42\n",
      "Evaluating Epoch 70  10.0% | batch:         4 of        40\t|\tloss: 2880.82\n",
      "Evaluating Epoch 70  12.5% | batch:         5 of        40\t|\tloss: 2719.17\n",
      "Evaluating Epoch 70  15.0% | batch:         6 of        40\t|\tloss: 8436.28\n",
      "Evaluating Epoch 70  17.5% | batch:         7 of        40\t|\tloss: 3465.57\n",
      "Evaluating Epoch 70  20.0% | batch:         8 of        40\t|\tloss: 2695.02\n",
      "Evaluating Epoch 70  22.5% | batch:         9 of        40\t|\tloss: 2342.69\n",
      "Evaluating Epoch 70  25.0% | batch:        10 of        40\t|\tloss: 4820.12\n",
      "Evaluating Epoch 70  27.5% | batch:        11 of        40\t|\tloss: 1518.22\n",
      "Evaluating Epoch 70  30.0% | batch:        12 of        40\t|\tloss: 6524.25\n",
      "Evaluating Epoch 70  32.5% | batch:        13 of        40\t|\tloss: 3203.27\n",
      "Evaluating Epoch 70  35.0% | batch:        14 of        40\t|\tloss: 2123.94\n",
      "Evaluating Epoch 70  37.5% | batch:        15 of        40\t|\tloss: 3267.59\n",
      "Evaluating Epoch 70  40.0% | batch:        16 of        40\t|\tloss: 5042.14\n",
      "Evaluating Epoch 70  42.5% | batch:        17 of        40\t|\tloss: 3139.92\n",
      "Evaluating Epoch 70  45.0% | batch:        18 of        40\t|\tloss: 2592.96\n",
      "Evaluating Epoch 70  47.5% | batch:        19 of        40\t|\tloss: 6683.83\n",
      "Evaluating Epoch 70  50.0% | batch:        20 of        40\t|\tloss: 5192.72\n",
      "Evaluating Epoch 70  52.5% | batch:        21 of        40\t|\tloss: 1129.3\n",
      "Evaluating Epoch 70  55.0% | batch:        22 of        40\t|\tloss: 4482.79\n",
      "Evaluating Epoch 70  57.5% | batch:        23 of        40\t|\tloss: 3179.73\n",
      "Evaluating Epoch 70  60.0% | batch:        24 of        40\t|\tloss: 1683.64\n",
      "Evaluating Epoch 70  62.5% | batch:        25 of        40\t|\tloss: 3735.42\n",
      "Evaluating Epoch 70  65.0% | batch:        26 of        40\t|\tloss: 10271.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:14,169 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4554905891418457 seconds\n",
      "\n",
      "2023-05-04 17:01:14,170 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5318656738358315 seconds\n",
      "2023-05-04 17:01:14,171 | INFO : Avg batch val. time: 0.013296641845895787 seconds\n",
      "2023-05-04 17:01:14,172 | INFO : Avg sample val. time: 0.00010536166280424554 seconds\n",
      "2023-05-04 17:01:14,172 | INFO : Epoch 70 Validation Summary: epoch: 70.000000 | loss: 4235.145457 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 70  67.5% | batch:        27 of        40\t|\tloss: 3095.75\n",
      "Evaluating Epoch 70  70.0% | batch:        28 of        40\t|\tloss: 2015.9\n",
      "Evaluating Epoch 70  72.5% | batch:        29 of        40\t|\tloss: 8643.63\n",
      "Evaluating Epoch 70  75.0% | batch:        30 of        40\t|\tloss: 1636.38\n",
      "Evaluating Epoch 70  77.5% | batch:        31 of        40\t|\tloss: 1625.26\n",
      "Evaluating Epoch 70  80.0% | batch:        32 of        40\t|\tloss: 8063.46\n",
      "Evaluating Epoch 70  82.5% | batch:        33 of        40\t|\tloss: 5781.63\n",
      "Evaluating Epoch 70  85.0% | batch:        34 of        40\t|\tloss: 1272.57\n",
      "Evaluating Epoch 70  87.5% | batch:        35 of        40\t|\tloss: 6718.21\n",
      "Evaluating Epoch 70  90.0% | batch:        36 of        40\t|\tloss: 6537.8\n",
      "Evaluating Epoch 70  92.5% | batch:        37 of        40\t|\tloss: 2595.58\n",
      "Evaluating Epoch 70  95.0% | batch:        38 of        40\t|\tloss: 3518.74\n",
      "Evaluating Epoch 70  97.5% | batch:        39 of        40\t|\tloss: 14096.7\n",
      "\n",
      "Training Epoch 71   0.0% | batch:         0 of        94\t|\tloss: 813.166\n",
      "Training Epoch 71   1.1% | batch:         1 of        94\t|\tloss: 998.32\n",
      "Training Epoch 71   2.1% | batch:         2 of        94\t|\tloss: 1250.21\n",
      "Training Epoch 71   3.2% | batch:         3 of        94\t|\tloss: 1441.06\n",
      "Training Epoch 71   4.3% | batch:         4 of        94\t|\tloss: 1105.41\n",
      "Training Epoch 71   5.3% | batch:         5 of        94\t|\tloss: 811.402\n",
      "Training Epoch 71   6.4% | batch:         6 of        94\t|\tloss: 1174.47\n",
      "Training Epoch 71   7.4% | batch:         7 of        94\t|\tloss: 783.295\n",
      "Training Epoch 71   8.5% | batch:         8 of        94\t|\tloss: 1407.5\n",
      "Training Epoch 71   9.6% | batch:         9 of        94\t|\tloss: 927.222\n",
      "Training Epoch 71  10.6% | batch:        10 of        94\t|\tloss: 910.832\n",
      "Training Epoch 71  11.7% | batch:        11 of        94\t|\tloss: 977.26\n",
      "Training Epoch 71  12.8% | batch:        12 of        94\t|\tloss: 770.454\n",
      "Training Epoch 71  13.8% | batch:        13 of        94\t|\tloss: 1220.04\n",
      "Training Epoch 71  14.9% | batch:        14 of        94\t|\tloss: 706.311\n",
      "Training Epoch 71  16.0% | batch:        15 of        94\t|\tloss: 758.019\n",
      "Training Epoch 71  17.0% | batch:        16 of        94\t|\tloss: 809.223\n",
      "Training Epoch 71  18.1% | batch:        17 of        94\t|\tloss: 675.273\n",
      "Training Epoch 71  19.1% | batch:        18 of        94\t|\tloss: 1033.12\n",
      "Training Epoch 71  20.2% | batch:        19 of        94\t|\tloss: 1412.98\n",
      "Training Epoch 71  21.3% | batch:        20 of        94\t|\tloss: 1113.9\n",
      "Training Epoch 71  22.3% | batch:        21 of        94\t|\tloss: 1334.82\n",
      "Training Epoch 71  23.4% | batch:        22 of        94\t|\tloss: 899.803\n",
      "Training Epoch 71  24.5% | batch:        23 of        94\t|\tloss: 937.153\n",
      "Training Epoch 71  25.5% | batch:        24 of        94\t|\tloss: 861.682\n",
      "Training Epoch 71  26.6% | batch:        25 of        94\t|\tloss: 1294.72\n",
      "Training Epoch 71  27.7% | batch:        26 of        94\t|\tloss: 858.979\n",
      "Training Epoch 71  28.7% | batch:        27 of        94\t|\tloss: 900.635\n",
      "Training Epoch 71  29.8% | batch:        28 of        94\t|\tloss: 989.136\n",
      "Training Epoch 71  30.9% | batch:        29 of        94\t|\tloss: 1627.22\n",
      "Training Epoch 71  31.9% | batch:        30 of        94\t|\tloss: 1088.55\n",
      "Training Epoch 71  33.0% | batch:        31 of        94\t|\tloss: 784.615\n",
      "Training Epoch 71  34.0% | batch:        32 of        94\t|\tloss: 707.808\n",
      "Training Epoch 71  35.1% | batch:        33 of        94\t|\tloss: 1640.14\n",
      "Training Epoch 71  36.2% | batch:        34 of        94\t|\tloss: 1772.53\n",
      "Training Epoch 71  37.2% | batch:        35 of        94\t|\tloss: 961.303\n",
      "Training Epoch 71  38.3% | batch:        36 of        94\t|\tloss: 1747.63\n",
      "Training Epoch 71  39.4% | batch:        37 of        94\t|\tloss: 953.208\n",
      "Training Epoch 71  40.4% | batch:        38 of        94\t|\tloss: 765.014\n",
      "Training Epoch 71  41.5% | batch:        39 of        94\t|\tloss: 837.981\n",
      "Training Epoch 71  42.6% | batch:        40 of        94\t|\tloss: 768.741\n",
      "Training Epoch 71  43.6% | batch:        41 of        94\t|\tloss: 891.859\n",
      "Training Epoch 71  44.7% | batch:        42 of        94\t|\tloss: 866.968\n",
      "Training Epoch 71  45.7% | batch:        43 of        94\t|\tloss: 1005.14\n",
      "Training Epoch 71  46.8% | batch:        44 of        94\t|\tloss: 777.336\n",
      "Training Epoch 71  47.9% | batch:        45 of        94\t|\tloss: 1199.28\n",
      "Training Epoch 71  48.9% | batch:        46 of        94\t|\tloss: 852.198\n",
      "Training Epoch 71  50.0% | batch:        47 of        94\t|\tloss: 1808.26\n",
      "Training Epoch 71  51.1% | batch:        48 of        94\t|\tloss: 2417.2\n",
      "Training Epoch 71  52.1% | batch:        49 of        94\t|\tloss: 798.337\n",
      "Training Epoch 71  53.2% | batch:        50 of        94\t|\tloss: 962.038\n",
      "Training Epoch 71  54.3% | batch:        51 of        94\t|\tloss: 2124.42\n",
      "Training Epoch 71  55.3% | batch:        52 of        94\t|\tloss: 792.081\n",
      "Training Epoch 71  56.4% | batch:        53 of        94\t|\tloss: 802.174\n",
      "Training Epoch 71  57.4% | batch:        54 of        94\t|\tloss: 1084.89\n",
      "Training Epoch 71  58.5% | batch:        55 of        94\t|\tloss: 955.11\n",
      "Training Epoch 71  59.6% | batch:        56 of        94\t|\tloss: 1200.9\n",
      "Training Epoch 71  60.6% | batch:        57 of        94\t|\tloss: 951.654\n",
      "Training Epoch 71  61.7% | batch:        58 of        94\t|\tloss: 682.424\n",
      "Training Epoch 71  62.8% | batch:        59 of        94\t|\tloss: 1097.15\n",
      "Training Epoch 71  63.8% | batch:        60 of        94\t|\tloss: 1413.79\n",
      "Training Epoch 71  64.9% | batch:        61 of        94\t|\tloss: 865.252\n",
      "Training Epoch 71  66.0% | batch:        62 of        94\t|\tloss: 522.956\n",
      "Training Epoch 71  67.0% | batch:        63 of        94\t|\tloss: 1025.56\n",
      "Training Epoch 71  68.1% | batch:        64 of        94\t|\tloss: 674.514\n",
      "Training Epoch 71  69.1% | batch:        65 of        94\t|\tloss: 765.994\n",
      "Training Epoch 71  70.2% | batch:        66 of        94\t|\tloss: 2448.29\n",
      "Training Epoch 71  71.3% | batch:        67 of        94\t|\tloss: 876.571\n",
      "Training Epoch 71  72.3% | batch:        68 of        94\t|\tloss: 1124.11\n",
      "Training Epoch 71  73.4% | batch:        69 of        94\t|\tloss: 1325.44\n",
      "Training Epoch 71  74.5% | batch:        70 of        94\t|\tloss: 1340.6\n",
      "Training Epoch 71  75.5% | batch:        71 of        94\t|\tloss: 1236.18\n",
      "Training Epoch 71  76.6% | batch:        72 of        94\t|\tloss: 920.242\n",
      "Training Epoch 71  77.7% | batch:        73 of        94\t|\tloss: 779.768\n",
      "Training Epoch 71  78.7% | batch:        74 of        94\t|\tloss: 725.171\n",
      "Training Epoch 71  79.8% | batch:        75 of        94\t|\tloss: 996.772\n",
      "Training Epoch 71  80.9% | batch:        76 of        94\t|\tloss: 1063.74\n",
      "Training Epoch 71  81.9% | batch:        77 of        94\t|\tloss: 1626.27\n",
      "Training Epoch 71  83.0% | batch:        78 of        94\t|\tloss: 1297.19\n",
      "Training Epoch 71  84.0% | batch:        79 of        94\t|\tloss: 1232.68\n",
      "Training Epoch 71  85.1% | batch:        80 of        94\t|\tloss: 1268.07\n",
      "Training Epoch 71  86.2% | batch:        81 of        94\t|\tloss: 854.039\n",
      "Training Epoch 71  87.2% | batch:        82 of        94\t|\tloss: 825.055\n",
      "Training Epoch 71  88.3% | batch:        83 of        94\t|\tloss: 1085.38\n",
      "Training Epoch 71  89.4% | batch:        84 of        94\t|\tloss: 1085.04\n",
      "Training Epoch 71  90.4% | batch:        85 of        94\t|\tloss: 1107.58\n",
      "Training Epoch 71  91.5% | batch:        86 of        94\t|\tloss: 994.557\n",
      "Training Epoch 71  92.6% | batch:        87 of        94\t|\tloss: 1644.61\n",
      "Training Epoch 71  93.6% | batch:        88 of        94\t|\tloss: 1100.45\n",
      "Training Epoch 71  94.7% | batch:        89 of        94\t|\tloss: 706.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:16,020 | INFO : Epoch 71 Training Summary: epoch: 71.000000 | loss: 1078.837446 | \n",
      "2023-05-04 17:01:16,021 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8269860744476318 seconds\n",
      "\n",
      "2023-05-04 17:01:16,022 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7843000351543157 seconds\n",
      "2023-05-04 17:01:16,023 | INFO : Avg batch train. time: 0.018981915267599105 seconds\n",
      "2023-05-04 17:01:16,023 | INFO : Avg sample train. time: 0.00014971472018411778 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 71  95.7% | batch:        90 of        94\t|\tloss: 786.154\n",
      "Training Epoch 71  96.8% | batch:        91 of        94\t|\tloss: 1805.68\n",
      "Training Epoch 71  97.9% | batch:        92 of        94\t|\tloss: 724.607\n",
      "Training Epoch 71  98.9% | batch:        93 of        94\t|\tloss: 917.917\n",
      "\n",
      "Training Epoch 72   0.0% | batch:         0 of        94\t|\tloss: 1130.05\n",
      "Training Epoch 72   1.1% | batch:         1 of        94\t|\tloss: 885.344\n",
      "Training Epoch 72   2.1% | batch:         2 of        94\t|\tloss: 1001.12\n",
      "Training Epoch 72   3.2% | batch:         3 of        94\t|\tloss: 889.031\n",
      "Training Epoch 72   4.3% | batch:         4 of        94\t|\tloss: 985.385\n",
      "Training Epoch 72   5.3% | batch:         5 of        94\t|\tloss: 905.22\n",
      "Training Epoch 72   6.4% | batch:         6 of        94\t|\tloss: 826.942\n",
      "Training Epoch 72   7.4% | batch:         7 of        94\t|\tloss: 897.908\n",
      "Training Epoch 72   8.5% | batch:         8 of        94\t|\tloss: 2541.14\n",
      "Training Epoch 72   9.6% | batch:         9 of        94\t|\tloss: 1289.2\n",
      "Training Epoch 72  10.6% | batch:        10 of        94\t|\tloss: 886.017\n",
      "Training Epoch 72  11.7% | batch:        11 of        94\t|\tloss: 1041.37\n",
      "Training Epoch 72  12.8% | batch:        12 of        94\t|\tloss: 816.618\n",
      "Training Epoch 72  13.8% | batch:        13 of        94\t|\tloss: 979.585\n",
      "Training Epoch 72  14.9% | batch:        14 of        94\t|\tloss: 933.201\n",
      "Training Epoch 72  16.0% | batch:        15 of        94\t|\tloss: 769.593\n",
      "Training Epoch 72  17.0% | batch:        16 of        94\t|\tloss: 1301.95\n",
      "Training Epoch 72  18.1% | batch:        17 of        94\t|\tloss: 1153.84\n",
      "Training Epoch 72  19.1% | batch:        18 of        94\t|\tloss: 914.261\n",
      "Training Epoch 72  20.2% | batch:        19 of        94\t|\tloss: 1409.53\n",
      "Training Epoch 72  21.3% | batch:        20 of        94\t|\tloss: 990.11\n",
      "Training Epoch 72  22.3% | batch:        21 of        94\t|\tloss: 1346.45\n",
      "Training Epoch 72  23.4% | batch:        22 of        94\t|\tloss: 1024.59\n",
      "Training Epoch 72  24.5% | batch:        23 of        94\t|\tloss: 1365.2\n",
      "Training Epoch 72  25.5% | batch:        24 of        94\t|\tloss: 767.109\n",
      "Training Epoch 72  26.6% | batch:        25 of        94\t|\tloss: 675.364\n",
      "Training Epoch 72  27.7% | batch:        26 of        94\t|\tloss: 684.324\n",
      "Training Epoch 72  28.7% | batch:        27 of        94\t|\tloss: 798.537\n",
      "Training Epoch 72  29.8% | batch:        28 of        94\t|\tloss: 766.271\n",
      "Training Epoch 72  30.9% | batch:        29 of        94\t|\tloss: 1116.13\n",
      "Training Epoch 72  31.9% | batch:        30 of        94\t|\tloss: 714.334\n",
      "Training Epoch 72  33.0% | batch:        31 of        94\t|\tloss: 1248.81\n",
      "Training Epoch 72  34.0% | batch:        32 of        94\t|\tloss: 1313.32\n",
      "Training Epoch 72  35.1% | batch:        33 of        94\t|\tloss: 1853.33\n",
      "Training Epoch 72  36.2% | batch:        34 of        94\t|\tloss: 1713.78\n",
      "Training Epoch 72  37.2% | batch:        35 of        94\t|\tloss: 1283.67\n",
      "Training Epoch 72  38.3% | batch:        36 of        94\t|\tloss: 2273.65\n",
      "Training Epoch 72  39.4% | batch:        37 of        94\t|\tloss: 794.45\n",
      "Training Epoch 72  40.4% | batch:        38 of        94\t|\tloss: 1725.4\n",
      "Training Epoch 72  41.5% | batch:        39 of        94\t|\tloss: 969.167\n",
      "Training Epoch 72  42.6% | batch:        40 of        94\t|\tloss: 1485.07\n",
      "Training Epoch 72  43.6% | batch:        41 of        94\t|\tloss: 983.404\n",
      "Training Epoch 72  44.7% | batch:        42 of        94\t|\tloss: 869.803\n",
      "Training Epoch 72  45.7% | batch:        43 of        94\t|\tloss: 1053.14\n",
      "Training Epoch 72  46.8% | batch:        44 of        94\t|\tloss: 1112.05\n",
      "Training Epoch 72  47.9% | batch:        45 of        94\t|\tloss: 719.117\n",
      "Training Epoch 72  48.9% | batch:        46 of        94\t|\tloss: 750.566\n",
      "Training Epoch 72  50.0% | batch:        47 of        94\t|\tloss: 1439.07\n",
      "Training Epoch 72  51.1% | batch:        48 of        94\t|\tloss: 972.022\n",
      "Training Epoch 72  52.1% | batch:        49 of        94\t|\tloss: 986.481\n",
      "Training Epoch 72  53.2% | batch:        50 of        94\t|\tloss: 2391\n",
      "Training Epoch 72  54.3% | batch:        51 of        94\t|\tloss: 904.839\n",
      "Training Epoch 72  55.3% | batch:        52 of        94\t|\tloss: 672.763\n",
      "Training Epoch 72  56.4% | batch:        53 of        94\t|\tloss: 1075.25\n",
      "Training Epoch 72  57.4% | batch:        54 of        94\t|\tloss: 1041.9\n",
      "Training Epoch 72  58.5% | batch:        55 of        94\t|\tloss: 816.753\n",
      "Training Epoch 72  59.6% | batch:        56 of        94\t|\tloss: 794.078\n",
      "Training Epoch 72  60.6% | batch:        57 of        94\t|\tloss: 1100.58\n",
      "Training Epoch 72  61.7% | batch:        58 of        94\t|\tloss: 942.471\n",
      "Training Epoch 72  62.8% | batch:        59 of        94\t|\tloss: 1293.53\n",
      "Training Epoch 72  63.8% | batch:        60 of        94\t|\tloss: 1820.22\n",
      "Training Epoch 72  64.9% | batch:        61 of        94\t|\tloss: 1410.38\n",
      "Training Epoch 72  66.0% | batch:        62 of        94\t|\tloss: 1202.17\n",
      "Training Epoch 72  67.0% | batch:        63 of        94\t|\tloss: 720.626\n",
      "Training Epoch 72  68.1% | batch:        64 of        94\t|\tloss: 1044.74\n",
      "Training Epoch 72  69.1% | batch:        65 of        94\t|\tloss: 919.157\n",
      "Training Epoch 72  70.2% | batch:        66 of        94\t|\tloss: 796.094\n",
      "Training Epoch 72  71.3% | batch:        67 of        94\t|\tloss: 863.955\n",
      "Training Epoch 72  72.3% | batch:        68 of        94\t|\tloss: 1037.69\n",
      "Training Epoch 72  73.4% | batch:        69 of        94\t|\tloss: 1637.07\n",
      "Training Epoch 72  74.5% | batch:        70 of        94\t|\tloss: 845.255\n",
      "Training Epoch 72  75.5% | batch:        71 of        94\t|\tloss: 854.797\n",
      "Training Epoch 72  76.6% | batch:        72 of        94\t|\tloss: 1075.38\n",
      "Training Epoch 72  77.7% | batch:        73 of        94\t|\tloss: 862.404\n",
      "Training Epoch 72  78.7% | batch:        74 of        94\t|\tloss: 768.361\n",
      "Training Epoch 72  79.8% | batch:        75 of        94\t|\tloss: 736.376\n",
      "Training Epoch 72  80.9% | batch:        76 of        94\t|\tloss: 1605.75\n",
      "Training Epoch 72  81.9% | batch:        77 of        94\t|\tloss: 918.965\n",
      "Training Epoch 72  83.0% | batch:        78 of        94\t|\tloss: 785.305\n",
      "Training Epoch 72  84.0% | batch:        79 of        94\t|\tloss: 2154.74\n",
      "Training Epoch 72  85.1% | batch:        80 of        94\t|\tloss: 596.613\n",
      "Training Epoch 72  86.2% | batch:        81 of        94\t|\tloss: 711.371\n",
      "Training Epoch 72  87.2% | batch:        82 of        94\t|\tloss: 715.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:17,853 | INFO : Epoch 72 Training Summary: epoch: 72.000000 | loss: 1098.072723 | \n",
      "2023-05-04 17:01:17,855 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8097481727600098 seconds\n",
      "\n",
      "2023-05-04 17:01:17,855 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7846534815099504 seconds\n",
      "2023-05-04 17:01:17,855 | INFO : Avg batch train. time: 0.018985675335212237 seconds\n",
      "2023-05-04 17:01:17,856 | INFO : Avg sample train. time: 0.00014974437669994548 seconds\n",
      "2023-05-04 17:01:17,857 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 72  88.3% | batch:        83 of        94\t|\tloss: 1902.62\n",
      "Training Epoch 72  89.4% | batch:        84 of        94\t|\tloss: 888.576\n",
      "Training Epoch 72  90.4% | batch:        85 of        94\t|\tloss: 1404.57\n",
      "Training Epoch 72  91.5% | batch:        86 of        94\t|\tloss: 836.474\n",
      "Training Epoch 72  92.6% | batch:        87 of        94\t|\tloss: 1900.2\n",
      "Training Epoch 72  93.6% | batch:        88 of        94\t|\tloss: 769.184\n",
      "Training Epoch 72  94.7% | batch:        89 of        94\t|\tloss: 713.47\n",
      "Training Epoch 72  95.7% | batch:        90 of        94\t|\tloss: 691.263\n",
      "Training Epoch 72  96.8% | batch:        91 of        94\t|\tloss: 1116.44\n",
      "Training Epoch 72  97.9% | batch:        92 of        94\t|\tloss: 1441.95\n",
      "Training Epoch 72  98.9% | batch:        93 of        94\t|\tloss: 984.516\n",
      "\n",
      "Evaluating Epoch 72   0.0% | batch:         0 of        40\t|\tloss: 7876.75\n",
      "Evaluating Epoch 72   2.5% | batch:         1 of        40\t|\tloss: 1145.97\n",
      "Evaluating Epoch 72   5.0% | batch:         2 of        40\t|\tloss: 4101.91\n",
      "Evaluating Epoch 72   7.5% | batch:         3 of        40\t|\tloss: 7886.12\n",
      "Evaluating Epoch 72  10.0% | batch:         4 of        40\t|\tloss: 2617.55\n",
      "Evaluating Epoch 72  12.5% | batch:         5 of        40\t|\tloss: 2673.15\n",
      "Evaluating Epoch 72  15.0% | batch:         6 of        40\t|\tloss: 10506.1\n",
      "Evaluating Epoch 72  17.5% | batch:         7 of        40\t|\tloss: 3784.23\n",
      "Evaluating Epoch 72  20.0% | batch:         8 of        40\t|\tloss: 3004.85\n",
      "Evaluating Epoch 72  22.5% | batch:         9 of        40\t|\tloss: 3495.49\n",
      "Evaluating Epoch 72  25.0% | batch:        10 of        40\t|\tloss: 5076.15\n",
      "Evaluating Epoch 72  27.5% | batch:        11 of        40\t|\tloss: 1323.92\n",
      "Evaluating Epoch 72  30.0% | batch:        12 of        40\t|\tloss: 8188.47\n",
      "Evaluating Epoch 72  32.5% | batch:        13 of        40\t|\tloss: 3326.04\n",
      "Evaluating Epoch 72  35.0% | batch:        14 of        40\t|\tloss: 2095.52\n",
      "Evaluating Epoch 72  37.5% | batch:        15 of        40\t|\tloss: 3955.11\n",
      "Evaluating Epoch 72  40.0% | batch:        16 of        40\t|\tloss: 5807.63\n",
      "Evaluating Epoch 72  42.5% | batch:        17 of        40\t|\tloss: 3286.22\n",
      "Evaluating Epoch 72  45.0% | batch:        18 of        40\t|\tloss: 2654.72\n",
      "Evaluating Epoch 72  47.5% | batch:        19 of        40\t|\tloss: 6899.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:18,303 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44569921493530273 seconds\n",
      "\n",
      "2023-05-04 17:01:18,304 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5314326765549243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 72  50.0% | batch:        20 of        40\t|\tloss: 6507.01\n",
      "Evaluating Epoch 72  52.5% | batch:        21 of        40\t|\tloss: 1026.37\n",
      "Evaluating Epoch 72  55.0% | batch:        22 of        40\t|\tloss: 4983.93\n",
      "Evaluating Epoch 72  57.5% | batch:        23 of        40\t|\tloss: 3269.36\n",
      "Evaluating Epoch 72  60.0% | batch:        24 of        40\t|\tloss: 1628.61\n",
      "Evaluating Epoch 72  62.5% | batch:        25 of        40\t|\tloss: 3962.79\n",
      "Evaluating Epoch 72  65.0% | batch:        26 of        40\t|\tloss: 11890.7\n",
      "Evaluating Epoch 72  67.5% | batch:        27 of        40\t|\tloss: 2984.98\n",
      "Evaluating Epoch 72  70.0% | batch:        28 of        40\t|\tloss: 2314.73\n",
      "Evaluating Epoch 72  72.5% | batch:        29 of        40\t|\tloss: 9369.22\n",
      "Evaluating Epoch 72  75.0% | batch:        30 of        40\t|\tloss: 1798.55\n",
      "Evaluating Epoch 72  77.5% | batch:        31 of        40\t|\tloss: 1945.68\n",
      "Evaluating Epoch 72  80.0% | batch:        32 of        40\t|\tloss: 9196.46\n",
      "Evaluating Epoch 72  82.5% | batch:        33 of        40\t|\tloss: 6498.38\n",
      "Evaluating Epoch 72  85.0% | batch:        34 of        40\t|\tloss: 1144.36\n",
      "Evaluating Epoch 72  87.5% | batch:        35 of        40\t|\tloss: 6584.86\n",
      "Evaluating Epoch 72  90.0% | batch:        36 of        40\t|\tloss: 6915.6\n",
      "Evaluating Epoch 72  92.5% | batch:        37 of        40\t|\tloss: 2788.65\n",
      "Evaluating Epoch 72  95.0% | batch:        38 of        40\t|\tloss: 4491.59\n",
      "Evaluating Epoch 72  97.5% | batch:        39 of        40\t|\tloss: 15782.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:18,304 | INFO : Avg batch val. time: 0.013285816913873108 seconds\n",
      "2023-05-04 17:01:18,305 | INFO : Avg sample val. time: 0.00010527588679772669 seconds\n",
      "2023-05-04 17:01:18,306 | INFO : Epoch 72 Validation Summary: epoch: 72.000000 | loss: 4714.099563 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 73   0.0% | batch:         0 of        94\t|\tloss: 1276.45\n",
      "Training Epoch 73   1.1% | batch:         1 of        94\t|\tloss: 843.25\n",
      "Training Epoch 73   2.1% | batch:         2 of        94\t|\tloss: 977.789\n",
      "Training Epoch 73   3.2% | batch:         3 of        94\t|\tloss: 745.32\n",
      "Training Epoch 73   4.3% | batch:         4 of        94\t|\tloss: 1180.14\n",
      "Training Epoch 73   5.3% | batch:         5 of        94\t|\tloss: 1706.97\n",
      "Training Epoch 73   6.4% | batch:         6 of        94\t|\tloss: 667.067\n",
      "Training Epoch 73   7.4% | batch:         7 of        94\t|\tloss: 1004.22\n",
      "Training Epoch 73   8.5% | batch:         8 of        94\t|\tloss: 825.655\n",
      "Training Epoch 73   9.6% | batch:         9 of        94\t|\tloss: 2741.49\n",
      "Training Epoch 73  10.6% | batch:        10 of        94\t|\tloss: 1457.27\n",
      "Training Epoch 73  11.7% | batch:        11 of        94\t|\tloss: 819.348\n",
      "Training Epoch 73  12.8% | batch:        12 of        94\t|\tloss: 939.032\n",
      "Training Epoch 73  13.8% | batch:        13 of        94\t|\tloss: 1007.22\n",
      "Training Epoch 73  14.9% | batch:        14 of        94\t|\tloss: 910.937\n",
      "Training Epoch 73  16.0% | batch:        15 of        94\t|\tloss: 808.737\n",
      "Training Epoch 73  17.0% | batch:        16 of        94\t|\tloss: 1172.21\n",
      "Training Epoch 73  18.1% | batch:        17 of        94\t|\tloss: 844.858\n",
      "Training Epoch 73  19.1% | batch:        18 of        94\t|\tloss: 746.18\n",
      "Training Epoch 73  20.2% | batch:        19 of        94\t|\tloss: 1270.78\n",
      "Training Epoch 73  21.3% | batch:        20 of        94\t|\tloss: 641.674\n",
      "Training Epoch 73  22.3% | batch:        21 of        94\t|\tloss: 1009.37\n",
      "Training Epoch 73  23.4% | batch:        22 of        94\t|\tloss: 872.715\n",
      "Training Epoch 73  24.5% | batch:        23 of        94\t|\tloss: 1436.71\n",
      "Training Epoch 73  25.5% | batch:        24 of        94\t|\tloss: 1557.35\n",
      "Training Epoch 73  26.6% | batch:        25 of        94\t|\tloss: 798.423\n",
      "Training Epoch 73  27.7% | batch:        26 of        94\t|\tloss: 1038.1\n",
      "Training Epoch 73  28.7% | batch:        27 of        94\t|\tloss: 1918.13\n",
      "Training Epoch 73  29.8% | batch:        28 of        94\t|\tloss: 1014.23\n",
      "Training Epoch 73  30.9% | batch:        29 of        94\t|\tloss: 839.281\n",
      "Training Epoch 73  31.9% | batch:        30 of        94\t|\tloss: 815.012\n",
      "Training Epoch 73  33.0% | batch:        31 of        94\t|\tloss: 716.554\n",
      "Training Epoch 73  34.0% | batch:        32 of        94\t|\tloss: 1394.62\n",
      "Training Epoch 73  35.1% | batch:        33 of        94\t|\tloss: 533.71\n",
      "Training Epoch 73  36.2% | batch:        34 of        94\t|\tloss: 1005.9\n",
      "Training Epoch 73  37.2% | batch:        35 of        94\t|\tloss: 1045.65\n",
      "Training Epoch 73  38.3% | batch:        36 of        94\t|\tloss: 714.07\n",
      "Training Epoch 73  39.4% | batch:        37 of        94\t|\tloss: 1151.87\n",
      "Training Epoch 73  40.4% | batch:        38 of        94\t|\tloss: 1158.36\n",
      "Training Epoch 73  41.5% | batch:        39 of        94\t|\tloss: 764.428\n",
      "Training Epoch 73  42.6% | batch:        40 of        94\t|\tloss: 1863.98\n",
      "Training Epoch 73  43.6% | batch:        41 of        94\t|\tloss: 1151.12\n",
      "Training Epoch 73  44.7% | batch:        42 of        94\t|\tloss: 758.167\n",
      "Training Epoch 73  45.7% | batch:        43 of        94\t|\tloss: 691.984\n",
      "Training Epoch 73  46.8% | batch:        44 of        94\t|\tloss: 1137.2\n",
      "Training Epoch 73  47.9% | batch:        45 of        94\t|\tloss: 1349.29\n",
      "Training Epoch 73  48.9% | batch:        46 of        94\t|\tloss: 1617.37\n",
      "Training Epoch 73  50.0% | batch:        47 of        94\t|\tloss: 1162.82\n",
      "Training Epoch 73  51.1% | batch:        48 of        94\t|\tloss: 1131.98\n",
      "Training Epoch 73  52.1% | batch:        49 of        94\t|\tloss: 880.485\n",
      "Training Epoch 73  53.2% | batch:        50 of        94\t|\tloss: 1085.13\n",
      "Training Epoch 73  54.3% | batch:        51 of        94\t|\tloss: 1367.99\n",
      "Training Epoch 73  55.3% | batch:        52 of        94\t|\tloss: 1021.27\n",
      "Training Epoch 73  56.4% | batch:        53 of        94\t|\tloss: 980.11\n",
      "Training Epoch 73  57.4% | batch:        54 of        94\t|\tloss: 940.455\n",
      "Training Epoch 73  58.5% | batch:        55 of        94\t|\tloss: 1676.15\n",
      "Training Epoch 73  59.6% | batch:        56 of        94\t|\tloss: 859.53\n",
      "Training Epoch 73  60.6% | batch:        57 of        94\t|\tloss: 860.809\n",
      "Training Epoch 73  61.7% | batch:        58 of        94\t|\tloss: 828.116\n",
      "Training Epoch 73  62.8% | batch:        59 of        94\t|\tloss: 2413.46\n",
      "Training Epoch 73  63.8% | batch:        60 of        94\t|\tloss: 928.819\n",
      "Training Epoch 73  64.9% | batch:        61 of        94\t|\tloss: 803.352\n",
      "Training Epoch 73  66.0% | batch:        62 of        94\t|\tloss: 610.872\n",
      "Training Epoch 73  67.0% | batch:        63 of        94\t|\tloss: 714.04\n",
      "Training Epoch 73  68.1% | batch:        64 of        94\t|\tloss: 884.99\n",
      "Training Epoch 73  69.1% | batch:        65 of        94\t|\tloss: 778.99\n",
      "Training Epoch 73  70.2% | batch:        66 of        94\t|\tloss: 1935.25\n",
      "Training Epoch 73  71.3% | batch:        67 of        94\t|\tloss: 1204.88\n",
      "Training Epoch 73  72.3% | batch:        68 of        94\t|\tloss: 782.594\n",
      "Training Epoch 73  73.4% | batch:        69 of        94\t|\tloss: 896.352\n",
      "Training Epoch 73  74.5% | batch:        70 of        94\t|\tloss: 821.445\n",
      "Training Epoch 73  75.5% | batch:        71 of        94\t|\tloss: 1792.34\n",
      "Training Epoch 73  76.6% | batch:        72 of        94\t|\tloss: 746.305\n",
      "Training Epoch 73  77.7% | batch:        73 of        94\t|\tloss: 1129.87\n",
      "Training Epoch 73  78.7% | batch:        74 of        94\t|\tloss: 954.679\n",
      "Training Epoch 73  79.8% | batch:        75 of        94\t|\tloss: 754.593\n",
      "Training Epoch 73  80.9% | batch:        76 of        94\t|\tloss: 961.856\n",
      "Training Epoch 73  81.9% | batch:        77 of        94\t|\tloss: 1684.93\n",
      "Training Epoch 73  83.0% | batch:        78 of        94\t|\tloss: 667.215\n",
      "Training Epoch 73  84.0% | batch:        79 of        94\t|\tloss: 1267.02\n",
      "Training Epoch 73  85.1% | batch:        80 of        94\t|\tloss: 552.465\n",
      "Training Epoch 73  86.2% | batch:        81 of        94\t|\tloss: 947.045\n",
      "Training Epoch 73  87.2% | batch:        82 of        94\t|\tloss: 1617.91\n",
      "Training Epoch 73  88.3% | batch:        83 of        94\t|\tloss: 1848.04\n",
      "Training Epoch 73  89.4% | batch:        84 of        94\t|\tloss: 569.061\n",
      "Training Epoch 73  90.4% | batch:        85 of        94\t|\tloss: 708.466\n",
      "Training Epoch 73  91.5% | batch:        86 of        94\t|\tloss: 987.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:20,114 | INFO : Epoch 73 Training Summary: epoch: 73.000000 | loss: 1086.796474 | \n",
      "2023-05-04 17:01:20,115 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.786674976348877 seconds\n",
      "\n",
      "2023-05-04 17:01:20,115 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7846811732200727 seconds\n",
      "2023-05-04 17:01:20,116 | INFO : Avg batch train. time: 0.018985969927873114 seconds\n",
      "2023-05-04 17:01:20,116 | INFO : Avg sample train. time: 0.00014974670021984164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 73  92.6% | batch:        87 of        94\t|\tloss: 1819.87\n",
      "Training Epoch 73  93.6% | batch:        88 of        94\t|\tloss: 946.678\n",
      "Training Epoch 73  94.7% | batch:        89 of        94\t|\tloss: 1296.4\n",
      "Training Epoch 73  95.7% | batch:        90 of        94\t|\tloss: 1241.37\n",
      "Training Epoch 73  96.8% | batch:        91 of        94\t|\tloss: 964.17\n",
      "Training Epoch 73  97.9% | batch:        92 of        94\t|\tloss: 1191.52\n",
      "Training Epoch 73  98.9% | batch:        93 of        94\t|\tloss: 289.949\n",
      "\n",
      "Training Epoch 74   0.0% | batch:         0 of        94\t|\tloss: 870.265\n",
      "Training Epoch 74   1.1% | batch:         1 of        94\t|\tloss: 1566.99\n",
      "Training Epoch 74   2.1% | batch:         2 of        94\t|\tloss: 1032.67\n",
      "Training Epoch 74   3.2% | batch:         3 of        94\t|\tloss: 680.85\n",
      "Training Epoch 74   4.3% | batch:         4 of        94\t|\tloss: 847.612\n",
      "Training Epoch 74   5.3% | batch:         5 of        94\t|\tloss: 662.249\n",
      "Training Epoch 74   6.4% | batch:         6 of        94\t|\tloss: 1003.77\n",
      "Training Epoch 74   7.4% | batch:         7 of        94\t|\tloss: 830.738\n",
      "Training Epoch 74   8.5% | batch:         8 of        94\t|\tloss: 1025.27\n",
      "Training Epoch 74   9.6% | batch:         9 of        94\t|\tloss: 1102.38\n",
      "Training Epoch 74  10.6% | batch:        10 of        94\t|\tloss: 878.86\n",
      "Training Epoch 74  11.7% | batch:        11 of        94\t|\tloss: 1609.35\n",
      "Training Epoch 74  12.8% | batch:        12 of        94\t|\tloss: 691.185\n",
      "Training Epoch 74  13.8% | batch:        13 of        94\t|\tloss: 1809.49\n",
      "Training Epoch 74  14.9% | batch:        14 of        94\t|\tloss: 1178.18\n",
      "Training Epoch 74  16.0% | batch:        15 of        94\t|\tloss: 1022.54\n",
      "Training Epoch 74  17.0% | batch:        16 of        94\t|\tloss: 1092.57\n",
      "Training Epoch 74  18.1% | batch:        17 of        94\t|\tloss: 831.904\n",
      "Training Epoch 74  19.1% | batch:        18 of        94\t|\tloss: 875.927\n",
      "Training Epoch 74  20.2% | batch:        19 of        94\t|\tloss: 524.966\n",
      "Training Epoch 74  21.3% | batch:        20 of        94\t|\tloss: 993.338\n",
      "Training Epoch 74  22.3% | batch:        21 of        94\t|\tloss: 1568.62\n",
      "Training Epoch 74  23.4% | batch:        22 of        94\t|\tloss: 1102.25\n",
      "Training Epoch 74  24.5% | batch:        23 of        94\t|\tloss: 672.624\n",
      "Training Epoch 74  25.5% | batch:        24 of        94\t|\tloss: 995.807\n",
      "Training Epoch 74  26.6% | batch:        25 of        94\t|\tloss: 2041.69\n",
      "Training Epoch 74  27.7% | batch:        26 of        94\t|\tloss: 1021.56\n",
      "Training Epoch 74  28.7% | batch:        27 of        94\t|\tloss: 720.934\n",
      "Training Epoch 74  29.8% | batch:        28 of        94\t|\tloss: 865.925\n",
      "Training Epoch 74  30.9% | batch:        29 of        94\t|\tloss: 1084.1\n",
      "Training Epoch 74  31.9% | batch:        30 of        94\t|\tloss: 768.405\n",
      "Training Epoch 74  33.0% | batch:        31 of        94\t|\tloss: 1597\n",
      "Training Epoch 74  34.0% | batch:        32 of        94\t|\tloss: 1432.26\n",
      "Training Epoch 74  35.1% | batch:        33 of        94\t|\tloss: 1128.08\n",
      "Training Epoch 74  36.2% | batch:        34 of        94\t|\tloss: 1121.79\n",
      "Training Epoch 74  37.2% | batch:        35 of        94\t|\tloss: 1048.69\n",
      "Training Epoch 74  38.3% | batch:        36 of        94\t|\tloss: 679.783\n",
      "Training Epoch 74  39.4% | batch:        37 of        94\t|\tloss: 1058.44\n",
      "Training Epoch 74  40.4% | batch:        38 of        94\t|\tloss: 714.326\n",
      "Training Epoch 74  41.5% | batch:        39 of        94\t|\tloss: 912.047\n",
      "Training Epoch 74  42.6% | batch:        40 of        94\t|\tloss: 773.102\n",
      "Training Epoch 74  43.6% | batch:        41 of        94\t|\tloss: 1006.86\n",
      "Training Epoch 74  44.7% | batch:        42 of        94\t|\tloss: 880.453\n",
      "Training Epoch 74  45.7% | batch:        43 of        94\t|\tloss: 697.919\n",
      "Training Epoch 74  46.8% | batch:        44 of        94\t|\tloss: 777.604\n",
      "Training Epoch 74  47.9% | batch:        45 of        94\t|\tloss: 1599.22\n",
      "Training Epoch 74  48.9% | batch:        46 of        94\t|\tloss: 875.927\n",
      "Training Epoch 74  50.0% | batch:        47 of        94\t|\tloss: 3175.27\n",
      "Training Epoch 74  51.1% | batch:        48 of        94\t|\tloss: 591.246\n",
      "Training Epoch 74  52.1% | batch:        49 of        94\t|\tloss: 768.136\n",
      "Training Epoch 74  53.2% | batch:        50 of        94\t|\tloss: 902.777\n",
      "Training Epoch 74  54.3% | batch:        51 of        94\t|\tloss: 892.491\n",
      "Training Epoch 74  55.3% | batch:        52 of        94\t|\tloss: 859.443\n",
      "Training Epoch 74  56.4% | batch:        53 of        94\t|\tloss: 1041.98\n",
      "Training Epoch 74  57.4% | batch:        54 of        94\t|\tloss: 791.686\n",
      "Training Epoch 74  58.5% | batch:        55 of        94\t|\tloss: 891.917\n",
      "Training Epoch 74  59.6% | batch:        56 of        94\t|\tloss: 961.404\n",
      "Training Epoch 74  60.6% | batch:        57 of        94\t|\tloss: 630.965\n",
      "Training Epoch 74  61.7% | batch:        58 of        94\t|\tloss: 1179.26\n",
      "Training Epoch 74  62.8% | batch:        59 of        94\t|\tloss: 1586.2\n",
      "Training Epoch 74  63.8% | batch:        60 of        94\t|\tloss: 1165.89\n",
      "Training Epoch 74  64.9% | batch:        61 of        94\t|\tloss: 1036.55\n",
      "Training Epoch 74  66.0% | batch:        62 of        94\t|\tloss: 2228.68\n",
      "Training Epoch 74  67.0% | batch:        63 of        94\t|\tloss: 1209.3\n",
      "Training Epoch 74  68.1% | batch:        64 of        94\t|\tloss: 1468.79\n",
      "Training Epoch 74  69.1% | batch:        65 of        94\t|\tloss: 957.893\n",
      "Training Epoch 74  70.2% | batch:        66 of        94\t|\tloss: 982.372\n",
      "Training Epoch 74  71.3% | batch:        67 of        94\t|\tloss: 818.593\n",
      "Training Epoch 74  72.3% | batch:        68 of        94\t|\tloss: 687.64\n",
      "Training Epoch 74  73.4% | batch:        69 of        94\t|\tloss: 668.156\n",
      "Training Epoch 74  74.5% | batch:        70 of        94\t|\tloss: 883.376\n",
      "Training Epoch 74  75.5% | batch:        71 of        94\t|\tloss: 918.405\n",
      "Training Epoch 74  76.6% | batch:        72 of        94\t|\tloss: 2031.37\n",
      "Training Epoch 74  77.7% | batch:        73 of        94\t|\tloss: 1155.58\n",
      "Training Epoch 74  78.7% | batch:        74 of        94\t|\tloss: 774.784\n",
      "Training Epoch 74  79.8% | batch:        75 of        94\t|\tloss: 920.754\n",
      "Training Epoch 74  80.9% | batch:        76 of        94\t|\tloss: 1294.05\n",
      "Training Epoch 74  81.9% | batch:        77 of        94\t|\tloss: 488.313\n",
      "Training Epoch 74  83.0% | batch:        78 of        94\t|\tloss: 823.898\n",
      "Training Epoch 74  84.0% | batch:        79 of        94\t|\tloss: 1214.95\n",
      "Training Epoch 74  85.1% | batch:        80 of        94\t|\tloss: 661.492\n",
      "Training Epoch 74  86.2% | batch:        81 of        94\t|\tloss: 1240.64\n",
      "Training Epoch 74  87.2% | batch:        82 of        94\t|\tloss: 1074.64\n",
      "Training Epoch 74  88.3% | batch:        83 of        94\t|\tloss: 1011.52\n",
      "Training Epoch 74  89.4% | batch:        84 of        94\t|\tloss: 807.148\n",
      "Training Epoch 74  90.4% | batch:        85 of        94\t|\tloss: 1286.88\n",
      "Training Epoch 74  91.5% | batch:        86 of        94\t|\tloss: 957.32\n",
      "Training Epoch 74  92.6% | batch:        87 of        94\t|\tloss: 1056.25\n",
      "Training Epoch 74  93.6% | batch:        88 of        94\t|\tloss: 1773.31\n",
      "Training Epoch 74  94.7% | batch:        89 of        94\t|\tloss: 1577.06\n",
      "Training Epoch 74  95.7% | batch:        90 of        94\t|\tloss: 1598.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:21,945 | INFO : Epoch 74 Training Summary: epoch: 74.000000 | loss: 1066.686619 | \n",
      "2023-05-04 17:01:21,946 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8086519241333008 seconds\n",
      "\n",
      "2023-05-04 17:01:21,947 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7850051022864677 seconds\n",
      "2023-05-04 17:01:21,947 | INFO : Avg batch train. time: 0.018989415981770934 seconds\n",
      "2023-05-04 17:01:21,948 | INFO : Avg sample train. time: 0.00014977388003746162 seconds\n",
      "2023-05-04 17:01:21,948 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 74  96.8% | batch:        91 of        94\t|\tloss: 1023.39\n",
      "Training Epoch 74  97.9% | batch:        92 of        94\t|\tloss: 883.221\n",
      "Training Epoch 74  98.9% | batch:        93 of        94\t|\tloss: 807.887\n",
      "\n",
      "Evaluating Epoch 74   0.0% | batch:         0 of        40\t|\tloss: 6561.75\n",
      "Evaluating Epoch 74   2.5% | batch:         1 of        40\t|\tloss: 1075.78\n",
      "Evaluating Epoch 74   5.0% | batch:         2 of        40\t|\tloss: 3227.65\n",
      "Evaluating Epoch 74   7.5% | batch:         3 of        40\t|\tloss: 5854.72\n",
      "Evaluating Epoch 74  10.0% | batch:         4 of        40\t|\tloss: 2848.74\n",
      "Evaluating Epoch 74  12.5% | batch:         5 of        40\t|\tloss: 2288.26\n",
      "Evaluating Epoch 74  15.0% | batch:         6 of        40\t|\tloss: 8507.49\n",
      "Evaluating Epoch 74  17.5% | batch:         7 of        40\t|\tloss: 3204.95\n",
      "Evaluating Epoch 74  20.0% | batch:         8 of        40\t|\tloss: 2815.36\n",
      "Evaluating Epoch 74  22.5% | batch:         9 of        40\t|\tloss: 2086.43\n",
      "Evaluating Epoch 74  25.0% | batch:        10 of        40\t|\tloss: 4406.59\n",
      "Evaluating Epoch 74  27.5% | batch:        11 of        40\t|\tloss: 1444.11\n",
      "Evaluating Epoch 74  30.0% | batch:        12 of        40\t|\tloss: 5572.18\n",
      "Evaluating Epoch 74  32.5% | batch:        13 of        40\t|\tloss: 2656.64\n",
      "Evaluating Epoch 74  35.0% | batch:        14 of        40\t|\tloss: 2009.11\n",
      "Evaluating Epoch 74  37.5% | batch:        15 of        40\t|\tloss: 3666.78\n",
      "Evaluating Epoch 74  40.0% | batch:        16 of        40\t|\tloss: 3968.56\n",
      "Evaluating Epoch 74  42.5% | batch:        17 of        40\t|\tloss: 2752.89\n",
      "Evaluating Epoch 74  45.0% | batch:        18 of        40\t|\tloss: 2423.13\n",
      "Evaluating Epoch 74  47.5% | batch:        19 of        40\t|\tloss: 4582.04\n",
      "Evaluating Epoch 74  50.0% | batch:        20 of        40\t|\tloss: 4665.92\n",
      "Evaluating Epoch 74  52.5% | batch:        21 of        40\t|\tloss: 981.714\n",
      "Evaluating Epoch 74  55.0% | batch:        22 of        40\t|\tloss: 3590.17\n",
      "Evaluating Epoch 74  57.5% | batch:        23 of        40\t|\tloss: 2929.18\n",
      "Evaluating Epoch 74  60.0% | batch:        24 of        40\t|\tloss: 1592.12\n",
      "Evaluating Epoch 74  62.5% | batch:        25 of        40\t|\tloss: 3555.18\n",
      "Evaluating Epoch 74  65.0% | batch:        26 of        40\t|\tloss: 7948.45\n",
      "Evaluating Epoch 74  67.5% | batch:        27 of        40\t|\tloss: 2781.91\n",
      "Evaluating Epoch 74  70.0% | batch:        28 of        40\t|\tloss: 2170.26\n",
      "Evaluating Epoch 74  72.5% | batch:        29 of        40\t|\tloss: 7943.98\n",
      "Evaluating Epoch 74  75.0% | batch:        30 of        40\t|\tloss: 1626.87\n",
      "Evaluating Epoch 74  77.5% | batch:        31 of        40\t|\tloss: 1589\n",
      "Evaluating Epoch 74  80.0% | batch:        32 of        40\t|\tloss: 7130.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:22,404 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45497989654541016 seconds\n",
      "\n",
      "2023-05-04 17:01:22,404 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5310504126548767 seconds\n",
      "2023-05-04 17:01:22,405 | INFO : Avg batch val. time: 0.013276260316371918 seconds\n",
      "2023-05-04 17:01:22,405 | INFO : Avg sample val. time: 0.00010520016098551441 seconds\n",
      "2023-05-04 17:01:22,406 | INFO : Epoch 74 Validation Summary: epoch: 74.000000 | loss: 3736.571848 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 74  82.5% | batch:        33 of        40\t|\tloss: 5122.38\n",
      "Evaluating Epoch 74  85.0% | batch:        34 of        40\t|\tloss: 1117.5\n",
      "Evaluating Epoch 74  87.5% | batch:        35 of        40\t|\tloss: 5022.18\n",
      "Evaluating Epoch 74  90.0% | batch:        36 of        40\t|\tloss: 5351.1\n",
      "Evaluating Epoch 74  92.5% | batch:        37 of        40\t|\tloss: 2501.53\n",
      "Evaluating Epoch 74  95.0% | batch:        38 of        40\t|\tloss: 3605.32\n",
      "Evaluating Epoch 74  97.5% | batch:        39 of        40\t|\tloss: 9561.09\n",
      "\n",
      "Training Epoch 75   0.0% | batch:         0 of        94\t|\tloss: 776.119\n",
      "Training Epoch 75   1.1% | batch:         1 of        94\t|\tloss: 594.678\n",
      "Training Epoch 75   2.1% | batch:         2 of        94\t|\tloss: 697.8\n",
      "Training Epoch 75   3.2% | batch:         3 of        94\t|\tloss: 593.263\n",
      "Training Epoch 75   4.3% | batch:         4 of        94\t|\tloss: 995.367\n",
      "Training Epoch 75   5.3% | batch:         5 of        94\t|\tloss: 817.444\n",
      "Training Epoch 75   6.4% | batch:         6 of        94\t|\tloss: 822.997\n",
      "Training Epoch 75   7.4% | batch:         7 of        94\t|\tloss: 844.76\n",
      "Training Epoch 75   8.5% | batch:         8 of        94\t|\tloss: 936.088\n",
      "Training Epoch 75   9.6% | batch:         9 of        94\t|\tloss: 1210.6\n",
      "Training Epoch 75  10.6% | batch:        10 of        94\t|\tloss: 1512.92\n",
      "Training Epoch 75  11.7% | batch:        11 of        94\t|\tloss: 1165.22\n",
      "Training Epoch 75  12.8% | batch:        12 of        94\t|\tloss: 748.555\n",
      "Training Epoch 75  13.8% | batch:        13 of        94\t|\tloss: 755.293\n",
      "Training Epoch 75  14.9% | batch:        14 of        94\t|\tloss: 1096.24\n",
      "Training Epoch 75  16.0% | batch:        15 of        94\t|\tloss: 1816.37\n",
      "Training Epoch 75  17.0% | batch:        16 of        94\t|\tloss: 2478.18\n",
      "Training Epoch 75  18.1% | batch:        17 of        94\t|\tloss: 657.254\n",
      "Training Epoch 75  19.1% | batch:        18 of        94\t|\tloss: 748.83\n",
      "Training Epoch 75  20.2% | batch:        19 of        94\t|\tloss: 932.048\n",
      "Training Epoch 75  21.3% | batch:        20 of        94\t|\tloss: 1034.99\n",
      "Training Epoch 75  22.3% | batch:        21 of        94\t|\tloss: 730.372\n",
      "Training Epoch 75  23.4% | batch:        22 of        94\t|\tloss: 1580.25\n",
      "Training Epoch 75  24.5% | batch:        23 of        94\t|\tloss: 917.342\n",
      "Training Epoch 75  25.5% | batch:        24 of        94\t|\tloss: 1332.84\n",
      "Training Epoch 75  26.6% | batch:        25 of        94\t|\tloss: 1092.24\n",
      "Training Epoch 75  27.7% | batch:        26 of        94\t|\tloss: 674.211\n",
      "Training Epoch 75  28.7% | batch:        27 of        94\t|\tloss: 694.016\n",
      "Training Epoch 75  29.8% | batch:        28 of        94\t|\tloss: 757.364\n",
      "Training Epoch 75  30.9% | batch:        29 of        94\t|\tloss: 888.568\n",
      "Training Epoch 75  31.9% | batch:        30 of        94\t|\tloss: 854.253\n",
      "Training Epoch 75  33.0% | batch:        31 of        94\t|\tloss: 1240.63\n",
      "Training Epoch 75  34.0% | batch:        32 of        94\t|\tloss: 757.683\n",
      "Training Epoch 75  35.1% | batch:        33 of        94\t|\tloss: 1393.94\n",
      "Training Epoch 75  36.2% | batch:        34 of        94\t|\tloss: 787.009\n",
      "Training Epoch 75  37.2% | batch:        35 of        94\t|\tloss: 1705.84\n",
      "Training Epoch 75  38.3% | batch:        36 of        94\t|\tloss: 2529.91\n",
      "Training Epoch 75  39.4% | batch:        37 of        94\t|\tloss: 1979.57\n",
      "Training Epoch 75  40.4% | batch:        38 of        94\t|\tloss: 723.078\n",
      "Training Epoch 75  41.5% | batch:        39 of        94\t|\tloss: 758.945\n",
      "Training Epoch 75  42.6% | batch:        40 of        94\t|\tloss: 785.602\n",
      "Training Epoch 75  43.6% | batch:        41 of        94\t|\tloss: 1150.92\n",
      "Training Epoch 75  44.7% | batch:        42 of        94\t|\tloss: 1189.75\n",
      "Training Epoch 75  45.7% | batch:        43 of        94\t|\tloss: 2076.78\n",
      "Training Epoch 75  46.8% | batch:        44 of        94\t|\tloss: 1039.75\n",
      "Training Epoch 75  47.9% | batch:        45 of        94\t|\tloss: 1126.56\n",
      "Training Epoch 75  48.9% | batch:        46 of        94\t|\tloss: 1165.49\n",
      "Training Epoch 75  50.0% | batch:        47 of        94\t|\tloss: 880.844\n",
      "Training Epoch 75  51.1% | batch:        48 of        94\t|\tloss: 1140.45\n",
      "Training Epoch 75  52.1% | batch:        49 of        94\t|\tloss: 827.597\n",
      "Training Epoch 75  53.2% | batch:        50 of        94\t|\tloss: 1382.38\n",
      "Training Epoch 75  54.3% | batch:        51 of        94\t|\tloss: 1109.18\n",
      "Training Epoch 75  55.3% | batch:        52 of        94\t|\tloss: 690.748\n",
      "Training Epoch 75  56.4% | batch:        53 of        94\t|\tloss: 874.389\n",
      "Training Epoch 75  57.4% | batch:        54 of        94\t|\tloss: 897.646\n",
      "Training Epoch 75  58.5% | batch:        55 of        94\t|\tloss: 1075.01\n",
      "Training Epoch 75  59.6% | batch:        56 of        94\t|\tloss: 897.064\n",
      "Training Epoch 75  60.6% | batch:        57 of        94\t|\tloss: 732.943\n",
      "Training Epoch 75  61.7% | batch:        58 of        94\t|\tloss: 1040.35\n",
      "Training Epoch 75  62.8% | batch:        59 of        94\t|\tloss: 1050.66\n",
      "Training Epoch 75  63.8% | batch:        60 of        94\t|\tloss: 761.173\n",
      "Training Epoch 75  64.9% | batch:        61 of        94\t|\tloss: 931.971\n",
      "Training Epoch 75  66.0% | batch:        62 of        94\t|\tloss: 961.249\n",
      "Training Epoch 75  67.0% | batch:        63 of        94\t|\tloss: 681.333\n",
      "Training Epoch 75  68.1% | batch:        64 of        94\t|\tloss: 855.971\n",
      "Training Epoch 75  69.1% | batch:        65 of        94\t|\tloss: 644.833\n",
      "Training Epoch 75  70.2% | batch:        66 of        94\t|\tloss: 1412.01\n",
      "Training Epoch 75  71.3% | batch:        67 of        94\t|\tloss: 1038.75\n",
      "Training Epoch 75  72.3% | batch:        68 of        94\t|\tloss: 870.448\n",
      "Training Epoch 75  73.4% | batch:        69 of        94\t|\tloss: 876.629\n",
      "Training Epoch 75  74.5% | batch:        70 of        94\t|\tloss: 655.124\n",
      "Training Epoch 75  75.5% | batch:        71 of        94\t|\tloss: 680.157\n",
      "Training Epoch 75  76.6% | batch:        72 of        94\t|\tloss: 843.584\n",
      "Training Epoch 75  77.7% | batch:        73 of        94\t|\tloss: 996.208\n",
      "Training Epoch 75  78.7% | batch:        74 of        94\t|\tloss: 1682.47\n",
      "Training Epoch 75  79.8% | batch:        75 of        94\t|\tloss: 787.689\n",
      "Training Epoch 75  80.9% | batch:        76 of        94\t|\tloss: 1310.34\n",
      "Training Epoch 75  81.9% | batch:        77 of        94\t|\tloss: 1396.15\n",
      "Training Epoch 75  83.0% | batch:        78 of        94\t|\tloss: 1613.82\n",
      "Training Epoch 75  84.0% | batch:        79 of        94\t|\tloss: 968.827\n",
      "Training Epoch 75  85.1% | batch:        80 of        94\t|\tloss: 889.394\n",
      "Training Epoch 75  86.2% | batch:        81 of        94\t|\tloss: 680.114\n",
      "Training Epoch 75  87.2% | batch:        82 of        94\t|\tloss: 767.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:24,233 | INFO : Epoch 75 Training Summary: epoch: 75.000000 | loss: 1028.697148 | \n",
      "2023-05-04 17:01:24,235 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8057475090026855 seconds\n",
      "\n",
      "2023-05-04 17:01:24,235 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7852816677093506 seconds\n",
      "2023-05-04 17:01:24,236 | INFO : Avg batch train. time: 0.018992358167120752 seconds\n",
      "2023-05-04 17:01:24,236 | INFO : Avg sample train. time: 0.00014979708572825562 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 75  88.3% | batch:        83 of        94\t|\tloss: 945.464\n",
      "Training Epoch 75  89.4% | batch:        84 of        94\t|\tloss: 1308.3\n",
      "Training Epoch 75  90.4% | batch:        85 of        94\t|\tloss: 657.649\n",
      "Training Epoch 75  91.5% | batch:        86 of        94\t|\tloss: 835.427\n",
      "Training Epoch 75  92.6% | batch:        87 of        94\t|\tloss: 1088.35\n",
      "Training Epoch 75  93.6% | batch:        88 of        94\t|\tloss: 1100.13\n",
      "Training Epoch 75  94.7% | batch:        89 of        94\t|\tloss: 1178.02\n",
      "Training Epoch 75  95.7% | batch:        90 of        94\t|\tloss: 612.762\n",
      "Training Epoch 75  96.8% | batch:        91 of        94\t|\tloss: 958.922\n",
      "Training Epoch 75  97.9% | batch:        92 of        94\t|\tloss: 856.185\n",
      "Training Epoch 75  98.9% | batch:        93 of        94\t|\tloss: 1530.88\n",
      "\n",
      "Training Epoch 76   0.0% | batch:         0 of        94\t|\tloss: 864.796\n",
      "Training Epoch 76   1.1% | batch:         1 of        94\t|\tloss: 708.574\n",
      "Training Epoch 76   2.1% | batch:         2 of        94\t|\tloss: 666.222\n",
      "Training Epoch 76   3.2% | batch:         3 of        94\t|\tloss: 1119.35\n",
      "Training Epoch 76   4.3% | batch:         4 of        94\t|\tloss: 824.906\n",
      "Training Epoch 76   5.3% | batch:         5 of        94\t|\tloss: 1013.38\n",
      "Training Epoch 76   6.4% | batch:         6 of        94\t|\tloss: 969.147\n",
      "Training Epoch 76   7.4% | batch:         7 of        94\t|\tloss: 1098.51\n",
      "Training Epoch 76   8.5% | batch:         8 of        94\t|\tloss: 1564.37\n",
      "Training Epoch 76   9.6% | batch:         9 of        94\t|\tloss: 694.02\n",
      "Training Epoch 76  10.6% | batch:        10 of        94\t|\tloss: 743.148\n",
      "Training Epoch 76  11.7% | batch:        11 of        94\t|\tloss: 941.091\n",
      "Training Epoch 76  12.8% | batch:        12 of        94\t|\tloss: 1700.04\n",
      "Training Epoch 76  13.8% | batch:        13 of        94\t|\tloss: 662.746\n",
      "Training Epoch 76  14.9% | batch:        14 of        94\t|\tloss: 1175.28\n",
      "Training Epoch 76  16.0% | batch:        15 of        94\t|\tloss: 786.635\n",
      "Training Epoch 76  17.0% | batch:        16 of        94\t|\tloss: 898.51\n",
      "Training Epoch 76  18.1% | batch:        17 of        94\t|\tloss: 760.836\n",
      "Training Epoch 76  19.1% | batch:        18 of        94\t|\tloss: 774.521\n",
      "Training Epoch 76  20.2% | batch:        19 of        94\t|\tloss: 677.368\n",
      "Training Epoch 76  21.3% | batch:        20 of        94\t|\tloss: 769.439\n",
      "Training Epoch 76  22.3% | batch:        21 of        94\t|\tloss: 698.74\n",
      "Training Epoch 76  23.4% | batch:        22 of        94\t|\tloss: 659.643\n",
      "Training Epoch 76  24.5% | batch:        23 of        94\t|\tloss: 1005.21\n",
      "Training Epoch 76  25.5% | batch:        24 of        94\t|\tloss: 834.839\n",
      "Training Epoch 76  26.6% | batch:        25 of        94\t|\tloss: 1667.54\n",
      "Training Epoch 76  27.7% | batch:        26 of        94\t|\tloss: 1007.93\n",
      "Training Epoch 76  28.7% | batch:        27 of        94\t|\tloss: 1082.16\n",
      "Training Epoch 76  29.8% | batch:        28 of        94\t|\tloss: 645.896\n",
      "Training Epoch 76  30.9% | batch:        29 of        94\t|\tloss: 1102.65\n",
      "Training Epoch 76  31.9% | batch:        30 of        94\t|\tloss: 850.637\n",
      "Training Epoch 76  33.0% | batch:        31 of        94\t|\tloss: 927.244\n",
      "Training Epoch 76  34.0% | batch:        32 of        94\t|\tloss: 965.175\n",
      "Training Epoch 76  35.1% | batch:        33 of        94\t|\tloss: 1675.56\n",
      "Training Epoch 76  36.2% | batch:        34 of        94\t|\tloss: 1116.77\n",
      "Training Epoch 76  37.2% | batch:        35 of        94\t|\tloss: 1954.36\n",
      "Training Epoch 76  38.3% | batch:        36 of        94\t|\tloss: 1103.15\n",
      "Training Epoch 76  39.4% | batch:        37 of        94\t|\tloss: 875.709\n",
      "Training Epoch 76  40.4% | batch:        38 of        94\t|\tloss: 1004.55\n",
      "Training Epoch 76  41.5% | batch:        39 of        94\t|\tloss: 1416\n",
      "Training Epoch 76  42.6% | batch:        40 of        94\t|\tloss: 1110.51\n",
      "Training Epoch 76  43.6% | batch:        41 of        94\t|\tloss: 2995.01\n",
      "Training Epoch 76  44.7% | batch:        42 of        94\t|\tloss: 765.014\n",
      "Training Epoch 76  45.7% | batch:        43 of        94\t|\tloss: 964.231\n",
      "Training Epoch 76  46.8% | batch:        44 of        94\t|\tloss: 927.726\n",
      "Training Epoch 76  47.9% | batch:        45 of        94\t|\tloss: 686.332\n",
      "Training Epoch 76  48.9% | batch:        46 of        94\t|\tloss: 1235.32\n",
      "Training Epoch 76  50.0% | batch:        47 of        94\t|\tloss: 737.753\n",
      "Training Epoch 76  51.1% | batch:        48 of        94\t|\tloss: 787.848\n",
      "Training Epoch 76  52.1% | batch:        49 of        94\t|\tloss: 729.361\n",
      "Training Epoch 76  53.2% | batch:        50 of        94\t|\tloss: 812.455\n",
      "Training Epoch 76  54.3% | batch:        51 of        94\t|\tloss: 1715.17\n",
      "Training Epoch 76  55.3% | batch:        52 of        94\t|\tloss: 808.7\n",
      "Training Epoch 76  56.4% | batch:        53 of        94\t|\tloss: 756.349\n",
      "Training Epoch 76  57.4% | batch:        54 of        94\t|\tloss: 978.758\n",
      "Training Epoch 76  58.5% | batch:        55 of        94\t|\tloss: 896.277\n",
      "Training Epoch 76  59.6% | batch:        56 of        94\t|\tloss: 1025.91\n",
      "Training Epoch 76  60.6% | batch:        57 of        94\t|\tloss: 1192.05\n",
      "Training Epoch 76  61.7% | batch:        58 of        94\t|\tloss: 1375.87\n",
      "Training Epoch 76  62.8% | batch:        59 of        94\t|\tloss: 827.406\n",
      "Training Epoch 76  63.8% | batch:        60 of        94\t|\tloss: 959.566\n",
      "Training Epoch 76  64.9% | batch:        61 of        94\t|\tloss: 1709.74\n",
      "Training Epoch 76  66.0% | batch:        62 of        94\t|\tloss: 569.444\n",
      "Training Epoch 76  67.0% | batch:        63 of        94\t|\tloss: 1663.3\n",
      "Training Epoch 76  68.1% | batch:        64 of        94\t|\tloss: 1095.57\n",
      "Training Epoch 76  69.1% | batch:        65 of        94\t|\tloss: 748.866\n",
      "Training Epoch 76  70.2% | batch:        66 of        94\t|\tloss: 1093.29\n",
      "Training Epoch 76  71.3% | batch:        67 of        94\t|\tloss: 2684.32\n",
      "Training Epoch 76  72.3% | batch:        68 of        94\t|\tloss: 1057.06\n",
      "Training Epoch 76  73.4% | batch:        69 of        94\t|\tloss: 732.676\n",
      "Training Epoch 76  74.5% | batch:        70 of        94\t|\tloss: 1707.68\n",
      "Training Epoch 76  75.5% | batch:        71 of        94\t|\tloss: 776.876\n",
      "Training Epoch 76  76.6% | batch:        72 of        94\t|\tloss: 967.419\n",
      "Training Epoch 76  77.7% | batch:        73 of        94\t|\tloss: 817.344\n",
      "Training Epoch 76  78.7% | batch:        74 of        94\t|\tloss: 990.454\n",
      "Training Epoch 76  79.8% | batch:        75 of        94\t|\tloss: 1662.87\n",
      "Training Epoch 76  80.9% | batch:        76 of        94\t|\tloss: 1491.52\n",
      "Training Epoch 76  81.9% | batch:        77 of        94\t|\tloss: 924.679\n",
      "Training Epoch 76  83.0% | batch:        78 of        94\t|\tloss: 730.429\n",
      "Training Epoch 76  84.0% | batch:        79 of        94\t|\tloss: 882.203\n",
      "Training Epoch 76  85.1% | batch:        80 of        94\t|\tloss: 2062.11\n",
      "Training Epoch 76  86.2% | batch:        81 of        94\t|\tloss: 932.877\n",
      "Training Epoch 76  87.2% | batch:        82 of        94\t|\tloss: 1169.99\n",
      "Training Epoch 76  88.3% | batch:        83 of        94\t|\tloss: 2222.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:25,921 | INFO : Epoch 76 Training Summary: epoch: 76.000000 | loss: 1071.348941 | \n",
      "2023-05-04 17:01:25,922 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6645326614379883 seconds\n",
      "\n",
      "2023-05-04 17:01:25,923 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7836928649952537 seconds\n",
      "2023-05-04 17:01:25,924 | INFO : Avg batch train. time: 0.018975456010587807 seconds\n",
      "2023-05-04 17:01:25,924 | INFO : Avg sample train. time: 0.00014966377454231027 seconds\n",
      "2023-05-04 17:01:25,925 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 76  89.4% | batch:        84 of        94\t|\tloss: 991.46\n",
      "Training Epoch 76  90.4% | batch:        85 of        94\t|\tloss: 1111.42\n",
      "Training Epoch 76  91.5% | batch:        86 of        94\t|\tloss: 914.365\n",
      "Training Epoch 76  92.6% | batch:        87 of        94\t|\tloss: 809.227\n",
      "Training Epoch 76  93.6% | batch:        88 of        94\t|\tloss: 1327.52\n",
      "Training Epoch 76  94.7% | batch:        89 of        94\t|\tloss: 884.454\n",
      "Training Epoch 76  95.7% | batch:        90 of        94\t|\tloss: 777.115\n",
      "Training Epoch 76  96.8% | batch:        91 of        94\t|\tloss: 730.799\n",
      "Training Epoch 76  97.9% | batch:        92 of        94\t|\tloss: 1071.35\n",
      "Training Epoch 76  98.9% | batch:        93 of        94\t|\tloss: 1344.4\n",
      "\n",
      "Evaluating Epoch 76   0.0% | batch:         0 of        40\t|\tloss: 7991.55\n",
      "Evaluating Epoch 76   2.5% | batch:         1 of        40\t|\tloss: 1083.54\n",
      "Evaluating Epoch 76   5.0% | batch:         2 of        40\t|\tloss: 3015.63\n",
      "Evaluating Epoch 76   7.5% | batch:         3 of        40\t|\tloss: 7902.85\n",
      "Evaluating Epoch 76  10.0% | batch:         4 of        40\t|\tloss: 2833.17\n",
      "Evaluating Epoch 76  12.5% | batch:         5 of        40\t|\tloss: 3021.1\n",
      "Evaluating Epoch 76  15.0% | batch:         6 of        40\t|\tloss: 8675.34\n",
      "Evaluating Epoch 76  17.5% | batch:         7 of        40\t|\tloss: 3308.12\n",
      "Evaluating Epoch 76  20.0% | batch:         8 of        40\t|\tloss: 2992.84\n",
      "Evaluating Epoch 76  22.5% | batch:         9 of        40\t|\tloss: 2061.66\n",
      "Evaluating Epoch 76  25.0% | batch:        10 of        40\t|\tloss: 5617.82\n",
      "Evaluating Epoch 76  27.5% | batch:        11 of        40\t|\tloss: 1374.4\n",
      "Evaluating Epoch 76  30.0% | batch:        12 of        40\t|\tloss: 7023.88\n",
      "Evaluating Epoch 76  32.5% | batch:        13 of        40\t|\tloss: 3986.63\n",
      "Evaluating Epoch 76  35.0% | batch:        14 of        40\t|\tloss: 2063.09\n",
      "Evaluating Epoch 76  37.5% | batch:        15 of        40\t|\tloss: 3775.01\n",
      "Evaluating Epoch 76  40.0% | batch:        16 of        40\t|\tloss: 5263.48\n",
      "Evaluating Epoch 76  42.5% | batch:        17 of        40\t|\tloss: 2749.7\n",
      "Evaluating Epoch 76  45.0% | batch:        18 of        40\t|\tloss: 2739.03\n",
      "Evaluating Epoch 76  47.5% | batch:        19 of        40\t|\tloss: 5448.69\n",
      "Evaluating Epoch 76  50.0% | batch:        20 of        40\t|\tloss: 6077.99\n",
      "Evaluating Epoch 76  52.5% | batch:        21 of        40\t|\tloss: 1348.28\n",
      "Evaluating Epoch 76  55.0% | batch:        22 of        40\t|\tloss: 3920.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:26,375 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4490981101989746 seconds\n",
      "\n",
      "2023-05-04 17:01:26,375 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5306426897570862 seconds\n",
      "2023-05-04 17:01:26,376 | INFO : Avg batch val. time: 0.013266067243927154 seconds\n",
      "2023-05-04 17:01:26,377 | INFO : Avg sample val. time: 0.00010511939179023102 seconds\n",
      "2023-05-04 17:01:26,378 | INFO : Epoch 76 Validation Summary: epoch: 76.000000 | loss: 4341.840952 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 76  57.5% | batch:        23 of        40\t|\tloss: 3517.13\n",
      "Evaluating Epoch 76  60.0% | batch:        24 of        40\t|\tloss: 1621.63\n",
      "Evaluating Epoch 76  62.5% | batch:        25 of        40\t|\tloss: 3437.06\n",
      "Evaluating Epoch 76  65.0% | batch:        26 of        40\t|\tloss: 12125.5\n",
      "Evaluating Epoch 76  67.5% | batch:        27 of        40\t|\tloss: 2618.55\n",
      "Evaluating Epoch 76  70.0% | batch:        28 of        40\t|\tloss: 1772.25\n",
      "Evaluating Epoch 76  72.5% | batch:        29 of        40\t|\tloss: 9264.51\n",
      "Evaluating Epoch 76  75.0% | batch:        30 of        40\t|\tloss: 1680.78\n",
      "Evaluating Epoch 76  77.5% | batch:        31 of        40\t|\tloss: 1487.4\n",
      "Evaluating Epoch 76  80.0% | batch:        32 of        40\t|\tloss: 7275.51\n",
      "Evaluating Epoch 76  82.5% | batch:        33 of        40\t|\tloss: 7319.37\n",
      "Evaluating Epoch 76  85.0% | batch:        34 of        40\t|\tloss: 1039.57\n",
      "Evaluating Epoch 76  87.5% | batch:        35 of        40\t|\tloss: 4712.75\n",
      "Evaluating Epoch 76  90.0% | batch:        36 of        40\t|\tloss: 6819.98\n",
      "Evaluating Epoch 76  92.5% | batch:        37 of        40\t|\tloss: 2685.72\n",
      "Evaluating Epoch 76  95.0% | batch:        38 of        40\t|\tloss: 3471.69\n",
      "Evaluating Epoch 76  97.5% | batch:        39 of        40\t|\tloss: 13960\n",
      "\n",
      "Training Epoch 77   0.0% | batch:         0 of        94\t|\tloss: 1633.06\n",
      "Training Epoch 77   1.1% | batch:         1 of        94\t|\tloss: 956.689\n",
      "Training Epoch 77   2.1% | batch:         2 of        94\t|\tloss: 731.94\n",
      "Training Epoch 77   3.2% | batch:         3 of        94\t|\tloss: 576.999\n",
      "Training Epoch 77   4.3% | batch:         4 of        94\t|\tloss: 1027.81\n",
      "Training Epoch 77   5.3% | batch:         5 of        94\t|\tloss: 794.098\n",
      "Training Epoch 77   6.4% | batch:         6 of        94\t|\tloss: 1030.89\n",
      "Training Epoch 77   7.4% | batch:         7 of        94\t|\tloss: 975.471\n",
      "Training Epoch 77   8.5% | batch:         8 of        94\t|\tloss: 1610.95\n",
      "Training Epoch 77   9.6% | batch:         9 of        94\t|\tloss: 833.908\n",
      "Training Epoch 77  10.6% | batch:        10 of        94\t|\tloss: 955.995\n",
      "Training Epoch 77  11.7% | batch:        11 of        94\t|\tloss: 1080.93\n",
      "Training Epoch 77  12.8% | batch:        12 of        94\t|\tloss: 1184.38\n",
      "Training Epoch 77  13.8% | batch:        13 of        94\t|\tloss: 978.696\n",
      "Training Epoch 77  14.9% | batch:        14 of        94\t|\tloss: 841.357\n",
      "Training Epoch 77  16.0% | batch:        15 of        94\t|\tloss: 1019.95\n",
      "Training Epoch 77  17.0% | batch:        16 of        94\t|\tloss: 758.05\n",
      "Training Epoch 77  18.1% | batch:        17 of        94\t|\tloss: 629.716\n",
      "Training Epoch 77  19.1% | batch:        18 of        94\t|\tloss: 1713.33\n",
      "Training Epoch 77  20.2% | batch:        19 of        94\t|\tloss: 974.271\n",
      "Training Epoch 77  21.3% | batch:        20 of        94\t|\tloss: 665.267\n",
      "Training Epoch 77  22.3% | batch:        21 of        94\t|\tloss: 1189.24\n",
      "Training Epoch 77  23.4% | batch:        22 of        94\t|\tloss: 1420.42\n",
      "Training Epoch 77  24.5% | batch:        23 of        94\t|\tloss: 866.274\n",
      "Training Epoch 77  25.5% | batch:        24 of        94\t|\tloss: 544.504\n",
      "Training Epoch 77  26.6% | batch:        25 of        94\t|\tloss: 626.604\n",
      "Training Epoch 77  27.7% | batch:        26 of        94\t|\tloss: 1031.43\n",
      "Training Epoch 77  28.7% | batch:        27 of        94\t|\tloss: 980.136\n",
      "Training Epoch 77  29.8% | batch:        28 of        94\t|\tloss: 1372.33\n",
      "Training Epoch 77  30.9% | batch:        29 of        94\t|\tloss: 1748.31\n",
      "Training Epoch 77  31.9% | batch:        30 of        94\t|\tloss: 951.381\n",
      "Training Epoch 77  33.0% | batch:        31 of        94\t|\tloss: 931.34\n",
      "Training Epoch 77  34.0% | batch:        32 of        94\t|\tloss: 1952.75\n",
      "Training Epoch 77  35.1% | batch:        33 of        94\t|\tloss: 1025.89\n",
      "Training Epoch 77  36.2% | batch:        34 of        94\t|\tloss: 1004.23\n",
      "Training Epoch 77  37.2% | batch:        35 of        94\t|\tloss: 856.625\n",
      "Training Epoch 77  38.3% | batch:        36 of        94\t|\tloss: 1232\n",
      "Training Epoch 77  39.4% | batch:        37 of        94\t|\tloss: 810.142\n",
      "Training Epoch 77  40.4% | batch:        38 of        94\t|\tloss: 985.46\n",
      "Training Epoch 77  41.5% | batch:        39 of        94\t|\tloss: 751.29\n",
      "Training Epoch 77  42.6% | batch:        40 of        94\t|\tloss: 657.025\n",
      "Training Epoch 77  43.6% | batch:        41 of        94\t|\tloss: 998.504\n",
      "Training Epoch 77  44.7% | batch:        42 of        94\t|\tloss: 1085.33\n",
      "Training Epoch 77  45.7% | batch:        43 of        94\t|\tloss: 831.999\n",
      "Training Epoch 77  46.8% | batch:        44 of        94\t|\tloss: 925.112\n",
      "Training Epoch 77  47.9% | batch:        45 of        94\t|\tloss: 859.921\n",
      "Training Epoch 77  48.9% | batch:        46 of        94\t|\tloss: 1389.33\n",
      "Training Epoch 77  50.0% | batch:        47 of        94\t|\tloss: 921.64\n",
      "Training Epoch 77  51.1% | batch:        48 of        94\t|\tloss: 829.217\n",
      "Training Epoch 77  52.1% | batch:        49 of        94\t|\tloss: 720.508\n",
      "Training Epoch 77  53.2% | batch:        50 of        94\t|\tloss: 1967.28\n",
      "Training Epoch 77  54.3% | batch:        51 of        94\t|\tloss: 941.606\n",
      "Training Epoch 77  55.3% | batch:        52 of        94\t|\tloss: 778.368\n",
      "Training Epoch 77  56.4% | batch:        53 of        94\t|\tloss: 867.029\n",
      "Training Epoch 77  57.4% | batch:        54 of        94\t|\tloss: 495.045\n",
      "Training Epoch 77  58.5% | batch:        55 of        94\t|\tloss: 1381.88\n",
      "Training Epoch 77  59.6% | batch:        56 of        94\t|\tloss: 1248.53\n",
      "Training Epoch 77  60.6% | batch:        57 of        94\t|\tloss: 931.131\n",
      "Training Epoch 77  61.7% | batch:        58 of        94\t|\tloss: 756.081\n",
      "Training Epoch 77  62.8% | batch:        59 of        94\t|\tloss: 1253.24\n",
      "Training Epoch 77  63.8% | batch:        60 of        94\t|\tloss: 863.001\n",
      "Training Epoch 77  64.9% | batch:        61 of        94\t|\tloss: 960.051\n",
      "Training Epoch 77  66.0% | batch:        62 of        94\t|\tloss: 751.936\n",
      "Training Epoch 77  67.0% | batch:        63 of        94\t|\tloss: 710.216\n",
      "Training Epoch 77  68.1% | batch:        64 of        94\t|\tloss: 1557.57\n",
      "Training Epoch 77  69.1% | batch:        65 of        94\t|\tloss: 2968.87\n",
      "Training Epoch 77  70.2% | batch:        66 of        94\t|\tloss: 828.19\n",
      "Training Epoch 77  71.3% | batch:        67 of        94\t|\tloss: 1720.94\n",
      "Training Epoch 77  72.3% | batch:        68 of        94\t|\tloss: 1602.42\n",
      "Training Epoch 77  73.4% | batch:        69 of        94\t|\tloss: 721.273\n",
      "Training Epoch 77  74.5% | batch:        70 of        94\t|\tloss: 1282.56\n",
      "Training Epoch 77  75.5% | batch:        71 of        94\t|\tloss: 778.5\n",
      "Training Epoch 77  76.6% | batch:        72 of        94\t|\tloss: 939.295\n",
      "Training Epoch 77  77.7% | batch:        73 of        94\t|\tloss: 905.989\n",
      "Training Epoch 77  78.7% | batch:        74 of        94\t|\tloss: 754.301\n",
      "Training Epoch 77  79.8% | batch:        75 of        94\t|\tloss: 854.968\n",
      "Training Epoch 77  80.9% | batch:        76 of        94\t|\tloss: 764.85\n",
      "Training Epoch 77  81.9% | batch:        77 of        94\t|\tloss: 1355.49\n",
      "Training Epoch 77  83.0% | batch:        78 of        94\t|\tloss: 769.292\n",
      "Training Epoch 77  84.0% | batch:        79 of        94\t|\tloss: 1216.8\n",
      "Training Epoch 77  85.1% | batch:        80 of        94\t|\tloss: 880.349\n",
      "Training Epoch 77  86.2% | batch:        81 of        94\t|\tloss: 1025.52\n",
      "Training Epoch 77  87.2% | batch:        82 of        94\t|\tloss: 841.01\n",
      "Training Epoch 77  88.3% | batch:        83 of        94\t|\tloss: 594.973\n",
      "Training Epoch 77  89.4% | batch:        84 of        94\t|\tloss: 1796.61\n",
      "Training Epoch 77  90.4% | batch:        85 of        94\t|\tloss: 833.742\n",
      "Training Epoch 77  91.5% | batch:        86 of        94\t|\tloss: 973.224\n",
      "Training Epoch 77  92.6% | batch:        87 of        94\t|\tloss: 823.234\n",
      "Training Epoch 77  93.6% | batch:        88 of        94\t|\tloss: 883.464\n",
      "Training Epoch 77  94.7% | batch:        89 of        94\t|\tloss: 961.291\n",
      "Training Epoch 77  95.7% | batch:        90 of        94\t|\tloss: 1178.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:28,145 | INFO : Epoch 77 Training Summary: epoch: 77.000000 | loss: 1031.906174 | \n",
      "2023-05-04 17:01:28,146 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7452139854431152 seconds\n",
      "\n",
      "2023-05-04 17:01:28,147 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7831931392867844 seconds\n",
      "2023-05-04 17:01:28,147 | INFO : Avg batch train. time: 0.018970139779646643 seconds\n",
      "2023-05-04 17:01:28,148 | INFO : Avg sample train. time: 0.0001496218442093291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 77  96.8% | batch:        91 of        94\t|\tloss: 993.87\n",
      "Training Epoch 77  97.9% | batch:        92 of        94\t|\tloss: 773.046\n",
      "Training Epoch 77  98.9% | batch:        93 of        94\t|\tloss: 1116.1\n",
      "\n",
      "Training Epoch 78   0.0% | batch:         0 of        94\t|\tloss: 703.642\n",
      "Training Epoch 78   1.1% | batch:         1 of        94\t|\tloss: 974.966\n",
      "Training Epoch 78   2.1% | batch:         2 of        94\t|\tloss: 931.986\n",
      "Training Epoch 78   3.2% | batch:         3 of        94\t|\tloss: 1039.77\n",
      "Training Epoch 78   4.3% | batch:         4 of        94\t|\tloss: 1107.41\n",
      "Training Epoch 78   5.3% | batch:         5 of        94\t|\tloss: 756.63\n",
      "Training Epoch 78   6.4% | batch:         6 of        94\t|\tloss: 929.123\n",
      "Training Epoch 78   7.4% | batch:         7 of        94\t|\tloss: 726.304\n",
      "Training Epoch 78   8.5% | batch:         8 of        94\t|\tloss: 882.646\n",
      "Training Epoch 78   9.6% | batch:         9 of        94\t|\tloss: 857.461\n",
      "Training Epoch 78  10.6% | batch:        10 of        94\t|\tloss: 1262.56\n",
      "Training Epoch 78  11.7% | batch:        11 of        94\t|\tloss: 774.536\n",
      "Training Epoch 78  12.8% | batch:        12 of        94\t|\tloss: 1174.22\n",
      "Training Epoch 78  13.8% | batch:        13 of        94\t|\tloss: 1318.74\n",
      "Training Epoch 78  14.9% | batch:        14 of        94\t|\tloss: 1264.84\n",
      "Training Epoch 78  16.0% | batch:        15 of        94\t|\tloss: 737.579\n",
      "Training Epoch 78  17.0% | batch:        16 of        94\t|\tloss: 932.722\n",
      "Training Epoch 78  18.1% | batch:        17 of        94\t|\tloss: 1477.14\n",
      "Training Epoch 78  19.1% | batch:        18 of        94\t|\tloss: 803.905\n",
      "Training Epoch 78  20.2% | batch:        19 of        94\t|\tloss: 653.488\n",
      "Training Epoch 78  21.3% | batch:        20 of        94\t|\tloss: 660.055\n",
      "Training Epoch 78  22.3% | batch:        21 of        94\t|\tloss: 1081.91\n",
      "Training Epoch 78  23.4% | batch:        22 of        94\t|\tloss: 1918.46\n",
      "Training Epoch 78  24.5% | batch:        23 of        94\t|\tloss: 1439.43\n",
      "Training Epoch 78  25.5% | batch:        24 of        94\t|\tloss: 1192.28\n",
      "Training Epoch 78  26.6% | batch:        25 of        94\t|\tloss: 914.421\n",
      "Training Epoch 78  27.7% | batch:        26 of        94\t|\tloss: 1028.44\n",
      "Training Epoch 78  28.7% | batch:        27 of        94\t|\tloss: 513.667\n",
      "Training Epoch 78  29.8% | batch:        28 of        94\t|\tloss: 1047.12\n",
      "Training Epoch 78  30.9% | batch:        29 of        94\t|\tloss: 697.626\n",
      "Training Epoch 78  31.9% | batch:        30 of        94\t|\tloss: 1101.13\n",
      "Training Epoch 78  33.0% | batch:        31 of        94\t|\tloss: 829.826\n",
      "Training Epoch 78  34.0% | batch:        32 of        94\t|\tloss: 1375.52\n",
      "Training Epoch 78  35.1% | batch:        33 of        94\t|\tloss: 1312.21\n",
      "Training Epoch 78  36.2% | batch:        34 of        94\t|\tloss: 822.254\n",
      "Training Epoch 78  37.2% | batch:        35 of        94\t|\tloss: 965.729\n",
      "Training Epoch 78  38.3% | batch:        36 of        94\t|\tloss: 867.396\n",
      "Training Epoch 78  39.4% | batch:        37 of        94\t|\tloss: 1128.88\n",
      "Training Epoch 78  40.4% | batch:        38 of        94\t|\tloss: 947.34\n",
      "Training Epoch 78  41.5% | batch:        39 of        94\t|\tloss: 849.313\n",
      "Training Epoch 78  42.6% | batch:        40 of        94\t|\tloss: 1110.31\n",
      "Training Epoch 78  43.6% | batch:        41 of        94\t|\tloss: 1000.56\n",
      "Training Epoch 78  44.7% | batch:        42 of        94\t|\tloss: 831.045\n",
      "Training Epoch 78  45.7% | batch:        43 of        94\t|\tloss: 784.221\n",
      "Training Epoch 78  46.8% | batch:        44 of        94\t|\tloss: 731.885\n",
      "Training Epoch 78  47.9% | batch:        45 of        94\t|\tloss: 733.211\n",
      "Training Epoch 78  48.9% | batch:        46 of        94\t|\tloss: 779.261\n",
      "Training Epoch 78  50.0% | batch:        47 of        94\t|\tloss: 931.594\n",
      "Training Epoch 78  51.1% | batch:        48 of        94\t|\tloss: 1209.06\n",
      "Training Epoch 78  52.1% | batch:        49 of        94\t|\tloss: 813.597\n",
      "Training Epoch 78  53.2% | batch:        50 of        94\t|\tloss: 804.825\n",
      "Training Epoch 78  54.3% | batch:        51 of        94\t|\tloss: 853.218\n",
      "Training Epoch 78  55.3% | batch:        52 of        94\t|\tloss: 897.332\n",
      "Training Epoch 78  56.4% | batch:        53 of        94\t|\tloss: 1022.14\n",
      "Training Epoch 78  57.4% | batch:        54 of        94\t|\tloss: 1154.51\n",
      "Training Epoch 78  58.5% | batch:        55 of        94\t|\tloss: 1572.51\n",
      "Training Epoch 78  59.6% | batch:        56 of        94\t|\tloss: 691.24\n",
      "Training Epoch 78  60.6% | batch:        57 of        94\t|\tloss: 896.721\n",
      "Training Epoch 78  61.7% | batch:        58 of        94\t|\tloss: 623.771\n",
      "Training Epoch 78  62.8% | batch:        59 of        94\t|\tloss: 853.072\n",
      "Training Epoch 78  63.8% | batch:        60 of        94\t|\tloss: 923.477\n",
      "Training Epoch 78  64.9% | batch:        61 of        94\t|\tloss: 1276.63\n",
      "Training Epoch 78  66.0% | batch:        62 of        94\t|\tloss: 1060.29\n",
      "Training Epoch 78  67.0% | batch:        63 of        94\t|\tloss: 997.574\n",
      "Training Epoch 78  68.1% | batch:        64 of        94\t|\tloss: 1259.76\n",
      "Training Epoch 78  69.1% | batch:        65 of        94\t|\tloss: 889.605\n",
      "Training Epoch 78  70.2% | batch:        66 of        94\t|\tloss: 981.452\n",
      "Training Epoch 78  71.3% | batch:        67 of        94\t|\tloss: 1068.92\n",
      "Training Epoch 78  72.3% | batch:        68 of        94\t|\tloss: 946.668\n",
      "Training Epoch 78  73.4% | batch:        69 of        94\t|\tloss: 789.811\n",
      "Training Epoch 78  74.5% | batch:        70 of        94\t|\tloss: 1215.44\n",
      "Training Epoch 78  75.5% | batch:        71 of        94\t|\tloss: 762.367\n",
      "Training Epoch 78  76.6% | batch:        72 of        94\t|\tloss: 1524.3\n",
      "Training Epoch 78  77.7% | batch:        73 of        94\t|\tloss: 978.904\n",
      "Training Epoch 78  78.7% | batch:        74 of        94\t|\tloss: 824.212\n",
      "Training Epoch 78  79.8% | batch:        75 of        94\t|\tloss: 792.121\n",
      "Training Epoch 78  80.9% | batch:        76 of        94\t|\tloss: 891.947\n",
      "Training Epoch 78  81.9% | batch:        77 of        94\t|\tloss: 1323.61\n",
      "Training Epoch 78  83.0% | batch:        78 of        94\t|\tloss: 686.745\n",
      "Training Epoch 78  84.0% | batch:        79 of        94\t|\tloss: 1281.83\n",
      "Training Epoch 78  85.1% | batch:        80 of        94\t|\tloss: 1678.73\n",
      "Training Epoch 78  86.2% | batch:        81 of        94\t|\tloss: 868.917\n",
      "Training Epoch 78  87.2% | batch:        82 of        94\t|\tloss: 691.637\n",
      "Training Epoch 78  88.3% | batch:        83 of        94\t|\tloss: 1714.54\n",
      "Training Epoch 78  89.4% | batch:        84 of        94\t|\tloss: 737.425\n",
      "Training Epoch 78  90.4% | batch:        85 of        94\t|\tloss: 1385.86\n",
      "Training Epoch 78  91.5% | batch:        86 of        94\t|\tloss: 1167.54\n",
      "Training Epoch 78  92.6% | batch:        87 of        94\t|\tloss: 957.385\n",
      "Training Epoch 78  93.6% | batch:        88 of        94\t|\tloss: 1159.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:29,892 | INFO : Epoch 78 Training Summary: epoch: 78.000000 | loss: 1001.815823 | \n",
      "2023-05-04 17:01:29,893 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7201383113861084 seconds\n",
      "\n",
      "2023-05-04 17:01:29,894 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7823847440572886 seconds\n",
      "2023-05-04 17:01:29,894 | INFO : Avg batch train. time: 0.01896153983039669 seconds\n",
      "2023-05-04 17:01:29,894 | INFO : Avg sample train. time: 0.00014955401443675858 seconds\n",
      "2023-05-04 17:01:29,895 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 78  94.7% | batch:        89 of        94\t|\tloss: 852.136\n",
      "Training Epoch 78  95.7% | batch:        90 of        94\t|\tloss: 746.763\n",
      "Training Epoch 78  96.8% | batch:        91 of        94\t|\tloss: 1188.07\n",
      "Training Epoch 78  97.9% | batch:        92 of        94\t|\tloss: 1276.14\n",
      "Training Epoch 78  98.9% | batch:        93 of        94\t|\tloss: 744.648\n",
      "\n",
      "Evaluating Epoch 78   0.0% | batch:         0 of        40\t|\tloss: 7631.72\n",
      "Evaluating Epoch 78   2.5% | batch:         1 of        40\t|\tloss: 1430.22\n",
      "Evaluating Epoch 78   5.0% | batch:         2 of        40\t|\tloss: 4595.43\n",
      "Evaluating Epoch 78   7.5% | batch:         3 of        40\t|\tloss: 7344.68\n",
      "Evaluating Epoch 78  10.0% | batch:         4 of        40\t|\tloss: 2897.55\n",
      "Evaluating Epoch 78  12.5% | batch:         5 of        40\t|\tloss: 3117.91\n",
      "Evaluating Epoch 78  15.0% | batch:         6 of        40\t|\tloss: 9174.53\n",
      "Evaluating Epoch 78  17.5% | batch:         7 of        40\t|\tloss: 3369.82\n",
      "Evaluating Epoch 78  20.0% | batch:         8 of        40\t|\tloss: 3229.92\n",
      "Evaluating Epoch 78  22.5% | batch:         9 of        40\t|\tloss: 2457.17\n",
      "Evaluating Epoch 78  25.0% | batch:        10 of        40\t|\tloss: 4566.33\n",
      "Evaluating Epoch 78  27.5% | batch:        11 of        40\t|\tloss: 1856.1\n",
      "Evaluating Epoch 78  30.0% | batch:        12 of        40\t|\tloss: 6084.9\n",
      "Evaluating Epoch 78  32.5% | batch:        13 of        40\t|\tloss: 2880.3\n",
      "Evaluating Epoch 78  35.0% | batch:        14 of        40\t|\tloss: 2110.57\n",
      "Evaluating Epoch 78  37.5% | batch:        15 of        40\t|\tloss: 3786.59\n",
      "Evaluating Epoch 78  40.0% | batch:        16 of        40\t|\tloss: 4250.45\n",
      "Evaluating Epoch 78  42.5% | batch:        17 of        40\t|\tloss: 2971.59\n",
      "Evaluating Epoch 78  45.0% | batch:        18 of        40\t|\tloss: 2943.95\n",
      "Evaluating Epoch 78  47.5% | batch:        19 of        40\t|\tloss: 5275.47\n",
      "Evaluating Epoch 78  50.0% | batch:        20 of        40\t|\tloss: 5283.15\n",
      "Evaluating Epoch 78  52.5% | batch:        21 of        40\t|\tloss: 1147.87\n",
      "Evaluating Epoch 78  55.0% | batch:        22 of        40\t|\tloss: 4056.41\n",
      "Evaluating Epoch 78  57.5% | batch:        23 of        40\t|\tloss: 3356.21\n",
      "Evaluating Epoch 78  60.0% | batch:        24 of        40\t|\tloss: 1880.23\n",
      "Evaluating Epoch 78  62.5% | batch:        25 of        40\t|\tloss: 4162.75\n",
      "Evaluating Epoch 78  65.0% | batch:        26 of        40\t|\tloss: 8245.18\n",
      "Evaluating Epoch 78  67.5% | batch:        27 of        40\t|\tloss: 3071.48\n",
      "Evaluating Epoch 78  70.0% | batch:        28 of        40\t|\tloss: 2956.38\n",
      "Evaluating Epoch 78  72.5% | batch:        29 of        40\t|\tloss: 8123.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:30,345 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44933342933654785 seconds\n",
      "\n",
      "2023-05-04 17:01:30,345 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5302401686658954 seconds\n",
      "2023-05-04 17:01:30,346 | INFO : Avg batch val. time: 0.013256004216647386 seconds\n",
      "2023-05-04 17:01:30,347 | INFO : Avg sample val. time: 0.00010503965306376692 seconds\n",
      "2023-05-04 17:01:30,347 | INFO : Epoch 78 Validation Summary: epoch: 78.000000 | loss: 4286.679223 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 78  75.0% | batch:        30 of        40\t|\tloss: 1861.96\n",
      "Evaluating Epoch 78  77.5% | batch:        31 of        40\t|\tloss: 2256.19\n",
      "Evaluating Epoch 78  80.0% | batch:        32 of        40\t|\tloss: 7960.88\n",
      "Evaluating Epoch 78  82.5% | batch:        33 of        40\t|\tloss: 5781.79\n",
      "Evaluating Epoch 78  85.0% | batch:        34 of        40\t|\tloss: 1472.72\n",
      "Evaluating Epoch 78  87.5% | batch:        35 of        40\t|\tloss: 7450.59\n",
      "Evaluating Epoch 78  90.0% | batch:        36 of        40\t|\tloss: 5366.79\n",
      "Evaluating Epoch 78  92.5% | batch:        37 of        40\t|\tloss: 2913.15\n",
      "Evaluating Epoch 78  95.0% | batch:        38 of        40\t|\tloss: 3975.89\n",
      "Evaluating Epoch 78  97.5% | batch:        39 of        40\t|\tloss: 13159.1\n",
      "\n",
      "Training Epoch 79   0.0% | batch:         0 of        94\t|\tloss: 1139.71\n",
      "Training Epoch 79   1.1% | batch:         1 of        94\t|\tloss: 893.648\n",
      "Training Epoch 79   2.1% | batch:         2 of        94\t|\tloss: 1178.15\n",
      "Training Epoch 79   3.2% | batch:         3 of        94\t|\tloss: 1038.44\n",
      "Training Epoch 79   4.3% | batch:         4 of        94\t|\tloss: 1149.68\n",
      "Training Epoch 79   5.3% | batch:         5 of        94\t|\tloss: 757.344\n",
      "Training Epoch 79   6.4% | batch:         6 of        94\t|\tloss: 723.583\n",
      "Training Epoch 79   7.4% | batch:         7 of        94\t|\tloss: 1121.73\n",
      "Training Epoch 79   8.5% | batch:         8 of        94\t|\tloss: 1348.72\n",
      "Training Epoch 79   9.6% | batch:         9 of        94\t|\tloss: 935.106\n",
      "Training Epoch 79  10.6% | batch:        10 of        94\t|\tloss: 1504.39\n",
      "Training Epoch 79  11.7% | batch:        11 of        94\t|\tloss: 994.829\n",
      "Training Epoch 79  12.8% | batch:        12 of        94\t|\tloss: 875.077\n",
      "Training Epoch 79  13.8% | batch:        13 of        94\t|\tloss: 1018.36\n",
      "Training Epoch 79  14.9% | batch:        14 of        94\t|\tloss: 989.058\n",
      "Training Epoch 79  16.0% | batch:        15 of        94\t|\tloss: 677.909\n",
      "Training Epoch 79  17.0% | batch:        16 of        94\t|\tloss: 1343.68\n",
      "Training Epoch 79  18.1% | batch:        17 of        94\t|\tloss: 923.686\n",
      "Training Epoch 79  19.1% | batch:        18 of        94\t|\tloss: 897.87\n",
      "Training Epoch 79  20.2% | batch:        19 of        94\t|\tloss: 617.693\n",
      "Training Epoch 79  21.3% | batch:        20 of        94\t|\tloss: 734.081\n",
      "Training Epoch 79  22.3% | batch:        21 of        94\t|\tloss: 844.959\n",
      "Training Epoch 79  23.4% | batch:        22 of        94\t|\tloss: 1106.85\n",
      "Training Epoch 79  24.5% | batch:        23 of        94\t|\tloss: 746.593\n",
      "Training Epoch 79  25.5% | batch:        24 of        94\t|\tloss: 972.299\n",
      "Training Epoch 79  26.6% | batch:        25 of        94\t|\tloss: 1549.24\n",
      "Training Epoch 79  27.7% | batch:        26 of        94\t|\tloss: 706.213\n",
      "Training Epoch 79  28.7% | batch:        27 of        94\t|\tloss: 1067.82\n",
      "Training Epoch 79  29.8% | batch:        28 of        94\t|\tloss: 831.816\n",
      "Training Epoch 79  30.9% | batch:        29 of        94\t|\tloss: 930.387\n",
      "Training Epoch 79  31.9% | batch:        30 of        94\t|\tloss: 1058.71\n",
      "Training Epoch 79  33.0% | batch:        31 of        94\t|\tloss: 671.428\n",
      "Training Epoch 79  34.0% | batch:        32 of        94\t|\tloss: 667.004\n",
      "Training Epoch 79  35.1% | batch:        33 of        94\t|\tloss: 1514.57\n",
      "Training Epoch 79  36.2% | batch:        34 of        94\t|\tloss: 1202.26\n",
      "Training Epoch 79  37.2% | batch:        35 of        94\t|\tloss: 662.527\n",
      "Training Epoch 79  38.3% | batch:        36 of        94\t|\tloss: 681.653\n",
      "Training Epoch 79  39.4% | batch:        37 of        94\t|\tloss: 1163.72\n",
      "Training Epoch 79  40.4% | batch:        38 of        94\t|\tloss: 1080.71\n",
      "Training Epoch 79  41.5% | batch:        39 of        94\t|\tloss: 867.61\n",
      "Training Epoch 79  42.6% | batch:        40 of        94\t|\tloss: 758.391\n",
      "Training Epoch 79  43.6% | batch:        41 of        94\t|\tloss: 1193.68\n",
      "Training Epoch 79  44.7% | batch:        42 of        94\t|\tloss: 1145.17\n",
      "Training Epoch 79  45.7% | batch:        43 of        94\t|\tloss: 1146.22\n",
      "Training Epoch 79  46.8% | batch:        44 of        94\t|\tloss: 1042.28\n",
      "Training Epoch 79  47.9% | batch:        45 of        94\t|\tloss: 591.291\n",
      "Training Epoch 79  48.9% | batch:        46 of        94\t|\tloss: 1599.58\n",
      "Training Epoch 79  50.0% | batch:        47 of        94\t|\tloss: 1017.31\n",
      "Training Epoch 79  51.1% | batch:        48 of        94\t|\tloss: 848.482\n",
      "Training Epoch 79  52.1% | batch:        49 of        94\t|\tloss: 767.711\n",
      "Training Epoch 79  53.2% | batch:        50 of        94\t|\tloss: 1084.56\n",
      "Training Epoch 79  54.3% | batch:        51 of        94\t|\tloss: 903.044\n",
      "Training Epoch 79  55.3% | batch:        52 of        94\t|\tloss: 1124.14\n",
      "Training Epoch 79  56.4% | batch:        53 of        94\t|\tloss: 1198.89\n",
      "Training Epoch 79  57.4% | batch:        54 of        94\t|\tloss: 1106.65\n",
      "Training Epoch 79  58.5% | batch:        55 of        94\t|\tloss: 1511.73\n",
      "Training Epoch 79  59.6% | batch:        56 of        94\t|\tloss: 713.72\n",
      "Training Epoch 79  60.6% | batch:        57 of        94\t|\tloss: 797.003\n",
      "Training Epoch 79  61.7% | batch:        58 of        94\t|\tloss: 940.406\n",
      "Training Epoch 79  62.8% | batch:        59 of        94\t|\tloss: 1548.83\n",
      "Training Epoch 79  63.8% | batch:        60 of        94\t|\tloss: 801.536\n",
      "Training Epoch 79  64.9% | batch:        61 of        94\t|\tloss: 1387.97\n",
      "Training Epoch 79  66.0% | batch:        62 of        94\t|\tloss: 851.07\n",
      "Training Epoch 79  67.0% | batch:        63 of        94\t|\tloss: 973.285\n",
      "Training Epoch 79  68.1% | batch:        64 of        94\t|\tloss: 1252.41\n",
      "Training Epoch 79  69.1% | batch:        65 of        94\t|\tloss: 823.717\n",
      "Training Epoch 79  70.2% | batch:        66 of        94\t|\tloss: 1093.56\n",
      "Training Epoch 79  71.3% | batch:        67 of        94\t|\tloss: 1029.52\n",
      "Training Epoch 79  72.3% | batch:        68 of        94\t|\tloss: 903.082\n",
      "Training Epoch 79  73.4% | batch:        69 of        94\t|\tloss: 1443.21\n",
      "Training Epoch 79  74.5% | batch:        70 of        94\t|\tloss: 2027.79\n",
      "Training Epoch 79  75.5% | batch:        71 of        94\t|\tloss: 788.643\n",
      "Training Epoch 79  76.6% | batch:        72 of        94\t|\tloss: 872.754\n",
      "Training Epoch 79  77.7% | batch:        73 of        94\t|\tloss: 833.367\n",
      "Training Epoch 79  78.7% | batch:        74 of        94\t|\tloss: 877.64\n",
      "Training Epoch 79  79.8% | batch:        75 of        94\t|\tloss: 1173.93\n",
      "Training Epoch 79  80.9% | batch:        76 of        94\t|\tloss: 649.986\n",
      "Training Epoch 79  81.9% | batch:        77 of        94\t|\tloss: 1837.88\n",
      "Training Epoch 79  83.0% | batch:        78 of        94\t|\tloss: 775.189\n",
      "Training Epoch 79  84.0% | batch:        79 of        94\t|\tloss: 803.492\n",
      "Training Epoch 79  85.1% | batch:        80 of        94\t|\tloss: 2356.21\n",
      "Training Epoch 79  86.2% | batch:        81 of        94\t|\tloss: 879.635\n",
      "Training Epoch 79  87.2% | batch:        82 of        94\t|\tloss: 1066.03\n",
      "Training Epoch 79  88.3% | batch:        83 of        94\t|\tloss: 912.874\n",
      "Training Epoch 79  89.4% | batch:        84 of        94\t|\tloss: 841.422\n",
      "Training Epoch 79  90.4% | batch:        85 of        94\t|\tloss: 1018.35\n",
      "Training Epoch 79  91.5% | batch:        86 of        94\t|\tloss: 794.582\n",
      "Training Epoch 79  92.6% | batch:        87 of        94\t|\tloss: 1579.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:32,057 | INFO : Epoch 79 Training Summary: epoch: 79.000000 | loss: 1050.448193 | \n",
      "2023-05-04 17:01:32,058 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6873886585235596 seconds\n",
      "\n",
      "2023-05-04 17:01:32,058 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7811822619619249 seconds\n",
      "2023-05-04 17:01:32,059 | INFO : Avg batch train. time: 0.018948747467680053 seconds\n",
      "2023-05-04 17:01:32,059 | INFO : Avg sample train. time: 0.00014945311813743285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 79  93.6% | batch:        88 of        94\t|\tloss: 1441.56\n",
      "Training Epoch 79  94.7% | batch:        89 of        94\t|\tloss: 1453.13\n",
      "Training Epoch 79  95.7% | batch:        90 of        94\t|\tloss: 1265.47\n",
      "Training Epoch 79  96.8% | batch:        91 of        94\t|\tloss: 1464.63\n",
      "Training Epoch 79  97.9% | batch:        92 of        94\t|\tloss: 1138.38\n",
      "Training Epoch 79  98.9% | batch:        93 of        94\t|\tloss: 1526.99\n",
      "\n",
      "Training Epoch 80   0.0% | batch:         0 of        94\t|\tloss: 704.025\n",
      "Training Epoch 80   1.1% | batch:         1 of        94\t|\tloss: 816.616\n",
      "Training Epoch 80   2.1% | batch:         2 of        94\t|\tloss: 1422.25\n",
      "Training Epoch 80   3.2% | batch:         3 of        94\t|\tloss: 953.931\n",
      "Training Epoch 80   4.3% | batch:         4 of        94\t|\tloss: 1021.95\n",
      "Training Epoch 80   5.3% | batch:         5 of        94\t|\tloss: 1143\n",
      "Training Epoch 80   6.4% | batch:         6 of        94\t|\tloss: 820.51\n",
      "Training Epoch 80   7.4% | batch:         7 of        94\t|\tloss: 852.85\n",
      "Training Epoch 80   8.5% | batch:         8 of        94\t|\tloss: 854.23\n",
      "Training Epoch 80   9.6% | batch:         9 of        94\t|\tloss: 1049.29\n",
      "Training Epoch 80  10.6% | batch:        10 of        94\t|\tloss: 716.469\n",
      "Training Epoch 80  11.7% | batch:        11 of        94\t|\tloss: 1191.73\n",
      "Training Epoch 80  12.8% | batch:        12 of        94\t|\tloss: 765.728\n",
      "Training Epoch 80  13.8% | batch:        13 of        94\t|\tloss: 1664.37\n",
      "Training Epoch 80  14.9% | batch:        14 of        94\t|\tloss: 1208.51\n",
      "Training Epoch 80  16.0% | batch:        15 of        94\t|\tloss: 689.053\n",
      "Training Epoch 80  17.0% | batch:        16 of        94\t|\tloss: 802.805\n",
      "Training Epoch 80  18.1% | batch:        17 of        94\t|\tloss: 1212.48\n",
      "Training Epoch 80  19.1% | batch:        18 of        94\t|\tloss: 918.41\n",
      "Training Epoch 80  20.2% | batch:        19 of        94\t|\tloss: 670.303\n",
      "Training Epoch 80  21.3% | batch:        20 of        94\t|\tloss: 847.059\n",
      "Training Epoch 80  22.3% | batch:        21 of        94\t|\tloss: 1140.04\n",
      "Training Epoch 80  23.4% | batch:        22 of        94\t|\tloss: 1020.38\n",
      "Training Epoch 80  24.5% | batch:        23 of        94\t|\tloss: 931.979\n",
      "Training Epoch 80  25.5% | batch:        24 of        94\t|\tloss: 1090.48\n",
      "Training Epoch 80  26.6% | batch:        25 of        94\t|\tloss: 930.824\n",
      "Training Epoch 80  27.7% | batch:        26 of        94\t|\tloss: 1229.85\n",
      "Training Epoch 80  28.7% | batch:        27 of        94\t|\tloss: 1086.08\n",
      "Training Epoch 80  29.8% | batch:        28 of        94\t|\tloss: 717.534\n",
      "Training Epoch 80  30.9% | batch:        29 of        94\t|\tloss: 1187.69\n",
      "Training Epoch 80  31.9% | batch:        30 of        94\t|\tloss: 582.049\n",
      "Training Epoch 80  33.0% | batch:        31 of        94\t|\tloss: 736.306\n",
      "Training Epoch 80  34.0% | batch:        32 of        94\t|\tloss: 730.7\n",
      "Training Epoch 80  35.1% | batch:        33 of        94\t|\tloss: 898.666\n",
      "Training Epoch 80  36.2% | batch:        34 of        94\t|\tloss: 2486.58\n",
      "Training Epoch 80  37.2% | batch:        35 of        94\t|\tloss: 725.44\n",
      "Training Epoch 80  38.3% | batch:        36 of        94\t|\tloss: 780.627\n",
      "Training Epoch 80  39.4% | batch:        37 of        94\t|\tloss: 888.192\n",
      "Training Epoch 80  40.4% | batch:        38 of        94\t|\tloss: 1054.08\n",
      "Training Epoch 80  41.5% | batch:        39 of        94\t|\tloss: 954.302\n",
      "Training Epoch 80  42.6% | batch:        40 of        94\t|\tloss: 921.768\n",
      "Training Epoch 80  43.6% | batch:        41 of        94\t|\tloss: 880.292\n",
      "Training Epoch 80  44.7% | batch:        42 of        94\t|\tloss: 871.49\n",
      "Training Epoch 80  45.7% | batch:        43 of        94\t|\tloss: 862.47\n",
      "Training Epoch 80  46.8% | batch:        44 of        94\t|\tloss: 789.224\n",
      "Training Epoch 80  47.9% | batch:        45 of        94\t|\tloss: 750.806\n",
      "Training Epoch 80  48.9% | batch:        46 of        94\t|\tloss: 1507.22\n",
      "Training Epoch 80  50.0% | batch:        47 of        94\t|\tloss: 1170.55\n",
      "Training Epoch 80  51.1% | batch:        48 of        94\t|\tloss: 800.353\n",
      "Training Epoch 80  52.1% | batch:        49 of        94\t|\tloss: 905.652\n",
      "Training Epoch 80  53.2% | batch:        50 of        94\t|\tloss: 1674.08\n",
      "Training Epoch 80  54.3% | batch:        51 of        94\t|\tloss: 1110.13\n",
      "Training Epoch 80  55.3% | batch:        52 of        94\t|\tloss: 828.668\n",
      "Training Epoch 80  56.4% | batch:        53 of        94\t|\tloss: 1318.01\n",
      "Training Epoch 80  57.4% | batch:        54 of        94\t|\tloss: 894.882\n",
      "Training Epoch 80  58.5% | batch:        55 of        94\t|\tloss: 812.569\n",
      "Training Epoch 80  59.6% | batch:        56 of        94\t|\tloss: 843.454\n",
      "Training Epoch 80  60.6% | batch:        57 of        94\t|\tloss: 656.486\n",
      "Training Epoch 80  61.7% | batch:        58 of        94\t|\tloss: 620.832\n",
      "Training Epoch 80  62.8% | batch:        59 of        94\t|\tloss: 734.214\n",
      "Training Epoch 80  63.8% | batch:        60 of        94\t|\tloss: 889.677\n",
      "Training Epoch 80  64.9% | batch:        61 of        94\t|\tloss: 1229.17\n",
      "Training Epoch 80  66.0% | batch:        62 of        94\t|\tloss: 1384\n",
      "Training Epoch 80  67.0% | batch:        63 of        94\t|\tloss: 1008.49\n",
      "Training Epoch 80  68.1% | batch:        64 of        94\t|\tloss: 1264.83\n",
      "Training Epoch 80  69.1% | batch:        65 of        94\t|\tloss: 906.942\n",
      "Training Epoch 80  70.2% | batch:        66 of        94\t|\tloss: 1091.65\n",
      "Training Epoch 80  71.3% | batch:        67 of        94\t|\tloss: 759.324\n",
      "Training Epoch 80  72.3% | batch:        68 of        94\t|\tloss: 811.306\n",
      "Training Epoch 80  73.4% | batch:        69 of        94\t|\tloss: 919.917\n",
      "Training Epoch 80  74.5% | batch:        70 of        94\t|\tloss: 883.28\n",
      "Training Epoch 80  75.5% | batch:        71 of        94\t|\tloss: 1098.54\n",
      "Training Epoch 80  76.6% | batch:        72 of        94\t|\tloss: 695.991\n",
      "Training Epoch 80  77.7% | batch:        73 of        94\t|\tloss: 874.698\n",
      "Training Epoch 80  78.7% | batch:        74 of        94\t|\tloss: 1102.18\n",
      "Training Epoch 80  79.8% | batch:        75 of        94\t|\tloss: 1034.79\n",
      "Training Epoch 80  80.9% | batch:        76 of        94\t|\tloss: 805.861\n",
      "Training Epoch 80  81.9% | batch:        77 of        94\t|\tloss: 852.868\n",
      "Training Epoch 80  83.0% | batch:        78 of        94\t|\tloss: 1018.44\n",
      "Training Epoch 80  84.0% | batch:        79 of        94\t|\tloss: 759.142\n",
      "Training Epoch 80  85.1% | batch:        80 of        94\t|\tloss: 659.622\n",
      "Training Epoch 80  86.2% | batch:        81 of        94\t|\tloss: 991.375\n",
      "Training Epoch 80  87.2% | batch:        82 of        94\t|\tloss: 991.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:33,849 | INFO : Epoch 80 Training Summary: epoch: 80.000000 | loss: 1015.862253 | \n",
      "2023-05-04 17:01:33,850 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7687866687774658 seconds\n",
      "\n",
      "2023-05-04 17:01:33,850 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7810273170471191 seconds\n",
      "2023-05-04 17:01:33,851 | INFO : Avg batch train. time: 0.018947099117522546 seconds\n",
      "2023-05-04 17:01:33,852 | INFO : Avg sample train. time: 0.0001494401172216076 seconds\n",
      "2023-05-04 17:01:33,852 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 80  88.3% | batch:        83 of        94\t|\tloss: 1069.27\n",
      "Training Epoch 80  89.4% | batch:        84 of        94\t|\tloss: 1079.55\n",
      "Training Epoch 80  90.4% | batch:        85 of        94\t|\tloss: 1521.84\n",
      "Training Epoch 80  91.5% | batch:        86 of        94\t|\tloss: 1093.46\n",
      "Training Epoch 80  92.6% | batch:        87 of        94\t|\tloss: 1133.64\n",
      "Training Epoch 80  93.6% | batch:        88 of        94\t|\tloss: 923.176\n",
      "Training Epoch 80  94.7% | batch:        89 of        94\t|\tloss: 1895.35\n",
      "Training Epoch 80  95.7% | batch:        90 of        94\t|\tloss: 1449.86\n",
      "Training Epoch 80  96.8% | batch:        91 of        94\t|\tloss: 914.597\n",
      "Training Epoch 80  97.9% | batch:        92 of        94\t|\tloss: 2897.98\n",
      "Training Epoch 80  98.9% | batch:        93 of        94\t|\tloss: 1124.55\n",
      "\n",
      "Evaluating Epoch 80   0.0% | batch:         0 of        40\t|\tloss: 8243.81\n",
      "Evaluating Epoch 80   2.5% | batch:         1 of        40\t|\tloss: 978.834\n",
      "Evaluating Epoch 80   5.0% | batch:         2 of        40\t|\tloss: 3397.5\n",
      "Evaluating Epoch 80   7.5% | batch:         3 of        40\t|\tloss: 7796.07\n",
      "Evaluating Epoch 80  10.0% | batch:         4 of        40\t|\tloss: 2457.63\n",
      "Evaluating Epoch 80  12.5% | batch:         5 of        40\t|\tloss: 2320.26\n",
      "Evaluating Epoch 80  15.0% | batch:         6 of        40\t|\tloss: 9148.38\n",
      "Evaluating Epoch 80  17.5% | batch:         7 of        40\t|\tloss: 3344.15\n",
      "Evaluating Epoch 80  20.0% | batch:         8 of        40\t|\tloss: 2805.67\n",
      "Evaluating Epoch 80  22.5% | batch:         9 of        40\t|\tloss: 1701.05\n",
      "Evaluating Epoch 80  25.0% | batch:        10 of        40\t|\tloss: 5092.88\n",
      "Evaluating Epoch 80  27.5% | batch:        11 of        40\t|\tloss: 1281.17\n",
      "Evaluating Epoch 80  30.0% | batch:        12 of        40\t|\tloss: 7363.74\n",
      "Evaluating Epoch 80  32.5% | batch:        13 of        40\t|\tloss: 3250.37\n",
      "Evaluating Epoch 80  35.0% | batch:        14 of        40\t|\tloss: 1847.26\n",
      "Evaluating Epoch 80  37.5% | batch:        15 of        40\t|\tloss: 3563.57\n",
      "Evaluating Epoch 80  40.0% | batch:        16 of        40\t|\tloss: 5223.68\n",
      "Evaluating Epoch 80  42.5% | batch:        17 of        40\t|\tloss: 2841.95\n",
      "Evaluating Epoch 80  45.0% | batch:        18 of        40\t|\tloss: 2765.8\n",
      "Evaluating Epoch 80  47.5% | batch:        19 of        40\t|\tloss: 5604.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:34,303 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44983482360839844 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 80  50.0% | batch:        20 of        40\t|\tloss: 5327.02\n",
      "Evaluating Epoch 80  52.5% | batch:        21 of        40\t|\tloss: 1107.52\n",
      "Evaluating Epoch 80  55.0% | batch:        22 of        40\t|\tloss: 3372.88\n",
      "Evaluating Epoch 80  57.5% | batch:        23 of        40\t|\tloss: 3034\n",
      "Evaluating Epoch 80  60.0% | batch:        24 of        40\t|\tloss: 1537.84\n",
      "Evaluating Epoch 80  62.5% | batch:        25 of        40\t|\tloss: 4230.04\n",
      "Evaluating Epoch 80  65.0% | batch:        26 of        40\t|\tloss: 10412.3\n",
      "Evaluating Epoch 80  67.5% | batch:        27 of        40\t|\tloss: 2824.57\n",
      "Evaluating Epoch 80  70.0% | batch:        28 of        40\t|\tloss: 2373.91\n",
      "Evaluating Epoch 80  72.5% | batch:        29 of        40\t|\tloss: 9092.88\n",
      "Evaluating Epoch 80  75.0% | batch:        30 of        40\t|\tloss: 1691.06\n",
      "Evaluating Epoch 80  77.5% | batch:        31 of        40\t|\tloss: 1524.33\n",
      "Evaluating Epoch 80  80.0% | batch:        32 of        40\t|\tloss: 7221.87\n",
      "Evaluating Epoch 80  82.5% | batch:        33 of        40\t|\tloss: 6025.24\n",
      "Evaluating Epoch 80  85.0% | batch:        34 of        40\t|\tloss: 1141.88\n",
      "Evaluating Epoch 80  87.5% | batch:        35 of        40\t|\tloss: 5598.55\n",
      "Evaluating Epoch 80  90.0% | batch:        36 of        40\t|\tloss: 6738.19\n",
      "Evaluating Epoch 80  92.5% | batch:        37 of        40\t|\tloss: 2634.92\n",
      "Evaluating Epoch 80  95.0% | batch:        38 of        40\t|\tloss: 3777.23\n",
      "Evaluating Epoch 80  97.5% | batch:        39 of        40\t|\tloss: 15212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:34,303 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5298440832222624 seconds\n",
      "2023-05-04 17:01:34,304 | INFO : Avg batch val. time: 0.01324610208055656 seconds\n",
      "2023-05-04 17:01:34,305 | INFO : Avg sample val. time: 0.00010496118922786497 seconds\n",
      "2023-05-04 17:01:34,306 | INFO : Epoch 80 Validation Summary: epoch: 80.000000 | loss: 4243.414790 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 81   0.0% | batch:         0 of        94\t|\tloss: 912.57\n",
      "Training Epoch 81   1.1% | batch:         1 of        94\t|\tloss: 1302.19\n",
      "Training Epoch 81   2.1% | batch:         2 of        94\t|\tloss: 622.348\n",
      "Training Epoch 81   3.2% | batch:         3 of        94\t|\tloss: 914.962\n",
      "Training Epoch 81   4.3% | batch:         4 of        94\t|\tloss: 992.54\n",
      "Training Epoch 81   5.3% | batch:         5 of        94\t|\tloss: 654.949\n",
      "Training Epoch 81   6.4% | batch:         6 of        94\t|\tloss: 728.538\n",
      "Training Epoch 81   7.4% | batch:         7 of        94\t|\tloss: 1494.09\n",
      "Training Epoch 81   8.5% | batch:         8 of        94\t|\tloss: 1101.3\n",
      "Training Epoch 81   9.6% | batch:         9 of        94\t|\tloss: 885.928\n",
      "Training Epoch 81  10.6% | batch:        10 of        94\t|\tloss: 865.721\n",
      "Training Epoch 81  11.7% | batch:        11 of        94\t|\tloss: 850.587\n",
      "Training Epoch 81  12.8% | batch:        12 of        94\t|\tloss: 660.904\n",
      "Training Epoch 81  13.8% | batch:        13 of        94\t|\tloss: 829.242\n",
      "Training Epoch 81  14.9% | batch:        14 of        94\t|\tloss: 997.219\n",
      "Training Epoch 81  16.0% | batch:        15 of        94\t|\tloss: 1076.66\n",
      "Training Epoch 81  17.0% | batch:        16 of        94\t|\tloss: 669.733\n",
      "Training Epoch 81  18.1% | batch:        17 of        94\t|\tloss: 621.828\n",
      "Training Epoch 81  19.1% | batch:        18 of        94\t|\tloss: 613.014\n",
      "Training Epoch 81  20.2% | batch:        19 of        94\t|\tloss: 1080.92\n",
      "Training Epoch 81  21.3% | batch:        20 of        94\t|\tloss: 677.037\n",
      "Training Epoch 81  22.3% | batch:        21 of        94\t|\tloss: 837.29\n",
      "Training Epoch 81  23.4% | batch:        22 of        94\t|\tloss: 564.335\n",
      "Training Epoch 81  24.5% | batch:        23 of        94\t|\tloss: 609.221\n",
      "Training Epoch 81  25.5% | batch:        24 of        94\t|\tloss: 918.257\n",
      "Training Epoch 81  26.6% | batch:        25 of        94\t|\tloss: 1010.09\n",
      "Training Epoch 81  27.7% | batch:        26 of        94\t|\tloss: 779.478\n",
      "Training Epoch 81  28.7% | batch:        27 of        94\t|\tloss: 1094.99\n",
      "Training Epoch 81  29.8% | batch:        28 of        94\t|\tloss: 714.853\n",
      "Training Epoch 81  30.9% | batch:        29 of        94\t|\tloss: 833.376\n",
      "Training Epoch 81  31.9% | batch:        30 of        94\t|\tloss: 745.221\n",
      "Training Epoch 81  33.0% | batch:        31 of        94\t|\tloss: 1030.55\n",
      "Training Epoch 81  34.0% | batch:        32 of        94\t|\tloss: 722.989\n",
      "Training Epoch 81  35.1% | batch:        33 of        94\t|\tloss: 640.776\n",
      "Training Epoch 81  36.2% | batch:        34 of        94\t|\tloss: 746.37\n",
      "Training Epoch 81  37.2% | batch:        35 of        94\t|\tloss: 1132.99\n",
      "Training Epoch 81  38.3% | batch:        36 of        94\t|\tloss: 979.272\n",
      "Training Epoch 81  39.4% | batch:        37 of        94\t|\tloss: 745.837\n",
      "Training Epoch 81  40.4% | batch:        38 of        94\t|\tloss: 1064.33\n",
      "Training Epoch 81  41.5% | batch:        39 of        94\t|\tloss: 884.259\n",
      "Training Epoch 81  42.6% | batch:        40 of        94\t|\tloss: 1249.95\n",
      "Training Epoch 81  43.6% | batch:        41 of        94\t|\tloss: 742.73\n",
      "Training Epoch 81  44.7% | batch:        42 of        94\t|\tloss: 1199.45\n",
      "Training Epoch 81  45.7% | batch:        43 of        94\t|\tloss: 2346.79\n",
      "Training Epoch 81  46.8% | batch:        44 of        94\t|\tloss: 1480.34\n",
      "Training Epoch 81  47.9% | batch:        45 of        94\t|\tloss: 1059.31\n",
      "Training Epoch 81  48.9% | batch:        46 of        94\t|\tloss: 1273.77\n",
      "Training Epoch 81  50.0% | batch:        47 of        94\t|\tloss: 868.089\n",
      "Training Epoch 81  51.1% | batch:        48 of        94\t|\tloss: 2914.93\n",
      "Training Epoch 81  52.1% | batch:        49 of        94\t|\tloss: 1362.47\n",
      "Training Epoch 81  53.2% | batch:        50 of        94\t|\tloss: 917.29\n",
      "Training Epoch 81  54.3% | batch:        51 of        94\t|\tloss: 969.465\n",
      "Training Epoch 81  55.3% | batch:        52 of        94\t|\tloss: 961.495\n",
      "Training Epoch 81  56.4% | batch:        53 of        94\t|\tloss: 1103.67\n",
      "Training Epoch 81  57.4% | batch:        54 of        94\t|\tloss: 1363.01\n",
      "Training Epoch 81  58.5% | batch:        55 of        94\t|\tloss: 1195.37\n",
      "Training Epoch 81  59.6% | batch:        56 of        94\t|\tloss: 842.894\n",
      "Training Epoch 81  60.6% | batch:        57 of        94\t|\tloss: 1152.33\n",
      "Training Epoch 81  61.7% | batch:        58 of        94\t|\tloss: 1008.19\n",
      "Training Epoch 81  62.8% | batch:        59 of        94\t|\tloss: 815.252\n",
      "Training Epoch 81  63.8% | batch:        60 of        94\t|\tloss: 662.824\n",
      "Training Epoch 81  64.9% | batch:        61 of        94\t|\tloss: 1689.27\n",
      "Training Epoch 81  66.0% | batch:        62 of        94\t|\tloss: 751.157\n",
      "Training Epoch 81  67.0% | batch:        63 of        94\t|\tloss: 820.289\n",
      "Training Epoch 81  68.1% | batch:        64 of        94\t|\tloss: 906.297\n",
      "Training Epoch 81  69.1% | batch:        65 of        94\t|\tloss: 972.582\n",
      "Training Epoch 81  70.2% | batch:        66 of        94\t|\tloss: 1135.64\n",
      "Training Epoch 81  71.3% | batch:        67 of        94\t|\tloss: 1025.75\n",
      "Training Epoch 81  72.3% | batch:        68 of        94\t|\tloss: 988.786\n",
      "Training Epoch 81  73.4% | batch:        69 of        94\t|\tloss: 1421.89\n",
      "Training Epoch 81  74.5% | batch:        70 of        94\t|\tloss: 1741.65\n",
      "Training Epoch 81  75.5% | batch:        71 of        94\t|\tloss: 1193.2\n",
      "Training Epoch 81  76.6% | batch:        72 of        94\t|\tloss: 849.905\n",
      "Training Epoch 81  77.7% | batch:        73 of        94\t|\tloss: 749.321\n",
      "Training Epoch 81  78.7% | batch:        74 of        94\t|\tloss: 1027.34\n",
      "Training Epoch 81  79.8% | batch:        75 of        94\t|\tloss: 1536.27\n",
      "Training Epoch 81  80.9% | batch:        76 of        94\t|\tloss: 761.49\n",
      "Training Epoch 81  81.9% | batch:        77 of        94\t|\tloss: 832.394\n",
      "Training Epoch 81  83.0% | batch:        78 of        94\t|\tloss: 926.086\n",
      "Training Epoch 81  84.0% | batch:        79 of        94\t|\tloss: 992.481\n",
      "Training Epoch 81  85.1% | batch:        80 of        94\t|\tloss: 1376.41\n",
      "Training Epoch 81  86.2% | batch:        81 of        94\t|\tloss: 779.664\n",
      "Training Epoch 81  87.2% | batch:        82 of        94\t|\tloss: 1442.18\n",
      "Training Epoch 81  88.3% | batch:        83 of        94\t|\tloss: 1018.36\n",
      "Training Epoch 81  89.4% | batch:        84 of        94\t|\tloss: 647.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:36,141 | INFO : Epoch 81 Training Summary: epoch: 81.000000 | loss: 1015.238476 | \n",
      "2023-05-04 17:01:36,143 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8143846988677979 seconds\n",
      "\n",
      "2023-05-04 17:01:36,143 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7814391365757696 seconds\n",
      "2023-05-04 17:01:36,144 | INFO : Avg batch train. time: 0.018951480176337975 seconds\n",
      "2023-05-04 17:01:36,144 | INFO : Avg sample train. time: 0.00014947467163750375 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 81  90.4% | batch:        85 of        94\t|\tloss: 1449.74\n",
      "Training Epoch 81  91.5% | batch:        86 of        94\t|\tloss: 1862.68\n",
      "Training Epoch 81  92.6% | batch:        87 of        94\t|\tloss: 1029.52\n",
      "Training Epoch 81  93.6% | batch:        88 of        94\t|\tloss: 873.126\n",
      "Training Epoch 81  94.7% | batch:        89 of        94\t|\tloss: 939.072\n",
      "Training Epoch 81  95.7% | batch:        90 of        94\t|\tloss: 835.337\n",
      "Training Epoch 81  96.8% | batch:        91 of        94\t|\tloss: 926.927\n",
      "Training Epoch 81  97.9% | batch:        92 of        94\t|\tloss: 872.322\n",
      "Training Epoch 81  98.9% | batch:        93 of        94\t|\tloss: 522.948\n",
      "\n",
      "Training Epoch 82   0.0% | batch:         0 of        94\t|\tloss: 1024.22\n",
      "Training Epoch 82   1.1% | batch:         1 of        94\t|\tloss: 732.037\n",
      "Training Epoch 82   2.1% | batch:         2 of        94\t|\tloss: 532.618\n",
      "Training Epoch 82   3.2% | batch:         3 of        94\t|\tloss: 699.293\n",
      "Training Epoch 82   4.3% | batch:         4 of        94\t|\tloss: 1193.46\n",
      "Training Epoch 82   5.3% | batch:         5 of        94\t|\tloss: 2007.85\n",
      "Training Epoch 82   6.4% | batch:         6 of        94\t|\tloss: 990.97\n",
      "Training Epoch 82   7.4% | batch:         7 of        94\t|\tloss: 909.537\n",
      "Training Epoch 82   8.5% | batch:         8 of        94\t|\tloss: 1689.41\n",
      "Training Epoch 82   9.6% | batch:         9 of        94\t|\tloss: 935.367\n",
      "Training Epoch 82  10.6% | batch:        10 of        94\t|\tloss: 964.457\n",
      "Training Epoch 82  11.7% | batch:        11 of        94\t|\tloss: 1165.98\n",
      "Training Epoch 82  12.8% | batch:        12 of        94\t|\tloss: 1094.21\n",
      "Training Epoch 82  13.8% | batch:        13 of        94\t|\tloss: 1063.46\n",
      "Training Epoch 82  14.9% | batch:        14 of        94\t|\tloss: 884.329\n",
      "Training Epoch 82  16.0% | batch:        15 of        94\t|\tloss: 885.095\n",
      "Training Epoch 82  17.0% | batch:        16 of        94\t|\tloss: 585.577\n",
      "Training Epoch 82  18.1% | batch:        17 of        94\t|\tloss: 712.368\n",
      "Training Epoch 82  19.1% | batch:        18 of        94\t|\tloss: 931.985\n",
      "Training Epoch 82  20.2% | batch:        19 of        94\t|\tloss: 799.993\n",
      "Training Epoch 82  21.3% | batch:        20 of        94\t|\tloss: 1150.92\n",
      "Training Epoch 82  22.3% | batch:        21 of        94\t|\tloss: 1698.57\n",
      "Training Epoch 82  23.4% | batch:        22 of        94\t|\tloss: 812.381\n",
      "Training Epoch 82  24.5% | batch:        23 of        94\t|\tloss: 1093.63\n",
      "Training Epoch 82  25.5% | batch:        24 of        94\t|\tloss: 1492\n",
      "Training Epoch 82  26.6% | batch:        25 of        94\t|\tloss: 1028.69\n",
      "Training Epoch 82  27.7% | batch:        26 of        94\t|\tloss: 883.599\n",
      "Training Epoch 82  28.7% | batch:        27 of        94\t|\tloss: 501.029\n",
      "Training Epoch 82  29.8% | batch:        28 of        94\t|\tloss: 976.217\n",
      "Training Epoch 82  30.9% | batch:        29 of        94\t|\tloss: 692.655\n",
      "Training Epoch 82  31.9% | batch:        30 of        94\t|\tloss: 964.199\n",
      "Training Epoch 82  33.0% | batch:        31 of        94\t|\tloss: 1467.89\n",
      "Training Epoch 82  34.0% | batch:        32 of        94\t|\tloss: 965.942\n",
      "Training Epoch 82  35.1% | batch:        33 of        94\t|\tloss: 1114.44\n",
      "Training Epoch 82  36.2% | batch:        34 of        94\t|\tloss: 808.086\n",
      "Training Epoch 82  37.2% | batch:        35 of        94\t|\tloss: 1058.57\n",
      "Training Epoch 82  38.3% | batch:        36 of        94\t|\tloss: 1006.45\n",
      "Training Epoch 82  39.4% | batch:        37 of        94\t|\tloss: 1360.97\n",
      "Training Epoch 82  40.4% | batch:        38 of        94\t|\tloss: 807.818\n",
      "Training Epoch 82  41.5% | batch:        39 of        94\t|\tloss: 1126.14\n",
      "Training Epoch 82  42.6% | batch:        40 of        94\t|\tloss: 1564.71\n",
      "Training Epoch 82  43.6% | batch:        41 of        94\t|\tloss: 1011.52\n",
      "Training Epoch 82  44.7% | batch:        42 of        94\t|\tloss: 1066.72\n",
      "Training Epoch 82  45.7% | batch:        43 of        94\t|\tloss: 974.096\n",
      "Training Epoch 82  46.8% | batch:        44 of        94\t|\tloss: 2279.21\n",
      "Training Epoch 82  47.9% | batch:        45 of        94\t|\tloss: 936.484\n",
      "Training Epoch 82  48.9% | batch:        46 of        94\t|\tloss: 1606.25\n",
      "Training Epoch 82  50.0% | batch:        47 of        94\t|\tloss: 923.811\n",
      "Training Epoch 82  51.1% | batch:        48 of        94\t|\tloss: 1109.8\n",
      "Training Epoch 82  52.1% | batch:        49 of        94\t|\tloss: 839.279\n",
      "Training Epoch 82  53.2% | batch:        50 of        94\t|\tloss: 892.518\n",
      "Training Epoch 82  54.3% | batch:        51 of        94\t|\tloss: 879.12\n",
      "Training Epoch 82  55.3% | batch:        52 of        94\t|\tloss: 844.831\n",
      "Training Epoch 82  56.4% | batch:        53 of        94\t|\tloss: 722.664\n",
      "Training Epoch 82  57.4% | batch:        54 of        94\t|\tloss: 1047.1\n",
      "Training Epoch 82  58.5% | batch:        55 of        94\t|\tloss: 886.235\n",
      "Training Epoch 82  59.6% | batch:        56 of        94\t|\tloss: 934.178\n",
      "Training Epoch 82  60.6% | batch:        57 of        94\t|\tloss: 3158.06\n",
      "Training Epoch 82  61.7% | batch:        58 of        94\t|\tloss: 877.137\n",
      "Training Epoch 82  62.8% | batch:        59 of        94\t|\tloss: 1122.8\n",
      "Training Epoch 82  63.8% | batch:        60 of        94\t|\tloss: 796.57\n",
      "Training Epoch 82  64.9% | batch:        61 of        94\t|\tloss: 821.847\n",
      "Training Epoch 82  66.0% | batch:        62 of        94\t|\tloss: 899.079\n",
      "Training Epoch 82  67.0% | batch:        63 of        94\t|\tloss: 872.635\n",
      "Training Epoch 82  68.1% | batch:        64 of        94\t|\tloss: 732.297\n",
      "Training Epoch 82  69.1% | batch:        65 of        94\t|\tloss: 1048.5\n",
      "Training Epoch 82  70.2% | batch:        66 of        94\t|\tloss: 1186.47\n",
      "Training Epoch 82  71.3% | batch:        67 of        94\t|\tloss: 992.46\n",
      "Training Epoch 82  72.3% | batch:        68 of        94\t|\tloss: 715.055\n",
      "Training Epoch 82  73.4% | batch:        69 of        94\t|\tloss: 525.128\n",
      "Training Epoch 82  74.5% | batch:        70 of        94\t|\tloss: 1030.7\n",
      "Training Epoch 82  75.5% | batch:        71 of        94\t|\tloss: 1283.32\n",
      "Training Epoch 82  76.6% | batch:        72 of        94\t|\tloss: 965.57\n",
      "Training Epoch 82  77.7% | batch:        73 of        94\t|\tloss: 769.117\n",
      "Training Epoch 82  78.7% | batch:        74 of        94\t|\tloss: 932.229\n",
      "Training Epoch 82  79.8% | batch:        75 of        94\t|\tloss: 1154.15\n",
      "Training Epoch 82  80.9% | batch:        76 of        94\t|\tloss: 839.696\n",
      "Training Epoch 82  81.9% | batch:        77 of        94\t|\tloss: 1723.75\n",
      "Training Epoch 82  83.0% | batch:        78 of        94\t|\tloss: 1631.64\n",
      "Training Epoch 82  84.0% | batch:        79 of        94\t|\tloss: 1142.84\n",
      "Training Epoch 82  85.1% | batch:        80 of        94\t|\tloss: 1206.59\n",
      "Training Epoch 82  86.2% | batch:        81 of        94\t|\tloss: 1246.96\n",
      "Training Epoch 82  87.2% | batch:        82 of        94\t|\tloss: 824.274\n",
      "Training Epoch 82  88.3% | batch:        83 of        94\t|\tloss: 1263.12\n",
      "Training Epoch 82  89.4% | batch:        84 of        94\t|\tloss: 817.617\n",
      "Training Epoch 82  90.4% | batch:        85 of        94\t|\tloss: 1280.66\n",
      "Training Epoch 82  91.5% | batch:        86 of        94\t|\tloss: 1405.55\n",
      "Training Epoch 82  92.6% | batch:        87 of        94\t|\tloss: 804.931\n",
      "Training Epoch 82  93.6% | batch:        88 of        94\t|\tloss: 683.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:37,990 | INFO : Epoch 82 Training Summary: epoch: 82.000000 | loss: 1060.596116 | \n",
      "2023-05-04 17:01:37,991 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.824646234512329 seconds\n",
      "\n",
      "2023-05-04 17:01:37,991 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7819660524042642 seconds\n",
      "2023-05-04 17:01:37,992 | INFO : Avg batch train. time: 0.01895708566387515 seconds\n",
      "2023-05-04 17:01:37,993 | INFO : Avg sample train. time: 0.00014951888340361338 seconds\n",
      "2023-05-04 17:01:37,993 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 82  94.7% | batch:        89 of        94\t|\tloss: 870.716\n",
      "Training Epoch 82  95.7% | batch:        90 of        94\t|\tloss: 1629.64\n",
      "Training Epoch 82  96.8% | batch:        91 of        94\t|\tloss: 998.406\n",
      "Training Epoch 82  97.9% | batch:        92 of        94\t|\tloss: 1078.7\n",
      "Training Epoch 82  98.9% | batch:        93 of        94\t|\tloss: 812.995\n",
      "\n",
      "Evaluating Epoch 82   0.0% | batch:         0 of        40\t|\tloss: 7870.59\n",
      "Evaluating Epoch 82   2.5% | batch:         1 of        40\t|\tloss: 1099.54\n",
      "Evaluating Epoch 82   5.0% | batch:         2 of        40\t|\tloss: 4265.08\n",
      "Evaluating Epoch 82   7.5% | batch:         3 of        40\t|\tloss: 7291.41\n",
      "Evaluating Epoch 82  10.0% | batch:         4 of        40\t|\tloss: 2381.18\n",
      "Evaluating Epoch 82  12.5% | batch:         5 of        40\t|\tloss: 2825.41\n",
      "Evaluating Epoch 82  15.0% | batch:         6 of        40\t|\tloss: 8849.76\n",
      "Evaluating Epoch 82  17.5% | batch:         7 of        40\t|\tloss: 3440.21\n",
      "Evaluating Epoch 82  20.0% | batch:         8 of        40\t|\tloss: 2868.65\n",
      "Evaluating Epoch 82  22.5% | batch:         9 of        40\t|\tloss: 2312.9\n",
      "Evaluating Epoch 82  25.0% | batch:        10 of        40\t|\tloss: 5355.86\n",
      "Evaluating Epoch 82  27.5% | batch:        11 of        40\t|\tloss: 1279.7\n",
      "Evaluating Epoch 82  30.0% | batch:        12 of        40\t|\tloss: 6359.41\n",
      "Evaluating Epoch 82  32.5% | batch:        13 of        40\t|\tloss: 3584.08\n",
      "Evaluating Epoch 82  35.0% | batch:        14 of        40\t|\tloss: 2033.92\n",
      "Evaluating Epoch 82  37.5% | batch:        15 of        40\t|\tloss: 3495.91\n",
      "Evaluating Epoch 82  40.0% | batch:        16 of        40\t|\tloss: 5209.16\n",
      "Evaluating Epoch 82  42.5% | batch:        17 of        40\t|\tloss: 3101.13\n",
      "Evaluating Epoch 82  45.0% | batch:        18 of        40\t|\tloss: 2460\n",
      "Evaluating Epoch 82  47.5% | batch:        19 of        40\t|\tloss: 5567.73\n",
      "Evaluating Epoch 82  50.0% | batch:        20 of        40\t|\tloss: 5486.12\n",
      "Evaluating Epoch 82  52.5% | batch:        21 of        40\t|\tloss: 1007.83\n",
      "Evaluating Epoch 82  55.0% | batch:        22 of        40\t|\tloss: 4708.17\n",
      "Evaluating Epoch 82  57.5% | batch:        23 of        40\t|\tloss: 3458.52\n",
      "Evaluating Epoch 82  60.0% | batch:        24 of        40\t|\tloss: 1717.67\n",
      "Evaluating Epoch 82  62.5% | batch:        25 of        40\t|\tloss: 3667.88\n",
      "Evaluating Epoch 82  65.0% | batch:        26 of        40\t|\tloss: 10982.3\n",
      "Evaluating Epoch 82  67.5% | batch:        27 of        40\t|\tloss: 2748.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:38,464 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4703226089477539 seconds\n",
      "\n",
      "2023-05-04 17:01:38,465 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5295523112895442 seconds\n",
      "2023-05-04 17:01:38,466 | INFO : Avg batch val. time: 0.013238807782238604 seconds\n",
      "2023-05-04 17:01:38,467 | INFO : Avg sample val. time: 0.00010490338971662919 seconds\n",
      "2023-05-04 17:01:38,467 | INFO : Epoch 82 Validation Summary: epoch: 82.000000 | loss: 4361.194876 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 82  70.0% | batch:        28 of        40\t|\tloss: 2122.53\n",
      "Evaluating Epoch 82  72.5% | batch:        29 of        40\t|\tloss: 9152.86\n",
      "Evaluating Epoch 82  75.0% | batch:        30 of        40\t|\tloss: 1918.48\n",
      "Evaluating Epoch 82  77.5% | batch:        31 of        40\t|\tloss: 1429.66\n",
      "Evaluating Epoch 82  80.0% | batch:        32 of        40\t|\tloss: 8626.87\n",
      "Evaluating Epoch 82  82.5% | batch:        33 of        40\t|\tloss: 6937.56\n",
      "Evaluating Epoch 82  85.0% | batch:        34 of        40\t|\tloss: 1078.1\n",
      "Evaluating Epoch 82  87.5% | batch:        35 of        40\t|\tloss: 5767.21\n",
      "Evaluating Epoch 82  90.0% | batch:        36 of        40\t|\tloss: 7220.32\n",
      "Evaluating Epoch 82  92.5% | batch:        37 of        40\t|\tloss: 2666.09\n",
      "Evaluating Epoch 82  95.0% | batch:        38 of        40\t|\tloss: 3626.84\n",
      "Evaluating Epoch 82  97.5% | batch:        39 of        40\t|\tloss: 13759.4\n",
      "\n",
      "Training Epoch 83   0.0% | batch:         0 of        94\t|\tloss: 925.037\n",
      "Training Epoch 83   1.1% | batch:         1 of        94\t|\tloss: 867.22\n",
      "Training Epoch 83   2.1% | batch:         2 of        94\t|\tloss: 959.655\n",
      "Training Epoch 83   3.2% | batch:         3 of        94\t|\tloss: 768.355\n",
      "Training Epoch 83   4.3% | batch:         4 of        94\t|\tloss: 720.471\n",
      "Training Epoch 83   5.3% | batch:         5 of        94\t|\tloss: 1381.9\n",
      "Training Epoch 83   6.4% | batch:         6 of        94\t|\tloss: 582.011\n",
      "Training Epoch 83   7.4% | batch:         7 of        94\t|\tloss: 1072.39\n",
      "Training Epoch 83   8.5% | batch:         8 of        94\t|\tloss: 1264.43\n",
      "Training Epoch 83   9.6% | batch:         9 of        94\t|\tloss: 848.325\n",
      "Training Epoch 83  10.6% | batch:        10 of        94\t|\tloss: 1080.47\n",
      "Training Epoch 83  11.7% | batch:        11 of        94\t|\tloss: 631.027\n",
      "Training Epoch 83  12.8% | batch:        12 of        94\t|\tloss: 589.892\n",
      "Training Epoch 83  13.8% | batch:        13 of        94\t|\tloss: 1162.2\n",
      "Training Epoch 83  14.9% | batch:        14 of        94\t|\tloss: 989.895\n",
      "Training Epoch 83  16.0% | batch:        15 of        94\t|\tloss: 951.73\n",
      "Training Epoch 83  17.0% | batch:        16 of        94\t|\tloss: 918.219\n",
      "Training Epoch 83  18.1% | batch:        17 of        94\t|\tloss: 791.05\n",
      "Training Epoch 83  19.1% | batch:        18 of        94\t|\tloss: 641.22\n",
      "Training Epoch 83  20.2% | batch:        19 of        94\t|\tloss: 1507.53\n",
      "Training Epoch 83  21.3% | batch:        20 of        94\t|\tloss: 1105.33\n",
      "Training Epoch 83  22.3% | batch:        21 of        94\t|\tloss: 1222.9\n",
      "Training Epoch 83  23.4% | batch:        22 of        94\t|\tloss: 1051.26\n",
      "Training Epoch 83  24.5% | batch:        23 of        94\t|\tloss: 856.992\n",
      "Training Epoch 83  25.5% | batch:        24 of        94\t|\tloss: 828.867\n",
      "Training Epoch 83  26.6% | batch:        25 of        94\t|\tloss: 872.212\n",
      "Training Epoch 83  27.7% | batch:        26 of        94\t|\tloss: 989.76\n",
      "Training Epoch 83  28.7% | batch:        27 of        94\t|\tloss: 818.371\n",
      "Training Epoch 83  29.8% | batch:        28 of        94\t|\tloss: 839.717\n",
      "Training Epoch 83  30.9% | batch:        29 of        94\t|\tloss: 860.213\n",
      "Training Epoch 83  31.9% | batch:        30 of        94\t|\tloss: 879.984\n",
      "Training Epoch 83  33.0% | batch:        31 of        94\t|\tloss: 737.998\n",
      "Training Epoch 83  34.0% | batch:        32 of        94\t|\tloss: 630.389\n",
      "Training Epoch 83  35.1% | batch:        33 of        94\t|\tloss: 1008.34\n",
      "Training Epoch 83  36.2% | batch:        34 of        94\t|\tloss: 1097.1\n",
      "Training Epoch 83  37.2% | batch:        35 of        94\t|\tloss: 957.289\n",
      "Training Epoch 83  38.3% | batch:        36 of        94\t|\tloss: 829.587\n",
      "Training Epoch 83  39.4% | batch:        37 of        94\t|\tloss: 791.616\n",
      "Training Epoch 83  40.4% | batch:        38 of        94\t|\tloss: 890.062\n",
      "Training Epoch 83  41.5% | batch:        39 of        94\t|\tloss: 1157.63\n",
      "Training Epoch 83  42.6% | batch:        40 of        94\t|\tloss: 614.415\n",
      "Training Epoch 83  43.6% | batch:        41 of        94\t|\tloss: 1415.5\n",
      "Training Epoch 83  44.7% | batch:        42 of        94\t|\tloss: 689.516\n",
      "Training Epoch 83  45.7% | batch:        43 of        94\t|\tloss: 878.046\n",
      "Training Epoch 83  46.8% | batch:        44 of        94\t|\tloss: 843.582\n",
      "Training Epoch 83  47.9% | batch:        45 of        94\t|\tloss: 716.269\n",
      "Training Epoch 83  48.9% | batch:        46 of        94\t|\tloss: 917.758\n",
      "Training Epoch 83  50.0% | batch:        47 of        94\t|\tloss: 1033.43\n",
      "Training Epoch 83  51.1% | batch:        48 of        94\t|\tloss: 990.662\n",
      "Training Epoch 83  52.1% | batch:        49 of        94\t|\tloss: 1084.76\n",
      "Training Epoch 83  53.2% | batch:        50 of        94\t|\tloss: 1359.67\n",
      "Training Epoch 83  54.3% | batch:        51 of        94\t|\tloss: 759.706\n",
      "Training Epoch 83  55.3% | batch:        52 of        94\t|\tloss: 866.786\n",
      "Training Epoch 83  56.4% | batch:        53 of        94\t|\tloss: 755.074\n",
      "Training Epoch 83  57.4% | batch:        54 of        94\t|\tloss: 897.973\n",
      "Training Epoch 83  58.5% | batch:        55 of        94\t|\tloss: 872.795\n",
      "Training Epoch 83  59.6% | batch:        56 of        94\t|\tloss: 881.897\n",
      "Training Epoch 83  60.6% | batch:        57 of        94\t|\tloss: 771.711\n",
      "Training Epoch 83  61.7% | batch:        58 of        94\t|\tloss: 1172.11\n",
      "Training Epoch 83  62.8% | batch:        59 of        94\t|\tloss: 1227.9\n",
      "Training Epoch 83  63.8% | batch:        60 of        94\t|\tloss: 1468.94\n",
      "Training Epoch 83  64.9% | batch:        61 of        94\t|\tloss: 1000.14\n",
      "Training Epoch 83  66.0% | batch:        62 of        94\t|\tloss: 3281.58\n",
      "Training Epoch 83  67.0% | batch:        63 of        94\t|\tloss: 752.467\n",
      "Training Epoch 83  68.1% | batch:        64 of        94\t|\tloss: 885.022\n",
      "Training Epoch 83  69.1% | batch:        65 of        94\t|\tloss: 518.166\n",
      "Training Epoch 83  70.2% | batch:        66 of        94\t|\tloss: 948.362\n",
      "Training Epoch 83  71.3% | batch:        67 of        94\t|\tloss: 1064.04\n",
      "Training Epoch 83  72.3% | batch:        68 of        94\t|\tloss: 1125.24\n",
      "Training Epoch 83  73.4% | batch:        69 of        94\t|\tloss: 944.764\n",
      "Training Epoch 83  74.5% | batch:        70 of        94\t|\tloss: 940.377\n",
      "Training Epoch 83  75.5% | batch:        71 of        94\t|\tloss: 758.106\n",
      "Training Epoch 83  76.6% | batch:        72 of        94\t|\tloss: 968.93\n",
      "Training Epoch 83  77.7% | batch:        73 of        94\t|\tloss: 931.426\n",
      "Training Epoch 83  78.7% | batch:        74 of        94\t|\tloss: 1179.04\n",
      "Training Epoch 83  79.8% | batch:        75 of        94\t|\tloss: 975.725\n",
      "Training Epoch 83  80.9% | batch:        76 of        94\t|\tloss: 1204.48\n",
      "Training Epoch 83  81.9% | batch:        77 of        94\t|\tloss: 1171.1\n",
      "Training Epoch 83  83.0% | batch:        78 of        94\t|\tloss: 887.261\n",
      "Training Epoch 83  84.0% | batch:        79 of        94\t|\tloss: 861.255\n",
      "Training Epoch 83  85.1% | batch:        80 of        94\t|\tloss: 1615.37\n",
      "Training Epoch 83  86.2% | batch:        81 of        94\t|\tloss: 1224.14\n",
      "Training Epoch 83  87.2% | batch:        82 of        94\t|\tloss: 1809.72\n",
      "Training Epoch 83  88.3% | batch:        83 of        94\t|\tloss: 765.163\n",
      "Training Epoch 83  89.4% | batch:        84 of        94\t|\tloss: 701.692\n",
      "Training Epoch 83  90.4% | batch:        85 of        94\t|\tloss: 829.836\n",
      "Training Epoch 83  91.5% | batch:        86 of        94\t|\tloss: 881.656\n",
      "Training Epoch 83  92.6% | batch:        87 of        94\t|\tloss: 1944.73\n",
      "Training Epoch 83  93.6% | batch:        88 of        94\t|\tloss: 643.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:40,315 | INFO : Epoch 83 Training Summary: epoch: 83.000000 | loss: 981.660289 | \n",
      "2023-05-04 17:01:40,316 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8251264095306396 seconds\n",
      "\n",
      "2023-05-04 17:01:40,316 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7824860567069916 seconds\n",
      "2023-05-04 17:01:40,317 | INFO : Avg batch train. time: 0.018962617624542464 seconds\n",
      "2023-05-04 17:01:40,317 | INFO : Avg sample train. time: 0.00014956251524643325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 83  94.7% | batch:        89 of        94\t|\tloss: 719.713\n",
      "Training Epoch 83  95.7% | batch:        90 of        94\t|\tloss: 650.747\n",
      "Training Epoch 83  96.8% | batch:        91 of        94\t|\tloss: 1104.42\n",
      "Training Epoch 83  97.9% | batch:        92 of        94\t|\tloss: 682.109\n",
      "Training Epoch 83  98.9% | batch:        93 of        94\t|\tloss: 1229.29\n",
      "\n",
      "Training Epoch 84   0.0% | batch:         0 of        94\t|\tloss: 1047.31\n",
      "Training Epoch 84   1.1% | batch:         1 of        94\t|\tloss: 839.637\n",
      "Training Epoch 84   2.1% | batch:         2 of        94\t|\tloss: 674.46\n",
      "Training Epoch 84   3.2% | batch:         3 of        94\t|\tloss: 564.222\n",
      "Training Epoch 84   4.3% | batch:         4 of        94\t|\tloss: 740.16\n",
      "Training Epoch 84   5.3% | batch:         5 of        94\t|\tloss: 790.379\n",
      "Training Epoch 84   6.4% | batch:         6 of        94\t|\tloss: 1004.05\n",
      "Training Epoch 84   7.4% | batch:         7 of        94\t|\tloss: 839.251\n",
      "Training Epoch 84   8.5% | batch:         8 of        94\t|\tloss: 743.603\n",
      "Training Epoch 84   9.6% | batch:         9 of        94\t|\tloss: 714.077\n",
      "Training Epoch 84  10.6% | batch:        10 of        94\t|\tloss: 783.015\n",
      "Training Epoch 84  11.7% | batch:        11 of        94\t|\tloss: 855.563\n",
      "Training Epoch 84  12.8% | batch:        12 of        94\t|\tloss: 968.073\n",
      "Training Epoch 84  13.8% | batch:        13 of        94\t|\tloss: 801.919\n",
      "Training Epoch 84  14.9% | batch:        14 of        94\t|\tloss: 1417.77\n",
      "Training Epoch 84  16.0% | batch:        15 of        94\t|\tloss: 1076.46\n",
      "Training Epoch 84  17.0% | batch:        16 of        94\t|\tloss: 952.012\n",
      "Training Epoch 84  18.1% | batch:        17 of        94\t|\tloss: 1070.92\n",
      "Training Epoch 84  19.1% | batch:        18 of        94\t|\tloss: 866.52\n",
      "Training Epoch 84  20.2% | batch:        19 of        94\t|\tloss: 854.703\n",
      "Training Epoch 84  21.3% | batch:        20 of        94\t|\tloss: 1648.93\n",
      "Training Epoch 84  22.3% | batch:        21 of        94\t|\tloss: 645.781\n",
      "Training Epoch 84  23.4% | batch:        22 of        94\t|\tloss: 586.815\n",
      "Training Epoch 84  24.5% | batch:        23 of        94\t|\tloss: 826.591\n",
      "Training Epoch 84  25.5% | batch:        24 of        94\t|\tloss: 777.995\n",
      "Training Epoch 84  26.6% | batch:        25 of        94\t|\tloss: 909.241\n",
      "Training Epoch 84  27.7% | batch:        26 of        94\t|\tloss: 750.871\n",
      "Training Epoch 84  28.7% | batch:        27 of        94\t|\tloss: 784.318\n",
      "Training Epoch 84  29.8% | batch:        28 of        94\t|\tloss: 927.39\n",
      "Training Epoch 84  30.9% | batch:        29 of        94\t|\tloss: 1020.6\n",
      "Training Epoch 84  31.9% | batch:        30 of        94\t|\tloss: 815.294\n",
      "Training Epoch 84  33.0% | batch:        31 of        94\t|\tloss: 1199.9\n",
      "Training Epoch 84  34.0% | batch:        32 of        94\t|\tloss: 835.966\n",
      "Training Epoch 84  35.1% | batch:        33 of        94\t|\tloss: 1072.17\n",
      "Training Epoch 84  36.2% | batch:        34 of        94\t|\tloss: 759.589\n",
      "Training Epoch 84  37.2% | batch:        35 of        94\t|\tloss: 878.398\n",
      "Training Epoch 84  38.3% | batch:        36 of        94\t|\tloss: 880.273\n",
      "Training Epoch 84  39.4% | batch:        37 of        94\t|\tloss: 1974.48\n",
      "Training Epoch 84  40.4% | batch:        38 of        94\t|\tloss: 969.796\n",
      "Training Epoch 84  41.5% | batch:        39 of        94\t|\tloss: 1088.67\n",
      "Training Epoch 84  42.6% | batch:        40 of        94\t|\tloss: 923.386\n",
      "Training Epoch 84  43.6% | batch:        41 of        94\t|\tloss: 760.168\n",
      "Training Epoch 84  44.7% | batch:        42 of        94\t|\tloss: 1190.28\n",
      "Training Epoch 84  45.7% | batch:        43 of        94\t|\tloss: 705.851\n",
      "Training Epoch 84  46.8% | batch:        44 of        94\t|\tloss: 908.241\n",
      "Training Epoch 84  47.9% | batch:        45 of        94\t|\tloss: 991.864\n",
      "Training Epoch 84  48.9% | batch:        46 of        94\t|\tloss: 1029.93\n",
      "Training Epoch 84  50.0% | batch:        47 of        94\t|\tloss: 979.517\n",
      "Training Epoch 84  51.1% | batch:        48 of        94\t|\tloss: 1454.21\n",
      "Training Epoch 84  52.1% | batch:        49 of        94\t|\tloss: 810.034\n",
      "Training Epoch 84  53.2% | batch:        50 of        94\t|\tloss: 1281.73\n",
      "Training Epoch 84  54.3% | batch:        51 of        94\t|\tloss: 820.218\n",
      "Training Epoch 84  55.3% | batch:        52 of        94\t|\tloss: 1494.51\n",
      "Training Epoch 84  56.4% | batch:        53 of        94\t|\tloss: 1245.59\n",
      "Training Epoch 84  57.4% | batch:        54 of        94\t|\tloss: 735.117\n",
      "Training Epoch 84  58.5% | batch:        55 of        94\t|\tloss: 787.775\n",
      "Training Epoch 84  59.6% | batch:        56 of        94\t|\tloss: 1019.63\n",
      "Training Epoch 84  60.6% | batch:        57 of        94\t|\tloss: 1193.66\n",
      "Training Epoch 84  61.7% | batch:        58 of        94\t|\tloss: 1162.89\n",
      "Training Epoch 84  62.8% | batch:        59 of        94\t|\tloss: 838.624\n",
      "Training Epoch 84  63.8% | batch:        60 of        94\t|\tloss: 1061.52\n",
      "Training Epoch 84  64.9% | batch:        61 of        94\t|\tloss: 831.156\n",
      "Training Epoch 84  66.0% | batch:        62 of        94\t|\tloss: 789.103\n",
      "Training Epoch 84  67.0% | batch:        63 of        94\t|\tloss: 732.553\n",
      "Training Epoch 84  68.1% | batch:        64 of        94\t|\tloss: 917.009\n",
      "Training Epoch 84  69.1% | batch:        65 of        94\t|\tloss: 2180.02\n",
      "Training Epoch 84  70.2% | batch:        66 of        94\t|\tloss: 758.11\n",
      "Training Epoch 84  71.3% | batch:        67 of        94\t|\tloss: 1224.34\n",
      "Training Epoch 84  72.3% | batch:        68 of        94\t|\tloss: 1148.69\n",
      "Training Epoch 84  73.4% | batch:        69 of        94\t|\tloss: 1219.76\n",
      "Training Epoch 84  74.5% | batch:        70 of        94\t|\tloss: 846.866\n",
      "Training Epoch 84  75.5% | batch:        71 of        94\t|\tloss: 991.93\n",
      "Training Epoch 84  76.6% | batch:        72 of        94\t|\tloss: 819.324\n",
      "Training Epoch 84  77.7% | batch:        73 of        94\t|\tloss: 884.112\n",
      "Training Epoch 84  78.7% | batch:        74 of        94\t|\tloss: 966.776\n",
      "Training Epoch 84  79.8% | batch:        75 of        94\t|\tloss: 888.7\n",
      "Training Epoch 84  80.9% | batch:        76 of        94\t|\tloss: 1017.98\n",
      "Training Epoch 84  81.9% | batch:        77 of        94\t|\tloss: 817.618\n",
      "Training Epoch 84  83.0% | batch:        78 of        94\t|\tloss: 596.509\n",
      "Training Epoch 84  84.0% | batch:        79 of        94\t|\tloss: 1117.1\n",
      "Training Epoch 84  85.1% | batch:        80 of        94\t|\tloss: 783.76\n",
      "Training Epoch 84  86.2% | batch:        81 of        94\t|\tloss: 919.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:42,133 | INFO : Epoch 84 Training Summary: epoch: 84.000000 | loss: 956.708722 | \n",
      "2023-05-04 17:01:42,134 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7950403690338135 seconds\n",
      "\n",
      "2023-05-04 17:01:42,134 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7826355128061204 seconds\n",
      "2023-05-04 17:01:42,135 | INFO : Avg batch train. time: 0.018964207583043836 seconds\n",
      "2023-05-04 17:01:42,135 | INFO : Avg sample train. time: 0.0001495750556138715 seconds\n",
      "2023-05-04 17:01:42,136 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 84  87.2% | batch:        82 of        94\t|\tloss: 1092.46\n",
      "Training Epoch 84  88.3% | batch:        83 of        94\t|\tloss: 932.401\n",
      "Training Epoch 84  89.4% | batch:        84 of        94\t|\tloss: 733.373\n",
      "Training Epoch 84  90.4% | batch:        85 of        94\t|\tloss: 973.994\n",
      "Training Epoch 84  91.5% | batch:        86 of        94\t|\tloss: 633.329\n",
      "Training Epoch 84  92.6% | batch:        87 of        94\t|\tloss: 1136.05\n",
      "Training Epoch 84  93.6% | batch:        88 of        94\t|\tloss: 743.559\n",
      "Training Epoch 84  94.7% | batch:        89 of        94\t|\tloss: 639.458\n",
      "Training Epoch 84  95.7% | batch:        90 of        94\t|\tloss: 577.764\n",
      "Training Epoch 84  96.8% | batch:        91 of        94\t|\tloss: 976.772\n",
      "Training Epoch 84  97.9% | batch:        92 of        94\t|\tloss: 1660.89\n",
      "Training Epoch 84  98.9% | batch:        93 of        94\t|\tloss: 1609.24\n",
      "\n",
      "Evaluating Epoch 84   0.0% | batch:         0 of        40\t|\tloss: 7653.96\n",
      "Evaluating Epoch 84   2.5% | batch:         1 of        40\t|\tloss: 963.743\n",
      "Evaluating Epoch 84   5.0% | batch:         2 of        40\t|\tloss: 3245.05\n",
      "Evaluating Epoch 84   7.5% | batch:         3 of        40\t|\tloss: 7628.79\n",
      "Evaluating Epoch 84  10.0% | batch:         4 of        40\t|\tloss: 3435.92\n",
      "Evaluating Epoch 84  12.5% | batch:         5 of        40\t|\tloss: 2908.08\n",
      "Evaluating Epoch 84  15.0% | batch:         6 of        40\t|\tloss: 8440.73\n",
      "Evaluating Epoch 84  17.5% | batch:         7 of        40\t|\tloss: 3431.29\n",
      "Evaluating Epoch 84  20.0% | batch:         8 of        40\t|\tloss: 2828.49\n",
      "Evaluating Epoch 84  22.5% | batch:         9 of        40\t|\tloss: 1769.89\n",
      "Evaluating Epoch 84  25.0% | batch:        10 of        40\t|\tloss: 5062.51\n",
      "Evaluating Epoch 84  27.5% | batch:        11 of        40\t|\tloss: 1418.28\n",
      "Evaluating Epoch 84  30.0% | batch:        12 of        40\t|\tloss: 7703.39\n",
      "Evaluating Epoch 84  32.5% | batch:        13 of        40\t|\tloss: 3116.48\n",
      "Evaluating Epoch 84  35.0% | batch:        14 of        40\t|\tloss: 2080.69\n",
      "Evaluating Epoch 84  37.5% | batch:        15 of        40\t|\tloss: 3351.6\n",
      "Evaluating Epoch 84  40.0% | batch:        16 of        40\t|\tloss: 4998.83\n",
      "Evaluating Epoch 84  42.5% | batch:        17 of        40\t|\tloss: 2865.97\n",
      "Evaluating Epoch 84  45.0% | batch:        18 of        40\t|\tloss: 2768.14\n",
      "Evaluating Epoch 84  47.5% | batch:        19 of        40\t|\tloss: 5906.66\n",
      "Evaluating Epoch 84  50.0% | batch:        20 of        40\t|\tloss: 5202.56\n",
      "Evaluating Epoch 84  52.5% | batch:        21 of        40\t|\tloss: 1410.07\n",
      "Evaluating Epoch 84  55.0% | batch:        22 of        40\t|\tloss: 3945.89\n",
      "Evaluating Epoch 84  57.5% | batch:        23 of        40\t|\tloss: 3386.96\n",
      "Evaluating Epoch 84  60.0% | batch:        24 of        40\t|\tloss: 1343.44\n",
      "Evaluating Epoch 84  62.5% | batch:        25 of        40\t|\tloss: 3952.17\n",
      "Evaluating Epoch 84  65.0% | batch:        26 of        40\t|\tloss: 12237.8\n",
      "Evaluating Epoch 84  67.5% | batch:        27 of        40\t|\tloss: 2841.63\n",
      "Evaluating Epoch 84  70.0% | batch:        28 of        40\t|\tloss: 1958.9\n",
      "Evaluating Epoch 84  72.5% | batch:        29 of        40\t|\tloss: 8951.62\n",
      "Evaluating Epoch 84  75.0% | batch:        30 of        40\t|\tloss: 1631.9\n",
      "Evaluating Epoch 84  77.5% | batch:        31 of        40\t|\tloss: 1523.85\n",
      "Evaluating Epoch 84  80.0% | batch:        32 of        40\t|\tloss: 7790.31\n",
      "Evaluating Epoch 84  82.5% | batch:        33 of        40\t|\tloss: 6297.6\n",
      "Evaluating Epoch 84  85.0% | batch:        34 of        40\t|\tloss: 1160.91\n",
      "Evaluating Epoch 84  87.5% | batch:        35 of        40\t|\tloss: 5253.81\n",
      "Evaluating Epoch 84  90.0% | batch:        36 of        40\t|\tloss: 6599.28\n",
      "Evaluating Epoch 84  92.5% | batch:        37 of        40\t|\tloss: 2667.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:42,586 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44931840896606445 seconds\n",
      "\n",
      "2023-05-04 17:01:42,586 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5291609264001613 seconds\n",
      "2023-05-04 17:01:42,587 | INFO : Avg batch val. time: 0.013229023160004034 seconds\n",
      "2023-05-04 17:01:42,587 | INFO : Avg sample val. time: 0.0001048258570523299 seconds\n",
      "2023-05-04 17:01:42,588 | INFO : Epoch 84 Validation Summary: epoch: 84.000000 | loss: 4302.522288 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 84  95.0% | batch:        38 of        40\t|\tloss: 3481.08\n",
      "Evaluating Epoch 84  97.5% | batch:        39 of        40\t|\tloss: 14777.7\n",
      "\n",
      "Training Epoch 85   0.0% | batch:         0 of        94\t|\tloss: 1060.46\n",
      "Training Epoch 85   1.1% | batch:         1 of        94\t|\tloss: 1047.66\n",
      "Training Epoch 85   2.1% | batch:         2 of        94\t|\tloss: 815.053\n",
      "Training Epoch 85   3.2% | batch:         3 of        94\t|\tloss: 1320.88\n",
      "Training Epoch 85   4.3% | batch:         4 of        94\t|\tloss: 857.702\n",
      "Training Epoch 85   5.3% | batch:         5 of        94\t|\tloss: 1218.98\n",
      "Training Epoch 85   6.4% | batch:         6 of        94\t|\tloss: 1142\n",
      "Training Epoch 85   7.4% | batch:         7 of        94\t|\tloss: 1160.28\n",
      "Training Epoch 85   8.5% | batch:         8 of        94\t|\tloss: 1031.78\n",
      "Training Epoch 85   9.6% | batch:         9 of        94\t|\tloss: 750.04\n",
      "Training Epoch 85  10.6% | batch:        10 of        94\t|\tloss: 1607.33\n",
      "Training Epoch 85  11.7% | batch:        11 of        94\t|\tloss: 671.127\n",
      "Training Epoch 85  12.8% | batch:        12 of        94\t|\tloss: 770.654\n",
      "Training Epoch 85  13.8% | batch:        13 of        94\t|\tloss: 1097.8\n",
      "Training Epoch 85  14.9% | batch:        14 of        94\t|\tloss: 712.171\n",
      "Training Epoch 85  16.0% | batch:        15 of        94\t|\tloss: 1166.82\n",
      "Training Epoch 85  17.0% | batch:        16 of        94\t|\tloss: 836.848\n",
      "Training Epoch 85  18.1% | batch:        17 of        94\t|\tloss: 1262.64\n",
      "Training Epoch 85  19.1% | batch:        18 of        94\t|\tloss: 1442.92\n",
      "Training Epoch 85  20.2% | batch:        19 of        94\t|\tloss: 600.299\n",
      "Training Epoch 85  21.3% | batch:        20 of        94\t|\tloss: 1288.27\n",
      "Training Epoch 85  22.3% | batch:        21 of        94\t|\tloss: 1187.6\n",
      "Training Epoch 85  23.4% | batch:        22 of        94\t|\tloss: 1373.26\n",
      "Training Epoch 85  24.5% | batch:        23 of        94\t|\tloss: 907.359\n",
      "Training Epoch 85  25.5% | batch:        24 of        94\t|\tloss: 1233.37\n",
      "Training Epoch 85  26.6% | batch:        25 of        94\t|\tloss: 494.1\n",
      "Training Epoch 85  27.7% | batch:        26 of        94\t|\tloss: 699.663\n",
      "Training Epoch 85  28.7% | batch:        27 of        94\t|\tloss: 895.651\n",
      "Training Epoch 85  29.8% | batch:        28 of        94\t|\tloss: 793.326\n",
      "Training Epoch 85  30.9% | batch:        29 of        94\t|\tloss: 618.429\n",
      "Training Epoch 85  31.9% | batch:        30 of        94\t|\tloss: 819.571\n",
      "Training Epoch 85  33.0% | batch:        31 of        94\t|\tloss: 1446.65\n",
      "Training Epoch 85  34.0% | batch:        32 of        94\t|\tloss: 720.617\n",
      "Training Epoch 85  35.1% | batch:        33 of        94\t|\tloss: 776.891\n",
      "Training Epoch 85  36.2% | batch:        34 of        94\t|\tloss: 816.617\n",
      "Training Epoch 85  37.2% | batch:        35 of        94\t|\tloss: 901.984\n",
      "Training Epoch 85  38.3% | batch:        36 of        94\t|\tloss: 634.714\n",
      "Training Epoch 85  39.4% | batch:        37 of        94\t|\tloss: 873.178\n",
      "Training Epoch 85  40.4% | batch:        38 of        94\t|\tloss: 976.39\n",
      "Training Epoch 85  41.5% | batch:        39 of        94\t|\tloss: 1080.25\n",
      "Training Epoch 85  42.6% | batch:        40 of        94\t|\tloss: 1038.02\n",
      "Training Epoch 85  43.6% | batch:        41 of        94\t|\tloss: 776.056\n",
      "Training Epoch 85  44.7% | batch:        42 of        94\t|\tloss: 1290.26\n",
      "Training Epoch 85  45.7% | batch:        43 of        94\t|\tloss: 1789.07\n",
      "Training Epoch 85  46.8% | batch:        44 of        94\t|\tloss: 995.834\n",
      "Training Epoch 85  47.9% | batch:        45 of        94\t|\tloss: 1243.13\n",
      "Training Epoch 85  48.9% | batch:        46 of        94\t|\tloss: 892.725\n",
      "Training Epoch 85  50.0% | batch:        47 of        94\t|\tloss: 1022.83\n",
      "Training Epoch 85  51.1% | batch:        48 of        94\t|\tloss: 2175.1\n",
      "Training Epoch 85  52.1% | batch:        49 of        94\t|\tloss: 1120.62\n",
      "Training Epoch 85  53.2% | batch:        50 of        94\t|\tloss: 792.197\n",
      "Training Epoch 85  54.3% | batch:        51 of        94\t|\tloss: 923.515\n",
      "Training Epoch 85  55.3% | batch:        52 of        94\t|\tloss: 1072.18\n",
      "Training Epoch 85  56.4% | batch:        53 of        94\t|\tloss: 653.111\n",
      "Training Epoch 85  57.4% | batch:        54 of        94\t|\tloss: 610.453\n",
      "Training Epoch 85  58.5% | batch:        55 of        94\t|\tloss: 818.199\n",
      "Training Epoch 85  59.6% | batch:        56 of        94\t|\tloss: 1013.92\n",
      "Training Epoch 85  60.6% | batch:        57 of        94\t|\tloss: 590.719\n",
      "Training Epoch 85  61.7% | batch:        58 of        94\t|\tloss: 782.316\n",
      "Training Epoch 85  62.8% | batch:        59 of        94\t|\tloss: 851.696\n",
      "Training Epoch 85  63.8% | batch:        60 of        94\t|\tloss: 840.386\n",
      "Training Epoch 85  64.9% | batch:        61 of        94\t|\tloss: 694.341\n",
      "Training Epoch 85  66.0% | batch:        62 of        94\t|\tloss: 920.203\n",
      "Training Epoch 85  67.0% | batch:        63 of        94\t|\tloss: 1029.27\n",
      "Training Epoch 85  68.1% | batch:        64 of        94\t|\tloss: 1163.19\n",
      "Training Epoch 85  69.1% | batch:        65 of        94\t|\tloss: 691.17\n",
      "Training Epoch 85  70.2% | batch:        66 of        94\t|\tloss: 1006.05\n",
      "Training Epoch 85  71.3% | batch:        67 of        94\t|\tloss: 840.883\n",
      "Training Epoch 85  72.3% | batch:        68 of        94\t|\tloss: 1043.6\n",
      "Training Epoch 85  73.4% | batch:        69 of        94\t|\tloss: 833.541\n",
      "Training Epoch 85  74.5% | batch:        70 of        94\t|\tloss: 970.332\n",
      "Training Epoch 85  75.5% | batch:        71 of        94\t|\tloss: 968.891\n",
      "Training Epoch 85  76.6% | batch:        72 of        94\t|\tloss: 855.975\n",
      "Training Epoch 85  77.7% | batch:        73 of        94\t|\tloss: 1083.42\n",
      "Training Epoch 85  78.7% | batch:        74 of        94\t|\tloss: 988.042\n",
      "Training Epoch 85  79.8% | batch:        75 of        94\t|\tloss: 712.336\n",
      "Training Epoch 85  80.9% | batch:        76 of        94\t|\tloss: 822.778\n",
      "Training Epoch 85  81.9% | batch:        77 of        94\t|\tloss: 1026.08\n",
      "Training Epoch 85  83.0% | batch:        78 of        94\t|\tloss: 889.194\n",
      "Training Epoch 85  84.0% | batch:        79 of        94\t|\tloss: 700.153\n",
      "Training Epoch 85  85.1% | batch:        80 of        94\t|\tloss: 825.666\n",
      "Training Epoch 85  86.2% | batch:        81 of        94\t|\tloss: 900.477\n",
      "Training Epoch 85  87.2% | batch:        82 of        94\t|\tloss: 1385.89\n",
      "Training Epoch 85  88.3% | batch:        83 of        94\t|\tloss: 916.271\n",
      "Training Epoch 85  89.4% | batch:        84 of        94\t|\tloss: 977.417\n",
      "Training Epoch 85  90.4% | batch:        85 of        94\t|\tloss: 863.939\n",
      "Training Epoch 85  91.5% | batch:        86 of        94\t|\tloss: 632.633\n",
      "Training Epoch 85  92.6% | batch:        87 of        94\t|\tloss: 942.887\n",
      "Training Epoch 85  93.6% | batch:        88 of        94\t|\tloss: 875.486\n",
      "Training Epoch 85  94.7% | batch:        89 of        94\t|\tloss: 2037.72\n",
      "Training Epoch 85  95.7% | batch:        90 of        94\t|\tloss: 3034.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:44,311 | INFO : Epoch 85 Training Summary: epoch: 85.000000 | loss: 1000.402246 | \n",
      "2023-05-04 17:01:44,312 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.701294183731079 seconds\n",
      "\n",
      "2023-05-04 17:01:44,313 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.781678555993473 seconds\n",
      "2023-05-04 17:01:44,313 | INFO : Avg batch train. time: 0.018954027191419923 seconds\n",
      "2023-05-04 17:01:44,314 | INFO : Avg sample train. time: 0.00014949476052974266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 85  96.8% | batch:        91 of        94\t|\tloss: 1042.69\n",
      "Training Epoch 85  97.9% | batch:        92 of        94\t|\tloss: 856.395\n",
      "Training Epoch 85  98.9% | batch:        93 of        94\t|\tloss: 1932.97\n",
      "\n",
      "Training Epoch 86   0.0% | batch:         0 of        94\t|\tloss: 541.564\n",
      "Training Epoch 86   1.1% | batch:         1 of        94\t|\tloss: 878.294\n",
      "Training Epoch 86   2.1% | batch:         2 of        94\t|\tloss: 826.203\n",
      "Training Epoch 86   3.2% | batch:         3 of        94\t|\tloss: 1369.59\n",
      "Training Epoch 86   4.3% | batch:         4 of        94\t|\tloss: 1140.77\n",
      "Training Epoch 86   5.3% | batch:         5 of        94\t|\tloss: 964.421\n",
      "Training Epoch 86   6.4% | batch:         6 of        94\t|\tloss: 698.797\n",
      "Training Epoch 86   7.4% | batch:         7 of        94\t|\tloss: 681.732\n",
      "Training Epoch 86   8.5% | batch:         8 of        94\t|\tloss: 1168.1\n",
      "Training Epoch 86   9.6% | batch:         9 of        94\t|\tloss: 1392.98\n",
      "Training Epoch 86  10.6% | batch:        10 of        94\t|\tloss: 2282.58\n",
      "Training Epoch 86  11.7% | batch:        11 of        94\t|\tloss: 1109.17\n",
      "Training Epoch 86  12.8% | batch:        12 of        94\t|\tloss: 493.591\n",
      "Training Epoch 86  13.8% | batch:        13 of        94\t|\tloss: 985.427\n",
      "Training Epoch 86  14.9% | batch:        14 of        94\t|\tloss: 1110.26\n",
      "Training Epoch 86  16.0% | batch:        15 of        94\t|\tloss: 682.736\n",
      "Training Epoch 86  17.0% | batch:        16 of        94\t|\tloss: 2257.68\n",
      "Training Epoch 86  18.1% | batch:        17 of        94\t|\tloss: 893.516\n",
      "Training Epoch 86  19.1% | batch:        18 of        94\t|\tloss: 834.478\n",
      "Training Epoch 86  20.2% | batch:        19 of        94\t|\tloss: 743.746\n",
      "Training Epoch 86  21.3% | batch:        20 of        94\t|\tloss: 1199.2\n",
      "Training Epoch 86  22.3% | batch:        21 of        94\t|\tloss: 732.565\n",
      "Training Epoch 86  23.4% | batch:        22 of        94\t|\tloss: 794.122\n",
      "Training Epoch 86  24.5% | batch:        23 of        94\t|\tloss: 1147.99\n",
      "Training Epoch 86  25.5% | batch:        24 of        94\t|\tloss: 1367.29\n",
      "Training Epoch 86  26.6% | batch:        25 of        94\t|\tloss: 801.818\n",
      "Training Epoch 86  27.7% | batch:        26 of        94\t|\tloss: 868.737\n",
      "Training Epoch 86  28.7% | batch:        27 of        94\t|\tloss: 748.868\n",
      "Training Epoch 86  29.8% | batch:        28 of        94\t|\tloss: 1004.36\n",
      "Training Epoch 86  30.9% | batch:        29 of        94\t|\tloss: 563.853\n",
      "Training Epoch 86  31.9% | batch:        30 of        94\t|\tloss: 1026.3\n",
      "Training Epoch 86  33.0% | batch:        31 of        94\t|\tloss: 533.064\n",
      "Training Epoch 86  34.0% | batch:        32 of        94\t|\tloss: 843.536\n",
      "Training Epoch 86  35.1% | batch:        33 of        94\t|\tloss: 1132.56\n",
      "Training Epoch 86  36.2% | batch:        34 of        94\t|\tloss: 575.86\n",
      "Training Epoch 86  37.2% | batch:        35 of        94\t|\tloss: 985.048\n",
      "Training Epoch 86  38.3% | batch:        36 of        94\t|\tloss: 691.285\n",
      "Training Epoch 86  39.4% | batch:        37 of        94\t|\tloss: 1144.55\n",
      "Training Epoch 86  40.4% | batch:        38 of        94\t|\tloss: 640.244\n",
      "Training Epoch 86  41.5% | batch:        39 of        94\t|\tloss: 834.851\n",
      "Training Epoch 86  42.6% | batch:        40 of        94\t|\tloss: 667.275\n",
      "Training Epoch 86  43.6% | batch:        41 of        94\t|\tloss: 525.557\n",
      "Training Epoch 86  44.7% | batch:        42 of        94\t|\tloss: 848.777\n",
      "Training Epoch 86  45.7% | batch:        43 of        94\t|\tloss: 999.946\n",
      "Training Epoch 86  46.8% | batch:        44 of        94\t|\tloss: 1521.01\n",
      "Training Epoch 86  47.9% | batch:        45 of        94\t|\tloss: 844.717\n",
      "Training Epoch 86  48.9% | batch:        46 of        94\t|\tloss: 837.507\n",
      "Training Epoch 86  50.0% | batch:        47 of        94\t|\tloss: 1304.39\n",
      "Training Epoch 86  51.1% | batch:        48 of        94\t|\tloss: 729.664\n",
      "Training Epoch 86  52.1% | batch:        49 of        94\t|\tloss: 777.81\n",
      "Training Epoch 86  53.2% | batch:        50 of        94\t|\tloss: 845.201\n",
      "Training Epoch 86  54.3% | batch:        51 of        94\t|\tloss: 416.361\n",
      "Training Epoch 86  55.3% | batch:        52 of        94\t|\tloss: 1530.06\n",
      "Training Epoch 86  56.4% | batch:        53 of        94\t|\tloss: 991.998\n",
      "Training Epoch 86  57.4% | batch:        54 of        94\t|\tloss: 805.238\n",
      "Training Epoch 86  58.5% | batch:        55 of        94\t|\tloss: 727.402\n",
      "Training Epoch 86  59.6% | batch:        56 of        94\t|\tloss: 747.386\n",
      "Training Epoch 86  60.6% | batch:        57 of        94\t|\tloss: 841.631\n",
      "Training Epoch 86  61.7% | batch:        58 of        94\t|\tloss: 916.042\n",
      "Training Epoch 86  62.8% | batch:        59 of        94\t|\tloss: 1083.96\n",
      "Training Epoch 86  63.8% | batch:        60 of        94\t|\tloss: 1306.65\n",
      "Training Epoch 86  64.9% | batch:        61 of        94\t|\tloss: 1701.21\n",
      "Training Epoch 86  66.0% | batch:        62 of        94\t|\tloss: 816.808\n",
      "Training Epoch 86  67.0% | batch:        63 of        94\t|\tloss: 1498.28\n",
      "Training Epoch 86  68.1% | batch:        64 of        94\t|\tloss: 953.316\n",
      "Training Epoch 86  69.1% | batch:        65 of        94\t|\tloss: 1029.49\n",
      "Training Epoch 86  70.2% | batch:        66 of        94\t|\tloss: 1178.25\n",
      "Training Epoch 86  71.3% | batch:        67 of        94\t|\tloss: 1063.97\n",
      "Training Epoch 86  72.3% | batch:        68 of        94\t|\tloss: 1343.86\n",
      "Training Epoch 86  73.4% | batch:        69 of        94\t|\tloss: 859.611\n",
      "Training Epoch 86  74.5% | batch:        70 of        94\t|\tloss: 921.92\n",
      "Training Epoch 86  75.5% | batch:        71 of        94\t|\tloss: 1014.08\n",
      "Training Epoch 86  76.6% | batch:        72 of        94\t|\tloss: 1508.17\n",
      "Training Epoch 86  77.7% | batch:        73 of        94\t|\tloss: 861.167\n",
      "Training Epoch 86  78.7% | batch:        74 of        94\t|\tloss: 968.703\n",
      "Training Epoch 86  79.8% | batch:        75 of        94\t|\tloss: 1263.38\n",
      "Training Epoch 86  80.9% | batch:        76 of        94\t|\tloss: 1004.55\n",
      "Training Epoch 86  81.9% | batch:        77 of        94\t|\tloss: 826.555\n",
      "Training Epoch 86  83.0% | batch:        78 of        94\t|\tloss: 858.876\n",
      "Training Epoch 86  84.0% | batch:        79 of        94\t|\tloss: 778.81\n",
      "Training Epoch 86  85.1% | batch:        80 of        94\t|\tloss: 580.369\n",
      "Training Epoch 86  86.2% | batch:        81 of        94\t|\tloss: 981.771\n",
      "Training Epoch 86  87.2% | batch:        82 of        94\t|\tloss: 1654.47\n",
      "Training Epoch 86  88.3% | batch:        83 of        94\t|\tloss: 859.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:46,143 | INFO : Epoch 86 Training Summary: epoch: 86.000000 | loss: 999.600496 | \n",
      "2023-05-04 17:01:46,144 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8081142902374268 seconds\n",
      "\n",
      "2023-05-04 17:01:46,145 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7819859482521234 seconds\n",
      "2023-05-04 17:01:46,145 | INFO : Avg batch train. time: 0.0189572973218311 seconds\n",
      "2023-05-04 17:01:46,146 | INFO : Avg sample train. time: 0.00014952055279846647 seconds\n",
      "2023-05-04 17:01:46,146 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 86  89.4% | batch:        84 of        94\t|\tloss: 1940.46\n",
      "Training Epoch 86  90.4% | batch:        85 of        94\t|\tloss: 717.966\n",
      "Training Epoch 86  91.5% | batch:        86 of        94\t|\tloss: 776.848\n",
      "Training Epoch 86  92.6% | batch:        87 of        94\t|\tloss: 1197.94\n",
      "Training Epoch 86  93.6% | batch:        88 of        94\t|\tloss: 998.227\n",
      "Training Epoch 86  94.7% | batch:        89 of        94\t|\tloss: 1140\n",
      "Training Epoch 86  95.7% | batch:        90 of        94\t|\tloss: 1020.42\n",
      "Training Epoch 86  96.8% | batch:        91 of        94\t|\tloss: 924.291\n",
      "Training Epoch 86  97.9% | batch:        92 of        94\t|\tloss: 1695.5\n",
      "Training Epoch 86  98.9% | batch:        93 of        94\t|\tloss: 1584.75\n",
      "\n",
      "Evaluating Epoch 86   0.0% | batch:         0 of        40\t|\tloss: 7328.58\n",
      "Evaluating Epoch 86   2.5% | batch:         1 of        40\t|\tloss: 1247.88\n",
      "Evaluating Epoch 86   5.0% | batch:         2 of        40\t|\tloss: 4443.64\n",
      "Evaluating Epoch 86   7.5% | batch:         3 of        40\t|\tloss: 7331.84\n",
      "Evaluating Epoch 86  10.0% | batch:         4 of        40\t|\tloss: 2740\n",
      "Evaluating Epoch 86  12.5% | batch:         5 of        40\t|\tloss: 3256.54\n",
      "Evaluating Epoch 86  15.0% | batch:         6 of        40\t|\tloss: 8627.71\n",
      "Evaluating Epoch 86  17.5% | batch:         7 of        40\t|\tloss: 3349.43\n",
      "Evaluating Epoch 86  20.0% | batch:         8 of        40\t|\tloss: 2868.47\n",
      "Evaluating Epoch 86  22.5% | batch:         9 of        40\t|\tloss: 2473.99\n",
      "Evaluating Epoch 86  25.0% | batch:        10 of        40\t|\tloss: 4877.75\n",
      "Evaluating Epoch 86  27.5% | batch:        11 of        40\t|\tloss: 1554.47\n",
      "Evaluating Epoch 86  30.0% | batch:        12 of        40\t|\tloss: 7042.8\n",
      "Evaluating Epoch 86  32.5% | batch:        13 of        40\t|\tloss: 3415.53\n",
      "Evaluating Epoch 86  35.0% | batch:        14 of        40\t|\tloss: 1954.02\n",
      "Evaluating Epoch 86  37.5% | batch:        15 of        40\t|\tloss: 3572.01\n",
      "Evaluating Epoch 86  40.0% | batch:        16 of        40\t|\tloss: 5089.53\n",
      "Evaluating Epoch 86  42.5% | batch:        17 of        40\t|\tloss: 2893.12\n",
      "Evaluating Epoch 86  45.0% | batch:        18 of        40\t|\tloss: 2582.42\n",
      "Evaluating Epoch 86  47.5% | batch:        19 of        40\t|\tloss: 5362.62\n",
      "Evaluating Epoch 86  50.0% | batch:        20 of        40\t|\tloss: 5560.06\n",
      "Evaluating Epoch 86  52.5% | batch:        21 of        40\t|\tloss: 1010.93\n",
      "Evaluating Epoch 86  55.0% | batch:        22 of        40\t|\tloss: 4396.34\n",
      "Evaluating Epoch 86  57.5% | batch:        23 of        40\t|\tloss: 3694.78\n",
      "Evaluating Epoch 86  60.0% | batch:        24 of        40\t|\tloss: 1769.97\n",
      "Evaluating Epoch 86  62.5% | batch:        25 of        40\t|\tloss: 3938.43\n",
      "Evaluating Epoch 86  65.0% | batch:        26 of        40\t|\tloss: 9687.12\n",
      "Evaluating Epoch 86  67.5% | batch:        27 of        40\t|\tloss: 2822.85\n",
      "Evaluating Epoch 86  70.0% | batch:        28 of        40\t|\tloss: 2596.98\n",
      "Evaluating Epoch 86  72.5% | batch:        29 of        40\t|\tloss: 8719.64\n",
      "Evaluating Epoch 86  75.0% | batch:        30 of        40\t|\tloss: 1777.95\n",
      "Evaluating Epoch 86  77.5% | batch:        31 of        40\t|\tloss: 1838.94\n",
      "Evaluating Epoch 86  80.0% | batch:        32 of        40\t|\tloss: 8715.49\n",
      "Evaluating Epoch 86  82.5% | batch:        33 of        40\t|\tloss: 5977.79\n",
      "Evaluating Epoch 86  85.0% | batch:        34 of        40\t|\tloss: 1264.82\n",
      "Evaluating Epoch 86  87.5% | batch:        35 of        40\t|\tloss: 7133.63\n",
      "Evaluating Epoch 86  90.0% | batch:        36 of        40\t|\tloss: 7141.15\n",
      "Evaluating Epoch 86  92.5% | batch:        37 of        40\t|\tloss: 2746.69\n",
      "Evaluating Epoch 86  95.0% | batch:        38 of        40\t|\tloss: 3988.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:46,600 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4530487060546875 seconds\n",
      "\n",
      "2023-05-04 17:01:46,601 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5287914496023678 seconds\n",
      "2023-05-04 17:01:46,601 | INFO : Avg batch val. time: 0.013219786240059195 seconds\n",
      "2023-05-04 17:01:46,602 | INFO : Avg sample val. time: 0.00010475266434278284 seconds\n",
      "2023-05-04 17:01:46,602 | INFO : Epoch 86 Validation Summary: epoch: 86.000000 | loss: 4366.289220 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 86  97.5% | batch:        39 of        40\t|\tloss: 12346.4\n",
      "\n",
      "Training Epoch 87   0.0% | batch:         0 of        94\t|\tloss: 703.768\n",
      "Training Epoch 87   1.1% | batch:         1 of        94\t|\tloss: 1006.36\n",
      "Training Epoch 87   2.1% | batch:         2 of        94\t|\tloss: 865.436\n",
      "Training Epoch 87   3.2% | batch:         3 of        94\t|\tloss: 920.316\n",
      "Training Epoch 87   4.3% | batch:         4 of        94\t|\tloss: 1309.55\n",
      "Training Epoch 87   5.3% | batch:         5 of        94\t|\tloss: 1162.33\n",
      "Training Epoch 87   6.4% | batch:         6 of        94\t|\tloss: 1195.23\n",
      "Training Epoch 87   7.4% | batch:         7 of        94\t|\tloss: 1330.88\n",
      "Training Epoch 87   8.5% | batch:         8 of        94\t|\tloss: 983.959\n",
      "Training Epoch 87   9.6% | batch:         9 of        94\t|\tloss: 1054.74\n",
      "Training Epoch 87  10.6% | batch:        10 of        94\t|\tloss: 997.368\n",
      "Training Epoch 87  11.7% | batch:        11 of        94\t|\tloss: 3167.72\n",
      "Training Epoch 87  12.8% | batch:        12 of        94\t|\tloss: 750.492\n",
      "Training Epoch 87  13.8% | batch:        13 of        94\t|\tloss: 878.005\n",
      "Training Epoch 87  14.9% | batch:        14 of        94\t|\tloss: 889.908\n",
      "Training Epoch 87  16.0% | batch:        15 of        94\t|\tloss: 558.124\n",
      "Training Epoch 87  17.0% | batch:        16 of        94\t|\tloss: 1147.4\n",
      "Training Epoch 87  18.1% | batch:        17 of        94\t|\tloss: 788.638\n",
      "Training Epoch 87  19.1% | batch:        18 of        94\t|\tloss: 1302.19\n",
      "Training Epoch 87  20.2% | batch:        19 of        94\t|\tloss: 1396.23\n",
      "Training Epoch 87  21.3% | batch:        20 of        94\t|\tloss: 1619.51\n",
      "Training Epoch 87  22.3% | batch:        21 of        94\t|\tloss: 730.703\n",
      "Training Epoch 87  23.4% | batch:        22 of        94\t|\tloss: 683.116\n",
      "Training Epoch 87  24.5% | batch:        23 of        94\t|\tloss: 1274.63\n",
      "Training Epoch 87  25.5% | batch:        24 of        94\t|\tloss: 1078.2\n",
      "Training Epoch 87  26.6% | batch:        25 of        94\t|\tloss: 938.844\n",
      "Training Epoch 87  27.7% | batch:        26 of        94\t|\tloss: 866.444\n",
      "Training Epoch 87  28.7% | batch:        27 of        94\t|\tloss: 908.239\n",
      "Training Epoch 87  29.8% | batch:        28 of        94\t|\tloss: 669.969\n",
      "Training Epoch 87  30.9% | batch:        29 of        94\t|\tloss: 729.198\n",
      "Training Epoch 87  31.9% | batch:        30 of        94\t|\tloss: 1111.74\n",
      "Training Epoch 87  33.0% | batch:        31 of        94\t|\tloss: 1216.32\n",
      "Training Epoch 87  34.0% | batch:        32 of        94\t|\tloss: 1330.98\n",
      "Training Epoch 87  35.1% | batch:        33 of        94\t|\tloss: 1772.75\n",
      "Training Epoch 87  36.2% | batch:        34 of        94\t|\tloss: 798.541\n",
      "Training Epoch 87  37.2% | batch:        35 of        94\t|\tloss: 988.478\n",
      "Training Epoch 87  38.3% | batch:        36 of        94\t|\tloss: 787.22\n",
      "Training Epoch 87  39.4% | batch:        37 of        94\t|\tloss: 657.388\n",
      "Training Epoch 87  40.4% | batch:        38 of        94\t|\tloss: 2455.23\n",
      "Training Epoch 87  41.5% | batch:        39 of        94\t|\tloss: 919.364\n",
      "Training Epoch 87  42.6% | batch:        40 of        94\t|\tloss: 610.085\n",
      "Training Epoch 87  43.6% | batch:        41 of        94\t|\tloss: 1222.46\n",
      "Training Epoch 87  44.7% | batch:        42 of        94\t|\tloss: 1370.91\n",
      "Training Epoch 87  45.7% | batch:        43 of        94\t|\tloss: 1223.77\n",
      "Training Epoch 87  46.8% | batch:        44 of        94\t|\tloss: 601.997\n",
      "Training Epoch 87  47.9% | batch:        45 of        94\t|\tloss: 936.715\n",
      "Training Epoch 87  48.9% | batch:        46 of        94\t|\tloss: 1380.94\n",
      "Training Epoch 87  50.0% | batch:        47 of        94\t|\tloss: 997.886\n",
      "Training Epoch 87  51.1% | batch:        48 of        94\t|\tloss: 880.703\n",
      "Training Epoch 87  52.1% | batch:        49 of        94\t|\tloss: 809.677\n",
      "Training Epoch 87  53.2% | batch:        50 of        94\t|\tloss: 1758.6\n",
      "Training Epoch 87  54.3% | batch:        51 of        94\t|\tloss: 1043.95\n",
      "Training Epoch 87  55.3% | batch:        52 of        94\t|\tloss: 801.636\n",
      "Training Epoch 87  56.4% | batch:        53 of        94\t|\tloss: 1534.5\n",
      "Training Epoch 87  57.4% | batch:        54 of        94\t|\tloss: 822.544\n",
      "Training Epoch 87  58.5% | batch:        55 of        94\t|\tloss: 917.528\n",
      "Training Epoch 87  59.6% | batch:        56 of        94\t|\tloss: 895.054\n",
      "Training Epoch 87  60.6% | batch:        57 of        94\t|\tloss: 766.14\n",
      "Training Epoch 87  61.7% | batch:        58 of        94\t|\tloss: 1033.4\n",
      "Training Epoch 87  62.8% | batch:        59 of        94\t|\tloss: 777.523\n",
      "Training Epoch 87  63.8% | batch:        60 of        94\t|\tloss: 698.369\n",
      "Training Epoch 87  64.9% | batch:        61 of        94\t|\tloss: 620.906\n",
      "Training Epoch 87  66.0% | batch:        62 of        94\t|\tloss: 1486.53\n",
      "Training Epoch 87  67.0% | batch:        63 of        94\t|\tloss: 1404.84\n",
      "Training Epoch 87  68.1% | batch:        64 of        94\t|\tloss: 1345.31\n",
      "Training Epoch 87  69.1% | batch:        65 of        94\t|\tloss: 633.66\n",
      "Training Epoch 87  70.2% | batch:        66 of        94\t|\tloss: 858.674\n",
      "Training Epoch 87  71.3% | batch:        67 of        94\t|\tloss: 825.83\n",
      "Training Epoch 87  72.3% | batch:        68 of        94\t|\tloss: 1021.4\n",
      "Training Epoch 87  73.4% | batch:        69 of        94\t|\tloss: 736.175\n",
      "Training Epoch 87  74.5% | batch:        70 of        94\t|\tloss: 709.564\n",
      "Training Epoch 87  75.5% | batch:        71 of        94\t|\tloss: 628.913\n",
      "Training Epoch 87  76.6% | batch:        72 of        94\t|\tloss: 937.68\n",
      "Training Epoch 87  77.7% | batch:        73 of        94\t|\tloss: 976.694\n",
      "Training Epoch 87  78.7% | batch:        74 of        94\t|\tloss: 656.832\n",
      "Training Epoch 87  79.8% | batch:        75 of        94\t|\tloss: 1369.57\n",
      "Training Epoch 87  80.9% | batch:        76 of        94\t|\tloss: 955.696\n",
      "Training Epoch 87  81.9% | batch:        77 of        94\t|\tloss: 792.739\n",
      "Training Epoch 87  83.0% | batch:        78 of        94\t|\tloss: 1260.9\n",
      "Training Epoch 87  84.0% | batch:        79 of        94\t|\tloss: 664.843\n",
      "Training Epoch 87  85.1% | batch:        80 of        94\t|\tloss: 1703.65\n",
      "Training Epoch 87  86.2% | batch:        81 of        94\t|\tloss: 1094.8\n",
      "Training Epoch 87  87.2% | batch:        82 of        94\t|\tloss: 712.067\n",
      "Training Epoch 87  88.3% | batch:        83 of        94\t|\tloss: 1097.48\n",
      "Training Epoch 87  89.4% | batch:        84 of        94\t|\tloss: 1299.74\n",
      "Training Epoch 87  90.4% | batch:        85 of        94\t|\tloss: 821.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:48,424 | INFO : Epoch 87 Training Summary: epoch: 87.000000 | loss: 1030.578127 | \n",
      "2023-05-04 17:01:48,426 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8012423515319824 seconds\n",
      "\n",
      "2023-05-04 17:01:48,426 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7822072862208576 seconds\n",
      "2023-05-04 17:01:48,427 | INFO : Avg batch train. time: 0.018959651981072953 seconds\n",
      "2023-05-04 17:01:48,428 | INFO : Avg sample train. time: 0.00014953912453606792 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 87  91.5% | batch:        86 of        94\t|\tloss: 808.865\n",
      "Training Epoch 87  92.6% | batch:        87 of        94\t|\tloss: 762.306\n",
      "Training Epoch 87  93.6% | batch:        88 of        94\t|\tloss: 837.174\n",
      "Training Epoch 87  94.7% | batch:        89 of        94\t|\tloss: 1435.33\n",
      "Training Epoch 87  95.7% | batch:        90 of        94\t|\tloss: 648.951\n",
      "Training Epoch 87  96.8% | batch:        91 of        94\t|\tloss: 719.078\n",
      "Training Epoch 87  97.9% | batch:        92 of        94\t|\tloss: 1029.11\n",
      "Training Epoch 87  98.9% | batch:        93 of        94\t|\tloss: 637.79\n",
      "\n",
      "Training Epoch 88   0.0% | batch:         0 of        94\t|\tloss: 1040.92\n",
      "Training Epoch 88   1.1% | batch:         1 of        94\t|\tloss: 809.238\n",
      "Training Epoch 88   2.1% | batch:         2 of        94\t|\tloss: 731.467\n",
      "Training Epoch 88   3.2% | batch:         3 of        94\t|\tloss: 901.089\n",
      "Training Epoch 88   4.3% | batch:         4 of        94\t|\tloss: 1589.98\n",
      "Training Epoch 88   5.3% | batch:         5 of        94\t|\tloss: 913.553\n",
      "Training Epoch 88   6.4% | batch:         6 of        94\t|\tloss: 527.727\n",
      "Training Epoch 88   7.4% | batch:         7 of        94\t|\tloss: 1269.29\n",
      "Training Epoch 88   8.5% | batch:         8 of        94\t|\tloss: 689.844\n",
      "Training Epoch 88   9.6% | batch:         9 of        94\t|\tloss: 798.813\n",
      "Training Epoch 88  10.6% | batch:        10 of        94\t|\tloss: 1676.61\n",
      "Training Epoch 88  11.7% | batch:        11 of        94\t|\tloss: 683.59\n",
      "Training Epoch 88  12.8% | batch:        12 of        94\t|\tloss: 524.773\n",
      "Training Epoch 88  13.8% | batch:        13 of        94\t|\tloss: 918.792\n",
      "Training Epoch 88  14.9% | batch:        14 of        94\t|\tloss: 708.302\n",
      "Training Epoch 88  16.0% | batch:        15 of        94\t|\tloss: 769.318\n",
      "Training Epoch 88  17.0% | batch:        16 of        94\t|\tloss: 816.642\n",
      "Training Epoch 88  18.1% | batch:        17 of        94\t|\tloss: 796.469\n",
      "Training Epoch 88  19.1% | batch:        18 of        94\t|\tloss: 780.611\n",
      "Training Epoch 88  20.2% | batch:        19 of        94\t|\tloss: 575.416\n",
      "Training Epoch 88  21.3% | batch:        20 of        94\t|\tloss: 871.064\n",
      "Training Epoch 88  22.3% | batch:        21 of        94\t|\tloss: 872.439\n",
      "Training Epoch 88  23.4% | batch:        22 of        94\t|\tloss: 1183.44\n",
      "Training Epoch 88  24.5% | batch:        23 of        94\t|\tloss: 902.712\n",
      "Training Epoch 88  25.5% | batch:        24 of        94\t|\tloss: 704.697\n",
      "Training Epoch 88  26.6% | batch:        25 of        94\t|\tloss: 619.519\n",
      "Training Epoch 88  27.7% | batch:        26 of        94\t|\tloss: 654.657\n",
      "Training Epoch 88  28.7% | batch:        27 of        94\t|\tloss: 848.388\n",
      "Training Epoch 88  29.8% | batch:        28 of        94\t|\tloss: 892.417\n",
      "Training Epoch 88  30.9% | batch:        29 of        94\t|\tloss: 720.625\n",
      "Training Epoch 88  31.9% | batch:        30 of        94\t|\tloss: 1752\n",
      "Training Epoch 88  33.0% | batch:        31 of        94\t|\tloss: 980.557\n",
      "Training Epoch 88  34.0% | batch:        32 of        94\t|\tloss: 1070.41\n",
      "Training Epoch 88  35.1% | batch:        33 of        94\t|\tloss: 837.348\n",
      "Training Epoch 88  36.2% | batch:        34 of        94\t|\tloss: 674.925\n",
      "Training Epoch 88  37.2% | batch:        35 of        94\t|\tloss: 1076.86\n",
      "Training Epoch 88  38.3% | batch:        36 of        94\t|\tloss: 662.904\n",
      "Training Epoch 88  39.4% | batch:        37 of        94\t|\tloss: 613.044\n",
      "Training Epoch 88  40.4% | batch:        38 of        94\t|\tloss: 759.918\n",
      "Training Epoch 88  41.5% | batch:        39 of        94\t|\tloss: 902.36\n",
      "Training Epoch 88  42.6% | batch:        40 of        94\t|\tloss: 1151.53\n",
      "Training Epoch 88  43.6% | batch:        41 of        94\t|\tloss: 890.358\n",
      "Training Epoch 88  44.7% | batch:        42 of        94\t|\tloss: 1123.64\n",
      "Training Epoch 88  45.7% | batch:        43 of        94\t|\tloss: 954.708\n",
      "Training Epoch 88  46.8% | batch:        44 of        94\t|\tloss: 564.23\n",
      "Training Epoch 88  47.9% | batch:        45 of        94\t|\tloss: 536.943\n",
      "Training Epoch 88  48.9% | batch:        46 of        94\t|\tloss: 652.756\n",
      "Training Epoch 88  50.0% | batch:        47 of        94\t|\tloss: 1220.22\n",
      "Training Epoch 88  51.1% | batch:        48 of        94\t|\tloss: 905.846\n",
      "Training Epoch 88  52.1% | batch:        49 of        94\t|\tloss: 840.411\n",
      "Training Epoch 88  53.2% | batch:        50 of        94\t|\tloss: 849.918\n",
      "Training Epoch 88  54.3% | batch:        51 of        94\t|\tloss: 1005.08\n",
      "Training Epoch 88  55.3% | batch:        52 of        94\t|\tloss: 786.012\n",
      "Training Epoch 88  56.4% | batch:        53 of        94\t|\tloss: 869.659\n",
      "Training Epoch 88  57.4% | batch:        54 of        94\t|\tloss: 1013.08\n",
      "Training Epoch 88  58.5% | batch:        55 of        94\t|\tloss: 662.527\n",
      "Training Epoch 88  59.6% | batch:        56 of        94\t|\tloss: 652.916\n",
      "Training Epoch 88  60.6% | batch:        57 of        94\t|\tloss: 912.287\n",
      "Training Epoch 88  61.7% | batch:        58 of        94\t|\tloss: 785.018\n",
      "Training Epoch 88  62.8% | batch:        59 of        94\t|\tloss: 932.217\n",
      "Training Epoch 88  63.8% | batch:        60 of        94\t|\tloss: 831.532\n",
      "Training Epoch 88  64.9% | batch:        61 of        94\t|\tloss: 916.761\n",
      "Training Epoch 88  66.0% | batch:        62 of        94\t|\tloss: 1279.32\n",
      "Training Epoch 88  67.0% | batch:        63 of        94\t|\tloss: 980.376\n",
      "Training Epoch 88  68.1% | batch:        64 of        94\t|\tloss: 894.291\n",
      "Training Epoch 88  69.1% | batch:        65 of        94\t|\tloss: 813.156\n",
      "Training Epoch 88  70.2% | batch:        66 of        94\t|\tloss: 604.51\n",
      "Training Epoch 88  71.3% | batch:        67 of        94\t|\tloss: 760.534\n",
      "Training Epoch 88  72.3% | batch:        68 of        94\t|\tloss: 933.818\n",
      "Training Epoch 88  73.4% | batch:        69 of        94\t|\tloss: 1001.23\n",
      "Training Epoch 88  74.5% | batch:        70 of        94\t|\tloss: 860.994\n",
      "Training Epoch 88  75.5% | batch:        71 of        94\t|\tloss: 1200.97\n",
      "Training Epoch 88  76.6% | batch:        72 of        94\t|\tloss: 1066.84\n",
      "Training Epoch 88  77.7% | batch:        73 of        94\t|\tloss: 1013.93\n",
      "Training Epoch 88  78.7% | batch:        74 of        94\t|\tloss: 1233.82\n",
      "Training Epoch 88  79.8% | batch:        75 of        94\t|\tloss: 760.995\n",
      "Training Epoch 88  80.9% | batch:        76 of        94\t|\tloss: 601.355\n",
      "Training Epoch 88  81.9% | batch:        77 of        94\t|\tloss: 725.286\n",
      "Training Epoch 88  83.0% | batch:        78 of        94\t|\tloss: 2607.5\n",
      "Training Epoch 88  84.0% | batch:        79 of        94\t|\tloss: 1375.87\n",
      "Training Epoch 88  85.1% | batch:        80 of        94\t|\tloss: 865.659\n",
      "Training Epoch 88  86.2% | batch:        81 of        94\t|\tloss: 1099.55\n",
      "Training Epoch 88  87.2% | batch:        82 of        94\t|\tloss: 649.438\n",
      "Training Epoch 88  88.3% | batch:        83 of        94\t|\tloss: 798.505\n",
      "Training Epoch 88  89.4% | batch:        84 of        94\t|\tloss: 867.633\n",
      "Training Epoch 88  90.4% | batch:        85 of        94\t|\tloss: 673.6\n",
      "Training Epoch 88  91.5% | batch:        86 of        94\t|\tloss: 612.844\n",
      "Training Epoch 88  92.6% | batch:        87 of        94\t|\tloss: 1821.48\n",
      "Training Epoch 88  93.6% | batch:        88 of        94\t|\tloss: 782.991\n",
      "Training Epoch 88  94.7% | batch:        89 of        94\t|\tloss: 1665.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:50,254 | INFO : Epoch 88 Training Summary: epoch: 88.000000 | loss: 920.899207 | \n",
      "2023-05-04 17:01:50,255 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8061177730560303 seconds\n",
      "\n",
      "2023-05-04 17:01:50,255 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.78247899629853 seconds\n",
      "2023-05-04 17:01:50,256 | INFO : Avg batch train. time: 0.018962542513814146 seconds\n",
      "2023-05-04 17:01:50,257 | INFO : Avg sample train. time: 0.00014956192283088857 seconds\n",
      "2023-05-04 17:01:50,257 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 88  95.7% | batch:        90 of        94\t|\tloss: 758.608\n",
      "Training Epoch 88  96.8% | batch:        91 of        94\t|\tloss: 980.993\n",
      "Training Epoch 88  97.9% | batch:        92 of        94\t|\tloss: 1085.79\n",
      "Training Epoch 88  98.9% | batch:        93 of        94\t|\tloss: 1701.75\n",
      "\n",
      "Evaluating Epoch 88   0.0% | batch:         0 of        40\t|\tloss: 7191.01\n",
      "Evaluating Epoch 88   2.5% | batch:         1 of        40\t|\tloss: 1282.5\n",
      "Evaluating Epoch 88   5.0% | batch:         2 of        40\t|\tloss: 4624.03\n",
      "Evaluating Epoch 88   7.5% | batch:         3 of        40\t|\tloss: 7363.41\n",
      "Evaluating Epoch 88  10.0% | batch:         4 of        40\t|\tloss: 5907.9\n",
      "Evaluating Epoch 88  12.5% | batch:         5 of        40\t|\tloss: 4834\n",
      "Evaluating Epoch 88  15.0% | batch:         6 of        40\t|\tloss: 9202.69\n",
      "Evaluating Epoch 88  17.5% | batch:         7 of        40\t|\tloss: 3351.42\n",
      "Evaluating Epoch 88  20.0% | batch:         8 of        40\t|\tloss: 2895.98\n",
      "Evaluating Epoch 88  22.5% | batch:         9 of        40\t|\tloss: 2448.2\n",
      "Evaluating Epoch 88  25.0% | batch:        10 of        40\t|\tloss: 5336.46\n",
      "Evaluating Epoch 88  27.5% | batch:        11 of        40\t|\tloss: 1478.91\n",
      "Evaluating Epoch 88  30.0% | batch:        12 of        40\t|\tloss: 7173.74\n",
      "Evaluating Epoch 88  32.5% | batch:        13 of        40\t|\tloss: 3213.89\n",
      "Evaluating Epoch 88  35.0% | batch:        14 of        40\t|\tloss: 2381.08\n",
      "Evaluating Epoch 88  37.5% | batch:        15 of        40\t|\tloss: 3781.93\n",
      "Evaluating Epoch 88  40.0% | batch:        16 of        40\t|\tloss: 5020.12\n",
      "Evaluating Epoch 88  42.5% | batch:        17 of        40\t|\tloss: 2890.14\n",
      "Evaluating Epoch 88  45.0% | batch:        18 of        40\t|\tloss: 2338.63\n",
      "Evaluating Epoch 88  47.5% | batch:        19 of        40\t|\tloss: 6724.84\n",
      "Evaluating Epoch 88  50.0% | batch:        20 of        40\t|\tloss: 5531.84\n",
      "Evaluating Epoch 88  52.5% | batch:        21 of        40\t|\tloss: 990.494\n",
      "Evaluating Epoch 88  55.0% | batch:        22 of        40\t|\tloss: 4770.85\n",
      "Evaluating Epoch 88  57.5% | batch:        23 of        40\t|\tloss: 3376.06\n",
      "Evaluating Epoch 88  60.0% | batch:        24 of        40\t|\tloss: 1726.62\n",
      "Evaluating Epoch 88  62.5% | batch:        25 of        40\t|\tloss: 4413.06\n",
      "Evaluating Epoch 88  65.0% | batch:        26 of        40\t|\tloss: 10993.1\n",
      "Evaluating Epoch 88  67.5% | batch:        27 of        40\t|\tloss: 3026.26\n",
      "Evaluating Epoch 88  70.0% | batch:        28 of        40\t|\tloss: 2697.65\n",
      "Evaluating Epoch 88  72.5% | batch:        29 of        40\t|\tloss: 9953.78\n",
      "Evaluating Epoch 88  75.0% | batch:        30 of        40\t|\tloss: 1878.39\n",
      "Evaluating Epoch 88  77.5% | batch:        31 of        40\t|\tloss: 1653.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:50,710 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4516422748565674 seconds\n",
      "\n",
      "2023-05-04 17:01:50,710 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5284187482750934 seconds\n",
      "2023-05-04 17:01:50,711 | INFO : Avg batch val. time: 0.013210468706877334 seconds\n",
      "2023-05-04 17:01:50,712 | INFO : Avg sample val. time: 0.00010467883285956684 seconds\n",
      "2023-05-04 17:01:50,712 | INFO : Epoch 88 Validation Summary: epoch: 88.000000 | loss: 4634.496806 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 88  80.0% | batch:        32 of        40\t|\tloss: 8701.87\n",
      "Evaluating Epoch 88  82.5% | batch:        33 of        40\t|\tloss: 6393.06\n",
      "Evaluating Epoch 88  85.0% | batch:        34 of        40\t|\tloss: 1452.08\n",
      "Evaluating Epoch 88  87.5% | batch:        35 of        40\t|\tloss: 7534.1\n",
      "Evaluating Epoch 88  90.0% | batch:        36 of        40\t|\tloss: 6080.44\n",
      "Evaluating Epoch 88  92.5% | batch:        37 of        40\t|\tloss: 2792.99\n",
      "Evaluating Epoch 88  95.0% | batch:        38 of        40\t|\tloss: 3237.63\n",
      "Evaluating Epoch 88  97.5% | batch:        39 of        40\t|\tloss: 14008.7\n",
      "\n",
      "Training Epoch 89   0.0% | batch:         0 of        94\t|\tloss: 1001.08\n",
      "Training Epoch 89   1.1% | batch:         1 of        94\t|\tloss: 785.512\n",
      "Training Epoch 89   2.1% | batch:         2 of        94\t|\tloss: 984.055\n",
      "Training Epoch 89   3.2% | batch:         3 of        94\t|\tloss: 618.849\n",
      "Training Epoch 89   4.3% | batch:         4 of        94\t|\tloss: 955.255\n",
      "Training Epoch 89   5.3% | batch:         5 of        94\t|\tloss: 623.257\n",
      "Training Epoch 89   6.4% | batch:         6 of        94\t|\tloss: 1204.83\n",
      "Training Epoch 89   7.4% | batch:         7 of        94\t|\tloss: 797.155\n",
      "Training Epoch 89   8.5% | batch:         8 of        94\t|\tloss: 1204.14\n",
      "Training Epoch 89   9.6% | batch:         9 of        94\t|\tloss: 1025.51\n",
      "Training Epoch 89  10.6% | batch:        10 of        94\t|\tloss: 702.61\n",
      "Training Epoch 89  11.7% | batch:        11 of        94\t|\tloss: 661.356\n",
      "Training Epoch 89  12.8% | batch:        12 of        94\t|\tloss: 761.331\n",
      "Training Epoch 89  13.8% | batch:        13 of        94\t|\tloss: 789.379\n",
      "Training Epoch 89  14.9% | batch:        14 of        94\t|\tloss: 545.239\n",
      "Training Epoch 89  16.0% | batch:        15 of        94\t|\tloss: 2041.11\n",
      "Training Epoch 89  17.0% | batch:        16 of        94\t|\tloss: 977.494\n",
      "Training Epoch 89  18.1% | batch:        17 of        94\t|\tloss: 1026\n",
      "Training Epoch 89  19.1% | batch:        18 of        94\t|\tloss: 830.303\n",
      "Training Epoch 89  20.2% | batch:        19 of        94\t|\tloss: 979.985\n",
      "Training Epoch 89  21.3% | batch:        20 of        94\t|\tloss: 788.229\n",
      "Training Epoch 89  22.3% | batch:        21 of        94\t|\tloss: 686.205\n",
      "Training Epoch 89  23.4% | batch:        22 of        94\t|\tloss: 639.4\n",
      "Training Epoch 89  24.5% | batch:        23 of        94\t|\tloss: 677.906\n",
      "Training Epoch 89  25.5% | batch:        24 of        94\t|\tloss: 1359.76\n",
      "Training Epoch 89  26.6% | batch:        25 of        94\t|\tloss: 971.757\n",
      "Training Epoch 89  27.7% | batch:        26 of        94\t|\tloss: 1061.3\n",
      "Training Epoch 89  28.7% | batch:        27 of        94\t|\tloss: 1170.1\n",
      "Training Epoch 89  29.8% | batch:        28 of        94\t|\tloss: 809.514\n",
      "Training Epoch 89  30.9% | batch:        29 of        94\t|\tloss: 786.063\n",
      "Training Epoch 89  31.9% | batch:        30 of        94\t|\tloss: 831.92\n",
      "Training Epoch 89  33.0% | batch:        31 of        94\t|\tloss: 1431.44\n",
      "Training Epoch 89  34.0% | batch:        32 of        94\t|\tloss: 994.743\n",
      "Training Epoch 89  35.1% | batch:        33 of        94\t|\tloss: 824.251\n",
      "Training Epoch 89  36.2% | batch:        34 of        94\t|\tloss: 878.137\n",
      "Training Epoch 89  37.2% | batch:        35 of        94\t|\tloss: 771.394\n",
      "Training Epoch 89  38.3% | batch:        36 of        94\t|\tloss: 920.812\n",
      "Training Epoch 89  39.4% | batch:        37 of        94\t|\tloss: 629.165\n",
      "Training Epoch 89  40.4% | batch:        38 of        94\t|\tloss: 567.546\n",
      "Training Epoch 89  41.5% | batch:        39 of        94\t|\tloss: 1095.43\n",
      "Training Epoch 89  42.6% | batch:        40 of        94\t|\tloss: 700.768\n",
      "Training Epoch 89  43.6% | batch:        41 of        94\t|\tloss: 608.392\n",
      "Training Epoch 89  44.7% | batch:        42 of        94\t|\tloss: 1138.37\n",
      "Training Epoch 89  45.7% | batch:        43 of        94\t|\tloss: 779.648\n",
      "Training Epoch 89  46.8% | batch:        44 of        94\t|\tloss: 1448.12\n",
      "Training Epoch 89  47.9% | batch:        45 of        94\t|\tloss: 1237.95\n",
      "Training Epoch 89  48.9% | batch:        46 of        94\t|\tloss: 980.896\n",
      "Training Epoch 89  50.0% | batch:        47 of        94\t|\tloss: 900.928\n",
      "Training Epoch 89  51.1% | batch:        48 of        94\t|\tloss: 2495.3\n",
      "Training Epoch 89  52.1% | batch:        49 of        94\t|\tloss: 743.245\n",
      "Training Epoch 89  53.2% | batch:        50 of        94\t|\tloss: 1208.79\n",
      "Training Epoch 89  54.3% | batch:        51 of        94\t|\tloss: 853.18\n",
      "Training Epoch 89  55.3% | batch:        52 of        94\t|\tloss: 857.541\n",
      "Training Epoch 89  56.4% | batch:        53 of        94\t|\tloss: 932.445\n",
      "Training Epoch 89  57.4% | batch:        54 of        94\t|\tloss: 843.822\n",
      "Training Epoch 89  58.5% | batch:        55 of        94\t|\tloss: 1332.87\n",
      "Training Epoch 89  59.6% | batch:        56 of        94\t|\tloss: 1030.19\n",
      "Training Epoch 89  60.6% | batch:        57 of        94\t|\tloss: 597.513\n",
      "Training Epoch 89  61.7% | batch:        58 of        94\t|\tloss: 561.042\n",
      "Training Epoch 89  62.8% | batch:        59 of        94\t|\tloss: 602.174\n",
      "Training Epoch 89  63.8% | batch:        60 of        94\t|\tloss: 946.915\n",
      "Training Epoch 89  64.9% | batch:        61 of        94\t|\tloss: 1518.45\n",
      "Training Epoch 89  66.0% | batch:        62 of        94\t|\tloss: 1975.86\n",
      "Training Epoch 89  67.0% | batch:        63 of        94\t|\tloss: 1174.3\n",
      "Training Epoch 89  68.1% | batch:        64 of        94\t|\tloss: 999.429\n",
      "Training Epoch 89  69.1% | batch:        65 of        94\t|\tloss: 976.978\n",
      "Training Epoch 89  70.2% | batch:        66 of        94\t|\tloss: 1058.96\n",
      "Training Epoch 89  71.3% | batch:        67 of        94\t|\tloss: 748.177\n",
      "Training Epoch 89  72.3% | batch:        68 of        94\t|\tloss: 800.219\n",
      "Training Epoch 89  73.4% | batch:        69 of        94\t|\tloss: 1126.66\n",
      "Training Epoch 89  74.5% | batch:        70 of        94\t|\tloss: 984.158\n",
      "Training Epoch 89  75.5% | batch:        71 of        94\t|\tloss: 901.722\n",
      "Training Epoch 89  76.6% | batch:        72 of        94\t|\tloss: 686.688\n",
      "Training Epoch 89  77.7% | batch:        73 of        94\t|\tloss: 817.731\n",
      "Training Epoch 89  78.7% | batch:        74 of        94\t|\tloss: 718.386\n",
      "Training Epoch 89  79.8% | batch:        75 of        94\t|\tloss: 821.918\n",
      "Training Epoch 89  80.9% | batch:        76 of        94\t|\tloss: 697.541\n",
      "Training Epoch 89  81.9% | batch:        77 of        94\t|\tloss: 1729.35\n",
      "Training Epoch 89  83.0% | batch:        78 of        94\t|\tloss: 911.22\n",
      "Training Epoch 89  84.0% | batch:        79 of        94\t|\tloss: 1996.06\n",
      "Training Epoch 89  85.1% | batch:        80 of        94\t|\tloss: 1385.09\n",
      "Training Epoch 89  86.2% | batch:        81 of        94\t|\tloss: 1668.57\n",
      "Training Epoch 89  87.2% | batch:        82 of        94\t|\tloss: 1025.76\n",
      "Training Epoch 89  88.3% | batch:        83 of        94\t|\tloss: 1254.74\n",
      "Training Epoch 89  89.4% | batch:        84 of        94\t|\tloss: 756.723\n",
      "Training Epoch 89  90.4% | batch:        85 of        94\t|\tloss: 997.049\n",
      "Training Epoch 89  91.5% | batch:        86 of        94\t|\tloss: 652.058\n",
      "Training Epoch 89  92.6% | batch:        87 of        94\t|\tloss: 681.736\n",
      "Training Epoch 89  93.6% | batch:        88 of        94\t|\tloss: 702.025\n",
      "Training Epoch 89  94.7% | batch:        89 of        94\t|\tloss: 695.958\n",
      "Training Epoch 89  95.7% | batch:        90 of        94\t|\tloss: 513.768\n",
      "Training Epoch 89  96.8% | batch:        91 of        94\t|\tloss: 1170.88\n",
      "Training Epoch 89  97.9% | batch:        92 of        94\t|\tloss: 1159.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:52,544 | INFO : Epoch 89 Training Summary: epoch: 89.000000 | loss: 973.280110 | \n",
      "2023-05-04 17:01:52,545 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.809877872467041 seconds\n",
      "\n",
      "2023-05-04 17:01:52,545 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7827868488397491 seconds\n",
      "2023-05-04 17:01:52,546 | INFO : Avg batch train. time: 0.018965817540848397 seconds\n",
      "2023-05-04 17:01:52,546 | INFO : Avg sample train. time: 0.00014958775372040184 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 89  98.9% | batch:        93 of        94\t|\tloss: 954.612\n",
      "\n",
      "Training Epoch 90   0.0% | batch:         0 of        94\t|\tloss: 775.413\n",
      "Training Epoch 90   1.1% | batch:         1 of        94\t|\tloss: 2060.32\n",
      "Training Epoch 90   2.1% | batch:         2 of        94\t|\tloss: 1230.67\n",
      "Training Epoch 90   3.2% | batch:         3 of        94\t|\tloss: 764.244\n",
      "Training Epoch 90   4.3% | batch:         4 of        94\t|\tloss: 697.479\n",
      "Training Epoch 90   5.3% | batch:         5 of        94\t|\tloss: 838.164\n",
      "Training Epoch 90   6.4% | batch:         6 of        94\t|\tloss: 1212.05\n",
      "Training Epoch 90   7.4% | batch:         7 of        94\t|\tloss: 717.312\n",
      "Training Epoch 90   8.5% | batch:         8 of        94\t|\tloss: 705.552\n",
      "Training Epoch 90   9.6% | batch:         9 of        94\t|\tloss: 578.401\n",
      "Training Epoch 90  10.6% | batch:        10 of        94\t|\tloss: 612.37\n",
      "Training Epoch 90  11.7% | batch:        11 of        94\t|\tloss: 909.823\n",
      "Training Epoch 90  12.8% | batch:        12 of        94\t|\tloss: 1151.1\n",
      "Training Epoch 90  13.8% | batch:        13 of        94\t|\tloss: 1227.37\n",
      "Training Epoch 90  14.9% | batch:        14 of        94\t|\tloss: 831.069\n",
      "Training Epoch 90  16.0% | batch:        15 of        94\t|\tloss: 949.269\n",
      "Training Epoch 90  17.0% | batch:        16 of        94\t|\tloss: 605.055\n",
      "Training Epoch 90  18.1% | batch:        17 of        94\t|\tloss: 992.888\n",
      "Training Epoch 90  19.1% | batch:        18 of        94\t|\tloss: 630.436\n",
      "Training Epoch 90  20.2% | batch:        19 of        94\t|\tloss: 651.089\n",
      "Training Epoch 90  21.3% | batch:        20 of        94\t|\tloss: 981.407\n",
      "Training Epoch 90  22.3% | batch:        21 of        94\t|\tloss: 820.472\n",
      "Training Epoch 90  23.4% | batch:        22 of        94\t|\tloss: 825.96\n",
      "Training Epoch 90  24.5% | batch:        23 of        94\t|\tloss: 1034.84\n",
      "Training Epoch 90  25.5% | batch:        24 of        94\t|\tloss: 1169.26\n",
      "Training Epoch 90  26.6% | batch:        25 of        94\t|\tloss: 796.219\n",
      "Training Epoch 90  27.7% | batch:        26 of        94\t|\tloss: 669.95\n",
      "Training Epoch 90  28.7% | batch:        27 of        94\t|\tloss: 928.649\n",
      "Training Epoch 90  29.8% | batch:        28 of        94\t|\tloss: 1519.59\n",
      "Training Epoch 90  30.9% | batch:        29 of        94\t|\tloss: 1063.73\n",
      "Training Epoch 90  31.9% | batch:        30 of        94\t|\tloss: 890.889\n",
      "Training Epoch 90  33.0% | batch:        31 of        94\t|\tloss: 858.899\n",
      "Training Epoch 90  34.0% | batch:        32 of        94\t|\tloss: 649.421\n",
      "Training Epoch 90  35.1% | batch:        33 of        94\t|\tloss: 876.452\n",
      "Training Epoch 90  36.2% | batch:        34 of        94\t|\tloss: 907.972\n",
      "Training Epoch 90  37.2% | batch:        35 of        94\t|\tloss: 644.474\n",
      "Training Epoch 90  38.3% | batch:        36 of        94\t|\tloss: 858.156\n",
      "Training Epoch 90  39.4% | batch:        37 of        94\t|\tloss: 2603.61\n",
      "Training Epoch 90  40.4% | batch:        38 of        94\t|\tloss: 680.334\n",
      "Training Epoch 90  41.5% | batch:        39 of        94\t|\tloss: 765.783\n",
      "Training Epoch 90  42.6% | batch:        40 of        94\t|\tloss: 893.268\n",
      "Training Epoch 90  43.6% | batch:        41 of        94\t|\tloss: 715.263\n",
      "Training Epoch 90  44.7% | batch:        42 of        94\t|\tloss: 865.091\n",
      "Training Epoch 90  45.7% | batch:        43 of        94\t|\tloss: 933.126\n",
      "Training Epoch 90  46.8% | batch:        44 of        94\t|\tloss: 738.878\n",
      "Training Epoch 90  47.9% | batch:        45 of        94\t|\tloss: 759.71\n",
      "Training Epoch 90  48.9% | batch:        46 of        94\t|\tloss: 855.932\n",
      "Training Epoch 90  50.0% | batch:        47 of        94\t|\tloss: 865.69\n",
      "Training Epoch 90  51.1% | batch:        48 of        94\t|\tloss: 1490.85\n",
      "Training Epoch 90  52.1% | batch:        49 of        94\t|\tloss: 559.901\n",
      "Training Epoch 90  53.2% | batch:        50 of        94\t|\tloss: 820.93\n",
      "Training Epoch 90  54.3% | batch:        51 of        94\t|\tloss: 721.683\n",
      "Training Epoch 90  55.3% | batch:        52 of        94\t|\tloss: 1060.83\n",
      "Training Epoch 90  56.4% | batch:        53 of        94\t|\tloss: 1129.19\n",
      "Training Epoch 90  57.4% | batch:        54 of        94\t|\tloss: 1091.75\n",
      "Training Epoch 90  58.5% | batch:        55 of        94\t|\tloss: 902.462\n",
      "Training Epoch 90  59.6% | batch:        56 of        94\t|\tloss: 822.557\n",
      "Training Epoch 90  60.6% | batch:        57 of        94\t|\tloss: 1415.93\n",
      "Training Epoch 90  61.7% | batch:        58 of        94\t|\tloss: 2268.7\n",
      "Training Epoch 90  62.8% | batch:        59 of        94\t|\tloss: 1291.58\n",
      "Training Epoch 90  63.8% | batch:        60 of        94\t|\tloss: 1296.35\n",
      "Training Epoch 90  64.9% | batch:        61 of        94\t|\tloss: 2367.15\n",
      "Training Epoch 90  66.0% | batch:        62 of        94\t|\tloss: 932.566\n",
      "Training Epoch 90  67.0% | batch:        63 of        94\t|\tloss: 1141.13\n",
      "Training Epoch 90  68.1% | batch:        64 of        94\t|\tloss: 611.121\n",
      "Training Epoch 90  69.1% | batch:        65 of        94\t|\tloss: 1106.62\n",
      "Training Epoch 90  70.2% | batch:        66 of        94\t|\tloss: 1558.33\n",
      "Training Epoch 90  71.3% | batch:        67 of        94\t|\tloss: 656.237\n",
      "Training Epoch 90  72.3% | batch:        68 of        94\t|\tloss: 1110.22\n",
      "Training Epoch 90  73.4% | batch:        69 of        94\t|\tloss: 777.216\n",
      "Training Epoch 90  74.5% | batch:        70 of        94\t|\tloss: 1504.01\n",
      "Training Epoch 90  75.5% | batch:        71 of        94\t|\tloss: 843.267\n",
      "Training Epoch 90  76.6% | batch:        72 of        94\t|\tloss: 613.105\n",
      "Training Epoch 90  77.7% | batch:        73 of        94\t|\tloss: 698.718\n",
      "Training Epoch 90  78.7% | batch:        74 of        94\t|\tloss: 911.522\n",
      "Training Epoch 90  79.8% | batch:        75 of        94\t|\tloss: 913.091\n",
      "Training Epoch 90  80.9% | batch:        76 of        94\t|\tloss: 813.535\n",
      "Training Epoch 90  81.9% | batch:        77 of        94\t|\tloss: 927.702\n",
      "Training Epoch 90  83.0% | batch:        78 of        94\t|\tloss: 586.383\n",
      "Training Epoch 90  84.0% | batch:        79 of        94\t|\tloss: 726.023\n",
      "Training Epoch 90  85.1% | batch:        80 of        94\t|\tloss: 1486.04\n",
      "Training Epoch 90  86.2% | batch:        81 of        94\t|\tloss: 564.836\n",
      "Training Epoch 90  87.2% | batch:        82 of        94\t|\tloss: 748.318\n",
      "Training Epoch 90  88.3% | batch:        83 of        94\t|\tloss: 782.526\n",
      "Training Epoch 90  89.4% | batch:        84 of        94\t|\tloss: 818.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:54,369 | INFO : Epoch 90 Training Summary: epoch: 90.000000 | loss: 962.722012 | \n",
      "2023-05-04 17:01:54,371 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8025188446044922 seconds\n",
      "\n",
      "2023-05-04 17:01:54,372 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7830060932371352 seconds\n",
      "2023-05-04 17:01:54,373 | INFO : Avg batch train. time: 0.01896814992805463 seconds\n",
      "2023-05-04 17:01:54,373 | INFO : Avg sample train. time: 0.00014960614979334916 seconds\n",
      "2023-05-04 17:01:54,373 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 90  90.4% | batch:        85 of        94\t|\tloss: 991.514\n",
      "Training Epoch 90  91.5% | batch:        86 of        94\t|\tloss: 718.987\n",
      "Training Epoch 90  92.6% | batch:        87 of        94\t|\tloss: 1141.21\n",
      "Training Epoch 90  93.6% | batch:        88 of        94\t|\tloss: 905.636\n",
      "Training Epoch 90  94.7% | batch:        89 of        94\t|\tloss: 749.14\n",
      "Training Epoch 90  95.7% | batch:        90 of        94\t|\tloss: 883.607\n",
      "Training Epoch 90  96.8% | batch:        91 of        94\t|\tloss: 751.803\n",
      "Training Epoch 90  97.9% | batch:        92 of        94\t|\tloss: 998.209\n",
      "Training Epoch 90  98.9% | batch:        93 of        94\t|\tloss: 1042.35\n",
      "\n",
      "Evaluating Epoch 90   0.0% | batch:         0 of        40\t|\tloss: 7458.28\n",
      "Evaluating Epoch 90   2.5% | batch:         1 of        40\t|\tloss: 1021.94\n",
      "Evaluating Epoch 90   5.0% | batch:         2 of        40\t|\tloss: 3694.71\n",
      "Evaluating Epoch 90   7.5% | batch:         3 of        40\t|\tloss: 7568.81\n",
      "Evaluating Epoch 90  10.0% | batch:         4 of        40\t|\tloss: 3016.86\n",
      "Evaluating Epoch 90  12.5% | batch:         5 of        40\t|\tloss: 3259.37\n",
      "Evaluating Epoch 90  15.0% | batch:         6 of        40\t|\tloss: 8878.84\n",
      "Evaluating Epoch 90  17.5% | batch:         7 of        40\t|\tloss: 3459.32\n",
      "Evaluating Epoch 90  20.0% | batch:         8 of        40\t|\tloss: 2864.52\n",
      "Evaluating Epoch 90  22.5% | batch:         9 of        40\t|\tloss: 2230.25\n",
      "Evaluating Epoch 90  25.0% | batch:        10 of        40\t|\tloss: 5200.93\n",
      "Evaluating Epoch 90  27.5% | batch:        11 of        40\t|\tloss: 1230.35\n",
      "Evaluating Epoch 90  30.0% | batch:        12 of        40\t|\tloss: 6441.21\n",
      "Evaluating Epoch 90  32.5% | batch:        13 of        40\t|\tloss: 3485.64\n",
      "Evaluating Epoch 90  35.0% | batch:        14 of        40\t|\tloss: 1720.94\n",
      "Evaluating Epoch 90  37.5% | batch:        15 of        40\t|\tloss: 3475.89\n",
      "Evaluating Epoch 90  40.0% | batch:        16 of        40\t|\tloss: 5092.22\n",
      "Evaluating Epoch 90  42.5% | batch:        17 of        40\t|\tloss: 3118.23\n",
      "Evaluating Epoch 90  45.0% | batch:        18 of        40\t|\tloss: 2291\n",
      "Evaluating Epoch 90  47.5% | batch:        19 of        40\t|\tloss: 4481.05\n",
      "Evaluating Epoch 90  50.0% | batch:        20 of        40\t|\tloss: 5586.93\n",
      "Evaluating Epoch 90  52.5% | batch:        21 of        40\t|\tloss: 1197.22\n",
      "Evaluating Epoch 90  55.0% | batch:        22 of        40\t|\tloss: 3627.73\n",
      "Evaluating Epoch 90  57.5% | batch:        23 of        40\t|\tloss: 3473.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:54,823 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4489457607269287 seconds\n",
      "\n",
      "2023-05-04 17:01:54,824 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5280366666041888 seconds\n",
      "2023-05-04 17:01:54,825 | INFO : Avg batch val. time: 0.01320091666510472 seconds\n",
      "2023-05-04 17:01:54,825 | INFO : Avg sample val. time: 0.00010460314314663012 seconds\n",
      "2023-05-04 17:01:54,826 | INFO : Epoch 90 Validation Summary: epoch: 90.000000 | loss: 4281.360426 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 90  60.0% | batch:        24 of        40\t|\tloss: 1447.07\n",
      "Evaluating Epoch 90  62.5% | batch:        25 of        40\t|\tloss: 3924.84\n",
      "Evaluating Epoch 90  65.0% | batch:        26 of        40\t|\tloss: 10554.9\n",
      "Evaluating Epoch 90  67.5% | batch:        27 of        40\t|\tloss: 3005.54\n",
      "Evaluating Epoch 90  70.0% | batch:        28 of        40\t|\tloss: 2215.44\n",
      "Evaluating Epoch 90  72.5% | batch:        29 of        40\t|\tloss: 9302.01\n",
      "Evaluating Epoch 90  75.0% | batch:        30 of        40\t|\tloss: 1632.05\n",
      "Evaluating Epoch 90  77.5% | batch:        31 of        40\t|\tloss: 1678.79\n",
      "Evaluating Epoch 90  80.0% | batch:        32 of        40\t|\tloss: 9150.18\n",
      "Evaluating Epoch 90  82.5% | batch:        33 of        40\t|\tloss: 6321.51\n",
      "Evaluating Epoch 90  85.0% | batch:        34 of        40\t|\tloss: 922.047\n",
      "Evaluating Epoch 90  87.5% | batch:        35 of        40\t|\tloss: 5985.8\n",
      "Evaluating Epoch 90  90.0% | batch:        36 of        40\t|\tloss: 7167.79\n",
      "Evaluating Epoch 90  92.5% | batch:        37 of        40\t|\tloss: 2412.25\n",
      "Evaluating Epoch 90  95.0% | batch:        38 of        40\t|\tloss: 3907.34\n",
      "Evaluating Epoch 90  97.5% | batch:        39 of        40\t|\tloss: 12212.5\n",
      "\n",
      "Training Epoch 91   0.0% | batch:         0 of        94\t|\tloss: 539.357\n",
      "Training Epoch 91   1.1% | batch:         1 of        94\t|\tloss: 673.514\n",
      "Training Epoch 91   2.1% | batch:         2 of        94\t|\tloss: 639.465\n",
      "Training Epoch 91   3.2% | batch:         3 of        94\t|\tloss: 572.261\n",
      "Training Epoch 91   4.3% | batch:         4 of        94\t|\tloss: 736.34\n",
      "Training Epoch 91   5.3% | batch:         5 of        94\t|\tloss: 716.187\n",
      "Training Epoch 91   6.4% | batch:         6 of        94\t|\tloss: 864.322\n",
      "Training Epoch 91   7.4% | batch:         7 of        94\t|\tloss: 1026.42\n",
      "Training Epoch 91   8.5% | batch:         8 of        94\t|\tloss: 1874.94\n",
      "Training Epoch 91   9.6% | batch:         9 of        94\t|\tloss: 834.566\n",
      "Training Epoch 91  10.6% | batch:        10 of        94\t|\tloss: 647.292\n",
      "Training Epoch 91  11.7% | batch:        11 of        94\t|\tloss: 1124.08\n",
      "Training Epoch 91  12.8% | batch:        12 of        94\t|\tloss: 859.464\n",
      "Training Epoch 91  13.8% | batch:        13 of        94\t|\tloss: 784.09\n",
      "Training Epoch 91  14.9% | batch:        14 of        94\t|\tloss: 658.714\n",
      "Training Epoch 91  16.0% | batch:        15 of        94\t|\tloss: 1736.07\n",
      "Training Epoch 91  17.0% | batch:        16 of        94\t|\tloss: 778.491\n",
      "Training Epoch 91  18.1% | batch:        17 of        94\t|\tloss: 900.78\n",
      "Training Epoch 91  19.1% | batch:        18 of        94\t|\tloss: 702.51\n",
      "Training Epoch 91  20.2% | batch:        19 of        94\t|\tloss: 804.591\n",
      "Training Epoch 91  21.3% | batch:        20 of        94\t|\tloss: 536.931\n",
      "Training Epoch 91  22.3% | batch:        21 of        94\t|\tloss: 917.723\n",
      "Training Epoch 91  23.4% | batch:        22 of        94\t|\tloss: 1486.25\n",
      "Training Epoch 91  24.5% | batch:        23 of        94\t|\tloss: 919.927\n",
      "Training Epoch 91  25.5% | batch:        24 of        94\t|\tloss: 1056.71\n",
      "Training Epoch 91  26.6% | batch:        25 of        94\t|\tloss: 957.61\n",
      "Training Epoch 91  27.7% | batch:        26 of        94\t|\tloss: 643.214\n",
      "Training Epoch 91  28.7% | batch:        27 of        94\t|\tloss: 734.218\n",
      "Training Epoch 91  29.8% | batch:        28 of        94\t|\tloss: 994.102\n",
      "Training Epoch 91  30.9% | batch:        29 of        94\t|\tloss: 2507\n",
      "Training Epoch 91  31.9% | batch:        30 of        94\t|\tloss: 764.793\n",
      "Training Epoch 91  33.0% | batch:        31 of        94\t|\tloss: 947.2\n",
      "Training Epoch 91  34.0% | batch:        32 of        94\t|\tloss: 766.654\n",
      "Training Epoch 91  35.1% | batch:        33 of        94\t|\tloss: 801.057\n",
      "Training Epoch 91  36.2% | batch:        34 of        94\t|\tloss: 970.345\n",
      "Training Epoch 91  37.2% | batch:        35 of        94\t|\tloss: 822.936\n",
      "Training Epoch 91  38.3% | batch:        36 of        94\t|\tloss: 919.96\n",
      "Training Epoch 91  39.4% | batch:        37 of        94\t|\tloss: 535.161\n",
      "Training Epoch 91  40.4% | batch:        38 of        94\t|\tloss: 789.205\n",
      "Training Epoch 91  41.5% | batch:        39 of        94\t|\tloss: 709.569\n",
      "Training Epoch 91  42.6% | batch:        40 of        94\t|\tloss: 632.351\n",
      "Training Epoch 91  43.6% | batch:        41 of        94\t|\tloss: 797.021\n",
      "Training Epoch 91  44.7% | batch:        42 of        94\t|\tloss: 527.909\n",
      "Training Epoch 91  45.7% | batch:        43 of        94\t|\tloss: 1637.51\n",
      "Training Epoch 91  46.8% | batch:        44 of        94\t|\tloss: 899.937\n",
      "Training Epoch 91  47.9% | batch:        45 of        94\t|\tloss: 636.554\n",
      "Training Epoch 91  48.9% | batch:        46 of        94\t|\tloss: 490.685\n",
      "Training Epoch 91  50.0% | batch:        47 of        94\t|\tloss: 1412.68\n",
      "Training Epoch 91  51.1% | batch:        48 of        94\t|\tloss: 694.682\n",
      "Training Epoch 91  52.1% | batch:        49 of        94\t|\tloss: 841.393\n",
      "Training Epoch 91  53.2% | batch:        50 of        94\t|\tloss: 2344.55\n",
      "Training Epoch 91  54.3% | batch:        51 of        94\t|\tloss: 955.467\n",
      "Training Epoch 91  55.3% | batch:        52 of        94\t|\tloss: 931.059\n",
      "Training Epoch 91  56.4% | batch:        53 of        94\t|\tloss: 619.884\n",
      "Training Epoch 91  57.4% | batch:        54 of        94\t|\tloss: 847.486\n",
      "Training Epoch 91  58.5% | batch:        55 of        94\t|\tloss: 904.396\n",
      "Training Epoch 91  59.6% | batch:        56 of        94\t|\tloss: 1132.57\n",
      "Training Epoch 91  60.6% | batch:        57 of        94\t|\tloss: 1805.09\n",
      "Training Epoch 91  61.7% | batch:        58 of        94\t|\tloss: 802.357\n",
      "Training Epoch 91  62.8% | batch:        59 of        94\t|\tloss: 959.139\n",
      "Training Epoch 91  63.8% | batch:        60 of        94\t|\tloss: 1139.1\n",
      "Training Epoch 91  64.9% | batch:        61 of        94\t|\tloss: 799.551\n",
      "Training Epoch 91  66.0% | batch:        62 of        94\t|\tloss: 717.134\n",
      "Training Epoch 91  67.0% | batch:        63 of        94\t|\tloss: 720.24\n",
      "Training Epoch 91  68.1% | batch:        64 of        94\t|\tloss: 1362.67\n",
      "Training Epoch 91  69.1% | batch:        65 of        94\t|\tloss: 888.416\n",
      "Training Epoch 91  70.2% | batch:        66 of        94\t|\tloss: 1047.93\n",
      "Training Epoch 91  71.3% | batch:        67 of        94\t|\tloss: 868.799\n",
      "Training Epoch 91  72.3% | batch:        68 of        94\t|\tloss: 917.397\n",
      "Training Epoch 91  73.4% | batch:        69 of        94\t|\tloss: 825.129\n",
      "Training Epoch 91  74.5% | batch:        70 of        94\t|\tloss: 1008.95\n",
      "Training Epoch 91  75.5% | batch:        71 of        94\t|\tloss: 762.149\n",
      "Training Epoch 91  76.6% | batch:        72 of        94\t|\tloss: 813.778\n",
      "Training Epoch 91  77.7% | batch:        73 of        94\t|\tloss: 1222.12\n",
      "Training Epoch 91  78.7% | batch:        74 of        94\t|\tloss: 855.429\n",
      "Training Epoch 91  79.8% | batch:        75 of        94\t|\tloss: 779.898\n",
      "Training Epoch 91  80.9% | batch:        76 of        94\t|\tloss: 1012.04\n",
      "Training Epoch 91  81.9% | batch:        77 of        94\t|\tloss: 834.194\n",
      "Training Epoch 91  83.0% | batch:        78 of        94\t|\tloss: 979.912\n",
      "Training Epoch 91  84.0% | batch:        79 of        94\t|\tloss: 730.575\n",
      "Training Epoch 91  85.1% | batch:        80 of        94\t|\tloss: 962.308\n",
      "Training Epoch 91  86.2% | batch:        81 of        94\t|\tloss: 624.607\n",
      "Training Epoch 91  87.2% | batch:        82 of        94\t|\tloss: 765.235\n",
      "Training Epoch 91  88.3% | batch:        83 of        94\t|\tloss: 820.652\n",
      "Training Epoch 91  89.4% | batch:        84 of        94\t|\tloss: 739.876\n",
      "Training Epoch 91  90.4% | batch:        85 of        94\t|\tloss: 642.163\n",
      "Training Epoch 91  91.5% | batch:        86 of        94\t|\tloss: 963.794\n",
      "Training Epoch 91  92.6% | batch:        87 of        94\t|\tloss: 1554.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:56,636 | INFO : Epoch 91 Training Summary: epoch: 91.000000 | loss: 926.231427 | \n",
      "2023-05-04 17:01:56,637 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7892265319824219 seconds\n",
      "\n",
      "2023-05-04 17:01:56,638 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7830744497068636 seconds\n",
      "2023-05-04 17:01:56,638 | INFO : Avg batch train. time: 0.0189688771245411 seconds\n",
      "2023-05-04 17:01:56,639 | INFO : Avg sample train. time: 0.00014961188535885748 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 91  93.6% | batch:        88 of        94\t|\tloss: 1372.73\n",
      "Training Epoch 91  94.7% | batch:        89 of        94\t|\tloss: 806.502\n",
      "Training Epoch 91  95.7% | batch:        90 of        94\t|\tloss: 1032.06\n",
      "Training Epoch 91  96.8% | batch:        91 of        94\t|\tloss: 798.048\n",
      "Training Epoch 91  97.9% | batch:        92 of        94\t|\tloss: 632.263\n",
      "Training Epoch 91  98.9% | batch:        93 of        94\t|\tloss: 1042.3\n",
      "\n",
      "Training Epoch 92   0.0% | batch:         0 of        94\t|\tloss: 601.628\n",
      "Training Epoch 92   1.1% | batch:         1 of        94\t|\tloss: 820.479\n",
      "Training Epoch 92   2.1% | batch:         2 of        94\t|\tloss: 979.041\n",
      "Training Epoch 92   3.2% | batch:         3 of        94\t|\tloss: 820.719\n",
      "Training Epoch 92   4.3% | batch:         4 of        94\t|\tloss: 716.423\n",
      "Training Epoch 92   5.3% | batch:         5 of        94\t|\tloss: 521.586\n",
      "Training Epoch 92   6.4% | batch:         6 of        94\t|\tloss: 1189.36\n",
      "Training Epoch 92   7.4% | batch:         7 of        94\t|\tloss: 1236.41\n",
      "Training Epoch 92   8.5% | batch:         8 of        94\t|\tloss: 801.738\n",
      "Training Epoch 92   9.6% | batch:         9 of        94\t|\tloss: 1246.38\n",
      "Training Epoch 92  10.6% | batch:        10 of        94\t|\tloss: 990.968\n",
      "Training Epoch 92  11.7% | batch:        11 of        94\t|\tloss: 1031.48\n",
      "Training Epoch 92  12.8% | batch:        12 of        94\t|\tloss: 1016.97\n",
      "Training Epoch 92  13.8% | batch:        13 of        94\t|\tloss: 961.942\n",
      "Training Epoch 92  14.9% | batch:        14 of        94\t|\tloss: 867.731\n",
      "Training Epoch 92  16.0% | batch:        15 of        94\t|\tloss: 1007.03\n",
      "Training Epoch 92  17.0% | batch:        16 of        94\t|\tloss: 650.371\n",
      "Training Epoch 92  18.1% | batch:        17 of        94\t|\tloss: 920.266\n",
      "Training Epoch 92  19.1% | batch:        18 of        94\t|\tloss: 795.1\n",
      "Training Epoch 92  20.2% | batch:        19 of        94\t|\tloss: 935.088\n",
      "Training Epoch 92  21.3% | batch:        20 of        94\t|\tloss: 1165.15\n",
      "Training Epoch 92  22.3% | batch:        21 of        94\t|\tloss: 715.945\n",
      "Training Epoch 92  23.4% | batch:        22 of        94\t|\tloss: 1294.51\n",
      "Training Epoch 92  24.5% | batch:        23 of        94\t|\tloss: 701.412\n",
      "Training Epoch 92  25.5% | batch:        24 of        94\t|\tloss: 1153.89\n",
      "Training Epoch 92  26.6% | batch:        25 of        94\t|\tloss: 958.898\n",
      "Training Epoch 92  27.7% | batch:        26 of        94\t|\tloss: 807.009\n",
      "Training Epoch 92  28.7% | batch:        27 of        94\t|\tloss: 836.305\n",
      "Training Epoch 92  29.8% | batch:        28 of        94\t|\tloss: 1060.61\n",
      "Training Epoch 92  30.9% | batch:        29 of        94\t|\tloss: 683.985\n",
      "Training Epoch 92  31.9% | batch:        30 of        94\t|\tloss: 1130.02\n",
      "Training Epoch 92  33.0% | batch:        31 of        94\t|\tloss: 1209.19\n",
      "Training Epoch 92  34.0% | batch:        32 of        94\t|\tloss: 1175.53\n",
      "Training Epoch 92  35.1% | batch:        33 of        94\t|\tloss: 1124.92\n",
      "Training Epoch 92  36.2% | batch:        34 of        94\t|\tloss: 829.986\n",
      "Training Epoch 92  37.2% | batch:        35 of        94\t|\tloss: 795.494\n",
      "Training Epoch 92  38.3% | batch:        36 of        94\t|\tloss: 2069.68\n",
      "Training Epoch 92  39.4% | batch:        37 of        94\t|\tloss: 1035.41\n",
      "Training Epoch 92  40.4% | batch:        38 of        94\t|\tloss: 1183.85\n",
      "Training Epoch 92  41.5% | batch:        39 of        94\t|\tloss: 703.478\n",
      "Training Epoch 92  42.6% | batch:        40 of        94\t|\tloss: 861.24\n",
      "Training Epoch 92  43.6% | batch:        41 of        94\t|\tloss: 677.511\n",
      "Training Epoch 92  44.7% | batch:        42 of        94\t|\tloss: 1305.64\n",
      "Training Epoch 92  45.7% | batch:        43 of        94\t|\tloss: 842.53\n",
      "Training Epoch 92  46.8% | batch:        44 of        94\t|\tloss: 1117.45\n",
      "Training Epoch 92  47.9% | batch:        45 of        94\t|\tloss: 686.125\n",
      "Training Epoch 92  48.9% | batch:        46 of        94\t|\tloss: 683.77\n",
      "Training Epoch 92  50.0% | batch:        47 of        94\t|\tloss: 1019.26\n",
      "Training Epoch 92  51.1% | batch:        48 of        94\t|\tloss: 1057.18\n",
      "Training Epoch 92  52.1% | batch:        49 of        94\t|\tloss: 839.621\n",
      "Training Epoch 92  53.2% | batch:        50 of        94\t|\tloss: 1368.35\n",
      "Training Epoch 92  54.3% | batch:        51 of        94\t|\tloss: 1888.79\n",
      "Training Epoch 92  55.3% | batch:        52 of        94\t|\tloss: 679.719\n",
      "Training Epoch 92  56.4% | batch:        53 of        94\t|\tloss: 734.967\n",
      "Training Epoch 92  57.4% | batch:        54 of        94\t|\tloss: 826.876\n",
      "Training Epoch 92  58.5% | batch:        55 of        94\t|\tloss: 697.907\n",
      "Training Epoch 92  59.6% | batch:        56 of        94\t|\tloss: 1280.38\n",
      "Training Epoch 92  60.6% | batch:        57 of        94\t|\tloss: 663.553\n",
      "Training Epoch 92  61.7% | batch:        58 of        94\t|\tloss: 2469.57\n",
      "Training Epoch 92  62.8% | batch:        59 of        94\t|\tloss: 655.883\n",
      "Training Epoch 92  63.8% | batch:        60 of        94\t|\tloss: 829.154\n",
      "Training Epoch 92  64.9% | batch:        61 of        94\t|\tloss: 791.053\n",
      "Training Epoch 92  66.0% | batch:        62 of        94\t|\tloss: 1083.16\n",
      "Training Epoch 92  67.0% | batch:        63 of        94\t|\tloss: 707.583\n",
      "Training Epoch 92  68.1% | batch:        64 of        94\t|\tloss: 725.37\n",
      "Training Epoch 92  69.1% | batch:        65 of        94\t|\tloss: 790.598\n",
      "Training Epoch 92  70.2% | batch:        66 of        94\t|\tloss: 700.486\n",
      "Training Epoch 92  71.3% | batch:        67 of        94\t|\tloss: 666.011\n",
      "Training Epoch 92  72.3% | batch:        68 of        94\t|\tloss: 1300.37\n",
      "Training Epoch 92  73.4% | batch:        69 of        94\t|\tloss: 676.225\n",
      "Training Epoch 92  74.5% | batch:        70 of        94\t|\tloss: 1645.69\n",
      "Training Epoch 92  75.5% | batch:        71 of        94\t|\tloss: 653.455\n",
      "Training Epoch 92  76.6% | batch:        72 of        94\t|\tloss: 934.176\n",
      "Training Epoch 92  77.7% | batch:        73 of        94\t|\tloss: 808.046\n",
      "Training Epoch 92  78.7% | batch:        74 of        94\t|\tloss: 780.479\n",
      "Training Epoch 92  79.8% | batch:        75 of        94\t|\tloss: 595.109\n",
      "Training Epoch 92  80.9% | batch:        76 of        94\t|\tloss: 733.431\n",
      "Training Epoch 92  81.9% | batch:        77 of        94\t|\tloss: 872.975\n",
      "Training Epoch 92  83.0% | batch:        78 of        94\t|\tloss: 700.392\n",
      "Training Epoch 92  84.0% | batch:        79 of        94\t|\tloss: 893.924\n",
      "Training Epoch 92  85.1% | batch:        80 of        94\t|\tloss: 605.247\n",
      "Training Epoch 92  86.2% | batch:        81 of        94\t|\tloss: 1165.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:58,422 | INFO : Epoch 92 Training Summary: epoch: 92.000000 | loss: 937.280359 | \n",
      "2023-05-04 17:01:58,423 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7620389461517334 seconds\n",
      "\n",
      "2023-05-04 17:01:58,423 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7828458029290903 seconds\n",
      "2023-05-04 17:01:58,424 | INFO : Avg batch train. time: 0.018966444712011598 seconds\n",
      "2023-05-04 17:01:58,425 | INFO : Avg sample train. time: 0.00014959270036323967 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 92  87.2% | batch:        82 of        94\t|\tloss: 896.81\n",
      "Training Epoch 92  88.3% | batch:        83 of        94\t|\tloss: 977.423\n",
      "Training Epoch 92  89.4% | batch:        84 of        94\t|\tloss: 1193.32\n",
      "Training Epoch 92  90.4% | batch:        85 of        94\t|\tloss: 966.086\n",
      "Training Epoch 92  91.5% | batch:        86 of        94\t|\tloss: 907.867\n",
      "Training Epoch 92  92.6% | batch:        87 of        94\t|\tloss: 606.177\n",
      "Training Epoch 92  93.6% | batch:        88 of        94\t|\tloss: 839.486\n",
      "Training Epoch 92  94.7% | batch:        89 of        94\t|\tloss: 719.965\n",
      "Training Epoch 92  95.7% | batch:        90 of        94\t|\tloss: 806.698\n",
      "Training Epoch 92  96.8% | batch:        91 of        94\t|\tloss: 816.369\n",
      "Training Epoch 92  97.9% | batch:        92 of        94\t|\tloss: 663.997\n",
      "Training Epoch 92  98.9% | batch:        93 of        94\t|\tloss: 1045.94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:58,425 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 92   0.0% | batch:         0 of        40\t|\tloss: 6712.15\n",
      "Evaluating Epoch 92   2.5% | batch:         1 of        40\t|\tloss: 1095.82\n",
      "Evaluating Epoch 92   5.0% | batch:         2 of        40\t|\tloss: 3784.69\n",
      "Evaluating Epoch 92   7.5% | batch:         3 of        40\t|\tloss: 7111.21\n",
      "Evaluating Epoch 92  10.0% | batch:         4 of        40\t|\tloss: 2826.64\n",
      "Evaluating Epoch 92  12.5% | batch:         5 of        40\t|\tloss: 2765.14\n",
      "Evaluating Epoch 92  15.0% | batch:         6 of        40\t|\tloss: 8947.05\n",
      "Evaluating Epoch 92  17.5% | batch:         7 of        40\t|\tloss: 3596.68\n",
      "Evaluating Epoch 92  20.0% | batch:         8 of        40\t|\tloss: 3275.27\n",
      "Evaluating Epoch 92  22.5% | batch:         9 of        40\t|\tloss: 2625.38\n",
      "Evaluating Epoch 92  25.0% | batch:        10 of        40\t|\tloss: 5724.06\n",
      "Evaluating Epoch 92  27.5% | batch:        11 of        40\t|\tloss: 1461.51\n",
      "Evaluating Epoch 92  30.0% | batch:        12 of        40\t|\tloss: 7411.92\n",
      "Evaluating Epoch 92  32.5% | batch:        13 of        40\t|\tloss: 3848.62\n",
      "Evaluating Epoch 92  35.0% | batch:        14 of        40\t|\tloss: 2174.19\n",
      "Evaluating Epoch 92  37.5% | batch:        15 of        40\t|\tloss: 3666.72\n",
      "Evaluating Epoch 92  40.0% | batch:        16 of        40\t|\tloss: 4784.79\n",
      "Evaluating Epoch 92  42.5% | batch:        17 of        40\t|\tloss: 3026.11\n",
      "Evaluating Epoch 92  45.0% | batch:        18 of        40\t|\tloss: 2880.63\n",
      "Evaluating Epoch 92  47.5% | batch:        19 of        40\t|\tloss: 4966.06\n",
      "Evaluating Epoch 92  50.0% | batch:        20 of        40\t|\tloss: 5218.83\n",
      "Evaluating Epoch 92  52.5% | batch:        21 of        40\t|\tloss: 1258.6\n",
      "Evaluating Epoch 92  55.0% | batch:        22 of        40\t|\tloss: 4723.15\n",
      "Evaluating Epoch 92  57.5% | batch:        23 of        40\t|\tloss: 3255.52\n",
      "Evaluating Epoch 92  60.0% | batch:        24 of        40\t|\tloss: 1620.58\n",
      "Evaluating Epoch 92  62.5% | batch:        25 of        40\t|\tloss: 4057.23\n",
      "Evaluating Epoch 92  65.0% | batch:        26 of        40\t|\tloss: 10317.2\n",
      "Evaluating Epoch 92  67.5% | batch:        27 of        40\t|\tloss: 2681.18\n",
      "Evaluating Epoch 92  70.0% | batch:        28 of        40\t|\tloss: 2372.53\n",
      "Evaluating Epoch 92  72.5% | batch:        29 of        40\t|\tloss: 8678.7\n",
      "Evaluating Epoch 92  75.0% | batch:        30 of        40\t|\tloss: 1756.25\n",
      "Evaluating Epoch 92  77.5% | batch:        31 of        40\t|\tloss: 1716.84\n",
      "Evaluating Epoch 92  80.0% | batch:        32 of        40\t|\tloss: 9640.35\n",
      "Evaluating Epoch 92  82.5% | batch:        33 of        40\t|\tloss: 6340.92\n",
      "Evaluating Epoch 92  85.0% | batch:        34 of        40\t|\tloss: 1013.21\n",
      "Evaluating Epoch 92  87.5% | batch:        35 of        40\t|\tloss: 6432.24\n",
      "Evaluating Epoch 92  90.0% | batch:        36 of        40\t|\tloss: 5975.63\n",
      "Evaluating Epoch 92  92.5% | batch:        37 of        40\t|\tloss: 2616.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:01:58,871 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4447481632232666 seconds\n",
      "\n",
      "2023-05-04 17:01:58,871 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5276381570186341 seconds\n",
      "2023-05-04 17:01:58,872 | INFO : Avg batch val. time: 0.013190953925465853 seconds\n",
      "2023-05-04 17:01:58,872 | INFO : Avg sample val. time: 0.00010452419909243941 seconds\n",
      "2023-05-04 17:01:58,873 | INFO : Epoch 92 Validation Summary: epoch: 92.000000 | loss: 4359.958294 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 92  95.0% | batch:        38 of        40\t|\tloss: 3827.61\n",
      "Evaluating Epoch 92  97.5% | batch:        39 of        40\t|\tloss: 13162.1\n",
      "\n",
      "Training Epoch 93   0.0% | batch:         0 of        94\t|\tloss: 930.775\n",
      "Training Epoch 93   1.1% | batch:         1 of        94\t|\tloss: 737.329\n",
      "Training Epoch 93   2.1% | batch:         2 of        94\t|\tloss: 1030.28\n",
      "Training Epoch 93   3.2% | batch:         3 of        94\t|\tloss: 893.877\n",
      "Training Epoch 93   4.3% | batch:         4 of        94\t|\tloss: 1073.19\n",
      "Training Epoch 93   5.3% | batch:         5 of        94\t|\tloss: 878.972\n",
      "Training Epoch 93   6.4% | batch:         6 of        94\t|\tloss: 636.933\n",
      "Training Epoch 93   7.4% | batch:         7 of        94\t|\tloss: 631.947\n",
      "Training Epoch 93   8.5% | batch:         8 of        94\t|\tloss: 742.367\n",
      "Training Epoch 93   9.6% | batch:         9 of        94\t|\tloss: 583.237\n",
      "Training Epoch 93  10.6% | batch:        10 of        94\t|\tloss: 801.866\n",
      "Training Epoch 93  11.7% | batch:        11 of        94\t|\tloss: 1470.87\n",
      "Training Epoch 93  12.8% | batch:        12 of        94\t|\tloss: 894.399\n",
      "Training Epoch 93  13.8% | batch:        13 of        94\t|\tloss: 455.309\n",
      "Training Epoch 93  14.9% | batch:        14 of        94\t|\tloss: 560.156\n",
      "Training Epoch 93  16.0% | batch:        15 of        94\t|\tloss: 720.961\n",
      "Training Epoch 93  17.0% | batch:        16 of        94\t|\tloss: 585.242\n",
      "Training Epoch 93  18.1% | batch:        17 of        94\t|\tloss: 716.967\n",
      "Training Epoch 93  19.1% | batch:        18 of        94\t|\tloss: 617.481\n",
      "Training Epoch 93  20.2% | batch:        19 of        94\t|\tloss: 578.193\n",
      "Training Epoch 93  21.3% | batch:        20 of        94\t|\tloss: 584.802\n",
      "Training Epoch 93  22.3% | batch:        21 of        94\t|\tloss: 1248.92\n",
      "Training Epoch 93  23.4% | batch:        22 of        94\t|\tloss: 730.786\n",
      "Training Epoch 93  24.5% | batch:        23 of        94\t|\tloss: 1051.95\n",
      "Training Epoch 93  25.5% | batch:        24 of        94\t|\tloss: 700.69\n",
      "Training Epoch 93  26.6% | batch:        25 of        94\t|\tloss: 632.95\n",
      "Training Epoch 93  27.7% | batch:        26 of        94\t|\tloss: 605.094\n",
      "Training Epoch 93  28.7% | batch:        27 of        94\t|\tloss: 685.468\n",
      "Training Epoch 93  29.8% | batch:        28 of        94\t|\tloss: 874.19\n",
      "Training Epoch 93  30.9% | batch:        29 of        94\t|\tloss: 609.675\n",
      "Training Epoch 93  31.9% | batch:        30 of        94\t|\tloss: 902.035\n",
      "Training Epoch 93  33.0% | batch:        31 of        94\t|\tloss: 1006.97\n",
      "Training Epoch 93  34.0% | batch:        32 of        94\t|\tloss: 873.31\n",
      "Training Epoch 93  35.1% | batch:        33 of        94\t|\tloss: 1476.33\n",
      "Training Epoch 93  36.2% | batch:        34 of        94\t|\tloss: 766.927\n",
      "Training Epoch 93  37.2% | batch:        35 of        94\t|\tloss: 1007.46\n",
      "Training Epoch 93  38.3% | batch:        36 of        94\t|\tloss: 918.536\n",
      "Training Epoch 93  39.4% | batch:        37 of        94\t|\tloss: 962.43\n",
      "Training Epoch 93  40.4% | batch:        38 of        94\t|\tloss: 800.298\n",
      "Training Epoch 93  41.5% | batch:        39 of        94\t|\tloss: 765.46\n",
      "Training Epoch 93  42.6% | batch:        40 of        94\t|\tloss: 904.234\n",
      "Training Epoch 93  43.6% | batch:        41 of        94\t|\tloss: 675.757\n",
      "Training Epoch 93  44.7% | batch:        42 of        94\t|\tloss: 804.455\n",
      "Training Epoch 93  45.7% | batch:        43 of        94\t|\tloss: 1697.85\n",
      "Training Epoch 93  46.8% | batch:        44 of        94\t|\tloss: 629.679\n",
      "Training Epoch 93  47.9% | batch:        45 of        94\t|\tloss: 1926.69\n",
      "Training Epoch 93  48.9% | batch:        46 of        94\t|\tloss: 611.515\n",
      "Training Epoch 93  50.0% | batch:        47 of        94\t|\tloss: 1382.52\n",
      "Training Epoch 93  51.1% | batch:        48 of        94\t|\tloss: 1401.73\n",
      "Training Epoch 93  52.1% | batch:        49 of        94\t|\tloss: 923.684\n",
      "Training Epoch 93  53.2% | batch:        50 of        94\t|\tloss: 548.341\n",
      "Training Epoch 93  54.3% | batch:        51 of        94\t|\tloss: 599.164\n",
      "Training Epoch 93  55.3% | batch:        52 of        94\t|\tloss: 521.755\n",
      "Training Epoch 93  56.4% | batch:        53 of        94\t|\tloss: 768.634\n",
      "Training Epoch 93  57.4% | batch:        54 of        94\t|\tloss: 682.532\n",
      "Training Epoch 93  58.5% | batch:        55 of        94\t|\tloss: 759.525\n",
      "Training Epoch 93  59.6% | batch:        56 of        94\t|\tloss: 584.263\n",
      "Training Epoch 93  60.6% | batch:        57 of        94\t|\tloss: 975.717\n",
      "Training Epoch 93  61.7% | batch:        58 of        94\t|\tloss: 965.578\n",
      "Training Epoch 93  62.8% | batch:        59 of        94\t|\tloss: 853.97\n",
      "Training Epoch 93  63.8% | batch:        60 of        94\t|\tloss: 926.518\n",
      "Training Epoch 93  64.9% | batch:        61 of        94\t|\tloss: 739.257\n",
      "Training Epoch 93  66.0% | batch:        62 of        94\t|\tloss: 926.741\n",
      "Training Epoch 93  67.0% | batch:        63 of        94\t|\tloss: 1504.44\n",
      "Training Epoch 93  68.1% | batch:        64 of        94\t|\tloss: 948.661\n",
      "Training Epoch 93  69.1% | batch:        65 of        94\t|\tloss: 1552.12\n",
      "Training Epoch 93  70.2% | batch:        66 of        94\t|\tloss: 664.427\n",
      "Training Epoch 93  71.3% | batch:        67 of        94\t|\tloss: 714.86\n",
      "Training Epoch 93  72.3% | batch:        68 of        94\t|\tloss: 709.437\n",
      "Training Epoch 93  73.4% | batch:        69 of        94\t|\tloss: 805.54\n",
      "Training Epoch 93  74.5% | batch:        70 of        94\t|\tloss: 714.843\n",
      "Training Epoch 93  75.5% | batch:        71 of        94\t|\tloss: 754.878\n",
      "Training Epoch 93  76.6% | batch:        72 of        94\t|\tloss: 982.759\n",
      "Training Epoch 93  77.7% | batch:        73 of        94\t|\tloss: 1251.67\n",
      "Training Epoch 93  78.7% | batch:        74 of        94\t|\tloss: 1366.62\n",
      "Training Epoch 93  79.8% | batch:        75 of        94\t|\tloss: 714.202\n",
      "Training Epoch 93  80.9% | batch:        76 of        94\t|\tloss: 839.718\n",
      "Training Epoch 93  81.9% | batch:        77 of        94\t|\tloss: 948.503\n",
      "Training Epoch 93  83.0% | batch:        78 of        94\t|\tloss: 1108.6\n",
      "Training Epoch 93  84.0% | batch:        79 of        94\t|\tloss: 1211.29\n",
      "Training Epoch 93  85.1% | batch:        80 of        94\t|\tloss: 809.86\n",
      "Training Epoch 93  86.2% | batch:        81 of        94\t|\tloss: 1003.36\n",
      "Training Epoch 93  87.2% | batch:        82 of        94\t|\tloss: 944.741\n",
      "Training Epoch 93  88.3% | batch:        83 of        94\t|\tloss: 1282.18\n",
      "Training Epoch 93  89.4% | batch:        84 of        94\t|\tloss: 853.523\n",
      "Training Epoch 93  90.4% | batch:        85 of        94\t|\tloss: 1020.2\n",
      "Training Epoch 93  91.5% | batch:        86 of        94\t|\tloss: 1110.25\n",
      "Training Epoch 93  92.6% | batch:        87 of        94\t|\tloss: 985.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:00,660 | INFO : Epoch 93 Training Summary: epoch: 93.000000 | loss: 901.484191 | \n",
      "2023-05-04 17:02:00,660 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.76426362991333 seconds\n",
      "\n",
      "2023-05-04 17:02:00,661 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.782645994617093 seconds\n",
      "2023-05-04 17:02:00,662 | INFO : Avg batch train. time: 0.018964319091671202 seconds\n",
      "2023-05-04 17:02:00,663 | INFO : Avg sample train. time: 0.00014957593510799572 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 93  93.6% | batch:        88 of        94\t|\tloss: 891.302\n",
      "Training Epoch 93  94.7% | batch:        89 of        94\t|\tloss: 2458.44\n",
      "Training Epoch 93  95.7% | batch:        90 of        94\t|\tloss: 745.743\n",
      "Training Epoch 93  96.8% | batch:        91 of        94\t|\tloss: 566.26\n",
      "Training Epoch 93  97.9% | batch:        92 of        94\t|\tloss: 863.114\n",
      "Training Epoch 93  98.9% | batch:        93 of        94\t|\tloss: 502.302\n",
      "\n",
      "Training Epoch 94   0.0% | batch:         0 of        94\t|\tloss: 621.892\n",
      "Training Epoch 94   1.1% | batch:         1 of        94\t|\tloss: 1135.13\n",
      "Training Epoch 94   2.1% | batch:         2 of        94\t|\tloss: 721.545\n",
      "Training Epoch 94   3.2% | batch:         3 of        94\t|\tloss: 1031.62\n",
      "Training Epoch 94   4.3% | batch:         4 of        94\t|\tloss: 731.708\n",
      "Training Epoch 94   5.3% | batch:         5 of        94\t|\tloss: 673.449\n",
      "Training Epoch 94   6.4% | batch:         6 of        94\t|\tloss: 903.708\n",
      "Training Epoch 94   7.4% | batch:         7 of        94\t|\tloss: 657.327\n",
      "Training Epoch 94   8.5% | batch:         8 of        94\t|\tloss: 868.158\n",
      "Training Epoch 94   9.6% | batch:         9 of        94\t|\tloss: 1064.21\n",
      "Training Epoch 94  10.6% | batch:        10 of        94\t|\tloss: 728.746\n",
      "Training Epoch 94  11.7% | batch:        11 of        94\t|\tloss: 571.934\n",
      "Training Epoch 94  12.8% | batch:        12 of        94\t|\tloss: 648.412\n",
      "Training Epoch 94  13.8% | batch:        13 of        94\t|\tloss: 673.676\n",
      "Training Epoch 94  14.9% | batch:        14 of        94\t|\tloss: 539.479\n",
      "Training Epoch 94  16.0% | batch:        15 of        94\t|\tloss: 630.723\n",
      "Training Epoch 94  17.0% | batch:        16 of        94\t|\tloss: 1061.52\n",
      "Training Epoch 94  18.1% | batch:        17 of        94\t|\tloss: 696.028\n",
      "Training Epoch 94  19.1% | batch:        18 of        94\t|\tloss: 971.309\n",
      "Training Epoch 94  20.2% | batch:        19 of        94\t|\tloss: 821.249\n",
      "Training Epoch 94  21.3% | batch:        20 of        94\t|\tloss: 851.525\n",
      "Training Epoch 94  22.3% | batch:        21 of        94\t|\tloss: 1450.74\n",
      "Training Epoch 94  23.4% | batch:        22 of        94\t|\tloss: 633.634\n",
      "Training Epoch 94  24.5% | batch:        23 of        94\t|\tloss: 870.162\n",
      "Training Epoch 94  25.5% | batch:        24 of        94\t|\tloss: 1133\n",
      "Training Epoch 94  26.6% | batch:        25 of        94\t|\tloss: 1112.74\n",
      "Training Epoch 94  27.7% | batch:        26 of        94\t|\tloss: 1243.79\n",
      "Training Epoch 94  28.7% | batch:        27 of        94\t|\tloss: 624.363\n",
      "Training Epoch 94  29.8% | batch:        28 of        94\t|\tloss: 893.586\n",
      "Training Epoch 94  30.9% | batch:        29 of        94\t|\tloss: 768.376\n",
      "Training Epoch 94  31.9% | batch:        30 of        94\t|\tloss: 728.758\n",
      "Training Epoch 94  33.0% | batch:        31 of        94\t|\tloss: 582.47\n",
      "Training Epoch 94  34.0% | batch:        32 of        94\t|\tloss: 921.35\n",
      "Training Epoch 94  35.1% | batch:        33 of        94\t|\tloss: 776.19\n",
      "Training Epoch 94  36.2% | batch:        34 of        94\t|\tloss: 807.979\n",
      "Training Epoch 94  37.2% | batch:        35 of        94\t|\tloss: 1485.7\n",
      "Training Epoch 94  38.3% | batch:        36 of        94\t|\tloss: 1057.33\n",
      "Training Epoch 94  39.4% | batch:        37 of        94\t|\tloss: 708.502\n",
      "Training Epoch 94  40.4% | batch:        38 of        94\t|\tloss: 1056.17\n",
      "Training Epoch 94  41.5% | batch:        39 of        94\t|\tloss: 578.604\n",
      "Training Epoch 94  42.6% | batch:        40 of        94\t|\tloss: 659.778\n",
      "Training Epoch 94  43.6% | batch:        41 of        94\t|\tloss: 947.768\n",
      "Training Epoch 94  44.7% | batch:        42 of        94\t|\tloss: 1256.64\n",
      "Training Epoch 94  45.7% | batch:        43 of        94\t|\tloss: 676.033\n",
      "Training Epoch 94  46.8% | batch:        44 of        94\t|\tloss: 633.004\n",
      "Training Epoch 94  47.9% | batch:        45 of        94\t|\tloss: 882.776\n",
      "Training Epoch 94  48.9% | batch:        46 of        94\t|\tloss: 716.343\n",
      "Training Epoch 94  50.0% | batch:        47 of        94\t|\tloss: 1035.37\n",
      "Training Epoch 94  51.1% | batch:        48 of        94\t|\tloss: 776.861\n",
      "Training Epoch 94  52.1% | batch:        49 of        94\t|\tloss: 757.841\n",
      "Training Epoch 94  53.2% | batch:        50 of        94\t|\tloss: 665.366\n",
      "Training Epoch 94  54.3% | batch:        51 of        94\t|\tloss: 1444.69\n",
      "Training Epoch 94  55.3% | batch:        52 of        94\t|\tloss: 661.663\n",
      "Training Epoch 94  56.4% | batch:        53 of        94\t|\tloss: 682.602\n",
      "Training Epoch 94  57.4% | batch:        54 of        94\t|\tloss: 901.677\n",
      "Training Epoch 94  58.5% | batch:        55 of        94\t|\tloss: 703.38\n",
      "Training Epoch 94  59.6% | batch:        56 of        94\t|\tloss: 518.566\n",
      "Training Epoch 94  60.6% | batch:        57 of        94\t|\tloss: 906.671\n",
      "Training Epoch 94  61.7% | batch:        58 of        94\t|\tloss: 805.166\n",
      "Training Epoch 94  62.8% | batch:        59 of        94\t|\tloss: 912.124\n",
      "Training Epoch 94  63.8% | batch:        60 of        94\t|\tloss: 920.773\n",
      "Training Epoch 94  64.9% | batch:        61 of        94\t|\tloss: 803.779\n",
      "Training Epoch 94  66.0% | batch:        62 of        94\t|\tloss: 929.978\n",
      "Training Epoch 94  67.0% | batch:        63 of        94\t|\tloss: 829.113\n",
      "Training Epoch 94  68.1% | batch:        64 of        94\t|\tloss: 1021.79\n",
      "Training Epoch 94  69.1% | batch:        65 of        94\t|\tloss: 1007.24\n",
      "Training Epoch 94  70.2% | batch:        66 of        94\t|\tloss: 1032.9\n",
      "Training Epoch 94  71.3% | batch:        67 of        94\t|\tloss: 2563.02\n",
      "Training Epoch 94  72.3% | batch:        68 of        94\t|\tloss: 1208.63\n",
      "Training Epoch 94  73.4% | batch:        69 of        94\t|\tloss: 1307.71\n",
      "Training Epoch 94  74.5% | batch:        70 of        94\t|\tloss: 1909.48\n",
      "Training Epoch 94  75.5% | batch:        71 of        94\t|\tloss: 721.624\n",
      "Training Epoch 94  76.6% | batch:        72 of        94\t|\tloss: 686.511\n",
      "Training Epoch 94  77.7% | batch:        73 of        94\t|\tloss: 1080.73\n",
      "Training Epoch 94  78.7% | batch:        74 of        94\t|\tloss: 769.62\n",
      "Training Epoch 94  79.8% | batch:        75 of        94\t|\tloss: 639.872\n",
      "Training Epoch 94  80.9% | batch:        76 of        94\t|\tloss: 836.973\n",
      "Training Epoch 94  81.9% | batch:        77 of        94\t|\tloss: 992.185\n",
      "Training Epoch 94  83.0% | batch:        78 of        94\t|\tloss: 734.201\n",
      "Training Epoch 94  84.0% | batch:        79 of        94\t|\tloss: 693.359\n",
      "Training Epoch 94  85.1% | batch:        80 of        94\t|\tloss: 1172.34\n",
      "Training Epoch 94  86.2% | batch:        81 of        94\t|\tloss: 710.355\n",
      "Training Epoch 94  87.2% | batch:        82 of        94\t|\tloss: 746.412\n",
      "Training Epoch 94  88.3% | batch:        83 of        94\t|\tloss: 990.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:02,419 | INFO : Epoch 94 Training Summary: epoch: 94.000000 | loss: 893.270203 | \n",
      "2023-05-04 17:02:02,419 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7354769706726074 seconds\n",
      "\n",
      "2023-05-04 17:02:02,420 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.782144196490024 seconds\n",
      "2023-05-04 17:02:02,421 | INFO : Avg batch train. time: 0.018958980813723658 seconds\n",
      "2023-05-04 17:02:02,421 | INFO : Avg sample train. time: 0.00014953383088521765 seconds\n",
      "2023-05-04 17:02:02,422 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 94  89.4% | batch:        84 of        94\t|\tloss: 754.849\n",
      "Training Epoch 94  90.4% | batch:        85 of        94\t|\tloss: 817.464\n",
      "Training Epoch 94  91.5% | batch:        86 of        94\t|\tloss: 757.124\n",
      "Training Epoch 94  92.6% | batch:        87 of        94\t|\tloss: 816.863\n",
      "Training Epoch 94  93.6% | batch:        88 of        94\t|\tloss: 756.771\n",
      "Training Epoch 94  94.7% | batch:        89 of        94\t|\tloss: 958.868\n",
      "Training Epoch 94  95.7% | batch:        90 of        94\t|\tloss: 830.008\n",
      "Training Epoch 94  96.8% | batch:        91 of        94\t|\tloss: 1370.5\n",
      "Training Epoch 94  97.9% | batch:        92 of        94\t|\tloss: 962.418\n",
      "Training Epoch 94  98.9% | batch:        93 of        94\t|\tloss: 2349.59\n",
      "\n",
      "Evaluating Epoch 94   0.0% | batch:         0 of        40\t|\tloss: 6665.17\n",
      "Evaluating Epoch 94   2.5% | batch:         1 of        40\t|\tloss: 1316.77\n",
      "Evaluating Epoch 94   5.0% | batch:         2 of        40\t|\tloss: 3808.11\n",
      "Evaluating Epoch 94   7.5% | batch:         3 of        40\t|\tloss: 7318.88\n",
      "Evaluating Epoch 94  10.0% | batch:         4 of        40\t|\tloss: 2815.64\n",
      "Evaluating Epoch 94  12.5% | batch:         5 of        40\t|\tloss: 2474.04\n",
      "Evaluating Epoch 94  15.0% | batch:         6 of        40\t|\tloss: 8949.61\n",
      "Evaluating Epoch 94  17.5% | batch:         7 of        40\t|\tloss: 3420.32\n",
      "Evaluating Epoch 94  20.0% | batch:         8 of        40\t|\tloss: 3289.52\n",
      "Evaluating Epoch 94  22.5% | batch:         9 of        40\t|\tloss: 2353.89\n",
      "Evaluating Epoch 94  25.0% | batch:        10 of        40\t|\tloss: 4737.71\n",
      "Evaluating Epoch 94  27.5% | batch:        11 of        40\t|\tloss: 1859.76\n",
      "Evaluating Epoch 94  30.0% | batch:        12 of        40\t|\tloss: 6084.79\n",
      "Evaluating Epoch 94  32.5% | batch:        13 of        40\t|\tloss: 2947.01\n",
      "Evaluating Epoch 94  35.0% | batch:        14 of        40\t|\tloss: 2412.87\n",
      "Evaluating Epoch 94  37.5% | batch:        15 of        40\t|\tloss: 3406.14\n",
      "Evaluating Epoch 94  40.0% | batch:        16 of        40\t|\tloss: 4377.89\n",
      "Evaluating Epoch 94  42.5% | batch:        17 of        40\t|\tloss: 3204.62\n",
      "Evaluating Epoch 94  45.0% | batch:        18 of        40\t|\tloss: 3140.52\n",
      "Evaluating Epoch 94  47.5% | batch:        19 of        40\t|\tloss: 5091.58\n",
      "Evaluating Epoch 94  50.0% | batch:        20 of        40\t|\tloss: 5580.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:02,873 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45073437690734863 seconds\n",
      "\n",
      "2023-05-04 17:02:02,875 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5272719485419137 seconds\n",
      "2023-05-04 17:02:02,875 | INFO : Avg batch val. time: 0.013181798713547844 seconds\n",
      "2023-05-04 17:02:02,876 | INFO : Avg sample val. time: 0.0001044516538315994 seconds\n",
      "2023-05-04 17:02:02,877 | INFO : Epoch 94 Validation Summary: epoch: 94.000000 | loss: 4209.237114 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 94  52.5% | batch:        21 of        40\t|\tloss: 1483.82\n",
      "Evaluating Epoch 94  55.0% | batch:        22 of        40\t|\tloss: 5117.19\n",
      "Evaluating Epoch 94  57.5% | batch:        23 of        40\t|\tloss: 3062.56\n",
      "Evaluating Epoch 94  60.0% | batch:        24 of        40\t|\tloss: 1780.31\n",
      "Evaluating Epoch 94  62.5% | batch:        25 of        40\t|\tloss: 3744.73\n",
      "Evaluating Epoch 94  65.0% | batch:        26 of        40\t|\tloss: 9815.1\n",
      "Evaluating Epoch 94  67.5% | batch:        27 of        40\t|\tloss: 2899.53\n",
      "Evaluating Epoch 94  70.0% | batch:        28 of        40\t|\tloss: 2203.29\n",
      "Evaluating Epoch 94  72.5% | batch:        29 of        40\t|\tloss: 8659.84\n",
      "Evaluating Epoch 94  75.0% | batch:        30 of        40\t|\tloss: 1836.64\n",
      "Evaluating Epoch 94  77.5% | batch:        31 of        40\t|\tloss: 1778.32\n",
      "Evaluating Epoch 94  80.0% | batch:        32 of        40\t|\tloss: 8677.4\n",
      "Evaluating Epoch 94  82.5% | batch:        33 of        40\t|\tloss: 5969.55\n",
      "Evaluating Epoch 94  85.0% | batch:        34 of        40\t|\tloss: 1685.35\n",
      "Evaluating Epoch 94  87.5% | batch:        35 of        40\t|\tloss: 5346.62\n",
      "Evaluating Epoch 94  90.0% | batch:        36 of        40\t|\tloss: 5573.9\n",
      "Evaluating Epoch 94  92.5% | batch:        37 of        40\t|\tloss: 2705.19\n",
      "Evaluating Epoch 94  95.0% | batch:        38 of        40\t|\tloss: 3819.13\n",
      "Evaluating Epoch 94  97.5% | batch:        39 of        40\t|\tloss: 10485.8\n",
      "\n",
      "Training Epoch 95   0.0% | batch:         0 of        94\t|\tloss: 537\n",
      "Training Epoch 95   1.1% | batch:         1 of        94\t|\tloss: 741.518\n",
      "Training Epoch 95   2.1% | batch:         2 of        94\t|\tloss: 1073.28\n",
      "Training Epoch 95   3.2% | batch:         3 of        94\t|\tloss: 607.942\n",
      "Training Epoch 95   4.3% | batch:         4 of        94\t|\tloss: 1730.73\n",
      "Training Epoch 95   5.3% | batch:         5 of        94\t|\tloss: 674.491\n",
      "Training Epoch 95   6.4% | batch:         6 of        94\t|\tloss: 1013.94\n",
      "Training Epoch 95   7.4% | batch:         7 of        94\t|\tloss: 927.459\n",
      "Training Epoch 95   8.5% | batch:         8 of        94\t|\tloss: 560.695\n",
      "Training Epoch 95   9.6% | batch:         9 of        94\t|\tloss: 549.32\n",
      "Training Epoch 95  10.6% | batch:        10 of        94\t|\tloss: 942.713\n",
      "Training Epoch 95  11.7% | batch:        11 of        94\t|\tloss: 1162.13\n",
      "Training Epoch 95  12.8% | batch:        12 of        94\t|\tloss: 555.015\n",
      "Training Epoch 95  13.8% | batch:        13 of        94\t|\tloss: 628.947\n",
      "Training Epoch 95  14.9% | batch:        14 of        94\t|\tloss: 1116.16\n",
      "Training Epoch 95  16.0% | batch:        15 of        94\t|\tloss: 826.843\n",
      "Training Epoch 95  17.0% | batch:        16 of        94\t|\tloss: 1268.44\n",
      "Training Epoch 95  18.1% | batch:        17 of        94\t|\tloss: 665.228\n",
      "Training Epoch 95  19.1% | batch:        18 of        94\t|\tloss: 1721.65\n",
      "Training Epoch 95  20.2% | batch:        19 of        94\t|\tloss: 1122.74\n",
      "Training Epoch 95  21.3% | batch:        20 of        94\t|\tloss: 540.716\n",
      "Training Epoch 95  22.3% | batch:        21 of        94\t|\tloss: 574.495\n",
      "Training Epoch 95  23.4% | batch:        22 of        94\t|\tloss: 901.842\n",
      "Training Epoch 95  24.5% | batch:        23 of        94\t|\tloss: 1032.18\n",
      "Training Epoch 95  25.5% | batch:        24 of        94\t|\tloss: 951.8\n",
      "Training Epoch 95  26.6% | batch:        25 of        94\t|\tloss: 769.702\n",
      "Training Epoch 95  27.7% | batch:        26 of        94\t|\tloss: 1240.18\n",
      "Training Epoch 95  28.7% | batch:        27 of        94\t|\tloss: 873.836\n",
      "Training Epoch 95  29.8% | batch:        28 of        94\t|\tloss: 765.835\n",
      "Training Epoch 95  30.9% | batch:        29 of        94\t|\tloss: 512.555\n",
      "Training Epoch 95  31.9% | batch:        30 of        94\t|\tloss: 802.505\n",
      "Training Epoch 95  33.0% | batch:        31 of        94\t|\tloss: 1106.32\n",
      "Training Epoch 95  34.0% | batch:        32 of        94\t|\tloss: 909.131\n",
      "Training Epoch 95  35.1% | batch:        33 of        94\t|\tloss: 1301.36\n",
      "Training Epoch 95  36.2% | batch:        34 of        94\t|\tloss: 898.463\n",
      "Training Epoch 95  37.2% | batch:        35 of        94\t|\tloss: 869.712\n",
      "Training Epoch 95  38.3% | batch:        36 of        94\t|\tloss: 987.018\n",
      "Training Epoch 95  39.4% | batch:        37 of        94\t|\tloss: 829.008\n",
      "Training Epoch 95  40.4% | batch:        38 of        94\t|\tloss: 733.613\n",
      "Training Epoch 95  41.5% | batch:        39 of        94\t|\tloss: 935.898\n",
      "Training Epoch 95  42.6% | batch:        40 of        94\t|\tloss: 1070.54\n",
      "Training Epoch 95  43.6% | batch:        41 of        94\t|\tloss: 1096.55\n",
      "Training Epoch 95  44.7% | batch:        42 of        94\t|\tloss: 555.687\n",
      "Training Epoch 95  45.7% | batch:        43 of        94\t|\tloss: 706.995\n",
      "Training Epoch 95  46.8% | batch:        44 of        94\t|\tloss: 579.098\n",
      "Training Epoch 95  47.9% | batch:        45 of        94\t|\tloss: 2469.92\n",
      "Training Epoch 95  48.9% | batch:        46 of        94\t|\tloss: 684.96\n",
      "Training Epoch 95  50.0% | batch:        47 of        94\t|\tloss: 947.223\n",
      "Training Epoch 95  51.1% | batch:        48 of        94\t|\tloss: 764.417\n",
      "Training Epoch 95  52.1% | batch:        49 of        94\t|\tloss: 1494.04\n",
      "Training Epoch 95  53.2% | batch:        50 of        94\t|\tloss: 632.044\n",
      "Training Epoch 95  54.3% | batch:        51 of        94\t|\tloss: 641.953\n",
      "Training Epoch 95  55.3% | batch:        52 of        94\t|\tloss: 689.083\n",
      "Training Epoch 95  56.4% | batch:        53 of        94\t|\tloss: 624.37\n",
      "Training Epoch 95  57.4% | batch:        54 of        94\t|\tloss: 831.194\n",
      "Training Epoch 95  58.5% | batch:        55 of        94\t|\tloss: 539.179\n",
      "Training Epoch 95  59.6% | batch:        56 of        94\t|\tloss: 918.387\n",
      "Training Epoch 95  60.6% | batch:        57 of        94\t|\tloss: 1468.8\n",
      "Training Epoch 95  61.7% | batch:        58 of        94\t|\tloss: 709.762\n",
      "Training Epoch 95  62.8% | batch:        59 of        94\t|\tloss: 1007.69\n",
      "Training Epoch 95  63.8% | batch:        60 of        94\t|\tloss: 794.491\n",
      "Training Epoch 95  64.9% | batch:        61 of        94\t|\tloss: 1222.84\n",
      "Training Epoch 95  66.0% | batch:        62 of        94\t|\tloss: 759.281\n",
      "Training Epoch 95  67.0% | batch:        63 of        94\t|\tloss: 1136.83\n",
      "Training Epoch 95  68.1% | batch:        64 of        94\t|\tloss: 714.766\n",
      "Training Epoch 95  69.1% | batch:        65 of        94\t|\tloss: 655.527\n",
      "Training Epoch 95  70.2% | batch:        66 of        94\t|\tloss: 977.225\n",
      "Training Epoch 95  71.3% | batch:        67 of        94\t|\tloss: 920.497\n",
      "Training Epoch 95  72.3% | batch:        68 of        94\t|\tloss: 875.04\n",
      "Training Epoch 95  73.4% | batch:        69 of        94\t|\tloss: 1029.92\n",
      "Training Epoch 95  74.5% | batch:        70 of        94\t|\tloss: 766.765\n",
      "Training Epoch 95  75.5% | batch:        71 of        94\t|\tloss: 957.124\n",
      "Training Epoch 95  76.6% | batch:        72 of        94\t|\tloss: 849.815\n",
      "Training Epoch 95  77.7% | batch:        73 of        94\t|\tloss: 884.96\n",
      "Training Epoch 95  78.7% | batch:        74 of        94\t|\tloss: 781.376\n",
      "Training Epoch 95  79.8% | batch:        75 of        94\t|\tloss: 785.438\n",
      "Training Epoch 95  80.9% | batch:        76 of        94\t|\tloss: 891.929\n",
      "Training Epoch 95  81.9% | batch:        77 of        94\t|\tloss: 784.946\n",
      "Training Epoch 95  83.0% | batch:        78 of        94\t|\tloss: 823.685\n",
      "Training Epoch 95  84.0% | batch:        79 of        94\t|\tloss: 1117.15\n",
      "Training Epoch 95  85.1% | batch:        80 of        94\t|\tloss: 912.713\n",
      "Training Epoch 95  86.2% | batch:        81 of        94\t|\tloss: 703.235\n",
      "Training Epoch 95  87.2% | batch:        82 of        94\t|\tloss: 795.582\n",
      "Training Epoch 95  88.3% | batch:        83 of        94\t|\tloss: 661.276\n",
      "Training Epoch 95  89.4% | batch:        84 of        94\t|\tloss: 854.896\n",
      "Training Epoch 95  90.4% | batch:        85 of        94\t|\tloss: 790.022\n",
      "Training Epoch 95  91.5% | batch:        86 of        94\t|\tloss: 1291.14\n",
      "Training Epoch 95  92.6% | batch:        87 of        94\t|\tloss: 1214.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:04,697 | INFO : Epoch 95 Training Summary: epoch: 95.000000 | loss: 917.906555 | \n",
      "2023-05-04 17:02:04,698 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7986366748809814 seconds\n",
      "\n",
      "2023-05-04 17:02:04,699 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7823178015257184 seconds\n",
      "2023-05-04 17:02:04,700 | INFO : Avg batch train. time: 0.018960827675805515 seconds\n",
      "2023-05-04 17:02:04,700 | INFO : Avg sample train. time: 0.0001495483975101291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 95  93.6% | batch:        88 of        94\t|\tloss: 1230.31\n",
      "Training Epoch 95  94.7% | batch:        89 of        94\t|\tloss: 1503.68\n",
      "Training Epoch 95  95.7% | batch:        90 of        94\t|\tloss: 1438.53\n",
      "Training Epoch 95  96.8% | batch:        91 of        94\t|\tloss: 920.903\n",
      "Training Epoch 95  97.9% | batch:        92 of        94\t|\tloss: 882.25\n",
      "Training Epoch 95  98.9% | batch:        93 of        94\t|\tloss: 1306.86\n",
      "\n",
      "Training Epoch 96   0.0% | batch:         0 of        94\t|\tloss: 1041.16\n",
      "Training Epoch 96   1.1% | batch:         1 of        94\t|\tloss: 1170.25\n",
      "Training Epoch 96   2.1% | batch:         2 of        94\t|\tloss: 1078.91\n",
      "Training Epoch 96   3.2% | batch:         3 of        94\t|\tloss: 651.882\n",
      "Training Epoch 96   4.3% | batch:         4 of        94\t|\tloss: 778.272\n",
      "Training Epoch 96   5.3% | batch:         5 of        94\t|\tloss: 872.079\n",
      "Training Epoch 96   6.4% | batch:         6 of        94\t|\tloss: 827.681\n",
      "Training Epoch 96   7.4% | batch:         7 of        94\t|\tloss: 719.072\n",
      "Training Epoch 96   8.5% | batch:         8 of        94\t|\tloss: 636.612\n",
      "Training Epoch 96   9.6% | batch:         9 of        94\t|\tloss: 744.711\n",
      "Training Epoch 96  10.6% | batch:        10 of        94\t|\tloss: 1014.26\n",
      "Training Epoch 96  11.7% | batch:        11 of        94\t|\tloss: 567.313\n",
      "Training Epoch 96  12.8% | batch:        12 of        94\t|\tloss: 767.87\n",
      "Training Epoch 96  13.8% | batch:        13 of        94\t|\tloss: 839.608\n",
      "Training Epoch 96  14.9% | batch:        14 of        94\t|\tloss: 829.059\n",
      "Training Epoch 96  16.0% | batch:        15 of        94\t|\tloss: 778.77\n",
      "Training Epoch 96  17.0% | batch:        16 of        94\t|\tloss: 537.125\n",
      "Training Epoch 96  18.1% | batch:        17 of        94\t|\tloss: 532.612\n",
      "Training Epoch 96  19.1% | batch:        18 of        94\t|\tloss: 1500.54\n",
      "Training Epoch 96  20.2% | batch:        19 of        94\t|\tloss: 959.978\n",
      "Training Epoch 96  21.3% | batch:        20 of        94\t|\tloss: 776.175\n",
      "Training Epoch 96  22.3% | batch:        21 of        94\t|\tloss: 881.2\n",
      "Training Epoch 96  23.4% | batch:        22 of        94\t|\tloss: 806.278\n",
      "Training Epoch 96  24.5% | batch:        23 of        94\t|\tloss: 796.628\n",
      "Training Epoch 96  25.5% | batch:        24 of        94\t|\tloss: 1596.4\n",
      "Training Epoch 96  26.6% | batch:        25 of        94\t|\tloss: 751.476\n",
      "Training Epoch 96  27.7% | batch:        26 of        94\t|\tloss: 721.735\n",
      "Training Epoch 96  28.7% | batch:        27 of        94\t|\tloss: 682.416\n",
      "Training Epoch 96  29.8% | batch:        28 of        94\t|\tloss: 1089.97\n",
      "Training Epoch 96  30.9% | batch:        29 of        94\t|\tloss: 1001.7\n",
      "Training Epoch 96  31.9% | batch:        30 of        94\t|\tloss: 687.541\n",
      "Training Epoch 96  33.0% | batch:        31 of        94\t|\tloss: 996.688\n",
      "Training Epoch 96  34.0% | batch:        32 of        94\t|\tloss: 731.702\n",
      "Training Epoch 96  35.1% | batch:        33 of        94\t|\tloss: 917.041\n",
      "Training Epoch 96  36.2% | batch:        34 of        94\t|\tloss: 620.687\n",
      "Training Epoch 96  37.2% | batch:        35 of        94\t|\tloss: 754.984\n",
      "Training Epoch 96  38.3% | batch:        36 of        94\t|\tloss: 921.063\n",
      "Training Epoch 96  39.4% | batch:        37 of        94\t|\tloss: 872.513\n",
      "Training Epoch 96  40.4% | batch:        38 of        94\t|\tloss: 1291.34\n",
      "Training Epoch 96  41.5% | batch:        39 of        94\t|\tloss: 966.218\n",
      "Training Epoch 96  42.6% | batch:        40 of        94\t|\tloss: 850.705\n",
      "Training Epoch 96  43.6% | batch:        41 of        94\t|\tloss: 823.893\n",
      "Training Epoch 96  44.7% | batch:        42 of        94\t|\tloss: 1419.4\n",
      "Training Epoch 96  45.7% | batch:        43 of        94\t|\tloss: 2957.12\n",
      "Training Epoch 96  46.8% | batch:        44 of        94\t|\tloss: 870.145\n",
      "Training Epoch 96  47.9% | batch:        45 of        94\t|\tloss: 734.966\n",
      "Training Epoch 96  48.9% | batch:        46 of        94\t|\tloss: 548.959\n",
      "Training Epoch 96  50.0% | batch:        47 of        94\t|\tloss: 1029.89\n",
      "Training Epoch 96  51.1% | batch:        48 of        94\t|\tloss: 1060.75\n",
      "Training Epoch 96  52.1% | batch:        49 of        94\t|\tloss: 1160.12\n",
      "Training Epoch 96  53.2% | batch:        50 of        94\t|\tloss: 877.055\n",
      "Training Epoch 96  54.3% | batch:        51 of        94\t|\tloss: 975.113\n",
      "Training Epoch 96  55.3% | batch:        52 of        94\t|\tloss: 745.686\n",
      "Training Epoch 96  56.4% | batch:        53 of        94\t|\tloss: 1178.39\n",
      "Training Epoch 96  57.4% | batch:        54 of        94\t|\tloss: 988.401\n",
      "Training Epoch 96  58.5% | batch:        55 of        94\t|\tloss: 1951.66\n",
      "Training Epoch 96  59.6% | batch:        56 of        94\t|\tloss: 715.827\n",
      "Training Epoch 96  60.6% | batch:        57 of        94\t|\tloss: 1275.91\n",
      "Training Epoch 96  61.7% | batch:        58 of        94\t|\tloss: 588.882\n",
      "Training Epoch 96  62.8% | batch:        59 of        94\t|\tloss: 744.676\n",
      "Training Epoch 96  63.8% | batch:        60 of        94\t|\tloss: 558.41\n",
      "Training Epoch 96  64.9% | batch:        61 of        94\t|\tloss: 607.599\n",
      "Training Epoch 96  66.0% | batch:        62 of        94\t|\tloss: 849.252\n",
      "Training Epoch 96  67.0% | batch:        63 of        94\t|\tloss: 879.024\n",
      "Training Epoch 96  68.1% | batch:        64 of        94\t|\tloss: 543.093\n",
      "Training Epoch 96  69.1% | batch:        65 of        94\t|\tloss: 857.544\n",
      "Training Epoch 96  70.2% | batch:        66 of        94\t|\tloss: 799.297\n",
      "Training Epoch 96  71.3% | batch:        67 of        94\t|\tloss: 1764.29\n",
      "Training Epoch 96  72.3% | batch:        68 of        94\t|\tloss: 811.841\n",
      "Training Epoch 96  73.4% | batch:        69 of        94\t|\tloss: 1330.99\n",
      "Training Epoch 96  74.5% | batch:        70 of        94\t|\tloss: 984.624\n",
      "Training Epoch 96  75.5% | batch:        71 of        94\t|\tloss: 1096.87\n",
      "Training Epoch 96  76.6% | batch:        72 of        94\t|\tloss: 1097.32\n",
      "Training Epoch 96  77.7% | batch:        73 of        94\t|\tloss: 934.536\n",
      "Training Epoch 96  78.7% | batch:        74 of        94\t|\tloss: 911.087\n",
      "Training Epoch 96  79.8% | batch:        75 of        94\t|\tloss: 1010.42\n",
      "Training Epoch 96  80.9% | batch:        76 of        94\t|\tloss: 808.568\n",
      "Training Epoch 96  81.9% | batch:        77 of        94\t|\tloss: 635.864\n",
      "Training Epoch 96  83.0% | batch:        78 of        94\t|\tloss: 744.583\n",
      "Training Epoch 96  84.0% | batch:        79 of        94\t|\tloss: 922.286\n",
      "Training Epoch 96  85.1% | batch:        80 of        94\t|\tloss: 636.775\n",
      "Training Epoch 96  86.2% | batch:        81 of        94\t|\tloss: 649.065\n",
      "Training Epoch 96  87.2% | batch:        82 of        94\t|\tloss: 1368.12\n",
      "Training Epoch 96  88.3% | batch:        83 of        94\t|\tloss: 1510.46\n",
      "Training Epoch 96  89.4% | batch:        84 of        94\t|\tloss: 698.727\n",
      "Training Epoch 96  90.4% | batch:        85 of        94\t|\tloss: 929.142\n",
      "Training Epoch 96  91.5% | batch:        86 of        94\t|\tloss: 670.889\n",
      "Training Epoch 96  92.6% | batch:        87 of        94\t|\tloss: 981.584\n",
      "Training Epoch 96  93.6% | batch:        88 of        94\t|\tloss: 973.125\n",
      "Training Epoch 96  94.7% | batch:        89 of        94\t|\tloss: 804.274\n",
      "Training Epoch 96  95.7% | batch:        90 of        94\t|\tloss: 1028.7\n",
      "Training Epoch 96  96.8% | batch:        91 of        94\t|\tloss: 889.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:06,532 | INFO : Epoch 96 Training Summary: epoch: 96.000000 | loss: 926.990324 | \n",
      "2023-05-04 17:02:06,533 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8055431842803955 seconds\n",
      "\n",
      "2023-05-04 17:02:06,533 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7825597325960796 seconds\n",
      "2023-05-04 17:02:06,534 | INFO : Avg batch train. time: 0.018963401410596593 seconds\n",
      "2023-05-04 17:02:06,534 | INFO : Avg sample train. time: 0.0001495686971468434 seconds\n",
      "2023-05-04 17:02:06,535 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 96  97.9% | batch:        92 of        94\t|\tloss: 715.011\n",
      "Training Epoch 96  98.9% | batch:        93 of        94\t|\tloss: 909.976\n",
      "\n",
      "Evaluating Epoch 96   0.0% | batch:         0 of        40\t|\tloss: 7503.22\n",
      "Evaluating Epoch 96   2.5% | batch:         1 of        40\t|\tloss: 1166.01\n",
      "Evaluating Epoch 96   5.0% | batch:         2 of        40\t|\tloss: 3162.41\n",
      "Evaluating Epoch 96   7.5% | batch:         3 of        40\t|\tloss: 7218.9\n",
      "Evaluating Epoch 96  10.0% | batch:         4 of        40\t|\tloss: 2861.66\n",
      "Evaluating Epoch 96  12.5% | batch:         5 of        40\t|\tloss: 3428.06\n",
      "Evaluating Epoch 96  15.0% | batch:         6 of        40\t|\tloss: 8813.43\n",
      "Evaluating Epoch 96  17.5% | batch:         7 of        40\t|\tloss: 3209.42\n",
      "Evaluating Epoch 96  20.0% | batch:         8 of        40\t|\tloss: 3037.43\n",
      "Evaluating Epoch 96  22.5% | batch:         9 of        40\t|\tloss: 2125.97\n",
      "Evaluating Epoch 96  25.0% | batch:        10 of        40\t|\tloss: 4953.48\n",
      "Evaluating Epoch 96  27.5% | batch:        11 of        40\t|\tloss: 1516.3\n",
      "Evaluating Epoch 96  30.0% | batch:        12 of        40\t|\tloss: 6054.79\n",
      "Evaluating Epoch 96  32.5% | batch:        13 of        40\t|\tloss: 2990.59\n",
      "Evaluating Epoch 96  35.0% | batch:        14 of        40\t|\tloss: 2316.56\n",
      "Evaluating Epoch 96  37.5% | batch:        15 of        40\t|\tloss: 3212.88\n",
      "Evaluating Epoch 96  40.0% | batch:        16 of        40\t|\tloss: 4477.3\n",
      "Evaluating Epoch 96  42.5% | batch:        17 of        40\t|\tloss: 2812.92\n",
      "Evaluating Epoch 96  45.0% | batch:        18 of        40\t|\tloss: 2548.39\n",
      "Evaluating Epoch 96  47.5% | batch:        19 of        40\t|\tloss: 5632.37\n",
      "Evaluating Epoch 96  50.0% | batch:        20 of        40\t|\tloss: 5384.31\n",
      "Evaluating Epoch 96  52.5% | batch:        21 of        40\t|\tloss: 1141.23\n",
      "Evaluating Epoch 96  55.0% | batch:        22 of        40\t|\tloss: 4045.53\n",
      "Evaluating Epoch 96  57.5% | batch:        23 of        40\t|\tloss: 3499.02\n",
      "Evaluating Epoch 96  60.0% | batch:        24 of        40\t|\tloss: 1835.36\n",
      "Evaluating Epoch 96  62.5% | batch:        25 of        40\t|\tloss: 3726.53\n",
      "Evaluating Epoch 96  65.0% | batch:        26 of        40\t|\tloss: 9968.1\n",
      "Evaluating Epoch 96  67.5% | batch:        27 of        40\t|\tloss: 2968.21\n",
      "Evaluating Epoch 96  70.0% | batch:        28 of        40\t|\tloss: 2201.4\n",
      "Evaluating Epoch 96  72.5% | batch:        29 of        40\t|\tloss: 9163.88\n",
      "Evaluating Epoch 96  75.0% | batch:        30 of        40\t|\tloss: 1669.15\n",
      "Evaluating Epoch 96  77.5% | batch:        31 of        40\t|\tloss: 1895.08\n",
      "Evaluating Epoch 96  80.0% | batch:        32 of        40\t|\tloss: 8409.65\n",
      "Evaluating Epoch 96  82.5% | batch:        33 of        40\t|\tloss: 5324.65\n",
      "Evaluating Epoch 96  85.0% | batch:        34 of        40\t|\tloss: 1142.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:06,984 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4485161304473877 seconds\n",
      "\n",
      "2023-05-04 17:02:06,985 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5268986982191909 seconds\n",
      "2023-05-04 17:02:06,985 | INFO : Avg batch val. time: 0.013172467455479772 seconds\n",
      "2023-05-04 17:02:06,986 | INFO : Avg sample val. time: 0.0001043777135933421 seconds\n",
      "2023-05-04 17:02:06,987 | INFO : Epoch 96 Validation Summary: epoch: 96.000000 | loss: 4182.360390 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 96  87.5% | batch:        35 of        40\t|\tloss: 5869.94\n",
      "Evaluating Epoch 96  90.0% | batch:        36 of        40\t|\tloss: 6339.44\n",
      "Evaluating Epoch 96  92.5% | batch:        37 of        40\t|\tloss: 2751.41\n",
      "Evaluating Epoch 96  95.0% | batch:        38 of        40\t|\tloss: 3666.67\n",
      "Evaluating Epoch 96  97.5% | batch:        39 of        40\t|\tloss: 11194.7\n",
      "\n",
      "Training Epoch 97   0.0% | batch:         0 of        94\t|\tloss: 950.674\n",
      "Training Epoch 97   1.1% | batch:         1 of        94\t|\tloss: 553.611\n",
      "Training Epoch 97   2.1% | batch:         2 of        94\t|\tloss: 822.771\n",
      "Training Epoch 97   3.2% | batch:         3 of        94\t|\tloss: 1203.97\n",
      "Training Epoch 97   4.3% | batch:         4 of        94\t|\tloss: 1415.34\n",
      "Training Epoch 97   5.3% | batch:         5 of        94\t|\tloss: 851.691\n",
      "Training Epoch 97   6.4% | batch:         6 of        94\t|\tloss: 800.727\n",
      "Training Epoch 97   7.4% | batch:         7 of        94\t|\tloss: 891.538\n",
      "Training Epoch 97   8.5% | batch:         8 of        94\t|\tloss: 1318.74\n",
      "Training Epoch 97   9.6% | batch:         9 of        94\t|\tloss: 942.676\n",
      "Training Epoch 97  10.6% | batch:        10 of        94\t|\tloss: 836.724\n",
      "Training Epoch 97  11.7% | batch:        11 of        94\t|\tloss: 757.598\n",
      "Training Epoch 97  12.8% | batch:        12 of        94\t|\tloss: 1187.06\n",
      "Training Epoch 97  13.8% | batch:        13 of        94\t|\tloss: 926.514\n",
      "Training Epoch 97  14.9% | batch:        14 of        94\t|\tloss: 702.615\n",
      "Training Epoch 97  16.0% | batch:        15 of        94\t|\tloss: 774.515\n",
      "Training Epoch 97  17.0% | batch:        16 of        94\t|\tloss: 887.23\n",
      "Training Epoch 97  18.1% | batch:        17 of        94\t|\tloss: 507.869\n",
      "Training Epoch 97  19.1% | batch:        18 of        94\t|\tloss: 752.445\n",
      "Training Epoch 97  20.2% | batch:        19 of        94\t|\tloss: 1151.29\n",
      "Training Epoch 97  21.3% | batch:        20 of        94\t|\tloss: 1189.16\n",
      "Training Epoch 97  22.3% | batch:        21 of        94\t|\tloss: 1476.48\n",
      "Training Epoch 97  23.4% | batch:        22 of        94\t|\tloss: 741.059\n",
      "Training Epoch 97  24.5% | batch:        23 of        94\t|\tloss: 752.97\n",
      "Training Epoch 97  25.5% | batch:        24 of        94\t|\tloss: 863.298\n",
      "Training Epoch 97  26.6% | batch:        25 of        94\t|\tloss: 483.476\n",
      "Training Epoch 97  27.7% | batch:        26 of        94\t|\tloss: 612.217\n",
      "Training Epoch 97  28.7% | batch:        27 of        94\t|\tloss: 1518.83\n",
      "Training Epoch 97  29.8% | batch:        28 of        94\t|\tloss: 1928.2\n",
      "Training Epoch 97  30.9% | batch:        29 of        94\t|\tloss: 806.436\n",
      "Training Epoch 97  31.9% | batch:        30 of        94\t|\tloss: 1355.16\n",
      "Training Epoch 97  33.0% | batch:        31 of        94\t|\tloss: 685.072\n",
      "Training Epoch 97  34.0% | batch:        32 of        94\t|\tloss: 667.034\n",
      "Training Epoch 97  35.1% | batch:        33 of        94\t|\tloss: 716.531\n",
      "Training Epoch 97  36.2% | batch:        34 of        94\t|\tloss: 655.09\n",
      "Training Epoch 97  37.2% | batch:        35 of        94\t|\tloss: 937.694\n",
      "Training Epoch 97  38.3% | batch:        36 of        94\t|\tloss: 784.085\n",
      "Training Epoch 97  39.4% | batch:        37 of        94\t|\tloss: 959.875\n",
      "Training Epoch 97  40.4% | batch:        38 of        94\t|\tloss: 963.959\n",
      "Training Epoch 97  41.5% | batch:        39 of        94\t|\tloss: 705.744\n",
      "Training Epoch 97  42.6% | batch:        40 of        94\t|\tloss: 721.36\n",
      "Training Epoch 97  43.6% | batch:        41 of        94\t|\tloss: 841.335\n",
      "Training Epoch 97  44.7% | batch:        42 of        94\t|\tloss: 794.067\n",
      "Training Epoch 97  45.7% | batch:        43 of        94\t|\tloss: 842.31\n",
      "Training Epoch 97  46.8% | batch:        44 of        94\t|\tloss: 980.561\n",
      "Training Epoch 97  47.9% | batch:        45 of        94\t|\tloss: 595.056\n",
      "Training Epoch 97  48.9% | batch:        46 of        94\t|\tloss: 516.773\n",
      "Training Epoch 97  50.0% | batch:        47 of        94\t|\tloss: 1185.5\n",
      "Training Epoch 97  51.1% | batch:        48 of        94\t|\tloss: 989.689\n",
      "Training Epoch 97  52.1% | batch:        49 of        94\t|\tloss: 758.33\n",
      "Training Epoch 97  53.2% | batch:        50 of        94\t|\tloss: 532.861\n",
      "Training Epoch 97  54.3% | batch:        51 of        94\t|\tloss: 787.919\n",
      "Training Epoch 97  55.3% | batch:        52 of        94\t|\tloss: 1102.87\n",
      "Training Epoch 97  56.4% | batch:        53 of        94\t|\tloss: 690.699\n",
      "Training Epoch 97  57.4% | batch:        54 of        94\t|\tloss: 602.314\n",
      "Training Epoch 97  58.5% | batch:        55 of        94\t|\tloss: 728.534\n",
      "Training Epoch 97  59.6% | batch:        56 of        94\t|\tloss: 609.331\n",
      "Training Epoch 97  60.6% | batch:        57 of        94\t|\tloss: 762.008\n",
      "Training Epoch 97  61.7% | batch:        58 of        94\t|\tloss: 655.221\n",
      "Training Epoch 97  62.8% | batch:        59 of        94\t|\tloss: 783.252\n",
      "Training Epoch 97  63.8% | batch:        60 of        94\t|\tloss: 687.433\n",
      "Training Epoch 97  64.9% | batch:        61 of        94\t|\tloss: 722.597\n",
      "Training Epoch 97  66.0% | batch:        62 of        94\t|\tloss: 693.841\n",
      "Training Epoch 97  67.0% | batch:        63 of        94\t|\tloss: 574.08\n",
      "Training Epoch 97  68.1% | batch:        64 of        94\t|\tloss: 865.702\n",
      "Training Epoch 97  69.1% | batch:        65 of        94\t|\tloss: 842.096\n",
      "Training Epoch 97  70.2% | batch:        66 of        94\t|\tloss: 877.202\n",
      "Training Epoch 97  71.3% | batch:        67 of        94\t|\tloss: 1101.52\n",
      "Training Epoch 97  72.3% | batch:        68 of        94\t|\tloss: 944.824\n",
      "Training Epoch 97  73.4% | batch:        69 of        94\t|\tloss: 1004.9\n",
      "Training Epoch 97  74.5% | batch:        70 of        94\t|\tloss: 698.71\n",
      "Training Epoch 97  75.5% | batch:        71 of        94\t|\tloss: 1227.01\n",
      "Training Epoch 97  76.6% | batch:        72 of        94\t|\tloss: 789.481\n",
      "Training Epoch 97  77.7% | batch:        73 of        94\t|\tloss: 845.085\n",
      "Training Epoch 97  78.7% | batch:        74 of        94\t|\tloss: 821.197\n",
      "Training Epoch 97  79.8% | batch:        75 of        94\t|\tloss: 1771.81\n",
      "Training Epoch 97  80.9% | batch:        76 of        94\t|\tloss: 924.94\n",
      "Training Epoch 97  81.9% | batch:        77 of        94\t|\tloss: 751.172\n",
      "Training Epoch 97  83.0% | batch:        78 of        94\t|\tloss: 739.414\n",
      "Training Epoch 97  84.0% | batch:        79 of        94\t|\tloss: 785.558\n",
      "Training Epoch 97  85.1% | batch:        80 of        94\t|\tloss: 727.79\n",
      "Training Epoch 97  86.2% | batch:        81 of        94\t|\tloss: 463.288\n",
      "Training Epoch 97  87.2% | batch:        82 of        94\t|\tloss: 689.075\n",
      "Training Epoch 97  88.3% | batch:        83 of        94\t|\tloss: 1271.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:08,781 | INFO : Epoch 97 Training Summary: epoch: 97.000000 | loss: 894.966138 | \n",
      "2023-05-04 17:02:08,782 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7733428478240967 seconds\n",
      "\n",
      "2023-05-04 17:02:08,783 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7824647131654405 seconds\n",
      "2023-05-04 17:02:08,784 | INFO : Avg batch train. time: 0.018962390565589793 seconds\n",
      "2023-05-04 17:02:08,785 | INFO : Avg sample train. time: 0.00014956072438038602 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 97  89.4% | batch:        84 of        94\t|\tloss: 1185.46\n",
      "Training Epoch 97  90.4% | batch:        85 of        94\t|\tloss: 1063.5\n",
      "Training Epoch 97  91.5% | batch:        86 of        94\t|\tloss: 2662.88\n",
      "Training Epoch 97  92.6% | batch:        87 of        94\t|\tloss: 1056.65\n",
      "Training Epoch 97  93.6% | batch:        88 of        94\t|\tloss: 695.261\n",
      "Training Epoch 97  94.7% | batch:        89 of        94\t|\tloss: 884.677\n",
      "Training Epoch 97  95.7% | batch:        90 of        94\t|\tloss: 1008.4\n",
      "Training Epoch 97  96.8% | batch:        91 of        94\t|\tloss: 748.101\n",
      "Training Epoch 97  97.9% | batch:        92 of        94\t|\tloss: 542.546\n",
      "Training Epoch 97  98.9% | batch:        93 of        94\t|\tloss: 1313.38\n",
      "\n",
      "Training Epoch 98   0.0% | batch:         0 of        94\t|\tloss: 1004.41\n",
      "Training Epoch 98   1.1% | batch:         1 of        94\t|\tloss: 824.028\n",
      "Training Epoch 98   2.1% | batch:         2 of        94\t|\tloss: 755.779\n",
      "Training Epoch 98   3.2% | batch:         3 of        94\t|\tloss: 1082.47\n",
      "Training Epoch 98   4.3% | batch:         4 of        94\t|\tloss: 690.229\n",
      "Training Epoch 98   5.3% | batch:         5 of        94\t|\tloss: 768.643\n",
      "Training Epoch 98   6.4% | batch:         6 of        94\t|\tloss: 912.078\n",
      "Training Epoch 98   7.4% | batch:         7 of        94\t|\tloss: 605.097\n",
      "Training Epoch 98   8.5% | batch:         8 of        94\t|\tloss: 914.704\n",
      "Training Epoch 98   9.6% | batch:         9 of        94\t|\tloss: 668.23\n",
      "Training Epoch 98  10.6% | batch:        10 of        94\t|\tloss: 686.214\n",
      "Training Epoch 98  11.7% | batch:        11 of        94\t|\tloss: 767.151\n",
      "Training Epoch 98  12.8% | batch:        12 of        94\t|\tloss: 797.957\n",
      "Training Epoch 98  13.8% | batch:        13 of        94\t|\tloss: 763.095\n",
      "Training Epoch 98  14.9% | batch:        14 of        94\t|\tloss: 607.3\n",
      "Training Epoch 98  16.0% | batch:        15 of        94\t|\tloss: 994.745\n",
      "Training Epoch 98  17.0% | batch:        16 of        94\t|\tloss: 728.636\n",
      "Training Epoch 98  18.1% | batch:        17 of        94\t|\tloss: 500.237\n",
      "Training Epoch 98  19.1% | batch:        18 of        94\t|\tloss: 844.372\n",
      "Training Epoch 98  20.2% | batch:        19 of        94\t|\tloss: 810.755\n",
      "Training Epoch 98  21.3% | batch:        20 of        94\t|\tloss: 887.106\n",
      "Training Epoch 98  22.3% | batch:        21 of        94\t|\tloss: 724.65\n",
      "Training Epoch 98  23.4% | batch:        22 of        94\t|\tloss: 600.127\n",
      "Training Epoch 98  24.5% | batch:        23 of        94\t|\tloss: 801.942\n",
      "Training Epoch 98  25.5% | batch:        24 of        94\t|\tloss: 979.002\n",
      "Training Epoch 98  26.6% | batch:        25 of        94\t|\tloss: 1161.24\n",
      "Training Epoch 98  27.7% | batch:        26 of        94\t|\tloss: 721.157\n",
      "Training Epoch 98  28.7% | batch:        27 of        94\t|\tloss: 873.55\n",
      "Training Epoch 98  29.8% | batch:        28 of        94\t|\tloss: 1079.41\n",
      "Training Epoch 98  30.9% | batch:        29 of        94\t|\tloss: 1361.65\n",
      "Training Epoch 98  31.9% | batch:        30 of        94\t|\tloss: 666.294\n",
      "Training Epoch 98  33.0% | batch:        31 of        94\t|\tloss: 1024.54\n",
      "Training Epoch 98  34.0% | batch:        32 of        94\t|\tloss: 565.537\n",
      "Training Epoch 98  35.1% | batch:        33 of        94\t|\tloss: 844.598\n",
      "Training Epoch 98  36.2% | batch:        34 of        94\t|\tloss: 980.082\n",
      "Training Epoch 98  37.2% | batch:        35 of        94\t|\tloss: 911.488\n",
      "Training Epoch 98  38.3% | batch:        36 of        94\t|\tloss: 802.094\n",
      "Training Epoch 98  39.4% | batch:        37 of        94\t|\tloss: 703.103\n",
      "Training Epoch 98  40.4% | batch:        38 of        94\t|\tloss: 883.968\n",
      "Training Epoch 98  41.5% | batch:        39 of        94\t|\tloss: 939.118\n",
      "Training Epoch 98  42.6% | batch:        40 of        94\t|\tloss: 828.747\n",
      "Training Epoch 98  43.6% | batch:        41 of        94\t|\tloss: 1057.61\n",
      "Training Epoch 98  44.7% | batch:        42 of        94\t|\tloss: 884.005\n",
      "Training Epoch 98  45.7% | batch:        43 of        94\t|\tloss: 1464.9\n",
      "Training Epoch 98  46.8% | batch:        44 of        94\t|\tloss: 690.561\n",
      "Training Epoch 98  47.9% | batch:        45 of        94\t|\tloss: 680.685\n",
      "Training Epoch 98  48.9% | batch:        46 of        94\t|\tloss: 892.305\n",
      "Training Epoch 98  50.0% | batch:        47 of        94\t|\tloss: 1633.94\n",
      "Training Epoch 98  51.1% | batch:        48 of        94\t|\tloss: 693.121\n",
      "Training Epoch 98  52.1% | batch:        49 of        94\t|\tloss: 1031.22\n",
      "Training Epoch 98  53.2% | batch:        50 of        94\t|\tloss: 743.408\n",
      "Training Epoch 98  54.3% | batch:        51 of        94\t|\tloss: 967.787\n",
      "Training Epoch 98  55.3% | batch:        52 of        94\t|\tloss: 808.691\n",
      "Training Epoch 98  56.4% | batch:        53 of        94\t|\tloss: 1118.42\n",
      "Training Epoch 98  57.4% | batch:        54 of        94\t|\tloss: 1051.11\n",
      "Training Epoch 98  58.5% | batch:        55 of        94\t|\tloss: 771.431\n",
      "Training Epoch 98  59.6% | batch:        56 of        94\t|\tloss: 775.445\n",
      "Training Epoch 98  60.6% | batch:        57 of        94\t|\tloss: 669.318\n",
      "Training Epoch 98  61.7% | batch:        58 of        94\t|\tloss: 576.154\n",
      "Training Epoch 98  62.8% | batch:        59 of        94\t|\tloss: 897.249\n",
      "Training Epoch 98  63.8% | batch:        60 of        94\t|\tloss: 435.733\n",
      "Training Epoch 98  64.9% | batch:        61 of        94\t|\tloss: 839.617\n",
      "Training Epoch 98  66.0% | batch:        62 of        94\t|\tloss: 577.724\n",
      "Training Epoch 98  67.0% | batch:        63 of        94\t|\tloss: 892.094\n",
      "Training Epoch 98  68.1% | batch:        64 of        94\t|\tloss: 837.419\n",
      "Training Epoch 98  69.1% | batch:        65 of        94\t|\tloss: 863.568\n",
      "Training Epoch 98  70.2% | batch:        66 of        94\t|\tloss: 1832.71\n",
      "Training Epoch 98  71.3% | batch:        67 of        94\t|\tloss: 553.683\n",
      "Training Epoch 98  72.3% | batch:        68 of        94\t|\tloss: 1034.39\n",
      "Training Epoch 98  73.4% | batch:        69 of        94\t|\tloss: 979.206\n",
      "Training Epoch 98  74.5% | batch:        70 of        94\t|\tloss: 2156.12\n",
      "Training Epoch 98  75.5% | batch:        71 of        94\t|\tloss: 553.068\n",
      "Training Epoch 98  76.6% | batch:        72 of        94\t|\tloss: 1452.23\n",
      "Training Epoch 98  77.7% | batch:        73 of        94\t|\tloss: 822.955\n",
      "Training Epoch 98  78.7% | batch:        74 of        94\t|\tloss: 1015.75\n",
      "Training Epoch 98  79.8% | batch:        75 of        94\t|\tloss: 796.052\n",
      "Training Epoch 98  80.9% | batch:        76 of        94\t|\tloss: 1142.96\n",
      "Training Epoch 98  81.9% | batch:        77 of        94\t|\tloss: 865.083\n",
      "Training Epoch 98  83.0% | batch:        78 of        94\t|\tloss: 658.886\n",
      "Training Epoch 98  84.0% | batch:        79 of        94\t|\tloss: 771.18\n",
      "Training Epoch 98  85.1% | batch:        80 of        94\t|\tloss: 837.987\n",
      "Training Epoch 98  86.2% | batch:        81 of        94\t|\tloss: 1442.9\n",
      "Training Epoch 98  87.2% | batch:        82 of        94\t|\tloss: 750.724\n",
      "Training Epoch 98  88.3% | batch:        83 of        94\t|\tloss: 843.678\n",
      "Training Epoch 98  89.4% | batch:        84 of        94\t|\tloss: 1554.13\n",
      "Training Epoch 98  90.4% | batch:        85 of        94\t|\tloss: 1307.47\n",
      "Training Epoch 98  91.5% | batch:        86 of        94\t|\tloss: 736.641\n",
      "Training Epoch 98  92.6% | batch:        87 of        94\t|\tloss: 965.676\n",
      "Training Epoch 98  93.6% | batch:        88 of        94\t|\tloss: 932.894\n",
      "Training Epoch 98  94.7% | batch:        89 of        94\t|\tloss: 805.924\n",
      "Training Epoch 98  95.7% | batch:        90 of        94\t|\tloss: 1243.52\n",
      "Training Epoch 98  96.8% | batch:        91 of        94\t|\tloss: 713.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:10,546 | INFO : Epoch 98 Training Summary: epoch: 98.000000 | loss: 901.334801 | \n",
      "2023-05-04 17:02:10,547 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7388722896575928 seconds\n",
      "\n",
      "2023-05-04 17:02:10,547 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7820198925174013 seconds\n",
      "2023-05-04 17:02:10,548 | INFO : Avg batch train. time: 0.018957658431036185 seconds\n",
      "2023-05-04 17:02:10,549 | INFO : Avg sample train. time: 0.00014952340094960575 seconds\n",
      "2023-05-04 17:02:10,549 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 98  97.9% | batch:        92 of        94\t|\tloss: 1035.66\n",
      "Training Epoch 98  98.9% | batch:        93 of        94\t|\tloss: 1813.29\n",
      "\n",
      "Evaluating Epoch 98   0.0% | batch:         0 of        40\t|\tloss: 7524.89\n",
      "Evaluating Epoch 98   2.5% | batch:         1 of        40\t|\tloss: 992.455\n",
      "Evaluating Epoch 98   5.0% | batch:         2 of        40\t|\tloss: 3109.53\n",
      "Evaluating Epoch 98   7.5% | batch:         3 of        40\t|\tloss: 7517.24\n",
      "Evaluating Epoch 98  10.0% | batch:         4 of        40\t|\tloss: 2641.21\n",
      "Evaluating Epoch 98  12.5% | batch:         5 of        40\t|\tloss: 2601.35\n",
      "Evaluating Epoch 98  15.0% | batch:         6 of        40\t|\tloss: 8258.52\n",
      "Evaluating Epoch 98  17.5% | batch:         7 of        40\t|\tloss: 3312.77\n",
      "Evaluating Epoch 98  20.0% | batch:         8 of        40\t|\tloss: 2808.7\n",
      "Evaluating Epoch 98  22.5% | batch:         9 of        40\t|\tloss: 2439.49\n",
      "Evaluating Epoch 98  25.0% | batch:        10 of        40\t|\tloss: 5129.91\n",
      "Evaluating Epoch 98  27.5% | batch:        11 of        40\t|\tloss: 1194.79\n",
      "Evaluating Epoch 98  30.0% | batch:        12 of        40\t|\tloss: 7146.67\n",
      "Evaluating Epoch 98  32.5% | batch:        13 of        40\t|\tloss: 3297.18\n",
      "Evaluating Epoch 98  35.0% | batch:        14 of        40\t|\tloss: 1809.4\n",
      "Evaluating Epoch 98  37.5% | batch:        15 of        40\t|\tloss: 3644.95\n",
      "Evaluating Epoch 98  40.0% | batch:        16 of        40\t|\tloss: 4626.33\n",
      "Evaluating Epoch 98  42.5% | batch:        17 of        40\t|\tloss: 2742.81\n",
      "Evaluating Epoch 98  45.0% | batch:        18 of        40\t|\tloss: 2332.23\n",
      "Evaluating Epoch 98  47.5% | batch:        19 of        40\t|\tloss: 5602.23\n",
      "Evaluating Epoch 98  50.0% | batch:        20 of        40\t|\tloss: 5090.95\n",
      "Evaluating Epoch 98  52.5% | batch:        21 of        40\t|\tloss: 1183.52\n",
      "Evaluating Epoch 98  55.0% | batch:        22 of        40\t|\tloss: 3907.19\n",
      "Evaluating Epoch 98  57.5% | batch:        23 of        40\t|\tloss: 3106.5\n",
      "Evaluating Epoch 98  60.0% | batch:        24 of        40\t|\tloss: 1618.33\n",
      "Evaluating Epoch 98  62.5% | batch:        25 of        40\t|\tloss: 4035.65\n",
      "Evaluating Epoch 98  65.0% | batch:        26 of        40\t|\tloss: 11182.3\n",
      "Evaluating Epoch 98  67.5% | batch:        27 of        40\t|\tloss: 2794.57\n",
      "Evaluating Epoch 98  70.0% | batch:        28 of        40\t|\tloss: 2080.42\n",
      "Evaluating Epoch 98  72.5% | batch:        29 of        40\t|\tloss: 8881.83\n",
      "Evaluating Epoch 98  75.0% | batch:        30 of        40\t|\tloss: 1734.93\n",
      "Evaluating Epoch 98  77.5% | batch:        31 of        40\t|\tloss: 1285.14\n",
      "Evaluating Epoch 98  80.0% | batch:        32 of        40\t|\tloss: 8153.87\n",
      "Evaluating Epoch 98  82.5% | batch:        33 of        40\t|\tloss: 6308.46\n",
      "Evaluating Epoch 98  85.0% | batch:        34 of        40\t|\tloss: 917.358\n",
      "Evaluating Epoch 98  87.5% | batch:        35 of        40\t|\tloss: 5716.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:10,988 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.43764472007751465 seconds\n",
      "\n",
      "2023-05-04 17:02:10,989 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5264776888883339 seconds\n",
      "2023-05-04 17:02:10,989 | INFO : Avg batch val. time: 0.013161942222208348 seconds\n",
      "2023-05-04 17:02:10,990 | INFO : Avg sample val. time: 0.00010429431237883001 seconds\n",
      "2023-05-04 17:02:10,991 | INFO : Epoch 98 Validation Summary: epoch: 98.000000 | loss: 4197.003895 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 98  90.0% | batch:        36 of        40\t|\tloss: 7289.02\n",
      "Evaluating Epoch 98  92.5% | batch:        37 of        40\t|\tloss: 2400.85\n",
      "Evaluating Epoch 98  95.0% | batch:        38 of        40\t|\tloss: 3906.39\n",
      "Evaluating Epoch 98  97.5% | batch:        39 of        40\t|\tloss: 11868.7\n",
      "\n",
      "Training Epoch 99   0.0% | batch:         0 of        94\t|\tloss: 898.31\n",
      "Training Epoch 99   1.1% | batch:         1 of        94\t|\tloss: 786.938\n",
      "Training Epoch 99   2.1% | batch:         2 of        94\t|\tloss: 956.329\n",
      "Training Epoch 99   3.2% | batch:         3 of        94\t|\tloss: 817.139\n",
      "Training Epoch 99   4.3% | batch:         4 of        94\t|\tloss: 739.038\n",
      "Training Epoch 99   5.3% | batch:         5 of        94\t|\tloss: 617.299\n",
      "Training Epoch 99   6.4% | batch:         6 of        94\t|\tloss: 616.63\n",
      "Training Epoch 99   7.4% | batch:         7 of        94\t|\tloss: 1091.37\n",
      "Training Epoch 99   8.5% | batch:         8 of        94\t|\tloss: 913.078\n",
      "Training Epoch 99   9.6% | batch:         9 of        94\t|\tloss: 758.118\n",
      "Training Epoch 99  10.6% | batch:        10 of        94\t|\tloss: 755.474\n",
      "Training Epoch 99  11.7% | batch:        11 of        94\t|\tloss: 1695.59\n",
      "Training Epoch 99  12.8% | batch:        12 of        94\t|\tloss: 1271.83\n",
      "Training Epoch 99  13.8% | batch:        13 of        94\t|\tloss: 1142.52\n",
      "Training Epoch 99  14.9% | batch:        14 of        94\t|\tloss: 944.557\n",
      "Training Epoch 99  16.0% | batch:        15 of        94\t|\tloss: 903.477\n",
      "Training Epoch 99  17.0% | batch:        16 of        94\t|\tloss: 605.794\n",
      "Training Epoch 99  18.1% | batch:        17 of        94\t|\tloss: 470.815\n",
      "Training Epoch 99  19.1% | batch:        18 of        94\t|\tloss: 1084.1\n",
      "Training Epoch 99  20.2% | batch:        19 of        94\t|\tloss: 730.234\n",
      "Training Epoch 99  21.3% | batch:        20 of        94\t|\tloss: 527.815\n",
      "Training Epoch 99  22.3% | batch:        21 of        94\t|\tloss: 607.095\n",
      "Training Epoch 99  23.4% | batch:        22 of        94\t|\tloss: 743.615\n",
      "Training Epoch 99  24.5% | batch:        23 of        94\t|\tloss: 1184.93\n",
      "Training Epoch 99  25.5% | batch:        24 of        94\t|\tloss: 743.647\n",
      "Training Epoch 99  26.6% | batch:        25 of        94\t|\tloss: 860.264\n",
      "Training Epoch 99  27.7% | batch:        26 of        94\t|\tloss: 872.115\n",
      "Training Epoch 99  28.7% | batch:        27 of        94\t|\tloss: 743.958\n",
      "Training Epoch 99  29.8% | batch:        28 of        94\t|\tloss: 758.314\n",
      "Training Epoch 99  30.9% | batch:        29 of        94\t|\tloss: 900.697\n",
      "Training Epoch 99  31.9% | batch:        30 of        94\t|\tloss: 601.037\n",
      "Training Epoch 99  33.0% | batch:        31 of        94\t|\tloss: 825.414\n",
      "Training Epoch 99  34.0% | batch:        32 of        94\t|\tloss: 837.674\n",
      "Training Epoch 99  35.1% | batch:        33 of        94\t|\tloss: 720.763\n",
      "Training Epoch 99  36.2% | batch:        34 of        94\t|\tloss: 490.585\n",
      "Training Epoch 99  37.2% | batch:        35 of        94\t|\tloss: 1214.35\n",
      "Training Epoch 99  38.3% | batch:        36 of        94\t|\tloss: 1770.31\n",
      "Training Epoch 99  39.4% | batch:        37 of        94\t|\tloss: 784.811\n",
      "Training Epoch 99  40.4% | batch:        38 of        94\t|\tloss: 834.158\n",
      "Training Epoch 99  41.5% | batch:        39 of        94\t|\tloss: 715.404\n",
      "Training Epoch 99  42.6% | batch:        40 of        94\t|\tloss: 751.458\n",
      "Training Epoch 99  43.6% | batch:        41 of        94\t|\tloss: 654.732\n",
      "Training Epoch 99  44.7% | batch:        42 of        94\t|\tloss: 745.441\n",
      "Training Epoch 99  45.7% | batch:        43 of        94\t|\tloss: 1057.62\n",
      "Training Epoch 99  46.8% | batch:        44 of        94\t|\tloss: 1057.96\n",
      "Training Epoch 99  47.9% | batch:        45 of        94\t|\tloss: 910.892\n",
      "Training Epoch 99  48.9% | batch:        46 of        94\t|\tloss: 684.099\n",
      "Training Epoch 99  50.0% | batch:        47 of        94\t|\tloss: 686.28\n",
      "Training Epoch 99  51.1% | batch:        48 of        94\t|\tloss: 903.374\n",
      "Training Epoch 99  52.1% | batch:        49 of        94\t|\tloss: 853.105\n",
      "Training Epoch 99  53.2% | batch:        50 of        94\t|\tloss: 590.221\n",
      "Training Epoch 99  54.3% | batch:        51 of        94\t|\tloss: 1482.17\n",
      "Training Epoch 99  55.3% | batch:        52 of        94\t|\tloss: 798.458\n",
      "Training Epoch 99  56.4% | batch:        53 of        94\t|\tloss: 635.355\n",
      "Training Epoch 99  57.4% | batch:        54 of        94\t|\tloss: 921.741\n",
      "Training Epoch 99  58.5% | batch:        55 of        94\t|\tloss: 449.242\n",
      "Training Epoch 99  59.6% | batch:        56 of        94\t|\tloss: 673.433\n",
      "Training Epoch 99  60.6% | batch:        57 of        94\t|\tloss: 587.497\n",
      "Training Epoch 99  61.7% | batch:        58 of        94\t|\tloss: 618.413\n",
      "Training Epoch 99  62.8% | batch:        59 of        94\t|\tloss: 828.718\n",
      "Training Epoch 99  63.8% | batch:        60 of        94\t|\tloss: 1202.6\n",
      "Training Epoch 99  64.9% | batch:        61 of        94\t|\tloss: 1049.97\n",
      "Training Epoch 99  66.0% | batch:        62 of        94\t|\tloss: 738.392\n",
      "Training Epoch 99  67.0% | batch:        63 of        94\t|\tloss: 721.219\n",
      "Training Epoch 99  68.1% | batch:        64 of        94\t|\tloss: 1527.04\n",
      "Training Epoch 99  69.1% | batch:        65 of        94\t|\tloss: 783.208\n",
      "Training Epoch 99  70.2% | batch:        66 of        94\t|\tloss: 872.511\n",
      "Training Epoch 99  71.3% | batch:        67 of        94\t|\tloss: 867.074\n",
      "Training Epoch 99  72.3% | batch:        68 of        94\t|\tloss: 760.237\n",
      "Training Epoch 99  73.4% | batch:        69 of        94\t|\tloss: 1238.06\n",
      "Training Epoch 99  74.5% | batch:        70 of        94\t|\tloss: 694.169\n",
      "Training Epoch 99  75.5% | batch:        71 of        94\t|\tloss: 751.339\n",
      "Training Epoch 99  76.6% | batch:        72 of        94\t|\tloss: 1243.64\n",
      "Training Epoch 99  77.7% | batch:        73 of        94\t|\tloss: 644.481\n",
      "Training Epoch 99  78.7% | batch:        74 of        94\t|\tloss: 857.278\n",
      "Training Epoch 99  79.8% | batch:        75 of        94\t|\tloss: 626.629\n",
      "Training Epoch 99  80.9% | batch:        76 of        94\t|\tloss: 1324.47\n",
      "Training Epoch 99  81.9% | batch:        77 of        94\t|\tloss: 1906.99\n",
      "Training Epoch 99  83.0% | batch:        78 of        94\t|\tloss: 730.571\n",
      "Training Epoch 99  84.0% | batch:        79 of        94\t|\tloss: 923.042\n",
      "Training Epoch 99  85.1% | batch:        80 of        94\t|\tloss: 934.041\n",
      "Training Epoch 99  86.2% | batch:        81 of        94\t|\tloss: 701.516\n",
      "Training Epoch 99  87.2% | batch:        82 of        94\t|\tloss: 1066.59\n",
      "Training Epoch 99  88.3% | batch:        83 of        94\t|\tloss: 949.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:12,799 | INFO : Epoch 99 Training Summary: epoch: 99.000000 | loss: 903.601850 | \n",
      "2023-05-04 17:02:12,800 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7869594097137451 seconds\n",
      "\n",
      "2023-05-04 17:02:12,801 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7820697866304955 seconds\n",
      "2023-05-04 17:02:12,802 | INFO : Avg batch train. time: 0.018958189219473356 seconds\n",
      "2023-05-04 17:02:12,802 | INFO : Avg sample train. time: 0.00014952758739977308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 99  89.4% | batch:        84 of        94\t|\tloss: 854.756\n",
      "Training Epoch 99  90.4% | batch:        85 of        94\t|\tloss: 872.917\n",
      "Training Epoch 99  91.5% | batch:        86 of        94\t|\tloss: 1482.08\n",
      "Training Epoch 99  92.6% | batch:        87 of        94\t|\tloss: 1492.67\n",
      "Training Epoch 99  93.6% | batch:        88 of        94\t|\tloss: 1805.72\n",
      "Training Epoch 99  94.7% | batch:        89 of        94\t|\tloss: 810.603\n",
      "Training Epoch 99  95.7% | batch:        90 of        94\t|\tloss: 928.763\n",
      "Training Epoch 99  96.8% | batch:        91 of        94\t|\tloss: 1047.45\n",
      "Training Epoch 99  97.9% | batch:        92 of        94\t|\tloss: 1211.19\n",
      "Training Epoch 99  98.9% | batch:        93 of        94\t|\tloss: 796.599\n",
      "\n",
      "Training Epoch 100   0.0% | batch:         0 of        94\t|\tloss: 919.907\n",
      "Training Epoch 100   1.1% | batch:         1 of        94\t|\tloss: 790.17\n",
      "Training Epoch 100   2.1% | batch:         2 of        94\t|\tloss: 617.776\n",
      "Training Epoch 100   3.2% | batch:         3 of        94\t|\tloss: 780.237\n",
      "Training Epoch 100   4.3% | batch:         4 of        94\t|\tloss: 1067.68\n",
      "Training Epoch 100   5.3% | batch:         5 of        94\t|\tloss: 699.842\n",
      "Training Epoch 100   6.4% | batch:         6 of        94\t|\tloss: 3352.36\n",
      "Training Epoch 100   7.4% | batch:         7 of        94\t|\tloss: 1046.42\n",
      "Training Epoch 100   8.5% | batch:         8 of        94\t|\tloss: 734.296\n",
      "Training Epoch 100   9.6% | batch:         9 of        94\t|\tloss: 1156.26\n",
      "Training Epoch 100  10.6% | batch:        10 of        94\t|\tloss: 751.811\n",
      "Training Epoch 100  11.7% | batch:        11 of        94\t|\tloss: 702.8\n",
      "Training Epoch 100  12.8% | batch:        12 of        94\t|\tloss: 1196.75\n",
      "Training Epoch 100  13.8% | batch:        13 of        94\t|\tloss: 684.134\n",
      "Training Epoch 100  14.9% | batch:        14 of        94\t|\tloss: 1538.98\n",
      "Training Epoch 100  16.0% | batch:        15 of        94\t|\tloss: 1360.29\n",
      "Training Epoch 100  17.0% | batch:        16 of        94\t|\tloss: 774.535\n",
      "Training Epoch 100  18.1% | batch:        17 of        94\t|\tloss: 1120.76\n",
      "Training Epoch 100  19.1% | batch:        18 of        94\t|\tloss: 1270.47\n",
      "Training Epoch 100  20.2% | batch:        19 of        94\t|\tloss: 834.159\n",
      "Training Epoch 100  21.3% | batch:        20 of        94\t|\tloss: 2254.47\n",
      "Training Epoch 100  22.3% | batch:        21 of        94\t|\tloss: 646.699\n",
      "Training Epoch 100  23.4% | batch:        22 of        94\t|\tloss: 836.963\n",
      "Training Epoch 100  24.5% | batch:        23 of        94\t|\tloss: 865.628\n",
      "Training Epoch 100  25.5% | batch:        24 of        94\t|\tloss: 774.272\n",
      "Training Epoch 100  26.6% | batch:        25 of        94\t|\tloss: 535.594\n",
      "Training Epoch 100  27.7% | batch:        26 of        94\t|\tloss: 585.991\n",
      "Training Epoch 100  28.7% | batch:        27 of        94\t|\tloss: 592.261\n",
      "Training Epoch 100  29.8% | batch:        28 of        94\t|\tloss: 631.971\n",
      "Training Epoch 100  30.9% | batch:        29 of        94\t|\tloss: 1069.67\n",
      "Training Epoch 100  31.9% | batch:        30 of        94\t|\tloss: 896.05\n",
      "Training Epoch 100  33.0% | batch:        31 of        94\t|\tloss: 950.257\n",
      "Training Epoch 100  34.0% | batch:        32 of        94\t|\tloss: 1844.31\n",
      "Training Epoch 100  35.1% | batch:        33 of        94\t|\tloss: 1124.7\n",
      "Training Epoch 100  36.2% | batch:        34 of        94\t|\tloss: 760.384\n",
      "Training Epoch 100  37.2% | batch:        35 of        94\t|\tloss: 759.466\n",
      "Training Epoch 100  38.3% | batch:        36 of        94\t|\tloss: 1048.37\n",
      "Training Epoch 100  39.4% | batch:        37 of        94\t|\tloss: 1113.33\n",
      "Training Epoch 100  40.4% | batch:        38 of        94\t|\tloss: 703.346\n",
      "Training Epoch 100  41.5% | batch:        39 of        94\t|\tloss: 817.276\n",
      "Training Epoch 100  42.6% | batch:        40 of        94\t|\tloss: 566.629\n",
      "Training Epoch 100  43.6% | batch:        41 of        94\t|\tloss: 648.275\n",
      "Training Epoch 100  44.7% | batch:        42 of        94\t|\tloss: 924.086\n",
      "Training Epoch 100  45.7% | batch:        43 of        94\t|\tloss: 864.057\n",
      "Training Epoch 100  46.8% | batch:        44 of        94\t|\tloss: 560.92\n",
      "Training Epoch 100  47.9% | batch:        45 of        94\t|\tloss: 987.249\n",
      "Training Epoch 100  48.9% | batch:        46 of        94\t|\tloss: 1168.2\n",
      "Training Epoch 100  50.0% | batch:        47 of        94\t|\tloss: 617.858\n",
      "Training Epoch 100  51.1% | batch:        48 of        94\t|\tloss: 900.095\n",
      "Training Epoch 100  52.1% | batch:        49 of        94\t|\tloss: 989.507\n",
      "Training Epoch 100  53.2% | batch:        50 of        94\t|\tloss: 767.267\n",
      "Training Epoch 100  54.3% | batch:        51 of        94\t|\tloss: 888.297\n",
      "Training Epoch 100  55.3% | batch:        52 of        94\t|\tloss: 747.384\n",
      "Training Epoch 100  56.4% | batch:        53 of        94\t|\tloss: 1045.6\n",
      "Training Epoch 100  57.4% | batch:        54 of        94\t|\tloss: 712.641\n",
      "Training Epoch 100  58.5% | batch:        55 of        94\t|\tloss: 777.801\n",
      "Training Epoch 100  59.6% | batch:        56 of        94\t|\tloss: 622.663\n",
      "Training Epoch 100  60.6% | batch:        57 of        94\t|\tloss: 521.918\n",
      "Training Epoch 100  61.7% | batch:        58 of        94\t|\tloss: 735.476\n",
      "Training Epoch 100  62.8% | batch:        59 of        94\t|\tloss: 938.494\n",
      "Training Epoch 100  63.8% | batch:        60 of        94\t|\tloss: 1044.6\n",
      "Training Epoch 100  64.9% | batch:        61 of        94\t|\tloss: 610.777\n",
      "Training Epoch 100  66.0% | batch:        62 of        94\t|\tloss: 594.775\n",
      "Training Epoch 100  67.0% | batch:        63 of        94\t|\tloss: 1014.1\n",
      "Training Epoch 100  68.1% | batch:        64 of        94\t|\tloss: 800.644\n",
      "Training Epoch 100  69.1% | batch:        65 of        94\t|\tloss: 704.748\n",
      "Training Epoch 100  70.2% | batch:        66 of        94\t|\tloss: 843.187\n",
      "Training Epoch 100  71.3% | batch:        67 of        94\t|\tloss: 588.801\n",
      "Training Epoch 100  72.3% | batch:        68 of        94\t|\tloss: 821.386\n",
      "Training Epoch 100  73.4% | batch:        69 of        94\t|\tloss: 1223.52\n",
      "Training Epoch 100  74.5% | batch:        70 of        94\t|\tloss: 864.784\n",
      "Training Epoch 100  75.5% | batch:        71 of        94\t|\tloss: 1387.8\n",
      "Training Epoch 100  76.6% | batch:        72 of        94\t|\tloss: 750.004\n",
      "Training Epoch 100  77.7% | batch:        73 of        94\t|\tloss: 1824.91\n",
      "Training Epoch 100  78.7% | batch:        74 of        94\t|\tloss: 745.026\n",
      "Training Epoch 100  79.8% | batch:        75 of        94\t|\tloss: 908.699\n",
      "Training Epoch 100  80.9% | batch:        76 of        94\t|\tloss: 624.608\n",
      "Training Epoch 100  81.9% | batch:        77 of        94\t|\tloss: 703.851\n",
      "Training Epoch 100  83.0% | batch:        78 of        94\t|\tloss: 957.933\n",
      "Training Epoch 100  84.0% | batch:        79 of        94\t|\tloss: 671.226\n",
      "Training Epoch 100  85.1% | batch:        80 of        94\t|\tloss: 1034.94\n",
      "Training Epoch 100  86.2% | batch:        81 of        94\t|\tloss: 686.466\n",
      "Training Epoch 100  87.2% | batch:        82 of        94\t|\tloss: 1863.15\n",
      "Training Epoch 100  88.3% | batch:        83 of        94\t|\tloss: 925.017\n",
      "Training Epoch 100  89.4% | batch:        84 of        94\t|\tloss: 732.713\n",
      "Training Epoch 100  90.4% | batch:        85 of        94\t|\tloss: 819.979\n",
      "Training Epoch 100  91.5% | batch:        86 of        94\t|\tloss: 750.889\n",
      "Training Epoch 100  92.6% | batch:        87 of        94\t|\tloss: 721.627\n",
      "Training Epoch 100  93.6% | batch:        88 of        94\t|\tloss: 748.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:14,590 | INFO : Epoch 100 Training Summary: epoch: 100.000000 | loss: 915.600737 | \n",
      "2023-05-04 17:02:14,591 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7670378684997559 seconds\n",
      "\n",
      "2023-05-04 17:02:14,592 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7819194674491883 seconds\n",
      "2023-05-04 17:02:14,592 | INFO : Avg batch train. time: 0.018956590079246684 seconds\n",
      "2023-05-04 17:02:14,593 | INFO : Avg sample train. time: 0.0001495149746139611 seconds\n",
      "2023-05-04 17:02:14,593 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 100  94.7% | batch:        89 of        94\t|\tloss: 822.854\n",
      "Training Epoch 100  95.7% | batch:        90 of        94\t|\tloss: 673.4\n",
      "Training Epoch 100  96.8% | batch:        91 of        94\t|\tloss: 779.798\n",
      "Training Epoch 100  97.9% | batch:        92 of        94\t|\tloss: 662.252\n",
      "Training Epoch 100  98.9% | batch:        93 of        94\t|\tloss: 1357.74\n",
      "\n",
      "Evaluating Epoch 100   0.0% | batch:         0 of        40\t|\tloss: 7752.27\n",
      "Evaluating Epoch 100   2.5% | batch:         1 of        40\t|\tloss: 1201.23\n",
      "Evaluating Epoch 100   5.0% | batch:         2 of        40\t|\tloss: 3293.98\n",
      "Evaluating Epoch 100   7.5% | batch:         3 of        40\t|\tloss: 6965.75\n",
      "Evaluating Epoch 100  10.0% | batch:         4 of        40\t|\tloss: 2329.23\n",
      "Evaluating Epoch 100  12.5% | batch:         5 of        40\t|\tloss: 2301.91\n",
      "Evaluating Epoch 100  15.0% | batch:         6 of        40\t|\tloss: 8325.72\n",
      "Evaluating Epoch 100  17.5% | batch:         7 of        40\t|\tloss: 3693.76\n",
      "Evaluating Epoch 100  20.0% | batch:         8 of        40\t|\tloss: 3231.85\n",
      "Evaluating Epoch 100  22.5% | batch:         9 of        40\t|\tloss: 2012.82\n",
      "Evaluating Epoch 100  25.0% | batch:        10 of        40\t|\tloss: 5587.96\n",
      "Evaluating Epoch 100  27.5% | batch:        11 of        40\t|\tloss: 1418.7\n",
      "Evaluating Epoch 100  30.0% | batch:        12 of        40\t|\tloss: 6711.6\n",
      "Evaluating Epoch 100  32.5% | batch:        13 of        40\t|\tloss: 3298.6\n",
      "Evaluating Epoch 100  35.0% | batch:        14 of        40\t|\tloss: 2192.08\n",
      "Evaluating Epoch 100  37.5% | batch:        15 of        40\t|\tloss: 3535.81\n",
      "Evaluating Epoch 100  40.0% | batch:        16 of        40\t|\tloss: 4446.89\n",
      "Evaluating Epoch 100  42.5% | batch:        17 of        40\t|\tloss: 3357.07\n",
      "Evaluating Epoch 100  45.0% | batch:        18 of        40\t|\tloss: 2163.42\n",
      "Evaluating Epoch 100  47.5% | batch:        19 of        40\t|\tloss: 5662.41\n",
      "Evaluating Epoch 100  50.0% | batch:        20 of        40\t|\tloss: 5712.93\n",
      "Evaluating Epoch 100  52.5% | batch:        21 of        40\t|\tloss: 1160.27\n",
      "Evaluating Epoch 100  55.0% | batch:        22 of        40\t|\tloss: 4514.09\n",
      "Evaluating Epoch 100  57.5% | batch:        23 of        40\t|\tloss: 3034.54\n",
      "Evaluating Epoch 100  60.0% | batch:        24 of        40\t|\tloss: 1725.7\n",
      "Evaluating Epoch 100  62.5% | batch:        25 of        40\t|\tloss: 3969.24\n",
      "Evaluating Epoch 100  65.0% | batch:        26 of        40\t|\tloss: 9841.28\n",
      "Evaluating Epoch 100  67.5% | batch:        27 of        40\t|\tloss: 2701.1\n",
      "Evaluating Epoch 100  70.0% | batch:        28 of        40\t|\tloss: 1999.65\n",
      "Evaluating Epoch 100  72.5% | batch:        29 of        40\t|\tloss: 8519.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 17:02:15,033 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4390065670013428 seconds\n",
      "\n",
      "2023-05-04 17:02:15,034 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5260670263442635 seconds\n",
      "2023-05-04 17:02:15,034 | INFO : Avg batch val. time: 0.013151675658606587 seconds\n",
      "2023-05-04 17:02:15,035 | INFO : Avg sample val. time: 0.00010421296084474316 seconds\n",
      "2023-05-04 17:02:15,036 | INFO : Epoch 100 Validation Summary: epoch: 100.000000 | loss: 4193.033844 | \n",
      "2023-05-04 17:02:15,060 | INFO : Exported per epoch performance metrics in '../experiments/BeijingPM25Quality_finetuned_2023-05-04_16-57-42_wdT/metrics_BeijingPM25Quality_finetuned.xls'\n",
      "2023-05-04 17:02:15,065 | INFO : Exported performance record to 'Regression_records.xls'\n",
      "2023-05-04 17:02:15,065 | INFO : Best loss was 3424.168098751981. Other metrics: OrderedDict([('epoch', 14), ('loss', 3424.168098751981)])\n",
      "2023-05-04 17:02:15,066 | INFO : All Done!\n",
      "2023-05-04 17:02:15,067 | INFO : Total runtime: 0.0 hours, 4.0 minutes, 31.545044898986816 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 100  75.0% | batch:        30 of        40\t|\tloss: 1842.61\n",
      "Evaluating Epoch 100  77.5% | batch:        31 of        40\t|\tloss: 1499.66\n",
      "Evaluating Epoch 100  80.0% | batch:        32 of        40\t|\tloss: 8207.79\n",
      "Evaluating Epoch 100  82.5% | batch:        33 of        40\t|\tloss: 6172.15\n",
      "Evaluating Epoch 100  85.0% | batch:        34 of        40\t|\tloss: 1064.73\n",
      "Evaluating Epoch 100  87.5% | batch:        35 of        40\t|\tloss: 5565.65\n",
      "Evaluating Epoch 100  90.0% | batch:        36 of        40\t|\tloss: 6693.4\n",
      "Evaluating Epoch 100  92.5% | batch:        37 of        40\t|\tloss: 2868.13\n",
      "Evaluating Epoch 100  95.0% | batch:        38 of        40\t|\tloss: 3696.24\n",
      "Evaluating Epoch 100  97.5% | batch:        39 of        40\t|\tloss: 11637.8\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3424.168098751981"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ed5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ff63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
