{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d884a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:14:59,401 | INFO : Loading packages ...\n",
      "2023-05-09 14:15:00,648 | INFO : Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-09 14:15:00,649 | INFO : NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Loading packages ...\")\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# 3rd party packages\n",
    "\n",
    "#from tqdm import tqdm\n",
    "# since we are using it in jupyter notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Project modules\n",
    "from options import Options\n",
    "from running import setup, pipeline_factory, validate, check_progress, NEG_METRICS\n",
    "from utils import utils\n",
    "from datasets.data import data_factory, Normalizer\n",
    "from datasets.datasplit import split_dataset\n",
    "from models.ts_transformer import model_factory\n",
    "from models.loss import get_loss_module\n",
    "from optimizers import get_optimizer\n",
    "\n",
    "import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e17d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"--output_dir ../experiments/ --comment 'regression_from_Scratch' \\\n",
    "        --name pm25_fromScratch_Regression --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --task regression\"\n",
    "\n",
    "text = \"--output_dir ../experiments/ --comment 'regression_from_Scratch' \\\n",
    "        --name pm25_fromScratch_Regression_test --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --task regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d020d0",
   "metadata": {},
   "source": [
    "### Pretrain\n",
    "python src/main.py --output_dir experiments --comment \"pretraining through imputation\" --name $1_pretrained \n",
    "--records_file Imputation_records.xls --data_dir /path/to/$1/ --data_class tsra --pattern TRAIN --val_ratio 0.2 --epochs 700 --lr 0.001 --optimizer RAdam --batch_size 32 --pos_encoding learnable --d_model 128\n",
    "\n",
    "### Finetune\n",
    "python src/main.py --output_dir experiments --comment \"finetune for regression\" --name BeijingPM25Quality_finetuned --records_file Regression_records.xls --data_dir /path/to/Datasets/Regression/BeijingPM25Quality/ --data_class tsra --pattern TRAIN --val_pattern TEST  --epochs 200 --lr 0.001 --optimizer RAdam --pos_encoding learnable --d_model 128 --load_model path/to/BeijingPM25Quality_pretrained/checkpoints/model_best.pth --task regression --change_output --batch_size 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036bf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain\n",
    "'''\n",
    "text = \"--output_dir ../experiments/ --comment 'pretraining_through_imputation' \\\n",
    "        --name pm25_pretrained --records_file Imputation_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_ratio 0.2 --epochs 20 --lr 0.001 --optimizer RAdam \\\n",
    "        --batch_size 32 --pos_encoding learnable --d_model 128\"\n",
    "'''\n",
    "\n",
    "\n",
    "# Finetune\n",
    "text = \"--output_dir ../experiments --comment 'finetune_for_regression' \\\n",
    "        --name BeijingPM25Quality_finetuned --records_file Regression_records.xls \\\n",
    "        --data_dir ../data/regression/BeijingPM25Quality/ --data_class tsra \\\n",
    "        --pattern TRAIN --val_pattern TEST  --epochs 100 --lr 0.001 --optimizer RAdam \\\n",
    "        --pos_encoding learnable --d_model 128 \\\n",
    "        --load_model ../experiments/pm25_pretrained_2023-05-04_11-01-18_AhP/checkpoints/model_best.pth \\\n",
    "        --task regression --change_output --batch_size 128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99d546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587e7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:15:00,794 | INFO : Stored configuration file in '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA'\n"
     ]
    }
   ],
   "source": [
    "input_text = text.split()\n",
    "args = Options().parse(input_text)\n",
    "config = setup(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062ce40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386c3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:15:00,800 | INFO : Running:\n",
      "/home/tianyi/anaconda3/envs/transformer/lib/python3.8/site-packages/ipykernel_launcher.py -f /home/tianyi/.local/share/jupyter/runtime/kernel-e8142a0c-6e6a-4546-8c41-7f518f56e232.json\n",
      "\n",
      "2023-05-09 14:15:00,910 | INFO : Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "total_epoch_time = 0\n",
    "total_eval_time = 0\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Add file logging besides stdout\n",
    "file_handler = logging.FileHandler(os.path.join(config['output_dir'], 'output.log'))\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('Running:\\n{}\\n'.format(' '.join(sys.argv)))  # command used to run\n",
    "\n",
    "if config['seed'] is not None:\n",
    "    torch.manual_seed(config['seed'])\n",
    "\n",
    "device = torch.device('cuda' if (torch.cuda.is_available() and config['gpu'] != '-1') else 'cpu')\n",
    "logger.info(\"Using device: {}\".format(device))\n",
    "if device == 'cuda':\n",
    "    logger.info(\"Device index: {}\".format(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4808df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRAIN'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8acbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:15:00,921 | INFO : Loading and preprocessing data ...\n",
      "11942it [00:24, 494.24it/s]\n"
     ]
    }
   ],
   "source": [
    " # Build data\n",
    "logger.info(\"Loading and preprocessing data ...\")\n",
    "data_class = data_factory[config['data_class']]\n",
    "my_data = data_class(config['data_dir'], \n",
    "                     pattern=config['pattern'], \n",
    "                     n_proc=config['n_proc'], \n",
    "                     limit_size=config['limit_size'], \n",
    "                     config=config)\n",
    "feat_dim = my_data.feature_df.shape[1]  # dimensionality of data features\n",
    "if config['task'] == 'classification':\n",
    "    validation_method = 'StratifiedShuffleSplit'\n",
    "    labels = my_data.labels_df.values.flatten()\n",
    "else:\n",
    "    validation_method = 'ShuffleSplit'\n",
    "    labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d859a255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dim = my_data.feature_df.shape[1]\n",
    "feat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6877ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_filepath': None,\n",
       " 'output_dir': '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA',\n",
       " 'data_dir': '../data/regression/BeijingPM25Quality/',\n",
       " 'load_model': '../experiments/pm25_pretrained_2023-05-04_11-01-18_AhP/checkpoints/model_best.pth',\n",
       " 'resume': False,\n",
       " 'change_output': True,\n",
       " 'save_all': False,\n",
       " 'experiment_name': 'BeijingPM25Quality_finetuned',\n",
       " 'comment': \"'finetune_for_regression'\",\n",
       " 'no_timestamp': False,\n",
       " 'records_file': 'Regression_records.xls',\n",
       " 'console': False,\n",
       " 'print_interval': 1,\n",
       " 'gpu': '0',\n",
       " 'n_proc': -1,\n",
       " 'num_workers': 0,\n",
       " 'seed': None,\n",
       " 'limit_size': None,\n",
       " 'test_only': None,\n",
       " 'data_class': 'tsra',\n",
       " 'labels': None,\n",
       " 'test_from': None,\n",
       " 'test_ratio': 0,\n",
       " 'val_ratio': 0,\n",
       " 'pattern': 'TRAIN',\n",
       " 'val_pattern': 'TEST',\n",
       " 'test_pattern': None,\n",
       " 'normalization': 'standardization',\n",
       " 'norm_from': None,\n",
       " 'subsample_factor': None,\n",
       " 'task': 'regression',\n",
       " 'masking_ratio': 0.15,\n",
       " 'mean_mask_length': 3,\n",
       " 'mask_mode': 'separate',\n",
       " 'mask_distribution': 'geometric',\n",
       " 'exclude_feats': None,\n",
       " 'mask_feats': [0, 1],\n",
       " 'start_hint': 0.0,\n",
       " 'end_hint': 0.0,\n",
       " 'harden': False,\n",
       " 'epochs': 100,\n",
       " 'val_interval': 2,\n",
       " 'optimizer': 'RAdam',\n",
       " 'lr': 0.001,\n",
       " 'lr_step': [1000000],\n",
       " 'lr_factor': [0.1],\n",
       " 'batch_size': 128,\n",
       " 'l2_reg': 0,\n",
       " 'global_reg': False,\n",
       " 'key_metric': 'loss',\n",
       " 'freeze': False,\n",
       " 'model': 'transformer',\n",
       " 'max_seq_len': None,\n",
       " 'data_window_len': None,\n",
       " 'd_model': 128,\n",
       " 'dim_feedforward': 256,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.1,\n",
       " 'pos_encoding': 'learnable',\n",
       " 'activation': 'gelu',\n",
       " 'normalization_layer': 'BatchNorm',\n",
       " 'initial_timestamp': '2023-05-09_14-15-00',\n",
       " 'save_dir': '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA/checkpoints',\n",
       " 'pred_dir': '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA/predictions',\n",
       " 'tensorboard_dir': '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA/tb_summaries'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b822bc4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>27.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1026.3</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>34.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>31.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>40.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>1025.5</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>43.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286032 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim_0  dim_1   dim_2  dim_3  dim_4   dim_5  dim_6  dim_7  dim_8\n",
       "0        4.0    7.0   300.0   77.0   -0.7  1023.0  -18.8    0.0    4.4\n",
       "0        4.0    7.0   300.0   77.0   -1.1  1023.2  -18.2    0.0    4.7\n",
       "0        5.0   10.0   300.0   73.0   -1.1  1023.5  -18.2    0.0    5.6\n",
       "0       11.0   11.0   300.0   72.0   -1.4  1024.5  -19.4    0.0    3.1\n",
       "0       12.0   12.0   300.0   72.0   -2.0  1025.2  -19.5    0.0    2.0\n",
       "...      ...    ...     ...    ...    ...     ...    ...    ...    ...\n",
       "11917   27.0   96.0  3300.0    9.0   -1.4  1026.3   -8.6    0.0    1.0\n",
       "11917   34.0   99.0  3700.0    9.0   -2.5  1026.2   -8.4    0.0    1.3\n",
       "11917   31.0   95.0  3100.0    9.0   -2.7  1025.8   -8.0    0.0    0.9\n",
       "11917   40.0   99.0  4200.0   13.0   -3.5  1025.5   -7.6    0.0    0.4\n",
       "11917   43.0  104.0  4800.0   16.0   -3.4  1025.2   -7.5    0.0    1.8\n",
       "\n",
       "[286032 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.feature_df\n",
    "#my_data.all_IDs[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8224d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11913</th>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11914</th>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11918 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0       24.0\n",
       "1       93.0\n",
       "2      117.0\n",
       "3       58.0\n",
       "4      226.0\n",
       "...      ...\n",
       "11913   89.0\n",
       "11914  281.0\n",
       "11915  543.0\n",
       "11916  505.0\n",
       "11917  227.0\n",
       "\n",
       "[11918 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887d1316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "286032.0/11918.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449dacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6d6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import utils\n",
    "#x, y = utils.load_from_tsfile_to_dataframe(\"../data/regression/BeijingPM25Quality/BeijingPM25Quality_TRAIN.ts\")\n",
    "#y.shape\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe72a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018a93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db83f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aaad192",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67fb3e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5072it [00:10, 490.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "test_data = my_data\n",
    "test_indices = None  # will be converted to empty list in `split_dataset`, if also test_set_ratio == 0\n",
    "val_data = my_data\n",
    "val_indices = []\n",
    "if config['test_pattern']:  # used if test data come from different files / file patterns\n",
    "    test_data = data_class(config['data_dir'], pattern=config['test_pattern'], n_proc=-1, config=config)\n",
    "    test_indices = test_data.all_IDs\n",
    "if config['test_from']:  # load test IDs directly from file, if available, otherwise use `test_set_ratio`. Can work together with `test_pattern`\n",
    "    test_indices = list(set([line.rstrip() for line in open(config['test_from']).readlines()]))\n",
    "    try:\n",
    "        test_indices = [int(ind) for ind in test_indices]  # integer indices\n",
    "    except ValueError:\n",
    "        pass  # in case indices are non-integers\n",
    "    logger.info(\"Loaded {} test IDs from file: '{}'\".format(len(test_indices), config['test_from']))\n",
    "if config['val_pattern']:  # used if val data come from different files / file patterns\n",
    "    val_data = data_class(config['data_dir'], pattern=config['val_pattern'], n_proc=-1, config=config)\n",
    "    val_indices = val_data.all_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f61ee028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: currently a validation set must exist, either with `val_pattern` or `val_ratio`\n",
    "# Using a `val_pattern` means that `val_ratio` == 0 and `test_ratio` == 0\n",
    "if config['val_ratio'] > 0:\n",
    "    train_indices, val_indices, test_indices = split_dataset(data_indices=my_data.all_IDs,\n",
    "                                                             validation_method=validation_method,\n",
    "                                                             n_splits=1,\n",
    "                                                             validation_ratio=config['val_ratio'],\n",
    "                                                             test_set_ratio=config['test_ratio'],  # used only if test_indices not explicitly specified\n",
    "                                                             test_indices=test_indices,\n",
    "                                                             random_seed=1337,\n",
    "                                                             labels=labels)\n",
    "    train_indices = train_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "    val_indices = val_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "else:\n",
    "    train_indices = my_data.all_IDs\n",
    "    if test_indices is None:\n",
    "        test_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd56158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:15,003 | INFO : 11918 samples may be used for training\n",
      "2023-05-09 14:20:15,004 | INFO : 5048 samples will be used for validation\n",
      "2023-05-09 14:20:15,004 | INFO : 0 samples will be used for testing\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"{} samples may be used for training\".format(len(train_indices)))\n",
    "logger.info(\"{} samples will be used for validation\".format(len(val_indices)))\n",
    "logger.info(\"{} samples will be used for testing\".format(len(test_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd16a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config['output_dir'], 'data_indices.json'), 'w') as f:\n",
    "    try:\n",
    "        json.dump({'train_indices': list(map(int, train_indices)),\n",
    "                   'val_indices': list(map(int, val_indices)),\n",
    "                   'test_indices': list(map(int, test_indices))}, f, indent=4)\n",
    "    except ValueError:  # in case indices are non-integers\n",
    "        json.dump({'train_indices': list(train_indices),\n",
    "                   'val_indices': list(val_indices),\n",
    "                   'test_indices': list(test_indices)}, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2791dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process features\n",
    "normalizer = None\n",
    "if config['norm_from']:\n",
    "    with open(config['norm_from'], 'rb') as f:\n",
    "        norm_dict = pickle.load(f)\n",
    "    normalizer = Normalizer(**norm_dict)\n",
    "elif config['normalization'] is not None:\n",
    "    normalizer = Normalizer(config['normalization'])\n",
    "    my_data.feature_df.loc[train_indices] = normalizer.normalize(my_data.feature_df.loc[train_indices])\n",
    "    if not config['normalization'].startswith('per_sample'):\n",
    "        # get normalizing values from training set and store for future use\n",
    "        norm_dict = normalizer.__dict__\n",
    "        with open(os.path.join(config['output_dir'], 'normalization.pickle'), 'wb') as f:\n",
    "            pickle.dump(norm_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "if normalizer is not None:\n",
    "    if len(val_indices):\n",
    "        val_data.feature_df.loc[val_indices] = normalizer.normalize(val_data.feature_df.loc[val_indices])\n",
    "    if len(test_indices):\n",
    "        test_data.feature_df.loc[test_indices] = normalizer.normalize(test_data.feature_df.loc[test_indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16123e",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "819d3824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:15,240 | INFO : Creating model ...\n",
      "2023-05-09 14:20:15,268 | INFO : Model:\n",
      "TSTransformerEncoderClassiregressor(\n",
      "  (project_inp): Linear(in_features=9, out_features=128, bias=True)\n",
      "  (pos_enc): LearnablePositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerBatchNormEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (output_layer): Linear(in_features=3072, out_features=1, bias=True)\n",
      ")\n",
      "2023-05-09 14:20:15,269 | INFO : Total number of parameters: 404865\n",
      "2023-05-09 14:20:15,270 | INFO : Trainable parameters: 404865\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "logger.info(\"Creating model ...\")\n",
    "model = model_factory(config, my_data)\n",
    "\n",
    "if config['freeze']:\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith('output_layer'):\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "logger.info(\"Model:\\n{}\".format(model))\n",
    "logger.info(\"Total number of parameters: {}\".format(utils.count_parameters(model)))\n",
    "logger.info(\"Trainable parameters: {}\".format(utils.count_parameters(model, trainable=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e1de7",
   "metadata": {},
   "source": [
    "# Initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1990cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../experiments/pm25_pretrained_2023-05-04_11-01-18_AhP/checkpoints/model_best.pth. Epoch: 20\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "if config['global_reg']:\n",
    "    weight_decay = config['l2_reg']\n",
    "    output_reg = None\n",
    "else:\n",
    "    weight_decay = 0\n",
    "    output_reg = config['l2_reg']\n",
    "\n",
    "optim_class = get_optimizer(config['optimizer'])\n",
    "optimizer = optim_class(model.parameters(), lr=config['lr'], weight_decay=weight_decay)\n",
    "\n",
    "start_epoch = 0\n",
    "lr_step = 0  # current step index of `lr_step`\n",
    "lr = config['lr']  # current learning step\n",
    "# Load model and optimizer state\n",
    "if args.load_model:\n",
    "    model, optimizer, start_epoch = utils.load_model(model, config['load_model'], optimizer, config['resume'],\n",
    "                                                     config['change_output'],\n",
    "                                                     config['lr'],\n",
    "                                                     config['lr_step'],\n",
    "                                                     config['lr_factor'])\n",
    "model.to(device)\n",
    "\n",
    "loss_module = get_loss_module(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cff7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['test_only'] == 'testset':  # Only evaluate and skip training\n",
    "    dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "    test_dataset = dataset_class(test_data, test_indices)\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=config['batch_size'],\n",
    "                             shuffle=False,\n",
    "                             num_workers=config['num_workers'],\n",
    "                             pin_memory=True,\n",
    "                             collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "    test_evaluator = runner_class(model, test_loader, device, loss_module,\n",
    "                                        print_interval=config['print_interval'], console=config['console'])\n",
    "    aggr_metrics_test, per_batch_test = test_evaluator.evaluate(keep_all=True)\n",
    "    print_str = 'Test Summary: '\n",
    "    for k, v in aggr_metrics_test.items():\n",
    "        print_str += '{}: {:8f} | '.format(k, v)\n",
    "    logger.info(print_str)\n",
    "    #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e05eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['test_only'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569f5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data generators\n",
    "if config['test_only'] != 'testset':  # Only evaluate and skip training\n",
    "    dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "    val_dataset = dataset_class(val_data, val_indices)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            shuffle=False,\n",
    "                            num_workers=config['num_workers'],\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    train_dataset = dataset_class(my_data, train_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=config['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=config['num_workers'],\n",
    "                              pin_memory=True,\n",
    "                              collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    trainer = runner_class(model, train_loader, device, loss_module, optimizer, l2_reg=output_reg,\n",
    "                                 print_interval=config['print_interval'], console=config['console'])\n",
    "    val_evaluator = runner_class(model, val_loader, device, loss_module,\n",
    "                                       print_interval=config['print_interval'], console=config['console'])\n",
    "\n",
    "    tensorboard_writer = SummaryWriter(config['tensorboard_dir'])\n",
    "\n",
    "    best_value = 1e16 if config['key_metric'] in NEG_METRICS else -1e16  # initialize with +inf or -inf depending on key metric\n",
    "    metrics = []  # (for validation) list of lists: for each epoch, stores metrics like loss, ...\n",
    "    best_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "516e900c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "torch.Size([128, 24, 9])\n",
      "tensor([[[-2.8290e-01, -7.5280e-01, -6.5212e-01,  1.3205e+00,  1.1679e+00,\n",
      "          -6.6312e-01,  9.5038e-01, -7.7886e-02,  3.4228e-01],\n",
      "         [-3.6742e-01, -8.0942e-01, -6.5212e-01,  9.0399e-01,  1.1046e+00,\n",
      "          -6.6312e-01,  9.2041e-01, -7.7886e-02,  4.2293e-01],\n",
      "         [-3.6742e-01, -8.3772e-01, -6.5212e-01,  7.1309e-01,  1.0322e+00,\n",
      "          -6.4347e-01,  9.1291e-01, -7.7886e-02, -1.4158e-01],\n",
      "         [-4.0968e-01, -8.0942e-01, -6.5212e-01,  6.4367e-01,  9.5990e-01,\n",
      "          -6.1399e-01,  9.2041e-01, -7.7886e-02,  4.2293e-01],\n",
      "         [-4.9420e-01, -5.5465e-01, -6.5212e-01,  2.7922e-01,  9.1469e-01,\n",
      "          -6.0416e-01,  9.2790e-01, -7.7886e-02,  1.9704e-02],\n",
      "         [-4.9420e-01, -8.3772e-01, -7.3978e-01,  2.9658e-01,  8.6044e-01,\n",
      "          -5.6485e-01,  9.0542e-01, -7.7886e-02, -4.6416e-01],\n",
      "         [-5.3646e-01, -8.9434e-01, -7.3978e-01,  1.0567e-01,  7.3386e-01,\n",
      "          -5.1572e-01,  9.8784e-01, -7.7886e-02, -2.2223e-01],\n",
      "         [-5.7872e-01, -8.9434e-01, -6.5212e-01,  1.5451e-03,  8.6044e-01,\n",
      "          -4.6658e-01,  9.8034e-01, -7.7886e-02, -6.2545e-01],\n",
      "         [-3.6742e-01, -8.0942e-01, -7.3978e-01,  2.6187e-01,  1.0232e+00,\n",
      "          -4.3710e-01,  9.6536e-01, -7.7886e-02, -2.2223e-01],\n",
      "         [-1.9837e-01, -8.6603e-01, -6.5212e-01,  7.1309e-01,  1.1046e+00,\n",
      "          -4.1745e-01,  1.0328e+00, -7.7886e-02, -3.0287e-01],\n",
      "         [ 9.7452e-02, -9.2265e-01, -4.7678e-01,  1.1122e+00,  1.1950e+00,\n",
      "          -4.4693e-01,  1.0777e+00, -7.7886e-02,  1.9704e-02],\n",
      "         [ 1.3971e-01, -9.7926e-01, -3.0145e-01,  1.7197e+00,  1.2944e+00,\n",
      "          -4.7641e-01,  1.0478e+00, -7.7886e-02,  5.0357e-01],\n",
      "         [ 1.3971e-01, -9.5095e-01, -3.0145e-01,  2.2056e+00,  1.3849e+00,\n",
      "          -5.5503e-01,  1.0703e+00, -7.7886e-02,  4.2293e-01],\n",
      "         [ 1.3971e-01, -8.9434e-01, -3.8911e-01,  2.7089e+00,  1.4843e+00,\n",
      "          -6.2381e-01,  1.0927e+00, -7.7886e-02,  8.2615e-01],\n",
      "         [ 2.6650e-01, -7.8111e-01,  4.9225e-02,  3.7675e+00,  1.6019e+00,\n",
      "          -7.0243e-01,  1.0178e+00, -7.7886e-02,  6.6486e-01],\n",
      "         [ 5.5191e-02, -9.2265e-01, -3.0145e-01,  4.3229e+00,  1.6561e+00,\n",
      "          -7.8104e-01,  9.6536e-01, -7.7886e-02,  6.6486e-01],\n",
      "         [-1.1385e-01, -9.2265e-01, -3.8911e-01,  4.6005e+00,  1.6832e+00,\n",
      "          -8.4001e-01,  1.0478e+00, -7.7886e-02,  7.4550e-01],\n",
      "         [-2.4064e-01, -9.5095e-01, -3.8911e-01,  4.3055e+00,  1.6651e+00,\n",
      "          -8.5966e-01,  9.4288e-01, -7.7886e-02,  1.3100e+00],\n",
      "         [-2.8290e-01, -9.5095e-01, -5.6445e-01,  3.9758e+00,  1.6380e+00,\n",
      "          -8.6949e-01,  9.5787e-01, -7.7886e-02,  7.4550e-01],\n",
      "         [-3.2516e-01, -9.2265e-01, -6.5212e-01,  3.7675e+00,  1.5566e+00,\n",
      "          -8.0070e-01,  8.9793e-01, -7.7886e-02,  1.2294e+00],\n",
      "         [-4.0968e-01, -8.9434e-01, -7.3978e-01,  2.8824e+00,  1.4662e+00,\n",
      "          -7.7122e-01,  8.3050e-01, -7.7886e-02,  9.8743e-01],\n",
      "         [-4.9420e-01, -8.9434e-01, -8.2745e-01,  2.2577e+00,  1.3849e+00,\n",
      "          -7.2208e-01,  7.7056e-01, -7.7886e-02,  6.6486e-01],\n",
      "         [-4.9420e-01, -8.6603e-01, -8.2745e-01,  1.8238e+00,  1.2944e+00,\n",
      "          -6.9260e-01,  7.3310e-01, -7.7886e-02,  1.8099e-01],\n",
      "         [-5.3646e-01, -8.3772e-01, -9.1512e-01,  1.1643e+00,  1.2221e+00,\n",
      "          -6.9260e-01,  7.3310e-01, -7.7886e-02, -2.2223e-01]],\n",
      "\n",
      "        [[-6.6324e-01, -1.2906e+00, -6.5212e-01,  1.5114e+00,  8.9661e-01,\n",
      "          -9.0879e-01,  1.1302e+00, -7.7886e-02,  3.4228e-01],\n",
      "         [-6.6324e-01, -1.0642e+00, -6.5212e-01,  1.0949e+00,  8.6948e-01,\n",
      "          -9.3827e-01,  1.1227e+00, -7.7886e-02, -3.0287e-01],\n",
      "         [-6.6324e-01, -1.0076e+00, -6.5212e-01,  7.1309e-01,  8.7852e-01,\n",
      "          -9.6775e-01,  1.1302e+00, -7.7886e-02, -4.6416e-01],\n",
      "         [-6.6324e-01, -1.0925e+00, -6.5212e-01,  5.7425e-01,  8.8757e-01,\n",
      "          -9.4810e-01,  1.1377e+00, -7.7886e-02, -6.2545e-01],\n",
      "         [-6.6324e-01, -9.2265e-01, -6.5212e-01,  3.1393e-01,  8.6948e-01,\n",
      "          -9.6775e-01,  1.1452e+00, -7.7886e-02, -2.2223e-01],\n",
      "         [-6.6324e-01, -8.6603e-01, -6.5212e-01,  8.8319e-02,  8.0619e-01,\n",
      "          -9.7758e-01,  1.1377e+00, -7.7886e-02, -5.4480e-01],\n",
      "         [-6.6324e-01, -6.1126e-01, -6.5212e-01, -1.7200e-01,  8.0619e-01,\n",
      "          -9.3827e-01,  1.1676e+00, -7.7886e-02, -2.2223e-01],\n",
      "         [-6.6324e-01, -6.9619e-01, -6.5212e-01, -1.8936e-01,  8.7852e-01,\n",
      "          -9.0879e-01,  1.1527e+00, -7.7886e-02, -4.6416e-01],\n",
      "         [-5.3646e-01, -8.3772e-01, -5.6445e-01,  1.0567e-01,  1.0141e+00,\n",
      "          -8.7931e-01,  1.1901e+00, -7.7886e-02, -3.8352e-01],\n",
      "         [-2.8290e-01, -9.7926e-01, -4.7678e-01,  6.0896e-01,  1.1859e+00,\n",
      "          -8.9897e-01,  1.1751e+00, -7.7886e-02, -6.2545e-01],\n",
      "         [-1.5611e-01, -1.0076e+00, -3.8911e-01,  8.6928e-01,  1.2673e+00,\n",
      "          -9.3827e-01,  1.2201e+00, -7.7886e-02, -1.4158e-01],\n",
      "         [-7.1592e-02, -1.0642e+00, -2.1378e-01,  1.4073e+00,  1.3758e+00,\n",
      "          -9.9723e-01,  1.2426e+00, -7.7886e-02, -1.4158e-01],\n",
      "         [-2.9331e-02, -8.9434e-01, -3.8442e-02,  2.1015e+00,  1.5114e+00,\n",
      "          -1.0758e+00,  1.2351e+00, -7.7886e-02,  1.0035e-01],\n",
      "         [-1.5611e-01, -9.7926e-01, -1.2611e-01,  2.9171e+00,  1.6290e+00,\n",
      "          -1.1839e+00,  1.2501e+00, -7.7886e-02,  2.6164e-01],\n",
      "         [-1.1385e-01, -8.0942e-01,  2.2456e-01,  3.8196e+00,  1.7103e+00,\n",
      "          -1.2822e+00,  1.2351e+00, -7.7886e-02,  3.4228e-01],\n",
      "         [-1.9837e-01, -7.8111e-01,  1.3689e-01,  4.4096e+00,  1.7827e+00,\n",
      "          -1.3608e+00,  1.0927e+00, -7.7886e-02,  1.1487e+00],\n",
      "         [-3.6742e-01, -1.0925e+00, -3.8911e-01,  3.7155e+00,  1.8098e+00,\n",
      "          -1.4198e+00,  1.0178e+00, -7.7886e-02,  8.2615e-01],\n",
      "         [-4.5194e-01, -1.1208e+00, -4.7678e-01,  3.1254e+00,  1.7736e+00,\n",
      "          -1.4788e+00,  1.0253e+00, -7.7886e-02,  7.4550e-01],\n",
      "         [-4.0968e-01, -1.0925e+00, -4.7678e-01,  3.0733e+00,  1.7375e+00,\n",
      "          -1.4788e+00,  1.0553e+00, -7.7886e-02,  7.4550e-01],\n",
      "         [-3.6742e-01, -9.2265e-01, -4.7678e-01,  2.8477e+00,  1.6651e+00,\n",
      "          -1.4591e+00,  1.0628e+00, -7.7886e-02,  4.2293e-01],\n",
      "         [-3.2516e-01, -8.3772e-01, -3.8911e-01,  2.6915e+00,  1.6019e+00,\n",
      "          -1.4198e+00,  1.0777e+00, -7.7886e-02,  1.9704e-02],\n",
      "         [-4.0968e-01, -5.8296e-01, -3.8911e-01,  2.0494e+00,  1.5295e+00,\n",
      "          -1.3510e+00,  1.1002e+00, -7.7886e-02, -4.6416e-01],\n",
      "         [-4.9420e-01, -2.9988e-01, -3.8911e-01,  1.3899e+00,  1.3035e+00,\n",
      "          -1.3608e+00,  1.0777e+00, -7.7886e-02, -3.0287e-01],\n",
      "         [-5.3646e-01, -5.5465e-01, -3.8911e-01,  1.2337e+00,  1.2673e+00,\n",
      "          -1.3805e+00,  1.0703e+00, -7.7886e-02, -7.0609e-01]]])\n",
      "--------------------\n",
      "torch.Size([128, 1])\n",
      "tensor([104.])\n",
      "--------------------\n",
      "torch.Size([128, 24])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True])\n",
      "--------------------\n",
      "[2833, 1851, 11063, 10863, 9644, 7877, 4416, 1009, 8552, 8158, 3147, 4046, 57, 1038, 3469, 642, 4429, 6052, 8449, 5088, 11741, 4528, 704, 2280, 9586, 2750, 6847, 3183, 416, 4417, 2963, 1511, 11099, 4888, 5287, 9983, 396, 11505, 2431, 961, 1513, 7691, 2313, 1074, 4099, 3174, 3692, 4002, 7119, 3525, 1761, 9114, 4911, 10321, 8442, 6394, 6655, 7656, 345, 3811, 8604, 2924, 6096, 9752, 5183, 958, 8927, 9269, 4752, 1782, 4083, 5524, 2862, 3187, 10387, 3098, 1215, 628, 11188, 6202, 7058, 11094, 8257, 249, 9126, 10983, 879, 6741, 6259, 7155, 5961, 3004, 3347, 5623, 10958, 3441, 11359, 3046, 10308, 4422, 5856, 726, 8087, 8463, 10176, 2385, 9839, 5625, 5628, 1727, 59, 7591, 8944, 9924, 7107, 4350, 11657, 2036, 7027, 2694, 10231, 120, 11905, 382, 3234, 6279, 11266, 8627]\n"
     ]
    }
   ],
   "source": [
    "print(config[\"batch_size\"])\n",
    "for batch in train_loader:\n",
    "    X, targets, padding_masks, IDs = batch\n",
    "    print(X.shape)\n",
    "    print(X[0:2])\n",
    "    print(\"-\"*20)\n",
    "    print(targets.shape)\n",
    "    print(targets[0])\n",
    "    print(\"-\"*20)\n",
    "    print(padding_masks.shape)\n",
    "    print(padding_masks[0])\n",
    "    print(\"-\"*20)\n",
    "    print(IDs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00b109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4560138",
   "metadata": {},
   "source": [
    "# Evaluate on validation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823cbc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:16,159 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 0   0.0% | batch:         0 of        40\t|\tloss: 34534.8\n",
      "Evaluating Epoch 0   2.5% | batch:         1 of        40\t|\tloss: 10961.1\n",
      "Evaluating Epoch 0   5.0% | batch:         2 of        40\t|\tloss: 49503.3\n",
      "Evaluating Epoch 0   7.5% | batch:         3 of        40\t|\tloss: 30586.2\n",
      "Evaluating Epoch 0  10.0% | batch:         4 of        40\t|\tloss: 11963.1\n",
      "Evaluating Epoch 0  12.5% | batch:         5 of        40\t|\tloss: 17937.4\n",
      "Evaluating Epoch 0  15.0% | batch:         6 of        40\t|\tloss: 44273.1\n",
      "Evaluating Epoch 0  17.5% | batch:         7 of        40\t|\tloss: 18926.2\n",
      "Evaluating Epoch 0  20.0% | batch:         8 of        40\t|\tloss: 13033\n",
      "Evaluating Epoch 0  22.5% | batch:         9 of        40\t|\tloss: 33832.9\n",
      "Evaluating Epoch 0  25.0% | batch:        10 of        40\t|\tloss: 28447.8\n",
      "Evaluating Epoch 0  27.5% | batch:        11 of        40\t|\tloss: 15381.3\n",
      "Evaluating Epoch 0  30.0% | batch:        12 of        40\t|\tloss: 67587\n",
      "Evaluating Epoch 0  32.5% | batch:        13 of        40\t|\tloss: 28920.4\n",
      "Evaluating Epoch 0  35.0% | batch:        14 of        40\t|\tloss: 15276.7\n",
      "Evaluating Epoch 0  37.5% | batch:        15 of        40\t|\tloss: 50046.3\n",
      "Evaluating Epoch 0  40.0% | batch:        16 of        40\t|\tloss: 33088.1\n",
      "Evaluating Epoch 0  42.5% | batch:        17 of        40\t|\tloss: 21318.5\n",
      "Evaluating Epoch 0  45.0% | batch:        18 of        40\t|\tloss: 24564.6\n",
      "Evaluating Epoch 0  47.5% | batch:        19 of        40\t|\tloss: 55400.2\n",
      "Evaluating Epoch 0  50.0% | batch:        20 of        40\t|\tloss: 21959\n",
      "Evaluating Epoch 0  52.5% | batch:        21 of        40\t|\tloss: 11472.6\n",
      "Evaluating Epoch 0  55.0% | batch:        22 of        40\t|\tloss: 36958.7\n",
      "Evaluating Epoch 0  57.5% | batch:        23 of        40\t|\tloss: 30234.5\n",
      "Evaluating Epoch 0  60.0% | batch:        24 of        40\t|\tloss: 12198.8\n",
      "Evaluating Epoch 0  62.5% | batch:        25 of        40\t|\tloss: 54063.7\n",
      "Evaluating Epoch 0  65.0% | batch:        26 of        40\t|\tloss: 50372.7\n",
      "Evaluating Epoch 0  67.5% | batch:        27 of        40\t|\tloss: 17497.5\n",
      "Evaluating Epoch 0  70.0% | batch:        28 of        40\t|\tloss: 38109.3\n",
      "Evaluating Epoch 0  72.5% | batch:        29 of        40\t|\tloss: 54051.9\n",
      "Evaluating Epoch 0  75.0% | batch:        30 of        40\t|\tloss: 17153.5\n",
      "Evaluating Epoch 0  77.5% | batch:        31 of        40\t|\tloss: 17636\n",
      "Evaluating Epoch 0  80.0% | batch:        32 of        40\t|\tloss: 54735.8\n",
      "Evaluating Epoch 0  82.5% | batch:        33 of        40\t|\tloss: 26179.2\n",
      "Evaluating Epoch 0  85.0% | batch:        34 of        40\t|\tloss: 12767.2\n",
      "Evaluating Epoch 0  87.5% | batch:        35 of        40\t|\tloss: 51785.8\n",
      "Evaluating Epoch 0  90.0% | batch:        36 of        40\t|\tloss: 34445.6\n",
      "Evaluating Epoch 0  92.5% | batch:        37 of        40\t|\tloss: 16547.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:17,265 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 1.1053051948547363 seconds\n",
      "\n",
      "2023-05-09 14:20:17,266 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 1.1053051948547363 seconds\n",
      "2023-05-09 14:20:17,266 | INFO : Avg batch val. time: 0.027632629871368407 seconds\n",
      "2023-05-09 14:20:17,267 | INFO : Avg sample val. time: 0.00021895903226123938 seconds\n",
      "2023-05-09 14:20:17,267 | INFO : Epoch 0 Validation Summary: epoch: 0.000000 | loss: 31395.387233 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 0  95.0% | batch:        38 of        40\t|\tloss: 48505.5\n",
      "Evaluating Epoch 0  97.5% | batch:        39 of        40\t|\tloss: 59198.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/anaconda3/envs/transformer/lib/python3.8/site-packages/numpy/lib/npyio.py:713: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config, best_metrics,\n",
    "                                                      best_value, epoch=0)\n",
    "metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "metrics.append(list(metrics_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f5b41",
   "metadata": {},
   "source": [
    "# Starting training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe4763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:17,286 | INFO : Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1   0.0% | batch:         0 of        94\t|\tloss: 33836.4\n",
      "Training Epoch 1   1.1% | batch:         1 of        94\t|\tloss: 26243.3\n",
      "Training Epoch 1   2.1% | batch:         2 of        94\t|\tloss: 39148.2\n",
      "Training Epoch 1   3.2% | batch:         3 of        94\t|\tloss: 24494.2\n",
      "Training Epoch 1   4.3% | batch:         4 of        94\t|\tloss: 33446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/Documents/mvts_transformer/src/optimizers.py:69: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541702/work/torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1   5.3% | batch:         5 of        94\t|\tloss: 35687.4\n",
      "Training Epoch 1   6.4% | batch:         6 of        94\t|\tloss: 26941.9\n",
      "Training Epoch 1   7.4% | batch:         7 of        94\t|\tloss: 29082.4\n",
      "Training Epoch 1   8.5% | batch:         8 of        94\t|\tloss: 28462.9\n",
      "Training Epoch 1   9.6% | batch:         9 of        94\t|\tloss: 36081.4\n",
      "Training Epoch 1  10.6% | batch:        10 of        94\t|\tloss: 34735.4\n",
      "Training Epoch 1  11.7% | batch:        11 of        94\t|\tloss: 32662.1\n",
      "Training Epoch 1  12.8% | batch:        12 of        94\t|\tloss: 33319.9\n",
      "Training Epoch 1  13.8% | batch:        13 of        94\t|\tloss: 32897.8\n",
      "Training Epoch 1  14.9% | batch:        14 of        94\t|\tloss: 33192.8\n",
      "Training Epoch 1  16.0% | batch:        15 of        94\t|\tloss: 28108.6\n",
      "Training Epoch 1  17.0% | batch:        16 of        94\t|\tloss: 31768.1\n",
      "Training Epoch 1  18.1% | batch:        17 of        94\t|\tloss: 27329.8\n",
      "Training Epoch 1  19.1% | batch:        18 of        94\t|\tloss: 40715.6\n",
      "Training Epoch 1  20.2% | batch:        19 of        94\t|\tloss: 20192.9\n",
      "Training Epoch 1  21.3% | batch:        20 of        94\t|\tloss: 26286.1\n",
      "Training Epoch 1  22.3% | batch:        21 of        94\t|\tloss: 32731.8\n",
      "Training Epoch 1  23.4% | batch:        22 of        94\t|\tloss: 26340.6\n",
      "Training Epoch 1  24.5% | batch:        23 of        94\t|\tloss: 32196.2\n",
      "Training Epoch 1  25.5% | batch:        24 of        94\t|\tloss: 34472.8\n",
      "Training Epoch 1  26.6% | batch:        25 of        94\t|\tloss: 29710.6\n",
      "Training Epoch 1  27.7% | batch:        26 of        94\t|\tloss: 26766.2\n",
      "Training Epoch 1  28.7% | batch:        27 of        94\t|\tloss: 24823.1\n",
      "Training Epoch 1  29.8% | batch:        28 of        94\t|\tloss: 29412.6\n",
      "Training Epoch 1  30.9% | batch:        29 of        94\t|\tloss: 26895.6\n",
      "Training Epoch 1  31.9% | batch:        30 of        94\t|\tloss: 53917.1\n",
      "Training Epoch 1  33.0% | batch:        31 of        94\t|\tloss: 37057.7\n",
      "Training Epoch 1  34.0% | batch:        32 of        94\t|\tloss: 30476.6\n",
      "Training Epoch 1  35.1% | batch:        33 of        94\t|\tloss: 33275.5\n",
      "Training Epoch 1  36.2% | batch:        34 of        94\t|\tloss: 35034.7\n",
      "Training Epoch 1  37.2% | batch:        35 of        94\t|\tloss: 31199.3\n",
      "Training Epoch 1  38.3% | batch:        36 of        94\t|\tloss: 33532.5\n",
      "Training Epoch 1  39.4% | batch:        37 of        94\t|\tloss: 32131\n",
      "Training Epoch 1  40.4% | batch:        38 of        94\t|\tloss: 25830.1\n",
      "Training Epoch 1  41.5% | batch:        39 of        94\t|\tloss: 33517.6\n",
      "Training Epoch 1  42.6% | batch:        40 of        94\t|\tloss: 37348.1\n",
      "Training Epoch 1  43.6% | batch:        41 of        94\t|\tloss: 28007.1\n",
      "Training Epoch 1  44.7% | batch:        42 of        94\t|\tloss: 25410\n",
      "Training Epoch 1  45.7% | batch:        43 of        94\t|\tloss: 32894.8\n",
      "Training Epoch 1  46.8% | batch:        44 of        94\t|\tloss: 39769.3\n",
      "Training Epoch 1  47.9% | batch:        45 of        94\t|\tloss: 32202.9\n",
      "Training Epoch 1  48.9% | batch:        46 of        94\t|\tloss: 31334.9\n",
      "Training Epoch 1  50.0% | batch:        47 of        94\t|\tloss: 28223.1\n",
      "Training Epoch 1  51.1% | batch:        48 of        94\t|\tloss: 28362.7\n",
      "Training Epoch 1  52.1% | batch:        49 of        94\t|\tloss: 36644.3\n",
      "Training Epoch 1  53.2% | batch:        50 of        94\t|\tloss: 32916.7\n",
      "Training Epoch 1  54.3% | batch:        51 of        94\t|\tloss: 32584.6\n",
      "Training Epoch 1  55.3% | batch:        52 of        94\t|\tloss: 26412.5\n",
      "Training Epoch 1  56.4% | batch:        53 of        94\t|\tloss: 26394.5\n",
      "Training Epoch 1  57.4% | batch:        54 of        94\t|\tloss: 28288.8\n",
      "Training Epoch 1  58.5% | batch:        55 of        94\t|\tloss: 28222.8\n",
      "Training Epoch 1  59.6% | batch:        56 of        94\t|\tloss: 26651\n",
      "Training Epoch 1  60.6% | batch:        57 of        94\t|\tloss: 29490.5\n",
      "Training Epoch 1  61.7% | batch:        58 of        94\t|\tloss: 29760.9\n",
      "Training Epoch 1  62.8% | batch:        59 of        94\t|\tloss: 29288.1\n",
      "Training Epoch 1  63.8% | batch:        60 of        94\t|\tloss: 30136.8\n",
      "Training Epoch 1  64.9% | batch:        61 of        94\t|\tloss: 25896.4\n",
      "Training Epoch 1  66.0% | batch:        62 of        94\t|\tloss: 32505.6\n",
      "Training Epoch 1  67.0% | batch:        63 of        94\t|\tloss: 23290.3\n",
      "Training Epoch 1  68.1% | batch:        64 of        94\t|\tloss: 24606\n",
      "Training Epoch 1  69.1% | batch:        65 of        94\t|\tloss: 35324.3\n",
      "Training Epoch 1  70.2% | batch:        66 of        94\t|\tloss: 29543.9\n",
      "Training Epoch 1  71.3% | batch:        67 of        94\t|\tloss: 25713.1\n",
      "Training Epoch 1  72.3% | batch:        68 of        94\t|\tloss: 26701.5\n",
      "Training Epoch 1  73.4% | batch:        69 of        94\t|\tloss: 29103.3\n",
      "Training Epoch 1  74.5% | batch:        70 of        94\t|\tloss: 24073.2\n",
      "Training Epoch 1  75.5% | batch:        71 of        94\t|\tloss: 31971.9\n",
      "Training Epoch 1  76.6% | batch:        72 of        94\t|\tloss: 29429.7\n",
      "Training Epoch 1  77.7% | batch:        73 of        94\t|\tloss: 32625.1\n",
      "Training Epoch 1  78.7% | batch:        74 of        94\t|\tloss: 27917.3\n",
      "Training Epoch 1  79.8% | batch:        75 of        94\t|\tloss: 29510.1\n",
      "Training Epoch 1  80.9% | batch:        76 of        94\t|\tloss: 35550.3\n",
      "Training Epoch 1  81.9% | batch:        77 of        94\t|\tloss: 36776.9\n",
      "Training Epoch 1  83.0% | batch:        78 of        94\t|\tloss: 37018\n",
      "Training Epoch 1  84.0% | batch:        79 of        94\t|\tloss: 31801.1\n",
      "Training Epoch 1  85.1% | batch:        80 of        94\t|\tloss: 24454.9\n",
      "Training Epoch 1  86.2% | batch:        81 of        94\t|\tloss: 23695.2\n",
      "Training Epoch 1  87.2% | batch:        82 of        94\t|\tloss: 23185.6\n",
      "Training Epoch 1  88.3% | batch:        83 of        94\t|\tloss: 36234.3\n",
      "Training Epoch 1  89.4% | batch:        84 of        94\t|\tloss: 25112.5\n",
      "Training Epoch 1  90.4% | batch:        85 of        94\t|\tloss: 25821.6\n",
      "Training Epoch 1  91.5% | batch:        86 of        94\t|\tloss: 23593.3\n",
      "Training Epoch 1  92.6% | batch:        87 of        94\t|\tloss: 24965.3\n",
      "Training Epoch 1  93.6% | batch:        88 of        94\t|\tloss: 24562.7\n",
      "Training Epoch 1  94.7% | batch:        89 of        94\t|\tloss: 27506.3\n",
      "Training Epoch 1  95.7% | batch:        90 of        94\t|\tloss: 30520.5\n",
      "Training Epoch 1  96.8% | batch:        91 of        94\t|\tloss: 27446.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:19,374 | INFO : Epoch 1 Training Summary: epoch: 1.000000 | loss: 30242.116851 | \n",
      "2023-05-09 14:20:19,375 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 2.079542875289917 seconds\n",
      "\n",
      "2023-05-09 14:20:19,376 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.079542875289917 seconds\n",
      "2023-05-09 14:20:19,376 | INFO : Avg batch train. time: 0.022122796545637414 seconds\n",
      "2023-05-09 14:20:19,377 | INFO : Avg sample train. time: 0.00017448757134501736 seconds\n",
      "2023-05-09 14:20:19,378 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1  97.9% | batch:        92 of        94\t|\tloss: 22996.4\n",
      "Training Epoch 1  98.9% | batch:        93 of        94\t|\tloss: 18948.8\n",
      "\n",
      "Evaluating Epoch 1   0.0% | batch:         0 of        40\t|\tloss: 29372.8\n",
      "Evaluating Epoch 1   2.5% | batch:         1 of        40\t|\tloss: 10550.1\n",
      "Evaluating Epoch 1   5.0% | batch:         2 of        40\t|\tloss: 36963.3\n",
      "Evaluating Epoch 1   7.5% | batch:         3 of        40\t|\tloss: 25418.8\n",
      "Evaluating Epoch 1  10.0% | batch:         4 of        40\t|\tloss: 11382.1\n",
      "Evaluating Epoch 1  12.5% | batch:         5 of        40\t|\tloss: 14642.8\n",
      "Evaluating Epoch 1  15.0% | batch:         6 of        40\t|\tloss: 35750\n",
      "Evaluating Epoch 1  17.5% | batch:         7 of        40\t|\tloss: 17606.8\n",
      "Evaluating Epoch 1  20.0% | batch:         8 of        40\t|\tloss: 12536.4\n",
      "Evaluating Epoch 1  22.5% | batch:         9 of        40\t|\tloss: 27220.6\n",
      "Evaluating Epoch 1  25.0% | batch:        10 of        40\t|\tloss: 25182.5\n",
      "Evaluating Epoch 1  27.5% | batch:        11 of        40\t|\tloss: 14063.7\n",
      "Evaluating Epoch 1  30.0% | batch:        12 of        40\t|\tloss: 52619.5\n",
      "Evaluating Epoch 1  32.5% | batch:        13 of        40\t|\tloss: 24143.4\n",
      "Evaluating Epoch 1  35.0% | batch:        14 of        40\t|\tloss: 14233.1\n",
      "Evaluating Epoch 1  37.5% | batch:        15 of        40\t|\tloss: 38292.9\n",
      "Evaluating Epoch 1  40.0% | batch:        16 of        40\t|\tloss: 27912.2\n",
      "Evaluating Epoch 1  42.5% | batch:        17 of        40\t|\tloss: 19530.2\n",
      "Evaluating Epoch 1  45.0% | batch:        18 of        40\t|\tloss: 20878.6\n",
      "Evaluating Epoch 1  47.5% | batch:        19 of        40\t|\tloss: 43659.2\n",
      "Evaluating Epoch 1  50.0% | batch:        20 of        40\t|\tloss: 20698\n",
      "Evaluating Epoch 1  52.5% | batch:        21 of        40\t|\tloss: 11199.1\n",
      "Evaluating Epoch 1  55.0% | batch:        22 of        40\t|\tloss: 30688.3\n",
      "Evaluating Epoch 1  57.5% | batch:        23 of        40\t|\tloss: 24590.6\n",
      "Evaluating Epoch 1  60.0% | batch:        24 of        40\t|\tloss: 11473.8\n",
      "Evaluating Epoch 1  62.5% | batch:        25 of        40\t|\tloss: 41424.7\n",
      "Evaluating Epoch 1  65.0% | batch:        26 of        40\t|\tloss: 43872.6\n",
      "Evaluating Epoch 1  67.5% | batch:        27 of        40\t|\tloss: 16763.9\n",
      "Evaluating Epoch 1  70.0% | batch:        28 of        40\t|\tloss: 30396.6\n",
      "Evaluating Epoch 1  72.5% | batch:        29 of        40\t|\tloss: 43952.2\n",
      "Evaluating Epoch 1  75.0% | batch:        30 of        40\t|\tloss: 15671.7\n",
      "Evaluating Epoch 1  77.5% | batch:        31 of        40\t|\tloss: 15360.9\n",
      "Evaluating Epoch 1  80.0% | batch:        32 of        40\t|\tloss: 42067.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:19,848 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4703075885772705 seconds\n",
      "\n",
      "2023-05-09 14:20:19,849 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.7878063917160034 seconds\n",
      "2023-05-09 14:20:19,849 | INFO : Avg batch val. time: 0.019695159792900086 seconds\n",
      "2023-05-09 14:20:19,850 | INFO : Avg sample val. time: 0.00015606307284389925 seconds\n",
      "2023-05-09 14:20:19,850 | INFO : Epoch 1 Validation Summary: epoch: 1.000000 | loss: 26037.953893 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 1  82.5% | batch:        33 of        40\t|\tloss: 22601.8\n",
      "Evaluating Epoch 1  85.0% | batch:        34 of        40\t|\tloss: 11840.3\n",
      "Evaluating Epoch 1  87.5% | batch:        35 of        40\t|\tloss: 38367\n",
      "Evaluating Epoch 1  90.0% | batch:        36 of        40\t|\tloss: 29474.9\n",
      "Evaluating Epoch 1  92.5% | batch:        37 of        40\t|\tloss: 15594.8\n",
      "Evaluating Epoch 1  95.0% | batch:        38 of        40\t|\tloss: 37511.1\n",
      "Evaluating Epoch 1  97.5% | batch:        39 of        40\t|\tloss: 48830.1\n",
      "\n",
      "Training Epoch 2   0.0% | batch:         0 of        94\t|\tloss: 27735.9\n",
      "Training Epoch 2   1.1% | batch:         1 of        94\t|\tloss: 27860.4\n",
      "Training Epoch 2   2.1% | batch:         2 of        94\t|\tloss: 25871.1\n",
      "Training Epoch 2   3.2% | batch:         3 of        94\t|\tloss: 23201.5\n",
      "Training Epoch 2   4.3% | batch:         4 of        94\t|\tloss: 24135.4\n",
      "Training Epoch 2   5.3% | batch:         5 of        94\t|\tloss: 24115.3\n",
      "Training Epoch 2   6.4% | batch:         6 of        94\t|\tloss: 23185.3\n",
      "Training Epoch 2   7.4% | batch:         7 of        94\t|\tloss: 24580.3\n",
      "Training Epoch 2   8.5% | batch:         8 of        94\t|\tloss: 23982.3\n",
      "Training Epoch 2   9.6% | batch:         9 of        94\t|\tloss: 22894.8\n",
      "Training Epoch 2  10.6% | batch:        10 of        94\t|\tloss: 31242.9\n",
      "Training Epoch 2  11.7% | batch:        11 of        94\t|\tloss: 25322.4\n",
      "Training Epoch 2  12.8% | batch:        12 of        94\t|\tloss: 22133.6\n",
      "Training Epoch 2  13.8% | batch:        13 of        94\t|\tloss: 27255\n",
      "Training Epoch 2  14.9% | batch:        14 of        94\t|\tloss: 29815.2\n",
      "Training Epoch 2  16.0% | batch:        15 of        94\t|\tloss: 27306.8\n",
      "Training Epoch 2  17.0% | batch:        16 of        94\t|\tloss: 28994.8\n",
      "Training Epoch 2  18.1% | batch:        17 of        94\t|\tloss: 23530.5\n",
      "Training Epoch 2  19.1% | batch:        18 of        94\t|\tloss: 25158.1\n",
      "Training Epoch 2  20.2% | batch:        19 of        94\t|\tloss: 25276.3\n",
      "Training Epoch 2  21.3% | batch:        20 of        94\t|\tloss: 28258.4\n",
      "Training Epoch 2  22.3% | batch:        21 of        94\t|\tloss: 20752.5\n",
      "Training Epoch 2  23.4% | batch:        22 of        94\t|\tloss: 30530.5\n",
      "Training Epoch 2  24.5% | batch:        23 of        94\t|\tloss: 29506.1\n",
      "Training Epoch 2  25.5% | batch:        24 of        94\t|\tloss: 29556.5\n",
      "Training Epoch 2  26.6% | batch:        25 of        94\t|\tloss: 22104.1\n",
      "Training Epoch 2  27.7% | batch:        26 of        94\t|\tloss: 20915.3\n",
      "Training Epoch 2  28.7% | batch:        27 of        94\t|\tloss: 19412.4\n",
      "Training Epoch 2  29.8% | batch:        28 of        94\t|\tloss: 22720.9\n",
      "Training Epoch 2  30.9% | batch:        29 of        94\t|\tloss: 30492.9\n",
      "Training Epoch 2  31.9% | batch:        30 of        94\t|\tloss: 18773.4\n",
      "Training Epoch 2  33.0% | batch:        31 of        94\t|\tloss: 24316.5\n",
      "Training Epoch 2  34.0% | batch:        32 of        94\t|\tloss: 25847.4\n",
      "Training Epoch 2  35.1% | batch:        33 of        94\t|\tloss: 23138.7\n",
      "Training Epoch 2  36.2% | batch:        34 of        94\t|\tloss: 21923.4\n",
      "Training Epoch 2  37.2% | batch:        35 of        94\t|\tloss: 20149.5\n",
      "Training Epoch 2  38.3% | batch:        36 of        94\t|\tloss: 26868.7\n",
      "Training Epoch 2  39.4% | batch:        37 of        94\t|\tloss: 27722.5\n",
      "Training Epoch 2  40.4% | batch:        38 of        94\t|\tloss: 25626.5\n",
      "Training Epoch 2  41.5% | batch:        39 of        94\t|\tloss: 21947.1\n",
      "Training Epoch 2  42.6% | batch:        40 of        94\t|\tloss: 21414.9\n",
      "Training Epoch 2  43.6% | batch:        41 of        94\t|\tloss: 23420.3\n",
      "Training Epoch 2  44.7% | batch:        42 of        94\t|\tloss: 25857.3\n",
      "Training Epoch 2  45.7% | batch:        43 of        94\t|\tloss: 18966.6\n",
      "Training Epoch 2  46.8% | batch:        44 of        94\t|\tloss: 25358.6\n",
      "Training Epoch 2  47.9% | batch:        45 of        94\t|\tloss: 21583.8\n",
      "Training Epoch 2  48.9% | batch:        46 of        94\t|\tloss: 21517.8\n",
      "Training Epoch 2  50.0% | batch:        47 of        94\t|\tloss: 32559.3\n",
      "Training Epoch 2  51.1% | batch:        48 of        94\t|\tloss: 22679.5\n",
      "Training Epoch 2  52.1% | batch:        49 of        94\t|\tloss: 18664\n",
      "Training Epoch 2  53.2% | batch:        50 of        94\t|\tloss: 21904\n",
      "Training Epoch 2  54.3% | batch:        51 of        94\t|\tloss: 24597.2\n",
      "Training Epoch 2  55.3% | batch:        52 of        94\t|\tloss: 17636.7\n",
      "Training Epoch 2  56.4% | batch:        53 of        94\t|\tloss: 20176.9\n",
      "Training Epoch 2  57.4% | batch:        54 of        94\t|\tloss: 18171.1\n",
      "Training Epoch 2  58.5% | batch:        55 of        94\t|\tloss: 15295.3\n",
      "Training Epoch 2  59.6% | batch:        56 of        94\t|\tloss: 21628.9\n",
      "Training Epoch 2  60.6% | batch:        57 of        94\t|\tloss: 25364.7\n",
      "Training Epoch 2  61.7% | batch:        58 of        94\t|\tloss: 19608.7\n",
      "Training Epoch 2  62.8% | batch:        59 of        94\t|\tloss: 20829.7\n",
      "Training Epoch 2  63.8% | batch:        60 of        94\t|\tloss: 20611.3\n",
      "Training Epoch 2  64.9% | batch:        61 of        94\t|\tloss: 21809.9\n",
      "Training Epoch 2  66.0% | batch:        62 of        94\t|\tloss: 24062.9\n",
      "Training Epoch 2  67.0% | batch:        63 of        94\t|\tloss: 17455.4\n",
      "Training Epoch 2  68.1% | batch:        64 of        94\t|\tloss: 18493.5\n",
      "Training Epoch 2  69.1% | batch:        65 of        94\t|\tloss: 17446.8\n",
      "Training Epoch 2  70.2% | batch:        66 of        94\t|\tloss: 13490.2\n",
      "Training Epoch 2  71.3% | batch:        67 of        94\t|\tloss: 22833.4\n",
      "Training Epoch 2  72.3% | batch:        68 of        94\t|\tloss: 19043.1\n",
      "Training Epoch 2  73.4% | batch:        69 of        94\t|\tloss: 18660.4\n",
      "Training Epoch 2  74.5% | batch:        70 of        94\t|\tloss: 16356.8\n",
      "Training Epoch 2  75.5% | batch:        71 of        94\t|\tloss: 21519.3\n",
      "Training Epoch 2  76.6% | batch:        72 of        94\t|\tloss: 21402.4\n",
      "Training Epoch 2  77.7% | batch:        73 of        94\t|\tloss: 17604.7\n",
      "Training Epoch 2  78.7% | batch:        74 of        94\t|\tloss: 23727.4\n",
      "Training Epoch 2  79.8% | batch:        75 of        94\t|\tloss: 17246.6\n",
      "Training Epoch 2  80.9% | batch:        76 of        94\t|\tloss: 24642.9\n",
      "Training Epoch 2  81.9% | batch:        77 of        94\t|\tloss: 20511.8\n",
      "Training Epoch 2  83.0% | batch:        78 of        94\t|\tloss: 19289.1\n",
      "Training Epoch 2  84.0% | batch:        79 of        94\t|\tloss: 20446.9\n",
      "Training Epoch 2  85.1% | batch:        80 of        94\t|\tloss: 18387.1\n",
      "Training Epoch 2  86.2% | batch:        81 of        94\t|\tloss: 17415.7\n",
      "Training Epoch 2  87.2% | batch:        82 of        94\t|\tloss: 17283.5\n",
      "Training Epoch 2  88.3% | batch:        83 of        94\t|\tloss: 14845.4\n",
      "Training Epoch 2  89.4% | batch:        84 of        94\t|\tloss: 19062.1\n",
      "Training Epoch 2  90.4% | batch:        85 of        94\t|\tloss: 17510.3\n",
      "Training Epoch 2  91.5% | batch:        86 of        94\t|\tloss: 16119.2\n",
      "Training Epoch 2  92.6% | batch:        87 of        94\t|\tloss: 14236.6\n",
      "Training Epoch 2  93.6% | batch:        88 of        94\t|\tloss: 17175.1\n",
      "Training Epoch 2  94.7% | batch:        89 of        94\t|\tloss: 16740.3\n",
      "Training Epoch 2  95.7% | batch:        90 of        94\t|\tloss: 16138.5\n",
      "Training Epoch 2  96.8% | batch:        91 of        94\t|\tloss: 17061.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:21,734 | INFO : Epoch 2 Training Summary: epoch: 2.000000 | loss: 22202.337968 | \n",
      "2023-05-09 14:20:21,735 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8611910343170166 seconds\n",
      "\n",
      "2023-05-09 14:20:21,735 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9703669548034668 seconds\n",
      "2023-05-09 14:20:21,736 | INFO : Avg batch train. time: 0.020961350583015605 seconds\n",
      "2023-05-09 14:20:21,737 | INFO : Avg sample train. time: 0.00016532698060106282 seconds\n",
      "2023-05-09 14:20:21,737 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2  97.9% | batch:        92 of        94\t|\tloss: 25693.5\n",
      "Training Epoch 2  98.9% | batch:        93 of        94\t|\tloss: 13947.3\n",
      "\n",
      "Evaluating Epoch 2   0.0% | batch:         0 of        40\t|\tloss: 19485.2\n",
      "Evaluating Epoch 2   2.5% | batch:         1 of        40\t|\tloss: 10056.9\n",
      "Evaluating Epoch 2   5.0% | batch:         2 of        40\t|\tloss: 20164.2\n",
      "Evaluating Epoch 2   7.5% | batch:         3 of        40\t|\tloss: 16537.3\n",
      "Evaluating Epoch 2  10.0% | batch:         4 of        40\t|\tloss: 9801.17\n",
      "Evaluating Epoch 2  12.5% | batch:         5 of        40\t|\tloss: 8973.09\n",
      "Evaluating Epoch 2  15.0% | batch:         6 of        40\t|\tloss: 22459.7\n",
      "Evaluating Epoch 2  17.5% | batch:         7 of        40\t|\tloss: 14183.7\n",
      "Evaluating Epoch 2  20.0% | batch:         8 of        40\t|\tloss: 11045\n",
      "Evaluating Epoch 2  22.5% | batch:         9 of        40\t|\tloss: 14759.9\n",
      "Evaluating Epoch 2  25.0% | batch:        10 of        40\t|\tloss: 17985.7\n",
      "Evaluating Epoch 2  27.5% | batch:        11 of        40\t|\tloss: 11895.9\n",
      "Evaluating Epoch 2  30.0% | batch:        12 of        40\t|\tloss: 30513\n",
      "Evaluating Epoch 2  32.5% | batch:        13 of        40\t|\tloss: 15263.4\n",
      "Evaluating Epoch 2  35.0% | batch:        14 of        40\t|\tloss: 12592.7\n",
      "Evaluating Epoch 2  37.5% | batch:        15 of        40\t|\tloss: 22390.9\n",
      "Evaluating Epoch 2  40.0% | batch:        16 of        40\t|\tloss: 16978.7\n",
      "Evaluating Epoch 2  42.5% | batch:        17 of        40\t|\tloss: 16321\n",
      "Evaluating Epoch 2  45.0% | batch:        18 of        40\t|\tloss: 14955.7\n",
      "Evaluating Epoch 2  47.5% | batch:        19 of        40\t|\tloss: 25140.5\n",
      "Evaluating Epoch 2  50.0% | batch:        20 of        40\t|\tloss: 16178.1\n",
      "Evaluating Epoch 2  52.5% | batch:        21 of        40\t|\tloss: 10128.4\n",
      "Evaluating Epoch 2  55.0% | batch:        22 of        40\t|\tloss: 17772.4\n",
      "Evaluating Epoch 2  57.5% | batch:        23 of        40\t|\tloss: 14577.1\n",
      "Evaluating Epoch 2  60.0% | batch:        24 of        40\t|\tloss: 10415.7\n",
      "Evaluating Epoch 2  62.5% | batch:        25 of        40\t|\tloss: 23821\n",
      "Evaluating Epoch 2  65.0% | batch:        26 of        40\t|\tloss: 30070.2\n",
      "Evaluating Epoch 2  67.5% | batch:        27 of        40\t|\tloss: 14900.9\n",
      "Evaluating Epoch 2  70.0% | batch:        28 of        40\t|\tloss: 17888.7\n",
      "Evaluating Epoch 2  72.5% | batch:        29 of        40\t|\tloss: 27018.4\n",
      "Evaluating Epoch 2  75.0% | batch:        30 of        40\t|\tloss: 12340.3\n",
      "Evaluating Epoch 2  77.5% | batch:        31 of        40\t|\tloss: 11837.1\n",
      "Evaluating Epoch 2  80.0% | batch:        32 of        40\t|\tloss: 24527.9\n",
      "Evaluating Epoch 2  82.5% | batch:        33 of        40\t|\tloss: 16883\n",
      "Evaluating Epoch 2  85.0% | batch:        34 of        40\t|\tloss: 11589.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:22,194 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4557347297668457 seconds\n",
      "\n",
      "2023-05-09 14:20:22,194 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.6771158377329508 seconds\n",
      "2023-05-09 14:20:22,194 | INFO : Avg batch val. time: 0.01692789594332377 seconds\n",
      "2023-05-09 14:20:22,195 | INFO : Avg sample val. time: 0.00013413546706278741 seconds\n",
      "2023-05-09 14:20:22,195 | INFO : Epoch 2 Validation Summary: epoch: 2.000000 | loss: 17283.527016 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 2  87.5% | batch:        35 of        40\t|\tloss: 20510.8\n",
      "Evaluating Epoch 2  90.0% | batch:        36 of        40\t|\tloss: 19311.1\n",
      "Evaluating Epoch 2  92.5% | batch:        37 of        40\t|\tloss: 13697.7\n",
      "Evaluating Epoch 2  95.0% | batch:        38 of        40\t|\tloss: 22499.6\n",
      "Evaluating Epoch 2  97.5% | batch:        39 of        40\t|\tloss: 32336.5\n",
      "\n",
      "Training Epoch 3   0.0% | batch:         0 of        94\t|\tloss: 18888.6\n",
      "Training Epoch 3   1.1% | batch:         1 of        94\t|\tloss: 20619.7\n",
      "Training Epoch 3   2.1% | batch:         2 of        94\t|\tloss: 17025.7\n",
      "Training Epoch 3   3.2% | batch:         3 of        94\t|\tloss: 18626.7\n",
      "Training Epoch 3   4.3% | batch:         4 of        94\t|\tloss: 16347.8\n",
      "Training Epoch 3   5.3% | batch:         5 of        94\t|\tloss: 23388\n",
      "Training Epoch 3   6.4% | batch:         6 of        94\t|\tloss: 16378.9\n",
      "Training Epoch 3   7.4% | batch:         7 of        94\t|\tloss: 16214.6\n",
      "Training Epoch 3   8.5% | batch:         8 of        94\t|\tloss: 10299.9\n",
      "Training Epoch 3   9.6% | batch:         9 of        94\t|\tloss: 12023\n",
      "Training Epoch 3  10.6% | batch:        10 of        94\t|\tloss: 16537.2\n",
      "Training Epoch 3  11.7% | batch:        11 of        94\t|\tloss: 13275.4\n",
      "Training Epoch 3  12.8% | batch:        12 of        94\t|\tloss: 13445.6\n",
      "Training Epoch 3  13.8% | batch:        13 of        94\t|\tloss: 16537.6\n",
      "Training Epoch 3  14.9% | batch:        14 of        94\t|\tloss: 17277.4\n",
      "Training Epoch 3  16.0% | batch:        15 of        94\t|\tloss: 18419.7\n",
      "Training Epoch 3  17.0% | batch:        16 of        94\t|\tloss: 11929.7\n",
      "Training Epoch 3  18.1% | batch:        17 of        94\t|\tloss: 16140.3\n",
      "Training Epoch 3  19.1% | batch:        18 of        94\t|\tloss: 22708\n",
      "Training Epoch 3  20.2% | batch:        19 of        94\t|\tloss: 17354.6\n",
      "Training Epoch 3  21.3% | batch:        20 of        94\t|\tloss: 14611.4\n",
      "Training Epoch 3  22.3% | batch:        21 of        94\t|\tloss: 16108.4\n",
      "Training Epoch 3  23.4% | batch:        22 of        94\t|\tloss: 14722.9\n",
      "Training Epoch 3  24.5% | batch:        23 of        94\t|\tloss: 10894.5\n",
      "Training Epoch 3  25.5% | batch:        24 of        94\t|\tloss: 15972.3\n",
      "Training Epoch 3  26.6% | batch:        25 of        94\t|\tloss: 16572.4\n",
      "Training Epoch 3  27.7% | batch:        26 of        94\t|\tloss: 13600.6\n",
      "Training Epoch 3  28.7% | batch:        27 of        94\t|\tloss: 14304.8\n",
      "Training Epoch 3  29.8% | batch:        28 of        94\t|\tloss: 16339.6\n",
      "Training Epoch 3  30.9% | batch:        29 of        94\t|\tloss: 11877.5\n",
      "Training Epoch 3  31.9% | batch:        30 of        94\t|\tloss: 13871.9\n",
      "Training Epoch 3  33.0% | batch:        31 of        94\t|\tloss: 16399.5\n",
      "Training Epoch 3  34.0% | batch:        32 of        94\t|\tloss: 16169.7\n",
      "Training Epoch 3  35.1% | batch:        33 of        94\t|\tloss: 16311.4\n",
      "Training Epoch 3  36.2% | batch:        34 of        94\t|\tloss: 10522.6\n",
      "Training Epoch 3  37.2% | batch:        35 of        94\t|\tloss: 15995.3\n",
      "Training Epoch 3  38.3% | batch:        36 of        94\t|\tloss: 13350.4\n",
      "Training Epoch 3  39.4% | batch:        37 of        94\t|\tloss: 14984.8\n",
      "Training Epoch 3  40.4% | batch:        38 of        94\t|\tloss: 19277.3\n",
      "Training Epoch 3  41.5% | batch:        39 of        94\t|\tloss: 13354.7\n",
      "Training Epoch 3  42.6% | batch:        40 of        94\t|\tloss: 15001.4\n",
      "Training Epoch 3  43.6% | batch:        41 of        94\t|\tloss: 9351.78\n",
      "Training Epoch 3  44.7% | batch:        42 of        94\t|\tloss: 14294.6\n",
      "Training Epoch 3  45.7% | batch:        43 of        94\t|\tloss: 16148.8\n",
      "Training Epoch 3  46.8% | batch:        44 of        94\t|\tloss: 16285.7\n",
      "Training Epoch 3  47.9% | batch:        45 of        94\t|\tloss: 15904.7\n",
      "Training Epoch 3  48.9% | batch:        46 of        94\t|\tloss: 10212.2\n",
      "Training Epoch 3  50.0% | batch:        47 of        94\t|\tloss: 12623\n",
      "Training Epoch 3  51.1% | batch:        48 of        94\t|\tloss: 9423.85\n",
      "Training Epoch 3  52.1% | batch:        49 of        94\t|\tloss: 10406.5\n",
      "Training Epoch 3  53.2% | batch:        50 of        94\t|\tloss: 11363.9\n",
      "Training Epoch 3  54.3% | batch:        51 of        94\t|\tloss: 13578.4\n",
      "Training Epoch 3  55.3% | batch:        52 of        94\t|\tloss: 9085.75\n",
      "Training Epoch 3  56.4% | batch:        53 of        94\t|\tloss: 11401.7\n",
      "Training Epoch 3  57.4% | batch:        54 of        94\t|\tloss: 11556.3\n",
      "Training Epoch 3  58.5% | batch:        55 of        94\t|\tloss: 12497.8\n",
      "Training Epoch 3  59.6% | batch:        56 of        94\t|\tloss: 11957\n",
      "Training Epoch 3  60.6% | batch:        57 of        94\t|\tloss: 11978.3\n",
      "Training Epoch 3  61.7% | batch:        58 of        94\t|\tloss: 8669.57\n",
      "Training Epoch 3  62.8% | batch:        59 of        94\t|\tloss: 8933.37\n",
      "Training Epoch 3  63.8% | batch:        60 of        94\t|\tloss: 11372.7\n",
      "Training Epoch 3  64.9% | batch:        61 of        94\t|\tloss: 12272.2\n",
      "Training Epoch 3  66.0% | batch:        62 of        94\t|\tloss: 8943.45\n",
      "Training Epoch 3  67.0% | batch:        63 of        94\t|\tloss: 11335.7\n",
      "Training Epoch 3  68.1% | batch:        64 of        94\t|\tloss: 12648.8\n",
      "Training Epoch 3  69.1% | batch:        65 of        94\t|\tloss: 8813.08\n",
      "Training Epoch 3  70.2% | batch:        66 of        94\t|\tloss: 9006.96\n",
      "Training Epoch 3  71.3% | batch:        67 of        94\t|\tloss: 8428.7\n",
      "Training Epoch 3  72.3% | batch:        68 of        94\t|\tloss: 13917\n",
      "Training Epoch 3  73.4% | batch:        69 of        94\t|\tloss: 8395.11\n",
      "Training Epoch 3  74.5% | batch:        70 of        94\t|\tloss: 10963.2\n",
      "Training Epoch 3  75.5% | batch:        71 of        94\t|\tloss: 13134.2\n",
      "Training Epoch 3  76.6% | batch:        72 of        94\t|\tloss: 9892.54\n",
      "Training Epoch 3  77.7% | batch:        73 of        94\t|\tloss: 14807.1\n",
      "Training Epoch 3  78.7% | batch:        74 of        94\t|\tloss: 10411.5\n",
      "Training Epoch 3  79.8% | batch:        75 of        94\t|\tloss: 8587.88\n",
      "Training Epoch 3  80.9% | batch:        76 of        94\t|\tloss: 10571.9\n",
      "Training Epoch 3  81.9% | batch:        77 of        94\t|\tloss: 8561.58\n",
      "Training Epoch 3  83.0% | batch:        78 of        94\t|\tloss: 12320.8\n",
      "Training Epoch 3  84.0% | batch:        79 of        94\t|\tloss: 11671.5\n",
      "Training Epoch 3  85.1% | batch:        80 of        94\t|\tloss: 18254.3\n",
      "Training Epoch 3  86.2% | batch:        81 of        94\t|\tloss: 9586.7\n",
      "Training Epoch 3  87.2% | batch:        82 of        94\t|\tloss: 8039.17\n",
      "Training Epoch 3  88.3% | batch:        83 of        94\t|\tloss: 8340.21\n",
      "Training Epoch 3  89.4% | batch:        84 of        94\t|\tloss: 10564.7\n",
      "Training Epoch 3  90.4% | batch:        85 of        94\t|\tloss: 12339.9\n",
      "Training Epoch 3  91.5% | batch:        86 of        94\t|\tloss: 12832.7\n",
      "Training Epoch 3  92.6% | batch:        87 of        94\t|\tloss: 9815.3\n",
      "Training Epoch 3  93.6% | batch:        88 of        94\t|\tloss: 11046.4\n",
      "Training Epoch 3  94.7% | batch:        89 of        94\t|\tloss: 10225.8\n",
      "Training Epoch 3  95.7% | batch:        90 of        94\t|\tloss: 8171.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:24,066 | INFO : Epoch 3 Training Summary: epoch: 3.000000 | loss: 13170.275736 | \n",
      "2023-05-09 14:20:24,067 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8393125534057617 seconds\n",
      "\n",
      "2023-05-09 14:20:24,068 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9266821543375652 seconds\n",
      "2023-05-09 14:20:24,068 | INFO : Avg batch train. time: 0.020496618663165586 seconds\n",
      "2023-05-09 14:20:24,069 | INFO : Avg sample train. time: 0.0001616615333392822 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 3  96.8% | batch:        91 of        94\t|\tloss: 11491.2\n",
      "Training Epoch 3  97.9% | batch:        92 of        94\t|\tloss: 8945.49\n",
      "Training Epoch 3  98.9% | batch:        93 of        94\t|\tloss: 11078.4\n",
      "\n",
      "Training Epoch 4   0.0% | batch:         0 of        94\t|\tloss: 8247.82\n",
      "Training Epoch 4   1.1% | batch:         1 of        94\t|\tloss: 6087.76\n",
      "Training Epoch 4   2.1% | batch:         2 of        94\t|\tloss: 9189.96\n",
      "Training Epoch 4   3.2% | batch:         3 of        94\t|\tloss: 8177.9\n",
      "Training Epoch 4   4.3% | batch:         4 of        94\t|\tloss: 8791.04\n",
      "Training Epoch 4   5.3% | batch:         5 of        94\t|\tloss: 5952.42\n",
      "Training Epoch 4   6.4% | batch:         6 of        94\t|\tloss: 7188.73\n",
      "Training Epoch 4   7.4% | batch:         7 of        94\t|\tloss: 8109.05\n",
      "Training Epoch 4   8.5% | batch:         8 of        94\t|\tloss: 6968.62\n",
      "Training Epoch 4   9.6% | batch:         9 of        94\t|\tloss: 12394.8\n",
      "Training Epoch 4  10.6% | batch:        10 of        94\t|\tloss: 6986.98\n",
      "Training Epoch 4  11.7% | batch:        11 of        94\t|\tloss: 8572.37\n",
      "Training Epoch 4  12.8% | batch:        12 of        94\t|\tloss: 8369.32\n",
      "Training Epoch 4  13.8% | batch:        13 of        94\t|\tloss: 7199.39\n",
      "Training Epoch 4  14.9% | batch:        14 of        94\t|\tloss: 7123.86\n",
      "Training Epoch 4  16.0% | batch:        15 of        94\t|\tloss: 9142.2\n",
      "Training Epoch 4  17.0% | batch:        16 of        94\t|\tloss: 6753.68\n",
      "Training Epoch 4  18.1% | batch:        17 of        94\t|\tloss: 7149.68\n",
      "Training Epoch 4  19.1% | batch:        18 of        94\t|\tloss: 8440.83\n",
      "Training Epoch 4  20.2% | batch:        19 of        94\t|\tloss: 4961.23\n",
      "Training Epoch 4  21.3% | batch:        20 of        94\t|\tloss: 11847.5\n",
      "Training Epoch 4  22.3% | batch:        21 of        94\t|\tloss: 11223\n",
      "Training Epoch 4  23.4% | batch:        22 of        94\t|\tloss: 9863.11\n",
      "Training Epoch 4  24.5% | batch:        23 of        94\t|\tloss: 7837.07\n",
      "Training Epoch 4  25.5% | batch:        24 of        94\t|\tloss: 10252\n",
      "Training Epoch 4  26.6% | batch:        25 of        94\t|\tloss: 7116.71\n",
      "Training Epoch 4  27.7% | batch:        26 of        94\t|\tloss: 4480.71\n",
      "Training Epoch 4  28.7% | batch:        27 of        94\t|\tloss: 6904.42\n",
      "Training Epoch 4  29.8% | batch:        28 of        94\t|\tloss: 8320.36\n",
      "Training Epoch 4  30.9% | batch:        29 of        94\t|\tloss: 8315.05\n",
      "Training Epoch 4  31.9% | batch:        30 of        94\t|\tloss: 7556.13\n",
      "Training Epoch 4  33.0% | batch:        31 of        94\t|\tloss: 8061.22\n",
      "Training Epoch 4  34.0% | batch:        32 of        94\t|\tloss: 12177.6\n",
      "Training Epoch 4  35.1% | batch:        33 of        94\t|\tloss: 7770.39\n",
      "Training Epoch 4  36.2% | batch:        34 of        94\t|\tloss: 4900.67\n",
      "Training Epoch 4  37.2% | batch:        35 of        94\t|\tloss: 5137.68\n",
      "Training Epoch 4  38.3% | batch:        36 of        94\t|\tloss: 4979.8\n",
      "Training Epoch 4  39.4% | batch:        37 of        94\t|\tloss: 7153.59\n",
      "Training Epoch 4  40.4% | batch:        38 of        94\t|\tloss: 8557.28\n",
      "Training Epoch 4  41.5% | batch:        39 of        94\t|\tloss: 7283.37\n",
      "Training Epoch 4  42.6% | batch:        40 of        94\t|\tloss: 3776.4\n",
      "Training Epoch 4  43.6% | batch:        41 of        94\t|\tloss: 6909.94\n",
      "Training Epoch 4  44.7% | batch:        42 of        94\t|\tloss: 4898.31\n",
      "Training Epoch 4  45.7% | batch:        43 of        94\t|\tloss: 3149.61\n",
      "Training Epoch 4  46.8% | batch:        44 of        94\t|\tloss: 8909.07\n",
      "Training Epoch 4  47.9% | batch:        45 of        94\t|\tloss: 8315.22\n",
      "Training Epoch 4  48.9% | batch:        46 of        94\t|\tloss: 4930.95\n",
      "Training Epoch 4  50.0% | batch:        47 of        94\t|\tloss: 4906.15\n",
      "Training Epoch 4  51.1% | batch:        48 of        94\t|\tloss: 5464.81\n",
      "Training Epoch 4  52.1% | batch:        49 of        94\t|\tloss: 3918.51\n",
      "Training Epoch 4  53.2% | batch:        50 of        94\t|\tloss: 3580.65\n",
      "Training Epoch 4  54.3% | batch:        51 of        94\t|\tloss: 6497.4\n",
      "Training Epoch 4  55.3% | batch:        52 of        94\t|\tloss: 7473.14\n",
      "Training Epoch 4  56.4% | batch:        53 of        94\t|\tloss: 7258.2\n",
      "Training Epoch 4  57.4% | batch:        54 of        94\t|\tloss: 5308.56\n",
      "Training Epoch 4  58.5% | batch:        55 of        94\t|\tloss: 5731.73\n",
      "Training Epoch 4  59.6% | batch:        56 of        94\t|\tloss: 5444.89\n",
      "Training Epoch 4  60.6% | batch:        57 of        94\t|\tloss: 5885.4\n",
      "Training Epoch 4  61.7% | batch:        58 of        94\t|\tloss: 9077.95\n",
      "Training Epoch 4  62.8% | batch:        59 of        94\t|\tloss: 4478.59\n",
      "Training Epoch 4  63.8% | batch:        60 of        94\t|\tloss: 6334.82\n",
      "Training Epoch 4  64.9% | batch:        61 of        94\t|\tloss: 9873.42\n",
      "Training Epoch 4  66.0% | batch:        62 of        94\t|\tloss: 3731.27\n",
      "Training Epoch 4  67.0% | batch:        63 of        94\t|\tloss: 5713.39\n",
      "Training Epoch 4  68.1% | batch:        64 of        94\t|\tloss: 4722.08\n",
      "Training Epoch 4  69.1% | batch:        65 of        94\t|\tloss: 8711.76\n",
      "Training Epoch 4  70.2% | batch:        66 of        94\t|\tloss: 7149.79\n",
      "Training Epoch 4  71.3% | batch:        67 of        94\t|\tloss: 4040.62\n",
      "Training Epoch 4  72.3% | batch:        68 of        94\t|\tloss: 2590.1\n",
      "Training Epoch 4  73.4% | batch:        69 of        94\t|\tloss: 5246.66\n",
      "Training Epoch 4  74.5% | batch:        70 of        94\t|\tloss: 4744.21\n",
      "Training Epoch 4  75.5% | batch:        71 of        94\t|\tloss: 4871.48\n",
      "Training Epoch 4  76.6% | batch:        72 of        94\t|\tloss: 6246.81\n",
      "Training Epoch 4  77.7% | batch:        73 of        94\t|\tloss: 5717.73\n",
      "Training Epoch 4  78.7% | batch:        74 of        94\t|\tloss: 9918.67\n",
      "Training Epoch 4  79.8% | batch:        75 of        94\t|\tloss: 5197.05\n",
      "Training Epoch 4  80.9% | batch:        76 of        94\t|\tloss: 4527.24\n",
      "Training Epoch 4  81.9% | batch:        77 of        94\t|\tloss: 6489.06\n",
      "Training Epoch 4  83.0% | batch:        78 of        94\t|\tloss: 5458.05\n",
      "Training Epoch 4  84.0% | batch:        79 of        94\t|\tloss: 6640.71\n",
      "Training Epoch 4  85.1% | batch:        80 of        94\t|\tloss: 3369.58\n",
      "Training Epoch 4  86.2% | batch:        81 of        94\t|\tloss: 5260.15\n",
      "Training Epoch 4  87.2% | batch:        82 of        94\t|\tloss: 2983.25\n",
      "Training Epoch 4  88.3% | batch:        83 of        94\t|\tloss: 6192.99\n",
      "Training Epoch 4  89.4% | batch:        84 of        94\t|\tloss: 4447.87\n",
      "Training Epoch 4  90.4% | batch:        85 of        94\t|\tloss: 4723.48\n",
      "Training Epoch 4  91.5% | batch:        86 of        94\t|\tloss: 3090.05\n",
      "Training Epoch 4  92.6% | batch:        87 of        94\t|\tloss: 2452.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:25,929 | INFO : Epoch 4 Training Summary: epoch: 4.000000 | loss: 6494.728836 | \n",
      "2023-05-09 14:20:25,930 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.838927984237671 seconds\n",
      "\n",
      "2023-05-09 14:20:25,930 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9047436118125916 seconds\n",
      "2023-05-09 14:20:25,931 | INFO : Avg batch train. time: 0.02026322991289991 seconds\n",
      "2023-05-09 14:20:25,932 | INFO : Avg sample train. time: 0.000159820742726346 seconds\n",
      "2023-05-09 14:20:25,932 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 4  93.6% | batch:        88 of        94\t|\tloss: 3627.19\n",
      "Training Epoch 4  94.7% | batch:        89 of        94\t|\tloss: 4572.36\n",
      "Training Epoch 4  95.7% | batch:        90 of        94\t|\tloss: 7305.41\n",
      "Training Epoch 4  96.8% | batch:        91 of        94\t|\tloss: 2487.13\n",
      "Training Epoch 4  97.9% | batch:        92 of        94\t|\tloss: 3336.62\n",
      "Training Epoch 4  98.9% | batch:        93 of        94\t|\tloss: 13589.7\n",
      "\n",
      "Evaluating Epoch 4   0.0% | batch:         0 of        40\t|\tloss: 10686.5\n",
      "Evaluating Epoch 4   2.5% | batch:         1 of        40\t|\tloss: 2267.13\n",
      "Evaluating Epoch 4   5.0% | batch:         2 of        40\t|\tloss: 5191.01\n",
      "Evaluating Epoch 4   7.5% | batch:         3 of        40\t|\tloss: 10526.3\n",
      "Evaluating Epoch 4  10.0% | batch:         4 of        40\t|\tloss: 3017.96\n",
      "Evaluating Epoch 4  12.5% | batch:         5 of        40\t|\tloss: 2001.17\n",
      "Evaluating Epoch 4  15.0% | batch:         6 of        40\t|\tloss: 11946\n",
      "Evaluating Epoch 4  17.5% | batch:         7 of        40\t|\tloss: 6598.12\n",
      "Evaluating Epoch 4  20.0% | batch:         8 of        40\t|\tloss: 4606.56\n",
      "Evaluating Epoch 4  22.5% | batch:         9 of        40\t|\tloss: 5480.92\n",
      "Evaluating Epoch 4  25.0% | batch:        10 of        40\t|\tloss: 9671.34\n",
      "Evaluating Epoch 4  27.5% | batch:        11 of        40\t|\tloss: 2552.48\n",
      "Evaluating Epoch 4  30.0% | batch:        12 of        40\t|\tloss: 11894.4\n",
      "Evaluating Epoch 4  32.5% | batch:        13 of        40\t|\tloss: 7782.93\n",
      "Evaluating Epoch 4  35.0% | batch:        14 of        40\t|\tloss: 3623.55\n",
      "Evaluating Epoch 4  37.5% | batch:        15 of        40\t|\tloss: 7498.36\n",
      "Evaluating Epoch 4  40.0% | batch:        16 of        40\t|\tloss: 9213.78\n",
      "Evaluating Epoch 4  42.5% | batch:        17 of        40\t|\tloss: 6253.72\n",
      "Evaluating Epoch 4  45.0% | batch:        18 of        40\t|\tloss: 4380.38\n",
      "Evaluating Epoch 4  47.5% | batch:        19 of        40\t|\tloss: 10632.9\n",
      "Evaluating Epoch 4  50.0% | batch:        20 of        40\t|\tloss: 8925.87\n",
      "Evaluating Epoch 4  52.5% | batch:        21 of        40\t|\tloss: 2575.63\n",
      "Evaluating Epoch 4  55.0% | batch:        22 of        40\t|\tloss: 6612.88\n",
      "Evaluating Epoch 4  57.5% | batch:        23 of        40\t|\tloss: 6535.27\n",
      "Evaluating Epoch 4  60.0% | batch:        24 of        40\t|\tloss: 2795.12\n",
      "Evaluating Epoch 4  62.5% | batch:        25 of        40\t|\tloss: 6848.86\n",
      "Evaluating Epoch 4  65.0% | batch:        26 of        40\t|\tloss: 18577.3\n",
      "Evaluating Epoch 4  67.5% | batch:        27 of        40\t|\tloss: 5782.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:26,388 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45545315742492676 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 4  70.0% | batch:        28 of        40\t|\tloss: 4632.45\n",
      "Evaluating Epoch 4  72.5% | batch:        29 of        40\t|\tloss: 14265.7\n",
      "Evaluating Epoch 4  75.0% | batch:        30 of        40\t|\tloss: 4065.43\n",
      "Evaluating Epoch 4  77.5% | batch:        31 of        40\t|\tloss: 2465.78\n",
      "Evaluating Epoch 4  80.0% | batch:        32 of        40\t|\tloss: 10884.3\n",
      "Evaluating Epoch 4  82.5% | batch:        33 of        40\t|\tloss: 10355.3\n",
      "Evaluating Epoch 4  85.0% | batch:        34 of        40\t|\tloss: 2564.46\n",
      "Evaluating Epoch 4  87.5% | batch:        35 of        40\t|\tloss: 6866.64\n",
      "Evaluating Epoch 4  90.0% | batch:        36 of        40\t|\tloss: 10803.2\n",
      "Evaluating Epoch 4  92.5% | batch:        37 of        40\t|\tloss: 4113.03\n",
      "Evaluating Epoch 4  95.0% | batch:        38 of        40\t|\tloss: 7431.19\n",
      "Evaluating Epoch 4  97.5% | batch:        39 of        40\t|\tloss: 18357.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:26,389 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.6217001676559448 seconds\n",
      "2023-05-09 14:20:26,389 | INFO : Avg batch val. time: 0.015542504191398621 seconds\n",
      "2023-05-09 14:20:26,390 | INFO : Avg sample val. time: 0.00012315771942471174 seconds\n",
      "2023-05-09 14:20:26,390 | INFO : Epoch 4 Validation Summary: epoch: 4.000000 | loss: 7124.135598 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch 5   0.0% | batch:         0 of        94\t|\tloss: 4072.63\n",
      "Training Epoch 5   1.1% | batch:         1 of        94\t|\tloss: 2786.77\n",
      "Training Epoch 5   2.1% | batch:         2 of        94\t|\tloss: 3820.42\n",
      "Training Epoch 5   3.2% | batch:         3 of        94\t|\tloss: 6942.85\n",
      "Training Epoch 5   4.3% | batch:         4 of        94\t|\tloss: 4138.14\n",
      "Training Epoch 5   5.3% | batch:         5 of        94\t|\tloss: 4002.09\n",
      "Training Epoch 5   6.4% | batch:         6 of        94\t|\tloss: 4880.69\n",
      "Training Epoch 5   7.4% | batch:         7 of        94\t|\tloss: 2629.07\n",
      "Training Epoch 5   8.5% | batch:         8 of        94\t|\tloss: 3250.11\n",
      "Training Epoch 5   9.6% | batch:         9 of        94\t|\tloss: 2636.97\n",
      "Training Epoch 5  10.6% | batch:        10 of        94\t|\tloss: 3871.94\n",
      "Training Epoch 5  11.7% | batch:        11 of        94\t|\tloss: 7136.64\n",
      "Training Epoch 5  12.8% | batch:        12 of        94\t|\tloss: 3409.91\n",
      "Training Epoch 5  13.8% | batch:        13 of        94\t|\tloss: 3065.46\n",
      "Training Epoch 5  14.9% | batch:        14 of        94\t|\tloss: 3200.3\n",
      "Training Epoch 5  16.0% | batch:        15 of        94\t|\tloss: 2285.96\n",
      "Training Epoch 5  17.0% | batch:        16 of        94\t|\tloss: 4220.75\n",
      "Training Epoch 5  18.1% | batch:        17 of        94\t|\tloss: 3197.81\n",
      "Training Epoch 5  19.1% | batch:        18 of        94\t|\tloss: 3303.89\n",
      "Training Epoch 5  20.2% | batch:        19 of        94\t|\tloss: 1772.13\n",
      "Training Epoch 5  21.3% | batch:        20 of        94\t|\tloss: 4055.69\n",
      "Training Epoch 5  22.3% | batch:        21 of        94\t|\tloss: 3368.59\n",
      "Training Epoch 5  23.4% | batch:        22 of        94\t|\tloss: 2349.1\n",
      "Training Epoch 5  24.5% | batch:        23 of        94\t|\tloss: 4509.37\n",
      "Training Epoch 5  25.5% | batch:        24 of        94\t|\tloss: 6879.77\n",
      "Training Epoch 5  26.6% | batch:        25 of        94\t|\tloss: 5359.97\n",
      "Training Epoch 5  27.7% | batch:        26 of        94\t|\tloss: 3007.35\n",
      "Training Epoch 5  28.7% | batch:        27 of        94\t|\tloss: 4340.43\n",
      "Training Epoch 5  29.8% | batch:        28 of        94\t|\tloss: 2547.27\n",
      "Training Epoch 5  30.9% | batch:        29 of        94\t|\tloss: 2456.56\n",
      "Training Epoch 5  31.9% | batch:        30 of        94\t|\tloss: 3808.12\n",
      "Training Epoch 5  33.0% | batch:        31 of        94\t|\tloss: 9506.01\n",
      "Training Epoch 5  34.0% | batch:        32 of        94\t|\tloss: 3646.59\n",
      "Training Epoch 5  35.1% | batch:        33 of        94\t|\tloss: 2585.09\n",
      "Training Epoch 5  36.2% | batch:        34 of        94\t|\tloss: 2590.24\n",
      "Training Epoch 5  37.2% | batch:        35 of        94\t|\tloss: 3406.67\n",
      "Training Epoch 5  38.3% | batch:        36 of        94\t|\tloss: 4763.99\n",
      "Training Epoch 5  39.4% | batch:        37 of        94\t|\tloss: 2177.69\n",
      "Training Epoch 5  40.4% | batch:        38 of        94\t|\tloss: 4547.04\n",
      "Training Epoch 5  41.5% | batch:        39 of        94\t|\tloss: 2872.4\n",
      "Training Epoch 5  42.6% | batch:        40 of        94\t|\tloss: 3333.94\n",
      "Training Epoch 5  43.6% | batch:        41 of        94\t|\tloss: 3486.9\n",
      "Training Epoch 5  44.7% | batch:        42 of        94\t|\tloss: 2578.88\n",
      "Training Epoch 5  45.7% | batch:        43 of        94\t|\tloss: 4094.87\n",
      "Training Epoch 5  46.8% | batch:        44 of        94\t|\tloss: 3908.69\n",
      "Training Epoch 5  47.9% | batch:        45 of        94\t|\tloss: 1533.94\n",
      "Training Epoch 5  48.9% | batch:        46 of        94\t|\tloss: 2104.75\n",
      "Training Epoch 5  50.0% | batch:        47 of        94\t|\tloss: 1692.07\n",
      "Training Epoch 5  51.1% | batch:        48 of        94\t|\tloss: 3494.05\n",
      "Training Epoch 5  52.1% | batch:        49 of        94\t|\tloss: 2725.69\n",
      "Training Epoch 5  53.2% | batch:        50 of        94\t|\tloss: 2346.63\n",
      "Training Epoch 5  54.3% | batch:        51 of        94\t|\tloss: 4080.57\n",
      "Training Epoch 5  55.3% | batch:        52 of        94\t|\tloss: 2696.26\n",
      "Training Epoch 5  56.4% | batch:        53 of        94\t|\tloss: 6694.18\n",
      "Training Epoch 5  57.4% | batch:        54 of        94\t|\tloss: 3764.24\n",
      "Training Epoch 5  58.5% | batch:        55 of        94\t|\tloss: 3042.78\n",
      "Training Epoch 5  59.6% | batch:        56 of        94\t|\tloss: 2812.08\n",
      "Training Epoch 5  60.6% | batch:        57 of        94\t|\tloss: 3124.93\n",
      "Training Epoch 5  61.7% | batch:        58 of        94\t|\tloss: 2657.6\n",
      "Training Epoch 5  62.8% | batch:        59 of        94\t|\tloss: 3100.72\n",
      "Training Epoch 5  63.8% | batch:        60 of        94\t|\tloss: 2375.72\n",
      "Training Epoch 5  64.9% | batch:        61 of        94\t|\tloss: 1813.85\n",
      "Training Epoch 5  66.0% | batch:        62 of        94\t|\tloss: 1669.11\n",
      "Training Epoch 5  67.0% | batch:        63 of        94\t|\tloss: 2820.79\n",
      "Training Epoch 5  68.1% | batch:        64 of        94\t|\tloss: 4598.71\n",
      "Training Epoch 5  69.1% | batch:        65 of        94\t|\tloss: 1509.4\n",
      "Training Epoch 5  70.2% | batch:        66 of        94\t|\tloss: 2679.07\n",
      "Training Epoch 5  71.3% | batch:        67 of        94\t|\tloss: 3274.41\n",
      "Training Epoch 5  72.3% | batch:        68 of        94\t|\tloss: 1866.8\n",
      "Training Epoch 5  73.4% | batch:        69 of        94\t|\tloss: 2047.63\n",
      "Training Epoch 5  74.5% | batch:        70 of        94\t|\tloss: 3734.34\n",
      "Training Epoch 5  75.5% | batch:        71 of        94\t|\tloss: 2302.47\n",
      "Training Epoch 5  76.6% | batch:        72 of        94\t|\tloss: 4090.86\n",
      "Training Epoch 5  77.7% | batch:        73 of        94\t|\tloss: 1801.62\n",
      "Training Epoch 5  78.7% | batch:        74 of        94\t|\tloss: 2227.61\n",
      "Training Epoch 5  79.8% | batch:        75 of        94\t|\tloss: 4095.93\n",
      "Training Epoch 5  80.9% | batch:        76 of        94\t|\tloss: 2638\n",
      "Training Epoch 5  81.9% | batch:        77 of        94\t|\tloss: 1593.65\n",
      "Training Epoch 5  83.0% | batch:        78 of        94\t|\tloss: 2660.73\n",
      "Training Epoch 5  84.0% | batch:        79 of        94\t|\tloss: 4318.5\n",
      "Training Epoch 5  85.1% | batch:        80 of        94\t|\tloss: 3255.76\n",
      "Training Epoch 5  86.2% | batch:        81 of        94\t|\tloss: 3049\n",
      "Training Epoch 5  87.2% | batch:        82 of        94\t|\tloss: 1531.8\n",
      "Training Epoch 5  88.3% | batch:        83 of        94\t|\tloss: 3071.06\n",
      "Training Epoch 5  89.4% | batch:        84 of        94\t|\tloss: 3039.7\n",
      "Training Epoch 5  90.4% | batch:        85 of        94\t|\tloss: 3982.21\n",
      "Training Epoch 5  91.5% | batch:        86 of        94\t|\tloss: 2598.17\n",
      "Training Epoch 5  92.6% | batch:        87 of        94\t|\tloss: 2806.08\n",
      "Training Epoch 5  93.6% | batch:        88 of        94\t|\tloss: 2812.81\n",
      "Training Epoch 5  94.7% | batch:        89 of        94\t|\tloss: 2235.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:28,261 | INFO : Epoch 5 Training Summary: epoch: 5.000000 | loss: 3294.265965 | \n",
      "2023-05-09 14:20:28,262 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.839257001876831 seconds\n",
      "\n",
      "2023-05-09 14:20:28,263 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8916462898254394 seconds\n",
      "2023-05-09 14:20:28,263 | INFO : Avg batch train. time: 0.020123896700270632 seconds\n",
      "2023-05-09 14:20:28,264 | INFO : Avg sample train. time: 0.00015872178971517364 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 5  95.7% | batch:        90 of        94\t|\tloss: 2748.6\n",
      "Training Epoch 5  96.8% | batch:        91 of        94\t|\tloss: 2707.7\n",
      "Training Epoch 5  97.9% | batch:        92 of        94\t|\tloss: 1819.85\n",
      "Training Epoch 5  98.9% | batch:        93 of        94\t|\tloss: 2501.84\n",
      "\n",
      "Training Epoch 6   0.0% | batch:         0 of        94\t|\tloss: 3710.08\n",
      "Training Epoch 6   1.1% | batch:         1 of        94\t|\tloss: 2157.93\n",
      "Training Epoch 6   2.1% | batch:         2 of        94\t|\tloss: 2057.19\n",
      "Training Epoch 6   3.2% | batch:         3 of        94\t|\tloss: 1877.5\n",
      "Training Epoch 6   4.3% | batch:         4 of        94\t|\tloss: 4933.2\n",
      "Training Epoch 6   5.3% | batch:         5 of        94\t|\tloss: 1943.87\n",
      "Training Epoch 6   6.4% | batch:         6 of        94\t|\tloss: 2234.7\n",
      "Training Epoch 6   7.4% | batch:         7 of        94\t|\tloss: 2069.45\n",
      "Training Epoch 6   8.5% | batch:         8 of        94\t|\tloss: 3270.9\n",
      "Training Epoch 6   9.6% | batch:         9 of        94\t|\tloss: 2118.11\n",
      "Training Epoch 6  10.6% | batch:        10 of        94\t|\tloss: 1616.86\n",
      "Training Epoch 6  11.7% | batch:        11 of        94\t|\tloss: 1614.82\n",
      "Training Epoch 6  12.8% | batch:        12 of        94\t|\tloss: 4353.41\n",
      "Training Epoch 6  13.8% | batch:        13 of        94\t|\tloss: 2244.17\n",
      "Training Epoch 6  14.9% | batch:        14 of        94\t|\tloss: 3210.08\n",
      "Training Epoch 6  16.0% | batch:        15 of        94\t|\tloss: 4288.3\n",
      "Training Epoch 6  17.0% | batch:        16 of        94\t|\tloss: 2448.03\n",
      "Training Epoch 6  18.1% | batch:        17 of        94\t|\tloss: 3278.08\n",
      "Training Epoch 6  19.1% | batch:        18 of        94\t|\tloss: 2837.84\n",
      "Training Epoch 6  20.2% | batch:        19 of        94\t|\tloss: 3459.83\n",
      "Training Epoch 6  21.3% | batch:        20 of        94\t|\tloss: 1392.64\n",
      "Training Epoch 6  22.3% | batch:        21 of        94\t|\tloss: 2470.44\n",
      "Training Epoch 6  23.4% | batch:        22 of        94\t|\tloss: 2565.87\n",
      "Training Epoch 6  24.5% | batch:        23 of        94\t|\tloss: 2234.73\n",
      "Training Epoch 6  25.5% | batch:        24 of        94\t|\tloss: 2849.15\n",
      "Training Epoch 6  26.6% | batch:        25 of        94\t|\tloss: 2431.74\n",
      "Training Epoch 6  27.7% | batch:        26 of        94\t|\tloss: 1559.32\n",
      "Training Epoch 6  28.7% | batch:        27 of        94\t|\tloss: 2926.74\n",
      "Training Epoch 6  29.8% | batch:        28 of        94\t|\tloss: 3333.44\n",
      "Training Epoch 6  30.9% | batch:        29 of        94\t|\tloss: 4859.81\n",
      "Training Epoch 6  31.9% | batch:        30 of        94\t|\tloss: 1894.76\n",
      "Training Epoch 6  33.0% | batch:        31 of        94\t|\tloss: 2337.98\n",
      "Training Epoch 6  34.0% | batch:        32 of        94\t|\tloss: 2231.19\n",
      "Training Epoch 6  35.1% | batch:        33 of        94\t|\tloss: 1754.45\n",
      "Training Epoch 6  36.2% | batch:        34 of        94\t|\tloss: 2642.11\n",
      "Training Epoch 6  37.2% | batch:        35 of        94\t|\tloss: 1935.67\n",
      "Training Epoch 6  38.3% | batch:        36 of        94\t|\tloss: 2643.77\n",
      "Training Epoch 6  39.4% | batch:        37 of        94\t|\tloss: 5533.18\n",
      "Training Epoch 6  40.4% | batch:        38 of        94\t|\tloss: 2243.68\n",
      "Training Epoch 6  41.5% | batch:        39 of        94\t|\tloss: 2049.11\n",
      "Training Epoch 6  42.6% | batch:        40 of        94\t|\tloss: 1985.52\n",
      "Training Epoch 6  43.6% | batch:        41 of        94\t|\tloss: 2614.3\n",
      "Training Epoch 6  44.7% | batch:        42 of        94\t|\tloss: 2753.87\n",
      "Training Epoch 6  45.7% | batch:        43 of        94\t|\tloss: 1755.25\n",
      "Training Epoch 6  46.8% | batch:        44 of        94\t|\tloss: 1867.45\n",
      "Training Epoch 6  47.9% | batch:        45 of        94\t|\tloss: 1777.61\n",
      "Training Epoch 6  48.9% | batch:        46 of        94\t|\tloss: 1614.4\n",
      "Training Epoch 6  50.0% | batch:        47 of        94\t|\tloss: 2042.42\n",
      "Training Epoch 6  51.1% | batch:        48 of        94\t|\tloss: 2684.19\n",
      "Training Epoch 6  52.1% | batch:        49 of        94\t|\tloss: 1882.41\n",
      "Training Epoch 6  53.2% | batch:        50 of        94\t|\tloss: 2447.85\n",
      "Training Epoch 6  54.3% | batch:        51 of        94\t|\tloss: 2167.06\n",
      "Training Epoch 6  55.3% | batch:        52 of        94\t|\tloss: 2405.61\n",
      "Training Epoch 6  56.4% | batch:        53 of        94\t|\tloss: 3286.89\n",
      "Training Epoch 6  57.4% | batch:        54 of        94\t|\tloss: 2644.26\n",
      "Training Epoch 6  58.5% | batch:        55 of        94\t|\tloss: 2963.38\n",
      "Training Epoch 6  59.6% | batch:        56 of        94\t|\tloss: 3510.02\n",
      "Training Epoch 6  60.6% | batch:        57 of        94\t|\tloss: 1738.95\n",
      "Training Epoch 6  61.7% | batch:        58 of        94\t|\tloss: 1829.65\n",
      "Training Epoch 6  62.8% | batch:        59 of        94\t|\tloss: 2702.82\n",
      "Training Epoch 6  63.8% | batch:        60 of        94\t|\tloss: 1896.8\n",
      "Training Epoch 6  64.9% | batch:        61 of        94\t|\tloss: 3113.09\n",
      "Training Epoch 6  66.0% | batch:        62 of        94\t|\tloss: 2066.5\n",
      "Training Epoch 6  67.0% | batch:        63 of        94\t|\tloss: 3101.03\n",
      "Training Epoch 6  68.1% | batch:        64 of        94\t|\tloss: 2624.85\n",
      "Training Epoch 6  69.1% | batch:        65 of        94\t|\tloss: 1493.45\n",
      "Training Epoch 6  70.2% | batch:        66 of        94\t|\tloss: 1739.44\n",
      "Training Epoch 6  71.3% | batch:        67 of        94\t|\tloss: 2098.69\n",
      "Training Epoch 6  72.3% | batch:        68 of        94\t|\tloss: 4216.51\n",
      "Training Epoch 6  73.4% | batch:        69 of        94\t|\tloss: 2065.56\n",
      "Training Epoch 6  74.5% | batch:        70 of        94\t|\tloss: 3708.62\n",
      "Training Epoch 6  75.5% | batch:        71 of        94\t|\tloss: 2180.43\n",
      "Training Epoch 6  76.6% | batch:        72 of        94\t|\tloss: 1734.27\n",
      "Training Epoch 6  77.7% | batch:        73 of        94\t|\tloss: 3733.3\n",
      "Training Epoch 6  78.7% | batch:        74 of        94\t|\tloss: 2910.46\n",
      "Training Epoch 6  79.8% | batch:        75 of        94\t|\tloss: 3556.96\n",
      "Training Epoch 6  80.9% | batch:        76 of        94\t|\tloss: 3300.2\n",
      "Training Epoch 6  81.9% | batch:        77 of        94\t|\tloss: 5047.93\n",
      "Training Epoch 6  83.0% | batch:        78 of        94\t|\tloss: 2842.95\n",
      "Training Epoch 6  84.0% | batch:        79 of        94\t|\tloss: 2537.94\n",
      "Training Epoch 6  85.1% | batch:        80 of        94\t|\tloss: 3502.18\n",
      "Training Epoch 6  86.2% | batch:        81 of        94\t|\tloss: 1957.85\n",
      "Training Epoch 6  87.2% | batch:        82 of        94\t|\tloss: 3933.49\n",
      "Training Epoch 6  88.3% | batch:        83 of        94\t|\tloss: 1621.17\n",
      "Training Epoch 6  89.4% | batch:        84 of        94\t|\tloss: 2258.9\n",
      "Training Epoch 6  90.4% | batch:        85 of        94\t|\tloss: 2665.69\n",
      "Training Epoch 6  91.5% | batch:        86 of        94\t|\tloss: 2004.68\n",
      "Training Epoch 6  92.6% | batch:        87 of        94\t|\tloss: 3723.68\n",
      "Training Epoch 6  93.6% | batch:        88 of        94\t|\tloss: 2220.79\n",
      "Training Epoch 6  94.7% | batch:        89 of        94\t|\tloss: 1666.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:30,118 | INFO : Epoch 6 Training Summary: epoch: 6.000000 | loss: 2625.539908 | \n",
      "2023-05-09 14:20:30,119 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8337030410766602 seconds\n",
      "\n",
      "2023-05-09 14:20:30,120 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8819890817006428 seconds\n",
      "2023-05-09 14:20:30,120 | INFO : Avg batch train. time: 0.02002116044362386 seconds\n",
      "2023-05-09 14:20:30,121 | INFO : Avg sample train. time: 0.00015791148529121018 seconds\n",
      "2023-05-09 14:20:30,121 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 6  95.7% | batch:        90 of        94\t|\tloss: 2743.31\n",
      "Training Epoch 6  96.8% | batch:        91 of        94\t|\tloss: 3522.12\n",
      "Training Epoch 6  97.9% | batch:        92 of        94\t|\tloss: 2165.57\n",
      "Training Epoch 6  98.9% | batch:        93 of        94\t|\tloss: 2002.93\n",
      "\n",
      "Evaluating Epoch 6   0.0% | batch:         0 of        40\t|\tloss: 6541.19\n",
      "Evaluating Epoch 6   2.5% | batch:         1 of        40\t|\tloss: 990.607\n",
      "Evaluating Epoch 6   5.0% | batch:         2 of        40\t|\tloss: 2666.74\n",
      "Evaluating Epoch 6   7.5% | batch:         3 of        40\t|\tloss: 6818.69\n",
      "Evaluating Epoch 6  10.0% | batch:         4 of        40\t|\tloss: 1970.73\n",
      "Evaluating Epoch 6  12.5% | batch:         5 of        40\t|\tloss: 2005.96\n",
      "Evaluating Epoch 6  15.0% | batch:         6 of        40\t|\tloss: 8032.79\n",
      "Evaluating Epoch 6  17.5% | batch:         7 of        40\t|\tloss: 3154.3\n",
      "Evaluating Epoch 6  20.0% | batch:         8 of        40\t|\tloss: 2466.11\n",
      "Evaluating Epoch 6  22.5% | batch:         9 of        40\t|\tloss: 1651.49\n",
      "Evaluating Epoch 6  25.0% | batch:        10 of        40\t|\tloss: 5035.81\n",
      "Evaluating Epoch 6  27.5% | batch:        11 of        40\t|\tloss: 1371.18\n",
      "Evaluating Epoch 6  30.0% | batch:        12 of        40\t|\tloss: 6402.51\n",
      "Evaluating Epoch 6  32.5% | batch:        13 of        40\t|\tloss: 3040.56\n",
      "Evaluating Epoch 6  35.0% | batch:        14 of        40\t|\tloss: 1677.92\n",
      "Evaluating Epoch 6  37.5% | batch:        15 of        40\t|\tloss: 3411.75\n",
      "Evaluating Epoch 6  40.0% | batch:        16 of        40\t|\tloss: 4387.16\n",
      "Evaluating Epoch 6  42.5% | batch:        17 of        40\t|\tloss: 2430.18\n",
      "Evaluating Epoch 6  45.0% | batch:        18 of        40\t|\tloss: 2144.11\n",
      "Evaluating Epoch 6  47.5% | batch:        19 of        40\t|\tloss: 4556.69\n",
      "Evaluating Epoch 6  50.0% | batch:        20 of        40\t|\tloss: 5255\n",
      "Evaluating Epoch 6  52.5% | batch:        21 of        40\t|\tloss: 1071.55\n",
      "Evaluating Epoch 6  55.0% | batch:        22 of        40\t|\tloss: 3145.54\n",
      "Evaluating Epoch 6  57.5% | batch:        23 of        40\t|\tloss: 2679.59\n",
      "Evaluating Epoch 6  60.0% | batch:        24 of        40\t|\tloss: 1813.84\n",
      "Evaluating Epoch 6  62.5% | batch:        25 of        40\t|\tloss: 2870.56\n",
      "Evaluating Epoch 6  65.0% | batch:        26 of        40\t|\tloss: 9904.26\n",
      "Evaluating Epoch 6  67.5% | batch:        27 of        40\t|\tloss: 2797.48\n",
      "Evaluating Epoch 6  70.0% | batch:        28 of        40\t|\tloss: 1757.07\n",
      "Evaluating Epoch 6  72.5% | batch:        29 of        40\t|\tloss: 8836.08\n",
      "Evaluating Epoch 6  75.0% | batch:        30 of        40\t|\tloss: 1699.08\n",
      "Evaluating Epoch 6  77.5% | batch:        31 of        40\t|\tloss: 1525.61\n",
      "Evaluating Epoch 6  80.0% | batch:        32 of        40\t|\tloss: 7246.09\n",
      "Evaluating Epoch 6  82.5% | batch:        33 of        40\t|\tloss: 6260.07\n",
      "Evaluating Epoch 6  85.0% | batch:        34 of        40\t|\tloss: 710.78\n",
      "Evaluating Epoch 6  87.5% | batch:        35 of        40\t|\tloss: 4682.96\n",
      "Evaluating Epoch 6  90.0% | batch:        36 of        40\t|\tloss: 5576.59\n",
      "Evaluating Epoch 6  92.5% | batch:        37 of        40\t|\tloss: 2399.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:30,579 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45781731605529785 seconds\n",
      "\n",
      "2023-05-09 14:20:30,580 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5889235973358155 seconds\n",
      "2023-05-09 14:20:30,580 | INFO : Avg batch val. time: 0.014723089933395387 seconds\n",
      "2023-05-09 14:20:30,581 | INFO : Avg sample val. time: 0.00011666473798253079 seconds\n",
      "2023-05-09 14:20:30,581 | INFO : Epoch 6 Validation Summary: epoch: 6.000000 | loss: 3777.355656 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 6  95.0% | batch:        38 of        40\t|\tloss: 3449.22\n",
      "Evaluating Epoch 6  97.5% | batch:        39 of        40\t|\tloss: 10358.8\n",
      "\n",
      "Training Epoch 7   0.0% | batch:         0 of        94\t|\tloss: 4642.71\n",
      "Training Epoch 7   1.1% | batch:         1 of        94\t|\tloss: 1786.71\n",
      "Training Epoch 7   2.1% | batch:         2 of        94\t|\tloss: 2890.27\n",
      "Training Epoch 7   3.2% | batch:         3 of        94\t|\tloss: 2899.52\n",
      "Training Epoch 7   4.3% | batch:         4 of        94\t|\tloss: 2418.64\n",
      "Training Epoch 7   5.3% | batch:         5 of        94\t|\tloss: 2104.13\n",
      "Training Epoch 7   6.4% | batch:         6 of        94\t|\tloss: 1718.12\n",
      "Training Epoch 7   7.4% | batch:         7 of        94\t|\tloss: 1834.75\n",
      "Training Epoch 7   8.5% | batch:         8 of        94\t|\tloss: 1823.19\n",
      "Training Epoch 7   9.6% | batch:         9 of        94\t|\tloss: 5191.47\n",
      "Training Epoch 7  10.6% | batch:        10 of        94\t|\tloss: 1518.04\n",
      "Training Epoch 7  11.7% | batch:        11 of        94\t|\tloss: 1923.49\n",
      "Training Epoch 7  12.8% | batch:        12 of        94\t|\tloss: 1265.75\n",
      "Training Epoch 7  13.8% | batch:        13 of        94\t|\tloss: 2046.93\n",
      "Training Epoch 7  14.9% | batch:        14 of        94\t|\tloss: 1350.82\n",
      "Training Epoch 7  16.0% | batch:        15 of        94\t|\tloss: 1404.37\n",
      "Training Epoch 7  17.0% | batch:        16 of        94\t|\tloss: 2023.8\n",
      "Training Epoch 7  18.1% | batch:        17 of        94\t|\tloss: 2093.96\n",
      "Training Epoch 7  19.1% | batch:        18 of        94\t|\tloss: 1756.38\n",
      "Training Epoch 7  20.2% | batch:        19 of        94\t|\tloss: 1723.03\n",
      "Training Epoch 7  21.3% | batch:        20 of        94\t|\tloss: 1973.49\n",
      "Training Epoch 7  22.3% | batch:        21 of        94\t|\tloss: 1763.65\n",
      "Training Epoch 7  23.4% | batch:        22 of        94\t|\tloss: 2572.17\n",
      "Training Epoch 7  24.5% | batch:        23 of        94\t|\tloss: 2407.55\n",
      "Training Epoch 7  25.5% | batch:        24 of        94\t|\tloss: 1763.7\n",
      "Training Epoch 7  26.6% | batch:        25 of        94\t|\tloss: 1937.91\n",
      "Training Epoch 7  27.7% | batch:        26 of        94\t|\tloss: 1373.91\n",
      "Training Epoch 7  28.7% | batch:        27 of        94\t|\tloss: 4212.14\n",
      "Training Epoch 7  29.8% | batch:        28 of        94\t|\tloss: 2333.63\n",
      "Training Epoch 7  30.9% | batch:        29 of        94\t|\tloss: 1453.15\n",
      "Training Epoch 7  31.9% | batch:        30 of        94\t|\tloss: 3320.19\n",
      "Training Epoch 7  33.0% | batch:        31 of        94\t|\tloss: 2891.93\n",
      "Training Epoch 7  34.0% | batch:        32 of        94\t|\tloss: 3144.92\n",
      "Training Epoch 7  35.1% | batch:        33 of        94\t|\tloss: 3365.71\n",
      "Training Epoch 7  36.2% | batch:        34 of        94\t|\tloss: 1531.14\n",
      "Training Epoch 7  37.2% | batch:        35 of        94\t|\tloss: 1997.74\n",
      "Training Epoch 7  38.3% | batch:        36 of        94\t|\tloss: 1511.67\n",
      "Training Epoch 7  39.4% | batch:        37 of        94\t|\tloss: 2359.91\n",
      "Training Epoch 7  40.4% | batch:        38 of        94\t|\tloss: 2552.83\n",
      "Training Epoch 7  41.5% | batch:        39 of        94\t|\tloss: 3664.16\n",
      "Training Epoch 7  42.6% | batch:        40 of        94\t|\tloss: 1660.53\n",
      "Training Epoch 7  43.6% | batch:        41 of        94\t|\tloss: 2164.51\n",
      "Training Epoch 7  44.7% | batch:        42 of        94\t|\tloss: 2946.96\n",
      "Training Epoch 7  45.7% | batch:        43 of        94\t|\tloss: 3386.67\n",
      "Training Epoch 7  46.8% | batch:        44 of        94\t|\tloss: 3108.34\n",
      "Training Epoch 7  47.9% | batch:        45 of        94\t|\tloss: 3609.48\n",
      "Training Epoch 7  48.9% | batch:        46 of        94\t|\tloss: 4412.39\n",
      "Training Epoch 7  50.0% | batch:        47 of        94\t|\tloss: 1793.47\n",
      "Training Epoch 7  51.1% | batch:        48 of        94\t|\tloss: 2799.16\n",
      "Training Epoch 7  52.1% | batch:        49 of        94\t|\tloss: 1858.08\n",
      "Training Epoch 7  53.2% | batch:        50 of        94\t|\tloss: 1453.38\n",
      "Training Epoch 7  54.3% | batch:        51 of        94\t|\tloss: 2239.46\n",
      "Training Epoch 7  55.3% | batch:        52 of        94\t|\tloss: 2034.1\n",
      "Training Epoch 7  56.4% | batch:        53 of        94\t|\tloss: 2023.29\n",
      "Training Epoch 7  57.4% | batch:        54 of        94\t|\tloss: 1981.62\n",
      "Training Epoch 7  58.5% | batch:        55 of        94\t|\tloss: 1781.99\n",
      "Training Epoch 7  59.6% | batch:        56 of        94\t|\tloss: 1806.09\n",
      "Training Epoch 7  60.6% | batch:        57 of        94\t|\tloss: 1980.58\n",
      "Training Epoch 7  61.7% | batch:        58 of        94\t|\tloss: 5542.54\n",
      "Training Epoch 7  62.8% | batch:        59 of        94\t|\tloss: 2331.64\n",
      "Training Epoch 7  63.8% | batch:        60 of        94\t|\tloss: 2197.95\n",
      "Training Epoch 7  64.9% | batch:        61 of        94\t|\tloss: 3015.56\n",
      "Training Epoch 7  66.0% | batch:        62 of        94\t|\tloss: 3333.54\n",
      "Training Epoch 7  67.0% | batch:        63 of        94\t|\tloss: 2814.5\n",
      "Training Epoch 7  68.1% | batch:        64 of        94\t|\tloss: 2460.85\n",
      "Training Epoch 7  69.1% | batch:        65 of        94\t|\tloss: 1967.72\n",
      "Training Epoch 7  70.2% | batch:        66 of        94\t|\tloss: 2328.82\n",
      "Training Epoch 7  71.3% | batch:        67 of        94\t|\tloss: 1906.02\n",
      "Training Epoch 7  72.3% | batch:        68 of        94\t|\tloss: 2190.12\n",
      "Training Epoch 7  73.4% | batch:        69 of        94\t|\tloss: 3232.13\n",
      "Training Epoch 7  74.5% | batch:        70 of        94\t|\tloss: 4771.93\n",
      "Training Epoch 7  75.5% | batch:        71 of        94\t|\tloss: 1596.84\n",
      "Training Epoch 7  76.6% | batch:        72 of        94\t|\tloss: 1677.73\n",
      "Training Epoch 7  77.7% | batch:        73 of        94\t|\tloss: 1895.18\n",
      "Training Epoch 7  78.7% | batch:        74 of        94\t|\tloss: 2345.83\n",
      "Training Epoch 7  79.8% | batch:        75 of        94\t|\tloss: 2285.37\n",
      "Training Epoch 7  80.9% | batch:        76 of        94\t|\tloss: 1955.26\n",
      "Training Epoch 7  81.9% | batch:        77 of        94\t|\tloss: 2192.06\n",
      "Training Epoch 7  83.0% | batch:        78 of        94\t|\tloss: 2933.74\n",
      "Training Epoch 7  84.0% | batch:        79 of        94\t|\tloss: 2629.68\n",
      "Training Epoch 7  85.1% | batch:        80 of        94\t|\tloss: 2153.65\n",
      "Training Epoch 7  86.2% | batch:        81 of        94\t|\tloss: 2052.75\n",
      "Training Epoch 7  87.2% | batch:        82 of        94\t|\tloss: 1181.33\n",
      "Training Epoch 7  88.3% | batch:        83 of        94\t|\tloss: 1947.57\n",
      "Training Epoch 7  89.4% | batch:        84 of        94\t|\tloss: 2577.1\n",
      "Training Epoch 7  90.4% | batch:        85 of        94\t|\tloss: 2017.96\n",
      "Training Epoch 7  91.5% | batch:        86 of        94\t|\tloss: 2713.08\n",
      "Training Epoch 7  92.6% | batch:        87 of        94\t|\tloss: 5706.41\n",
      "Training Epoch 7  93.6% | batch:        88 of        94\t|\tloss: 2115.19\n",
      "Training Epoch 7  94.7% | batch:        89 of        94\t|\tloss: 1956.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:32,474 | INFO : Epoch 7 Training Summary: epoch: 7.000000 | loss: 2409.426794 | \n",
      "2023-05-09 14:20:32,475 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8609893321990967 seconds\n",
      "\n",
      "2023-05-09 14:20:32,475 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8789891174861364 seconds\n",
      "2023-05-09 14:20:32,475 | INFO : Avg batch train. time: 0.01998924593070358 seconds\n",
      "2023-05-09 14:20:32,476 | INFO : Avg sample train. time: 0.00015765976820658972 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 7  95.7% | batch:        90 of        94\t|\tloss: 2627.02\n",
      "Training Epoch 7  96.8% | batch:        91 of        94\t|\tloss: 1472.3\n",
      "Training Epoch 7  97.9% | batch:        92 of        94\t|\tloss: 1911.02\n",
      "Training Epoch 7  98.9% | batch:        93 of        94\t|\tloss: 6544.31\n",
      "\n",
      "Training Epoch 8   0.0% | batch:         0 of        94\t|\tloss: 1681.83\n",
      "Training Epoch 8   1.1% | batch:         1 of        94\t|\tloss: 3617.58\n",
      "Training Epoch 8   2.1% | batch:         2 of        94\t|\tloss: 2009.93\n",
      "Training Epoch 8   3.2% | batch:         3 of        94\t|\tloss: 1949.63\n",
      "Training Epoch 8   4.3% | batch:         4 of        94\t|\tloss: 2710.26\n",
      "Training Epoch 8   5.3% | batch:         5 of        94\t|\tloss: 2122.1\n",
      "Training Epoch 8   6.4% | batch:         6 of        94\t|\tloss: 3462.45\n",
      "Training Epoch 8   7.4% | batch:         7 of        94\t|\tloss: 2393.22\n",
      "Training Epoch 8   8.5% | batch:         8 of        94\t|\tloss: 3852.82\n",
      "Training Epoch 8   9.6% | batch:         9 of        94\t|\tloss: 2818.44\n",
      "Training Epoch 8  10.6% | batch:        10 of        94\t|\tloss: 1633.44\n",
      "Training Epoch 8  11.7% | batch:        11 of        94\t|\tloss: 2151\n",
      "Training Epoch 8  12.8% | batch:        12 of        94\t|\tloss: 1630.27\n",
      "Training Epoch 8  13.8% | batch:        13 of        94\t|\tloss: 2312.01\n",
      "Training Epoch 8  14.9% | batch:        14 of        94\t|\tloss: 2331.87\n",
      "Training Epoch 8  16.0% | batch:        15 of        94\t|\tloss: 1581.59\n",
      "Training Epoch 8  17.0% | batch:        16 of        94\t|\tloss: 1695.26\n",
      "Training Epoch 8  18.1% | batch:        17 of        94\t|\tloss: 1750.2\n",
      "Training Epoch 8  19.1% | batch:        18 of        94\t|\tloss: 1521.71\n",
      "Training Epoch 8  20.2% | batch:        19 of        94\t|\tloss: 4809.37\n",
      "Training Epoch 8  21.3% | batch:        20 of        94\t|\tloss: 1258.2\n",
      "Training Epoch 8  22.3% | batch:        21 of        94\t|\tloss: 1941.76\n",
      "Training Epoch 8  23.4% | batch:        22 of        94\t|\tloss: 2555.07\n",
      "Training Epoch 8  24.5% | batch:        23 of        94\t|\tloss: 2135.88\n",
      "Training Epoch 8  25.5% | batch:        24 of        94\t|\tloss: 1980.28\n",
      "Training Epoch 8  26.6% | batch:        25 of        94\t|\tloss: 2400.32\n",
      "Training Epoch 8  27.7% | batch:        26 of        94\t|\tloss: 1496.74\n",
      "Training Epoch 8  28.7% | batch:        27 of        94\t|\tloss: 2148.14\n",
      "Training Epoch 8  29.8% | batch:        28 of        94\t|\tloss: 1754.79\n",
      "Training Epoch 8  30.9% | batch:        29 of        94\t|\tloss: 3006.98\n",
      "Training Epoch 8  31.9% | batch:        30 of        94\t|\tloss: 2822.35\n",
      "Training Epoch 8  33.0% | batch:        31 of        94\t|\tloss: 1979.53\n",
      "Training Epoch 8  34.0% | batch:        32 of        94\t|\tloss: 2329.33\n",
      "Training Epoch 8  35.1% | batch:        33 of        94\t|\tloss: 2121.97\n",
      "Training Epoch 8  36.2% | batch:        34 of        94\t|\tloss: 1899.12\n",
      "Training Epoch 8  37.2% | batch:        35 of        94\t|\tloss: 3533\n",
      "Training Epoch 8  38.3% | batch:        36 of        94\t|\tloss: 1773.51\n",
      "Training Epoch 8  39.4% | batch:        37 of        94\t|\tloss: 1560.91\n",
      "Training Epoch 8  40.4% | batch:        38 of        94\t|\tloss: 1569.12\n",
      "Training Epoch 8  41.5% | batch:        39 of        94\t|\tloss: 2386.77\n",
      "Training Epoch 8  42.6% | batch:        40 of        94\t|\tloss: 4852.5\n",
      "Training Epoch 8  43.6% | batch:        41 of        94\t|\tloss: 2631.59\n",
      "Training Epoch 8  44.7% | batch:        42 of        94\t|\tloss: 3240.47\n",
      "Training Epoch 8  45.7% | batch:        43 of        94\t|\tloss: 1163.59\n",
      "Training Epoch 8  46.8% | batch:        44 of        94\t|\tloss: 2114.55\n",
      "Training Epoch 8  47.9% | batch:        45 of        94\t|\tloss: 1703.44\n",
      "Training Epoch 8  48.9% | batch:        46 of        94\t|\tloss: 2009.26\n",
      "Training Epoch 8  50.0% | batch:        47 of        94\t|\tloss: 2796.82\n",
      "Training Epoch 8  51.1% | batch:        48 of        94\t|\tloss: 2492.21\n",
      "Training Epoch 8  52.1% | batch:        49 of        94\t|\tloss: 1761.8\n",
      "Training Epoch 8  53.2% | batch:        50 of        94\t|\tloss: 2582.76\n",
      "Training Epoch 8  54.3% | batch:        51 of        94\t|\tloss: 2504.45\n",
      "Training Epoch 8  55.3% | batch:        52 of        94\t|\tloss: 2143.56\n",
      "Training Epoch 8  56.4% | batch:        53 of        94\t|\tloss: 2032.94\n",
      "Training Epoch 8  57.4% | batch:        54 of        94\t|\tloss: 3726.21\n",
      "Training Epoch 8  58.5% | batch:        55 of        94\t|\tloss: 2122.48\n",
      "Training Epoch 8  59.6% | batch:        56 of        94\t|\tloss: 2109.1\n",
      "Training Epoch 8  60.6% | batch:        57 of        94\t|\tloss: 2468.48\n",
      "Training Epoch 8  61.7% | batch:        58 of        94\t|\tloss: 2485.39\n",
      "Training Epoch 8  62.8% | batch:        59 of        94\t|\tloss: 1773.17\n",
      "Training Epoch 8  63.8% | batch:        60 of        94\t|\tloss: 3558.34\n",
      "Training Epoch 8  64.9% | batch:        61 of        94\t|\tloss: 2968.12\n",
      "Training Epoch 8  66.0% | batch:        62 of        94\t|\tloss: 1842.98\n",
      "Training Epoch 8  67.0% | batch:        63 of        94\t|\tloss: 2306.04\n",
      "Training Epoch 8  68.1% | batch:        64 of        94\t|\tloss: 1947.44\n",
      "Training Epoch 8  69.1% | batch:        65 of        94\t|\tloss: 2847.1\n",
      "Training Epoch 8  70.2% | batch:        66 of        94\t|\tloss: 2304.33\n",
      "Training Epoch 8  71.3% | batch:        67 of        94\t|\tloss: 1943.4\n",
      "Training Epoch 8  72.3% | batch:        68 of        94\t|\tloss: 2580.33\n",
      "Training Epoch 8  73.4% | batch:        69 of        94\t|\tloss: 1531.86\n",
      "Training Epoch 8  74.5% | batch:        70 of        94\t|\tloss: 2485.7\n",
      "Training Epoch 8  75.5% | batch:        71 of        94\t|\tloss: 2041.21\n",
      "Training Epoch 8  76.6% | batch:        72 of        94\t|\tloss: 1915.71\n",
      "Training Epoch 8  77.7% | batch:        73 of        94\t|\tloss: 2301.55\n",
      "Training Epoch 8  78.7% | batch:        74 of        94\t|\tloss: 2552.61\n",
      "Training Epoch 8  79.8% | batch:        75 of        94\t|\tloss: 2538.46\n",
      "Training Epoch 8  80.9% | batch:        76 of        94\t|\tloss: 2865.47\n",
      "Training Epoch 8  81.9% | batch:        77 of        94\t|\tloss: 2339.73\n",
      "Training Epoch 8  83.0% | batch:        78 of        94\t|\tloss: 2149.71\n",
      "Training Epoch 8  84.0% | batch:        79 of        94\t|\tloss: 1391.38\n",
      "Training Epoch 8  85.1% | batch:        80 of        94\t|\tloss: 1919.53\n",
      "Training Epoch 8  86.2% | batch:        81 of        94\t|\tloss: 2013.14\n",
      "Training Epoch 8  87.2% | batch:        82 of        94\t|\tloss: 2187.21\n",
      "Training Epoch 8  88.3% | batch:        83 of        94\t|\tloss: 4050.16\n",
      "Training Epoch 8  89.4% | batch:        84 of        94\t|\tloss: 1740.61\n",
      "Training Epoch 8  90.4% | batch:        85 of        94\t|\tloss: 1734.05\n",
      "Training Epoch 8  91.5% | batch:        86 of        94\t|\tloss: 2387.02\n",
      "Training Epoch 8  92.6% | batch:        87 of        94\t|\tloss: 1830.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:34,329 | INFO : Epoch 8 Training Summary: epoch: 8.000000 | loss: 2348.907924 | \n",
      "2023-05-09 14:20:34,330 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8326561450958252 seconds\n",
      "\n",
      "2023-05-09 14:20:34,331 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8731974959373474 seconds\n",
      "2023-05-09 14:20:34,331 | INFO : Avg batch train. time: 0.019927632935503696 seconds\n",
      "2023-05-09 14:20:34,331 | INFO : Avg sample train. time: 0.00015717381237937133 seconds\n",
      "2023-05-09 14:20:34,332 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 8  93.6% | batch:        88 of        94\t|\tloss: 2345.38\n",
      "Training Epoch 8  94.7% | batch:        89 of        94\t|\tloss: 2329.02\n",
      "Training Epoch 8  95.7% | batch:        90 of        94\t|\tloss: 3921.98\n",
      "Training Epoch 8  96.8% | batch:        91 of        94\t|\tloss: 2540.65\n",
      "Training Epoch 8  97.9% | batch:        92 of        94\t|\tloss: 3688.48\n",
      "Training Epoch 8  98.9% | batch:        93 of        94\t|\tloss: 1850.17\n",
      "\n",
      "Evaluating Epoch 8   0.0% | batch:         0 of        40\t|\tloss: 6590.9\n",
      "Evaluating Epoch 8   2.5% | batch:         1 of        40\t|\tloss: 1057.88\n",
      "Evaluating Epoch 8   5.0% | batch:         2 of        40\t|\tloss: 3372.55\n",
      "Evaluating Epoch 8   7.5% | batch:         3 of        40\t|\tloss: 6858.62\n",
      "Evaluating Epoch 8  10.0% | batch:         4 of        40\t|\tloss: 2271.77\n",
      "Evaluating Epoch 8  12.5% | batch:         5 of        40\t|\tloss: 2658.16\n",
      "Evaluating Epoch 8  15.0% | batch:         6 of        40\t|\tloss: 7935.54\n",
      "Evaluating Epoch 8  17.5% | batch:         7 of        40\t|\tloss: 2607.24\n",
      "Evaluating Epoch 8  20.0% | batch:         8 of        40\t|\tloss: 2224.38\n",
      "Evaluating Epoch 8  22.5% | batch:         9 of        40\t|\tloss: 2190.51\n",
      "Evaluating Epoch 8  25.0% | batch:        10 of        40\t|\tloss: 4365.56\n",
      "Evaluating Epoch 8  27.5% | batch:        11 of        40\t|\tloss: 1529.71\n",
      "Evaluating Epoch 8  30.0% | batch:        12 of        40\t|\tloss: 5623.61\n",
      "Evaluating Epoch 8  32.5% | batch:        13 of        40\t|\tloss: 3196.3\n",
      "Evaluating Epoch 8  35.0% | batch:        14 of        40\t|\tloss: 1745.99\n",
      "Evaluating Epoch 8  37.5% | batch:        15 of        40\t|\tloss: 3505.77\n",
      "Evaluating Epoch 8  40.0% | batch:        16 of        40\t|\tloss: 4362.22\n",
      "Evaluating Epoch 8  42.5% | batch:        17 of        40\t|\tloss: 2113.35\n",
      "Evaluating Epoch 8  45.0% | batch:        18 of        40\t|\tloss: 2254.02\n",
      "Evaluating Epoch 8  47.5% | batch:        19 of        40\t|\tloss: 4455.39\n",
      "Evaluating Epoch 8  50.0% | batch:        20 of        40\t|\tloss: 4544.97\n",
      "Evaluating Epoch 8  52.5% | batch:        21 of        40\t|\tloss: 923.07\n",
      "Evaluating Epoch 8  55.0% | batch:        22 of        40\t|\tloss: 3940.12\n",
      "Evaluating Epoch 8  57.5% | batch:        23 of        40\t|\tloss: 3116.96\n",
      "Evaluating Epoch 8  60.0% | batch:        24 of        40\t|\tloss: 1817.4\n",
      "Evaluating Epoch 8  62.5% | batch:        25 of        40\t|\tloss: 3087.36\n",
      "Evaluating Epoch 8  65.0% | batch:        26 of        40\t|\tloss: 8935.94\n",
      "Evaluating Epoch 8  67.5% | batch:        27 of        40\t|\tloss: 2672.76\n",
      "Evaluating Epoch 8  70.0% | batch:        28 of        40\t|\tloss: 2307.94\n",
      "Evaluating Epoch 8  72.5% | batch:        29 of        40\t|\tloss: 8436.55\n",
      "Evaluating Epoch 8  75.0% | batch:        30 of        40\t|\tloss: 2308.17\n",
      "Evaluating Epoch 8  77.5% | batch:        31 of        40\t|\tloss: 2144.04\n",
      "Evaluating Epoch 8  80.0% | batch:        32 of        40\t|\tloss: 6805.52\n",
      "Evaluating Epoch 8  82.5% | batch:        33 of        40\t|\tloss: 6519.1\n",
      "Evaluating Epoch 8  85.0% | batch:        34 of        40\t|\tloss: 1027.14\n",
      "Evaluating Epoch 8  87.5% | batch:        35 of        40\t|\tloss: 4967.99\n",
      "Evaluating Epoch 8  90.0% | batch:        36 of        40\t|\tloss: 5627.08\n",
      "Evaluating Epoch 8  92.5% | batch:        37 of        40\t|\tloss: 2383.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:34,789 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4566922187805176 seconds\n",
      "\n",
      "2023-05-09 14:20:34,789 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5668850342432658 seconds\n",
      "2023-05-09 14:20:34,790 | INFO : Avg batch val. time: 0.014172125856081644 seconds\n",
      "2023-05-09 14:20:34,790 | INFO : Avg sample val. time: 0.00011229893705294488 seconds\n",
      "2023-05-09 14:20:34,791 | INFO : Epoch 8 Validation Summary: epoch: 8.000000 | loss: 3808.884927 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 8  95.0% | batch:        38 of        40\t|\tloss: 3552.16\n",
      "Evaluating Epoch 8  97.5% | batch:        39 of        40\t|\tloss: 9544.35\n",
      "\n",
      "Training Epoch 9   0.0% | batch:         0 of        94\t|\tloss: 2067.82\n",
      "Training Epoch 9   1.1% | batch:         1 of        94\t|\tloss: 2287.21\n",
      "Training Epoch 9   2.1% | batch:         2 of        94\t|\tloss: 3217.03\n",
      "Training Epoch 9   3.2% | batch:         3 of        94\t|\tloss: 4579.99\n",
      "Training Epoch 9   4.3% | batch:         4 of        94\t|\tloss: 1514.9\n",
      "Training Epoch 9   5.3% | batch:         5 of        94\t|\tloss: 1415.71\n",
      "Training Epoch 9   6.4% | batch:         6 of        94\t|\tloss: 1910.46\n",
      "Training Epoch 9   7.4% | batch:         7 of        94\t|\tloss: 2508.69\n",
      "Training Epoch 9   8.5% | batch:         8 of        94\t|\tloss: 1602.08\n",
      "Training Epoch 9   9.6% | batch:         9 of        94\t|\tloss: 1538.05\n",
      "Training Epoch 9  10.6% | batch:        10 of        94\t|\tloss: 3752.88\n",
      "Training Epoch 9  11.7% | batch:        11 of        94\t|\tloss: 1860.3\n",
      "Training Epoch 9  12.8% | batch:        12 of        94\t|\tloss: 1417.85\n",
      "Training Epoch 9  13.8% | batch:        13 of        94\t|\tloss: 2119.37\n",
      "Training Epoch 9  14.9% | batch:        14 of        94\t|\tloss: 5901.61\n",
      "Training Epoch 9  16.0% | batch:        15 of        94\t|\tloss: 2556\n",
      "Training Epoch 9  17.0% | batch:        16 of        94\t|\tloss: 2111.84\n",
      "Training Epoch 9  18.1% | batch:        17 of        94\t|\tloss: 1869.14\n",
      "Training Epoch 9  19.1% | batch:        18 of        94\t|\tloss: 1649.06\n",
      "Training Epoch 9  20.2% | batch:        19 of        94\t|\tloss: 1587.21\n",
      "Training Epoch 9  21.3% | batch:        20 of        94\t|\tloss: 2817.96\n",
      "Training Epoch 9  22.3% | batch:        21 of        94\t|\tloss: 3495.96\n",
      "Training Epoch 9  23.4% | batch:        22 of        94\t|\tloss: 1713.5\n",
      "Training Epoch 9  24.5% | batch:        23 of        94\t|\tloss: 2923.57\n",
      "Training Epoch 9  25.5% | batch:        24 of        94\t|\tloss: 2053.98\n",
      "Training Epoch 9  26.6% | batch:        25 of        94\t|\tloss: 1917.7\n",
      "Training Epoch 9  27.7% | batch:        26 of        94\t|\tloss: 1278.06\n",
      "Training Epoch 9  28.7% | batch:        27 of        94\t|\tloss: 1671.91\n",
      "Training Epoch 9  29.8% | batch:        28 of        94\t|\tloss: 2215.96\n",
      "Training Epoch 9  30.9% | batch:        29 of        94\t|\tloss: 2137.75\n",
      "Training Epoch 9  31.9% | batch:        30 of        94\t|\tloss: 1523.98\n",
      "Training Epoch 9  33.0% | batch:        31 of        94\t|\tloss: 2339.65\n",
      "Training Epoch 9  34.0% | batch:        32 of        94\t|\tloss: 2078.67\n",
      "Training Epoch 9  35.1% | batch:        33 of        94\t|\tloss: 2165.54\n",
      "Training Epoch 9  36.2% | batch:        34 of        94\t|\tloss: 1418.09\n",
      "Training Epoch 9  37.2% | batch:        35 of        94\t|\tloss: 1890.5\n",
      "Training Epoch 9  38.3% | batch:        36 of        94\t|\tloss: 3122.12\n",
      "Training Epoch 9  39.4% | batch:        37 of        94\t|\tloss: 2114.7\n",
      "Training Epoch 9  40.4% | batch:        38 of        94\t|\tloss: 2496\n",
      "Training Epoch 9  41.5% | batch:        39 of        94\t|\tloss: 1960.97\n",
      "Training Epoch 9  42.6% | batch:        40 of        94\t|\tloss: 3514.61\n",
      "Training Epoch 9  43.6% | batch:        41 of        94\t|\tloss: 4849.4\n",
      "Training Epoch 9  44.7% | batch:        42 of        94\t|\tloss: 2113.03\n",
      "Training Epoch 9  45.7% | batch:        43 of        94\t|\tloss: 1827.61\n",
      "Training Epoch 9  46.8% | batch:        44 of        94\t|\tloss: 1295.95\n",
      "Training Epoch 9  47.9% | batch:        45 of        94\t|\tloss: 2458.66\n",
      "Training Epoch 9  48.9% | batch:        46 of        94\t|\tloss: 1497.46\n",
      "Training Epoch 9  50.0% | batch:        47 of        94\t|\tloss: 1499.82\n",
      "Training Epoch 9  51.1% | batch:        48 of        94\t|\tloss: 2043.67\n",
      "Training Epoch 9  52.1% | batch:        49 of        94\t|\tloss: 5947.47\n",
      "Training Epoch 9  53.2% | batch:        50 of        94\t|\tloss: 1458.33\n",
      "Training Epoch 9  54.3% | batch:        51 of        94\t|\tloss: 2044.9\n",
      "Training Epoch 9  55.3% | batch:        52 of        94\t|\tloss: 3353.94\n",
      "Training Epoch 9  56.4% | batch:        53 of        94\t|\tloss: 4103.51\n",
      "Training Epoch 9  57.4% | batch:        54 of        94\t|\tloss: 1470.91\n",
      "Training Epoch 9  58.5% | batch:        55 of        94\t|\tloss: 3256.71\n",
      "Training Epoch 9  59.6% | batch:        56 of        94\t|\tloss: 1434.89\n",
      "Training Epoch 9  60.6% | batch:        57 of        94\t|\tloss: 1510.52\n",
      "Training Epoch 9  61.7% | batch:        58 of        94\t|\tloss: 2027.96\n",
      "Training Epoch 9  62.8% | batch:        59 of        94\t|\tloss: 2496.44\n",
      "Training Epoch 9  63.8% | batch:        60 of        94\t|\tloss: 1656.29\n",
      "Training Epoch 9  64.9% | batch:        61 of        94\t|\tloss: 2281.08\n",
      "Training Epoch 9  66.0% | batch:        62 of        94\t|\tloss: 1681.28\n",
      "Training Epoch 9  67.0% | batch:        63 of        94\t|\tloss: 2526.75\n",
      "Training Epoch 9  68.1% | batch:        64 of        94\t|\tloss: 2769.43\n",
      "Training Epoch 9  69.1% | batch:        65 of        94\t|\tloss: 1837.91\n",
      "Training Epoch 9  70.2% | batch:        66 of        94\t|\tloss: 2786.34\n",
      "Training Epoch 9  71.3% | batch:        67 of        94\t|\tloss: 2805.34\n",
      "Training Epoch 9  72.3% | batch:        68 of        94\t|\tloss: 2411.99\n",
      "Training Epoch 9  73.4% | batch:        69 of        94\t|\tloss: 3550.59\n",
      "Training Epoch 9  74.5% | batch:        70 of        94\t|\tloss: 2274.89\n",
      "Training Epoch 9  75.5% | batch:        71 of        94\t|\tloss: 2003.59\n",
      "Training Epoch 9  76.6% | batch:        72 of        94\t|\tloss: 1558.64\n",
      "Training Epoch 9  77.7% | batch:        73 of        94\t|\tloss: 1987.18\n",
      "Training Epoch 9  78.7% | batch:        74 of        94\t|\tloss: 1411.13\n",
      "Training Epoch 9  79.8% | batch:        75 of        94\t|\tloss: 2014.35\n",
      "Training Epoch 9  80.9% | batch:        76 of        94\t|\tloss: 1782.47\n",
      "Training Epoch 9  81.9% | batch:        77 of        94\t|\tloss: 1656.15\n",
      "Training Epoch 9  83.0% | batch:        78 of        94\t|\tloss: 2191.85\n",
      "Training Epoch 9  84.0% | batch:        79 of        94\t|\tloss: 2078.18\n",
      "Training Epoch 9  85.1% | batch:        80 of        94\t|\tloss: 2672.08\n",
      "Training Epoch 9  86.2% | batch:        81 of        94\t|\tloss: 2301.89\n",
      "Training Epoch 9  87.2% | batch:        82 of        94\t|\tloss: 2599.41\n",
      "Training Epoch 9  88.3% | batch:        83 of        94\t|\tloss: 1836.49\n",
      "Training Epoch 9  89.4% | batch:        84 of        94\t|\tloss: 1861.08\n",
      "Training Epoch 9  90.4% | batch:        85 of        94\t|\tloss: 1707.33\n",
      "Training Epoch 9  91.5% | batch:        86 of        94\t|\tloss: 2323.54\n",
      "Training Epoch 9  92.6% | batch:        87 of        94\t|\tloss: 2383.47\n",
      "Training Epoch 9  93.6% | batch:        88 of        94\t|\tloss: 1522.82\n",
      "Training Epoch 9  94.7% | batch:        89 of        94\t|\tloss: 1779.08\n",
      "Training Epoch 9  95.7% | batch:        90 of        94\t|\tloss: 1223.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:36,639 | INFO : Epoch 9 Training Summary: epoch: 9.000000 | loss: 2265.164929 | \n",
      "2023-05-09 14:20:36,640 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8276042938232422 seconds\n",
      "\n",
      "2023-05-09 14:20:36,640 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8681315845913358 seconds\n",
      "2023-05-09 14:20:36,641 | INFO : Avg batch train. time: 0.019873740261609953 seconds\n",
      "2023-05-09 14:20:36,642 | INFO : Avg sample train. time: 0.00015674874849734316 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 9  96.8% | batch:        91 of        94\t|\tloss: 1996.26\n",
      "Training Epoch 9  97.9% | batch:        92 of        94\t|\tloss: 2063.38\n",
      "Training Epoch 9  98.9% | batch:        93 of        94\t|\tloss: 3317.44\n",
      "\n",
      "Training Epoch 10   0.0% | batch:         0 of        94\t|\tloss: 1188.2\n",
      "Training Epoch 10   1.1% | batch:         1 of        94\t|\tloss: 1749.97\n",
      "Training Epoch 10   2.1% | batch:         2 of        94\t|\tloss: 1966.57\n",
      "Training Epoch 10   3.2% | batch:         3 of        94\t|\tloss: 1590.12\n",
      "Training Epoch 10   4.3% | batch:         4 of        94\t|\tloss: 2395.24\n",
      "Training Epoch 10   5.3% | batch:         5 of        94\t|\tloss: 3608.36\n",
      "Training Epoch 10   6.4% | batch:         6 of        94\t|\tloss: 4073.52\n",
      "Training Epoch 10   7.4% | batch:         7 of        94\t|\tloss: 1500.12\n",
      "Training Epoch 10   8.5% | batch:         8 of        94\t|\tloss: 2015.07\n",
      "Training Epoch 10   9.6% | batch:         9 of        94\t|\tloss: 3500.12\n",
      "Training Epoch 10  10.6% | batch:        10 of        94\t|\tloss: 3203.47\n",
      "Training Epoch 10  11.7% | batch:        11 of        94\t|\tloss: 1799.08\n",
      "Training Epoch 10  12.8% | batch:        12 of        94\t|\tloss: 2173.15\n",
      "Training Epoch 10  13.8% | batch:        13 of        94\t|\tloss: 2498.24\n",
      "Training Epoch 10  14.9% | batch:        14 of        94\t|\tloss: 1590.32\n",
      "Training Epoch 10  16.0% | batch:        15 of        94\t|\tloss: 3401.94\n",
      "Training Epoch 10  17.0% | batch:        16 of        94\t|\tloss: 1317.55\n",
      "Training Epoch 10  18.1% | batch:        17 of        94\t|\tloss: 3047.8\n",
      "Training Epoch 10  19.1% | batch:        18 of        94\t|\tloss: 1669.63\n",
      "Training Epoch 10  20.2% | batch:        19 of        94\t|\tloss: 1363.32\n",
      "Training Epoch 10  21.3% | batch:        20 of        94\t|\tloss: 1849.17\n",
      "Training Epoch 10  22.3% | batch:        21 of        94\t|\tloss: 2432.37\n",
      "Training Epoch 10  23.4% | batch:        22 of        94\t|\tloss: 1459.8\n",
      "Training Epoch 10  24.5% | batch:        23 of        94\t|\tloss: 2589.92\n",
      "Training Epoch 10  25.5% | batch:        24 of        94\t|\tloss: 1732.26\n",
      "Training Epoch 10  26.6% | batch:        25 of        94\t|\tloss: 3225.98\n",
      "Training Epoch 10  27.7% | batch:        26 of        94\t|\tloss: 1986.05\n",
      "Training Epoch 10  28.7% | batch:        27 of        94\t|\tloss: 3352.6\n",
      "Training Epoch 10  29.8% | batch:        28 of        94\t|\tloss: 1836.72\n",
      "Training Epoch 10  30.9% | batch:        29 of        94\t|\tloss: 2113.47\n",
      "Training Epoch 10  31.9% | batch:        30 of        94\t|\tloss: 6374.06\n",
      "Training Epoch 10  33.0% | batch:        31 of        94\t|\tloss: 1762\n",
      "Training Epoch 10  34.0% | batch:        32 of        94\t|\tloss: 2151.58\n",
      "Training Epoch 10  35.1% | batch:        33 of        94\t|\tloss: 2261.5\n",
      "Training Epoch 10  36.2% | batch:        34 of        94\t|\tloss: 3712.42\n",
      "Training Epoch 10  37.2% | batch:        35 of        94\t|\tloss: 1402.13\n",
      "Training Epoch 10  38.3% | batch:        36 of        94\t|\tloss: 1809.96\n",
      "Training Epoch 10  39.4% | batch:        37 of        94\t|\tloss: 3137.33\n",
      "Training Epoch 10  40.4% | batch:        38 of        94\t|\tloss: 2626.18\n",
      "Training Epoch 10  41.5% | batch:        39 of        94\t|\tloss: 1918.02\n",
      "Training Epoch 10  42.6% | batch:        40 of        94\t|\tloss: 2655.35\n",
      "Training Epoch 10  43.6% | batch:        41 of        94\t|\tloss: 1728.04\n",
      "Training Epoch 10  44.7% | batch:        42 of        94\t|\tloss: 2037.94\n",
      "Training Epoch 10  45.7% | batch:        43 of        94\t|\tloss: 1996.05\n",
      "Training Epoch 10  46.8% | batch:        44 of        94\t|\tloss: 3188.25\n",
      "Training Epoch 10  47.9% | batch:        45 of        94\t|\tloss: 2194.72\n",
      "Training Epoch 10  48.9% | batch:        46 of        94\t|\tloss: 1659.57\n",
      "Training Epoch 10  50.0% | batch:        47 of        94\t|\tloss: 1134.63\n",
      "Training Epoch 10  51.1% | batch:        48 of        94\t|\tloss: 2061.23\n",
      "Training Epoch 10  52.1% | batch:        49 of        94\t|\tloss: 1982.13\n",
      "Training Epoch 10  53.2% | batch:        50 of        94\t|\tloss: 3143.28\n",
      "Training Epoch 10  54.3% | batch:        51 of        94\t|\tloss: 1647.4\n",
      "Training Epoch 10  55.3% | batch:        52 of        94\t|\tloss: 1675.21\n",
      "Training Epoch 10  56.4% | batch:        53 of        94\t|\tloss: 1645.76\n",
      "Training Epoch 10  57.4% | batch:        54 of        94\t|\tloss: 2443.76\n",
      "Training Epoch 10  58.5% | batch:        55 of        94\t|\tloss: 1464.1\n",
      "Training Epoch 10  59.6% | batch:        56 of        94\t|\tloss: 1996.18\n",
      "Training Epoch 10  60.6% | batch:        57 of        94\t|\tloss: 1577.91\n",
      "Training Epoch 10  61.7% | batch:        58 of        94\t|\tloss: 3146.6\n",
      "Training Epoch 10  62.8% | batch:        59 of        94\t|\tloss: 2329.72\n",
      "Training Epoch 10  63.8% | batch:        60 of        94\t|\tloss: 1672.54\n",
      "Training Epoch 10  64.9% | batch:        61 of        94\t|\tloss: 2918.02\n",
      "Training Epoch 10  66.0% | batch:        62 of        94\t|\tloss: 2013\n",
      "Training Epoch 10  67.0% | batch:        63 of        94\t|\tloss: 2046.27\n",
      "Training Epoch 10  68.1% | batch:        64 of        94\t|\tloss: 1397.65\n",
      "Training Epoch 10  69.1% | batch:        65 of        94\t|\tloss: 1865.8\n",
      "Training Epoch 10  70.2% | batch:        66 of        94\t|\tloss: 2558.4\n",
      "Training Epoch 10  71.3% | batch:        67 of        94\t|\tloss: 1619.01\n",
      "Training Epoch 10  72.3% | batch:        68 of        94\t|\tloss: 1509.77\n",
      "Training Epoch 10  73.4% | batch:        69 of        94\t|\tloss: 1721.82\n",
      "Training Epoch 10  74.5% | batch:        70 of        94\t|\tloss: 1635.56\n",
      "Training Epoch 10  75.5% | batch:        71 of        94\t|\tloss: 1723.63\n",
      "Training Epoch 10  76.6% | batch:        72 of        94\t|\tloss: 1691.35\n",
      "Training Epoch 10  77.7% | batch:        73 of        94\t|\tloss: 1756.15\n",
      "Training Epoch 10  78.7% | batch:        74 of        94\t|\tloss: 1325.8\n",
      "Training Epoch 10  79.8% | batch:        75 of        94\t|\tloss: 2245.72\n",
      "Training Epoch 10  80.9% | batch:        76 of        94\t|\tloss: 1246.33\n",
      "Training Epoch 10  81.9% | batch:        77 of        94\t|\tloss: 1625.04\n",
      "Training Epoch 10  83.0% | batch:        78 of        94\t|\tloss: 2986.98\n",
      "Training Epoch 10  84.0% | batch:        79 of        94\t|\tloss: 2086.05\n",
      "Training Epoch 10  85.1% | batch:        80 of        94\t|\tloss: 2149.27\n",
      "Training Epoch 10  86.2% | batch:        81 of        94\t|\tloss: 1728.21\n",
      "Training Epoch 10  87.2% | batch:        82 of        94\t|\tloss: 1569.39\n",
      "Training Epoch 10  88.3% | batch:        83 of        94\t|\tloss: 2397.7\n",
      "Training Epoch 10  89.4% | batch:        84 of        94\t|\tloss: 2096.78\n",
      "Training Epoch 10  90.4% | batch:        85 of        94\t|\tloss: 1854.84\n",
      "Training Epoch 10  91.5% | batch:        86 of        94\t|\tloss: 1543.1\n",
      "Training Epoch 10  92.6% | batch:        87 of        94\t|\tloss: 1418.89\n",
      "Training Epoch 10  93.6% | batch:        88 of        94\t|\tloss: 3177.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:38,512 | INFO : Epoch 10 Training Summary: epoch: 10.000000 | loss: 2184.556390 | \n",
      "2023-05-09 14:20:38,513 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.849696159362793 seconds\n",
      "\n",
      "2023-05-09 14:20:38,514 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8662880420684815 seconds\n",
      "2023-05-09 14:20:38,514 | INFO : Avg batch train. time: 0.019854128107111506 seconds\n",
      "2023-05-09 14:20:38,515 | INFO : Avg sample train. time: 0.00015659406293576787 seconds\n",
      "2023-05-09 14:20:38,515 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 10  94.7% | batch:        89 of        94\t|\tloss: 1746\n",
      "Training Epoch 10  95.7% | batch:        90 of        94\t|\tloss: 2068\n",
      "Training Epoch 10  96.8% | batch:        91 of        94\t|\tloss: 3912.36\n",
      "Training Epoch 10  97.9% | batch:        92 of        94\t|\tloss: 2790.14\n",
      "Training Epoch 10  98.9% | batch:        93 of        94\t|\tloss: 1944.46\n",
      "\n",
      "Evaluating Epoch 10   0.0% | batch:         0 of        40\t|\tloss: 6665.52\n",
      "Evaluating Epoch 10   2.5% | batch:         1 of        40\t|\tloss: 1068.04\n",
      "Evaluating Epoch 10   5.0% | batch:         2 of        40\t|\tloss: 2279.03\n",
      "Evaluating Epoch 10   7.5% | batch:         3 of        40\t|\tloss: 7357.57\n",
      "Evaluating Epoch 10  10.0% | batch:         4 of        40\t|\tloss: 2002.23\n",
      "Evaluating Epoch 10  12.5% | batch:         5 of        40\t|\tloss: 1785.1\n",
      "Evaluating Epoch 10  15.0% | batch:         6 of        40\t|\tloss: 8340.92\n",
      "Evaluating Epoch 10  17.5% | batch:         7 of        40\t|\tloss: 2505.13\n",
      "Evaluating Epoch 10  20.0% | batch:         8 of        40\t|\tloss: 2509.44\n",
      "Evaluating Epoch 10  22.5% | batch:         9 of        40\t|\tloss: 1936.47\n",
      "Evaluating Epoch 10  25.0% | batch:        10 of        40\t|\tloss: 4411.74\n",
      "Evaluating Epoch 10  27.5% | batch:        11 of        40\t|\tloss: 1407.31\n",
      "Evaluating Epoch 10  30.0% | batch:        12 of        40\t|\tloss: 6624.57\n",
      "Evaluating Epoch 10  32.5% | batch:        13 of        40\t|\tloss: 3123.5\n",
      "Evaluating Epoch 10  35.0% | batch:        14 of        40\t|\tloss: 1680.54\n",
      "Evaluating Epoch 10  37.5% | batch:        15 of        40\t|\tloss: 3456.03\n",
      "Evaluating Epoch 10  40.0% | batch:        16 of        40\t|\tloss: 4883.47\n",
      "Evaluating Epoch 10  42.5% | batch:        17 of        40\t|\tloss: 2012.86\n",
      "Evaluating Epoch 10  45.0% | batch:        18 of        40\t|\tloss: 2214.46\n",
      "Evaluating Epoch 10  47.5% | batch:        19 of        40\t|\tloss: 6406.17\n",
      "Evaluating Epoch 10  50.0% | batch:        20 of        40\t|\tloss: 5339.91\n",
      "Evaluating Epoch 10  52.5% | batch:        21 of        40\t|\tloss: 1207.85\n",
      "Evaluating Epoch 10  55.0% | batch:        22 of        40\t|\tloss: 3392.21\n",
      "Evaluating Epoch 10  57.5% | batch:        23 of        40\t|\tloss: 2834.64\n",
      "Evaluating Epoch 10  60.0% | batch:        24 of        40\t|\tloss: 1697.1\n",
      "Evaluating Epoch 10  62.5% | batch:        25 of        40\t|\tloss: 3324.48\n",
      "Evaluating Epoch 10  65.0% | batch:        26 of        40\t|\tloss: 11531.8\n",
      "Evaluating Epoch 10  67.5% | batch:        27 of        40\t|\tloss: 2558.24\n",
      "Evaluating Epoch 10  70.0% | batch:        28 of        40\t|\tloss: 1857.85\n",
      "Evaluating Epoch 10  72.5% | batch:        29 of        40\t|\tloss: 9934.1\n",
      "Evaluating Epoch 10  75.0% | batch:        30 of        40\t|\tloss: 1731.75\n",
      "Evaluating Epoch 10  77.5% | batch:        31 of        40\t|\tloss: 1456.89\n",
      "Evaluating Epoch 10  80.0% | batch:        32 of        40\t|\tloss: 7061.75\n",
      "Evaluating Epoch 10  82.5% | batch:        33 of        40\t|\tloss: 6826.25\n",
      "Evaluating Epoch 10  85.0% | batch:        34 of        40\t|\tloss: 1089.78\n",
      "Evaluating Epoch 10  87.5% | batch:        35 of        40\t|\tloss: 4724.31\n",
      "Evaluating Epoch 10  90.0% | batch:        36 of        40\t|\tloss: 5519.37\n",
      "Evaluating Epoch 10  92.5% | batch:        37 of        40\t|\tloss: 2460.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:38,971 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4557464122772217 seconds\n",
      "\n",
      "2023-05-09 14:20:38,972 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5510080882481166 seconds\n",
      "2023-05-09 14:20:38,973 | INFO : Avg batch val. time: 0.013775202206202916 seconds\n",
      "2023-05-09 14:20:38,973 | INFO : Avg sample val. time: 0.0001091537417290247 seconds\n",
      "2023-05-09 14:20:38,974 | INFO : Epoch 10 Validation Summary: epoch: 10.000000 | loss: 3955.196953 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 10  95.0% | batch:        38 of        40\t|\tloss: 3574.55\n",
      "Evaluating Epoch 10  97.5% | batch:        39 of        40\t|\tloss: 11862.6\n",
      "\n",
      "Training Epoch 11   0.0% | batch:         0 of        94\t|\tloss: 2987.84\n",
      "Training Epoch 11   1.1% | batch:         1 of        94\t|\tloss: 2645.34\n",
      "Training Epoch 11   2.1% | batch:         2 of        94\t|\tloss: 1960.9\n",
      "Training Epoch 11   3.2% | batch:         3 of        94\t|\tloss: 3294.36\n",
      "Training Epoch 11   4.3% | batch:         4 of        94\t|\tloss: 2060.01\n",
      "Training Epoch 11   5.3% | batch:         5 of        94\t|\tloss: 2227.3\n",
      "Training Epoch 11   6.4% | batch:         6 of        94\t|\tloss: 2269.29\n",
      "Training Epoch 11   7.4% | batch:         7 of        94\t|\tloss: 7922.76\n",
      "Training Epoch 11   8.5% | batch:         8 of        94\t|\tloss: 1511.23\n",
      "Training Epoch 11   9.6% | batch:         9 of        94\t|\tloss: 1793.75\n",
      "Training Epoch 11  10.6% | batch:        10 of        94\t|\tloss: 2855.12\n",
      "Training Epoch 11  11.7% | batch:        11 of        94\t|\tloss: 1635.42\n",
      "Training Epoch 11  12.8% | batch:        12 of        94\t|\tloss: 4225.46\n",
      "Training Epoch 11  13.8% | batch:        13 of        94\t|\tloss: 2131.44\n",
      "Training Epoch 11  14.9% | batch:        14 of        94\t|\tloss: 1275.64\n",
      "Training Epoch 11  16.0% | batch:        15 of        94\t|\tloss: 2485.94\n",
      "Training Epoch 11  17.0% | batch:        16 of        94\t|\tloss: 3002.3\n",
      "Training Epoch 11  18.1% | batch:        17 of        94\t|\tloss: 3051.93\n",
      "Training Epoch 11  19.1% | batch:        18 of        94\t|\tloss: 2985.53\n",
      "Training Epoch 11  20.2% | batch:        19 of        94\t|\tloss: 2351.77\n",
      "Training Epoch 11  21.3% | batch:        20 of        94\t|\tloss: 2467.66\n",
      "Training Epoch 11  22.3% | batch:        21 of        94\t|\tloss: 2335.32\n",
      "Training Epoch 11  23.4% | batch:        22 of        94\t|\tloss: 1879.87\n",
      "Training Epoch 11  24.5% | batch:        23 of        94\t|\tloss: 1765.84\n",
      "Training Epoch 11  25.5% | batch:        24 of        94\t|\tloss: 2708.81\n",
      "Training Epoch 11  26.6% | batch:        25 of        94\t|\tloss: 2034.88\n",
      "Training Epoch 11  27.7% | batch:        26 of        94\t|\tloss: 2701.25\n",
      "Training Epoch 11  28.7% | batch:        27 of        94\t|\tloss: 2153.81\n",
      "Training Epoch 11  29.8% | batch:        28 of        94\t|\tloss: 1604.09\n",
      "Training Epoch 11  30.9% | batch:        29 of        94\t|\tloss: 1352.24\n",
      "Training Epoch 11  31.9% | batch:        30 of        94\t|\tloss: 2120.83\n",
      "Training Epoch 11  33.0% | batch:        31 of        94\t|\tloss: 1686.18\n",
      "Training Epoch 11  34.0% | batch:        32 of        94\t|\tloss: 2235.39\n",
      "Training Epoch 11  35.1% | batch:        33 of        94\t|\tloss: 1386.45\n",
      "Training Epoch 11  36.2% | batch:        34 of        94\t|\tloss: 1359.42\n",
      "Training Epoch 11  37.2% | batch:        35 of        94\t|\tloss: 1936.46\n",
      "Training Epoch 11  38.3% | batch:        36 of        94\t|\tloss: 1694.65\n",
      "Training Epoch 11  39.4% | batch:        37 of        94\t|\tloss: 2254.33\n",
      "Training Epoch 11  40.4% | batch:        38 of        94\t|\tloss: 1342.02\n",
      "Training Epoch 11  41.5% | batch:        39 of        94\t|\tloss: 2446.33\n",
      "Training Epoch 11  42.6% | batch:        40 of        94\t|\tloss: 1854.45\n",
      "Training Epoch 11  43.6% | batch:        41 of        94\t|\tloss: 2524.79\n",
      "Training Epoch 11  44.7% | batch:        42 of        94\t|\tloss: 1634.11\n",
      "Training Epoch 11  45.7% | batch:        43 of        94\t|\tloss: 2919.13\n",
      "Training Epoch 11  46.8% | batch:        44 of        94\t|\tloss: 3307.76\n",
      "Training Epoch 11  47.9% | batch:        45 of        94\t|\tloss: 1984.17\n",
      "Training Epoch 11  48.9% | batch:        46 of        94\t|\tloss: 2510.84\n",
      "Training Epoch 11  50.0% | batch:        47 of        94\t|\tloss: 2139.28\n",
      "Training Epoch 11  51.1% | batch:        48 of        94\t|\tloss: 1490.06\n",
      "Training Epoch 11  52.1% | batch:        49 of        94\t|\tloss: 1578.22\n",
      "Training Epoch 11  53.2% | batch:        50 of        94\t|\tloss: 1626.44\n",
      "Training Epoch 11  54.3% | batch:        51 of        94\t|\tloss: 1837.51\n",
      "Training Epoch 11  55.3% | batch:        52 of        94\t|\tloss: 2252.03\n",
      "Training Epoch 11  56.4% | batch:        53 of        94\t|\tloss: 1557.88\n",
      "Training Epoch 11  57.4% | batch:        54 of        94\t|\tloss: 1836.48\n",
      "Training Epoch 11  58.5% | batch:        55 of        94\t|\tloss: 5244.96\n",
      "Training Epoch 11  59.6% | batch:        56 of        94\t|\tloss: 2130.5\n",
      "Training Epoch 11  60.6% | batch:        57 of        94\t|\tloss: 2053.18\n",
      "Training Epoch 11  61.7% | batch:        58 of        94\t|\tloss: 2962.66\n",
      "Training Epoch 11  62.8% | batch:        59 of        94\t|\tloss: 3066.06\n",
      "Training Epoch 11  63.8% | batch:        60 of        94\t|\tloss: 1472.32\n",
      "Training Epoch 11  64.9% | batch:        61 of        94\t|\tloss: 3313.59\n",
      "Training Epoch 11  66.0% | batch:        62 of        94\t|\tloss: 1827.12\n",
      "Training Epoch 11  67.0% | batch:        63 of        94\t|\tloss: 2201.76\n",
      "Training Epoch 11  68.1% | batch:        64 of        94\t|\tloss: 2588.11\n",
      "Training Epoch 11  69.1% | batch:        65 of        94\t|\tloss: 2460\n",
      "Training Epoch 11  70.2% | batch:        66 of        94\t|\tloss: 1721.02\n",
      "Training Epoch 11  71.3% | batch:        67 of        94\t|\tloss: 1365.52\n",
      "Training Epoch 11  72.3% | batch:        68 of        94\t|\tloss: 1834.89\n",
      "Training Epoch 11  73.4% | batch:        69 of        94\t|\tloss: 1320.88\n",
      "Training Epoch 11  74.5% | batch:        70 of        94\t|\tloss: 1877.66\n",
      "Training Epoch 11  75.5% | batch:        71 of        94\t|\tloss: 2555.7\n",
      "Training Epoch 11  76.6% | batch:        72 of        94\t|\tloss: 1670.6\n",
      "Training Epoch 11  77.7% | batch:        73 of        94\t|\tloss: 2142.13\n",
      "Training Epoch 11  78.7% | batch:        74 of        94\t|\tloss: 1352.91\n",
      "Training Epoch 11  79.8% | batch:        75 of        94\t|\tloss: 2121.74\n",
      "Training Epoch 11  80.9% | batch:        76 of        94\t|\tloss: 1780.51\n",
      "Training Epoch 11  81.9% | batch:        77 of        94\t|\tloss: 1685.28\n",
      "Training Epoch 11  83.0% | batch:        78 of        94\t|\tloss: 1793.76\n",
      "Training Epoch 11  84.0% | batch:        79 of        94\t|\tloss: 1640.53\n",
      "Training Epoch 11  85.1% | batch:        80 of        94\t|\tloss: 1491.75\n",
      "Training Epoch 11  86.2% | batch:        81 of        94\t|\tloss: 1794.99\n",
      "Training Epoch 11  87.2% | batch:        82 of        94\t|\tloss: 2598.52\n",
      "Training Epoch 11  88.3% | batch:        83 of        94\t|\tloss: 1629.46\n",
      "Training Epoch 11  89.4% | batch:        84 of        94\t|\tloss: 1335.56\n",
      "Training Epoch 11  90.4% | batch:        85 of        94\t|\tloss: 2511.35\n",
      "Training Epoch 11  91.5% | batch:        86 of        94\t|\tloss: 2016.44\n",
      "Training Epoch 11  92.6% | batch:        87 of        94\t|\tloss: 2846.79\n",
      "Training Epoch 11  93.6% | batch:        88 of        94\t|\tloss: 1498.15\n",
      "Training Epoch 11  94.7% | batch:        89 of        94\t|\tloss: 2068.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:40,826 | INFO : Epoch 11 Training Summary: epoch: 11.000000 | loss: 2202.415544 | \n",
      "2023-05-09 14:20:40,826 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8304240703582764 seconds\n",
      "\n",
      "2023-05-09 14:20:40,827 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8630276810039172 seconds\n",
      "2023-05-09 14:20:40,827 | INFO : Avg batch train. time: 0.01981944341493529 seconds\n",
      "2023-05-09 14:20:40,828 | INFO : Avg sample train. time: 0.00015632049681187424 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 11  95.7% | batch:        90 of        94\t|\tloss: 1756.19\n",
      "Training Epoch 11  96.8% | batch:        91 of        94\t|\tloss: 1890.85\n",
      "Training Epoch 11  97.9% | batch:        92 of        94\t|\tloss: 1437.8\n",
      "Training Epoch 11  98.9% | batch:        93 of        94\t|\tloss: 7432.94\n",
      "\n",
      "Training Epoch 12   0.0% | batch:         0 of        94\t|\tloss: 1902.56\n",
      "Training Epoch 12   1.1% | batch:         1 of        94\t|\tloss: 2273.23\n",
      "Training Epoch 12   2.1% | batch:         2 of        94\t|\tloss: 3184.4\n",
      "Training Epoch 12   3.2% | batch:         3 of        94\t|\tloss: 2414.3\n",
      "Training Epoch 12   4.3% | batch:         4 of        94\t|\tloss: 1257.53\n",
      "Training Epoch 12   5.3% | batch:         5 of        94\t|\tloss: 1582.95\n",
      "Training Epoch 12   6.4% | batch:         6 of        94\t|\tloss: 1123.08\n",
      "Training Epoch 12   7.4% | batch:         7 of        94\t|\tloss: 2037.42\n",
      "Training Epoch 12   8.5% | batch:         8 of        94\t|\tloss: 1850.45\n",
      "Training Epoch 12   9.6% | batch:         9 of        94\t|\tloss: 1758.2\n",
      "Training Epoch 12  10.6% | batch:        10 of        94\t|\tloss: 1840.13\n",
      "Training Epoch 12  11.7% | batch:        11 of        94\t|\tloss: 1851.3\n",
      "Training Epoch 12  12.8% | batch:        12 of        94\t|\tloss: 1937.87\n",
      "Training Epoch 12  13.8% | batch:        13 of        94\t|\tloss: 2030.84\n",
      "Training Epoch 12  14.9% | batch:        14 of        94\t|\tloss: 2905.3\n",
      "Training Epoch 12  16.0% | batch:        15 of        94\t|\tloss: 1479.23\n",
      "Training Epoch 12  17.0% | batch:        16 of        94\t|\tloss: 2503.39\n",
      "Training Epoch 12  18.1% | batch:        17 of        94\t|\tloss: 2388.05\n",
      "Training Epoch 12  19.1% | batch:        18 of        94\t|\tloss: 3913.7\n",
      "Training Epoch 12  20.2% | batch:        19 of        94\t|\tloss: 2928.01\n",
      "Training Epoch 12  21.3% | batch:        20 of        94\t|\tloss: 2164.03\n",
      "Training Epoch 12  22.3% | batch:        21 of        94\t|\tloss: 2467.2\n",
      "Training Epoch 12  23.4% | batch:        22 of        94\t|\tloss: 2944.98\n",
      "Training Epoch 12  24.5% | batch:        23 of        94\t|\tloss: 2085.8\n",
      "Training Epoch 12  25.5% | batch:        24 of        94\t|\tloss: 1677.18\n",
      "Training Epoch 12  26.6% | batch:        25 of        94\t|\tloss: 1535.05\n",
      "Training Epoch 12  27.7% | batch:        26 of        94\t|\tloss: 1958.22\n",
      "Training Epoch 12  28.7% | batch:        27 of        94\t|\tloss: 2208.53\n",
      "Training Epoch 12  29.8% | batch:        28 of        94\t|\tloss: 1581.64\n",
      "Training Epoch 12  30.9% | batch:        29 of        94\t|\tloss: 2868.09\n",
      "Training Epoch 12  31.9% | batch:        30 of        94\t|\tloss: 1938.75\n",
      "Training Epoch 12  33.0% | batch:        31 of        94\t|\tloss: 1817.05\n",
      "Training Epoch 12  34.0% | batch:        32 of        94\t|\tloss: 2397.72\n",
      "Training Epoch 12  35.1% | batch:        33 of        94\t|\tloss: 2034.31\n",
      "Training Epoch 12  36.2% | batch:        34 of        94\t|\tloss: 1535.08\n",
      "Training Epoch 12  37.2% | batch:        35 of        94\t|\tloss: 1528.42\n",
      "Training Epoch 12  38.3% | batch:        36 of        94\t|\tloss: 1942.96\n",
      "Training Epoch 12  39.4% | batch:        37 of        94\t|\tloss: 1649.68\n",
      "Training Epoch 12  40.4% | batch:        38 of        94\t|\tloss: 2679.85\n",
      "Training Epoch 12  41.5% | batch:        39 of        94\t|\tloss: 2485.52\n",
      "Training Epoch 12  42.6% | batch:        40 of        94\t|\tloss: 1910.98\n",
      "Training Epoch 12  43.6% | batch:        41 of        94\t|\tloss: 2004.94\n",
      "Training Epoch 12  44.7% | batch:        42 of        94\t|\tloss: 1906.76\n",
      "Training Epoch 12  45.7% | batch:        43 of        94\t|\tloss: 1882.65\n",
      "Training Epoch 12  46.8% | batch:        44 of        94\t|\tloss: 4761.65\n",
      "Training Epoch 12  47.9% | batch:        45 of        94\t|\tloss: 1955.11\n",
      "Training Epoch 12  48.9% | batch:        46 of        94\t|\tloss: 1315.45\n",
      "Training Epoch 12  50.0% | batch:        47 of        94\t|\tloss: 1670.94\n",
      "Training Epoch 12  51.1% | batch:        48 of        94\t|\tloss: 1466.05\n",
      "Training Epoch 12  52.1% | batch:        49 of        94\t|\tloss: 1680.02\n",
      "Training Epoch 12  53.2% | batch:        50 of        94\t|\tloss: 5528.67\n",
      "Training Epoch 12  54.3% | batch:        51 of        94\t|\tloss: 1728.56\n",
      "Training Epoch 12  55.3% | batch:        52 of        94\t|\tloss: 1738.58\n",
      "Training Epoch 12  56.4% | batch:        53 of        94\t|\tloss: 1647.25\n",
      "Training Epoch 12  57.4% | batch:        54 of        94\t|\tloss: 2414.11\n",
      "Training Epoch 12  58.5% | batch:        55 of        94\t|\tloss: 3857.88\n",
      "Training Epoch 12  59.6% | batch:        56 of        94\t|\tloss: 3348.52\n",
      "Training Epoch 12  60.6% | batch:        57 of        94\t|\tloss: 3201.56\n",
      "Training Epoch 12  61.7% | batch:        58 of        94\t|\tloss: 2565.26\n",
      "Training Epoch 12  62.8% | batch:        59 of        94\t|\tloss: 1553.93\n",
      "Training Epoch 12  63.8% | batch:        60 of        94\t|\tloss: 1433.52\n",
      "Training Epoch 12  64.9% | batch:        61 of        94\t|\tloss: 2038\n",
      "Training Epoch 12  66.0% | batch:        62 of        94\t|\tloss: 2066.5\n",
      "Training Epoch 12  67.0% | batch:        63 of        94\t|\tloss: 2683\n",
      "Training Epoch 12  68.1% | batch:        64 of        94\t|\tloss: 1788.86\n",
      "Training Epoch 12  69.1% | batch:        65 of        94\t|\tloss: 2226.29\n",
      "Training Epoch 12  70.2% | batch:        66 of        94\t|\tloss: 2636.49\n",
      "Training Epoch 12  71.3% | batch:        67 of        94\t|\tloss: 2564.83\n",
      "Training Epoch 12  72.3% | batch:        68 of        94\t|\tloss: 1381.72\n",
      "Training Epoch 12  73.4% | batch:        69 of        94\t|\tloss: 1424.89\n",
      "Training Epoch 12  74.5% | batch:        70 of        94\t|\tloss: 2422.68\n",
      "Training Epoch 12  75.5% | batch:        71 of        94\t|\tloss: 1642.62\n",
      "Training Epoch 12  76.6% | batch:        72 of        94\t|\tloss: 2781.72\n",
      "Training Epoch 12  77.7% | batch:        73 of        94\t|\tloss: 2861.96\n",
      "Training Epoch 12  78.7% | batch:        74 of        94\t|\tloss: 3220.14\n",
      "Training Epoch 12  79.8% | batch:        75 of        94\t|\tloss: 1868.64\n",
      "Training Epoch 12  80.9% | batch:        76 of        94\t|\tloss: 2104.35\n",
      "Training Epoch 12  81.9% | batch:        77 of        94\t|\tloss: 1156.97\n",
      "Training Epoch 12  83.0% | batch:        78 of        94\t|\tloss: 1688.38\n",
      "Training Epoch 12  84.0% | batch:        79 of        94\t|\tloss: 1769.08\n",
      "Training Epoch 12  85.1% | batch:        80 of        94\t|\tloss: 1887.03\n",
      "Training Epoch 12  86.2% | batch:        81 of        94\t|\tloss: 2061.19\n",
      "Training Epoch 12  87.2% | batch:        82 of        94\t|\tloss: 4217.17\n",
      "Training Epoch 12  88.3% | batch:        83 of        94\t|\tloss: 1396.52\n",
      "Training Epoch 12  89.4% | batch:        84 of        94\t|\tloss: 4512.26\n",
      "Training Epoch 12  90.4% | batch:        85 of        94\t|\tloss: 1686\n",
      "Training Epoch 12  91.5% | batch:        86 of        94\t|\tloss: 3212.9\n",
      "Training Epoch 12  92.6% | batch:        87 of        94\t|\tloss: 1643.04\n",
      "Training Epoch 12  93.6% | batch:        88 of        94\t|\tloss: 1899.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:42,695 | INFO : Epoch 12 Training Summary: epoch: 12.000000 | loss: 2198.537278 | \n",
      "2023-05-09 14:20:42,696 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8464837074279785 seconds\n",
      "\n",
      "2023-05-09 14:20:42,696 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8616490165392559 seconds\n",
      "2023-05-09 14:20:42,696 | INFO : Avg batch train. time: 0.01980477677169421 seconds\n",
      "2023-05-09 14:20:42,697 | INFO : Avg sample train. time: 0.0001562048176320906 seconds\n",
      "2023-05-09 14:20:42,697 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 12  94.7% | batch:        89 of        94\t|\tloss: 2318.75\n",
      "Training Epoch 12  95.7% | batch:        90 of        94\t|\tloss: 1394.37\n",
      "Training Epoch 12  96.8% | batch:        91 of        94\t|\tloss: 1552.08\n",
      "Training Epoch 12  97.9% | batch:        92 of        94\t|\tloss: 1879.98\n",
      "Training Epoch 12  98.9% | batch:        93 of        94\t|\tloss: 4412.13\n",
      "\n",
      "Evaluating Epoch 12   0.0% | batch:         0 of        40\t|\tloss: 6316.59\n",
      "Evaluating Epoch 12   2.5% | batch:         1 of        40\t|\tloss: 781.392\n",
      "Evaluating Epoch 12   5.0% | batch:         2 of        40\t|\tloss: 2705.9\n",
      "Evaluating Epoch 12   7.5% | batch:         3 of        40\t|\tloss: 5854.85\n",
      "Evaluating Epoch 12  10.0% | batch:         4 of        40\t|\tloss: 2015.24\n",
      "Evaluating Epoch 12  12.5% | batch:         5 of        40\t|\tloss: 1946.59\n",
      "Evaluating Epoch 12  15.0% | batch:         6 of        40\t|\tloss: 7498.04\n",
      "Evaluating Epoch 12  17.5% | batch:         7 of        40\t|\tloss: 2716.08\n",
      "Evaluating Epoch 12  20.0% | batch:         8 of        40\t|\tloss: 2125.41\n",
      "Evaluating Epoch 12  22.5% | batch:         9 of        40\t|\tloss: 1539.19\n",
      "Evaluating Epoch 12  25.0% | batch:        10 of        40\t|\tloss: 3845.97\n",
      "Evaluating Epoch 12  27.5% | batch:        11 of        40\t|\tloss: 1200.11\n",
      "Evaluating Epoch 12  30.0% | batch:        12 of        40\t|\tloss: 5880.38\n",
      "Evaluating Epoch 12  32.5% | batch:        13 of        40\t|\tloss: 2685.22\n",
      "Evaluating Epoch 12  35.0% | batch:        14 of        40\t|\tloss: 1696.97\n",
      "Evaluating Epoch 12  37.5% | batch:        15 of        40\t|\tloss: 3564.26\n",
      "Evaluating Epoch 12  40.0% | batch:        16 of        40\t|\tloss: 3711.78\n",
      "Evaluating Epoch 12  42.5% | batch:        17 of        40\t|\tloss: 2434.67\n",
      "Evaluating Epoch 12  45.0% | batch:        18 of        40\t|\tloss: 1984.48\n",
      "Evaluating Epoch 12  47.5% | batch:        19 of        40\t|\tloss: 4859.25\n",
      "Evaluating Epoch 12  50.0% | batch:        20 of        40\t|\tloss: 4534.74\n",
      "Evaluating Epoch 12  52.5% | batch:        21 of        40\t|\tloss: 965.894\n",
      "Evaluating Epoch 12  55.0% | batch:        22 of        40\t|\tloss: 3218.71\n",
      "Evaluating Epoch 12  57.5% | batch:        23 of        40\t|\tloss: 2818.64\n",
      "Evaluating Epoch 12  60.0% | batch:        24 of        40\t|\tloss: 1348.28\n",
      "Evaluating Epoch 12  62.5% | batch:        25 of        40\t|\tloss: 3287.83\n",
      "Evaluating Epoch 12  65.0% | batch:        26 of        40\t|\tloss: 8212.97\n",
      "Evaluating Epoch 12  67.5% | batch:        27 of        40\t|\tloss: 2538.49\n",
      "Evaluating Epoch 12  70.0% | batch:        28 of        40\t|\tloss: 1769.29\n",
      "Evaluating Epoch 12  72.5% | batch:        29 of        40\t|\tloss: 8711.82\n",
      "Evaluating Epoch 12  75.0% | batch:        30 of        40\t|\tloss: 1793.24\n",
      "Evaluating Epoch 12  77.5% | batch:        31 of        40\t|\tloss: 1444.75\n",
      "Evaluating Epoch 12  80.0% | batch:        32 of        40\t|\tloss: 6458.68\n",
      "Evaluating Epoch 12  82.5% | batch:        33 of        40\t|\tloss: 5772.99\n",
      "Evaluating Epoch 12  85.0% | batch:        34 of        40\t|\tloss: 835.35\n",
      "Evaluating Epoch 12  87.5% | batch:        35 of        40\t|\tloss: 4354.54\n",
      "Evaluating Epoch 12  90.0% | batch:        36 of        40\t|\tloss: 4452.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:43,156 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45816707611083984 seconds\n",
      "\n",
      "2023-05-09 14:20:43,156 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.539402961730957 seconds\n",
      "2023-05-09 14:20:43,157 | INFO : Avg batch val. time: 0.013485074043273926 seconds\n",
      "2023-05-09 14:20:43,157 | INFO : Avg sample val. time: 0.00010685478639678229 seconds\n",
      "2023-05-09 14:20:43,158 | INFO : Epoch 12 Validation Summary: epoch: 12.000000 | loss: 3503.097864 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 12  92.5% | batch:        37 of        40\t|\tloss: 2225.78\n",
      "Evaluating Epoch 12  95.0% | batch:        38 of        40\t|\tloss: 3615.42\n",
      "Evaluating Epoch 12  97.5% | batch:        39 of        40\t|\tloss: 10127.8\n",
      "\n",
      "Training Epoch 13   0.0% | batch:         0 of        94\t|\tloss: 1741.23\n",
      "Training Epoch 13   1.1% | batch:         1 of        94\t|\tloss: 1718.67\n",
      "Training Epoch 13   2.1% | batch:         2 of        94\t|\tloss: 1784.51\n",
      "Training Epoch 13   3.2% | batch:         3 of        94\t|\tloss: 1960.32\n",
      "Training Epoch 13   4.3% | batch:         4 of        94\t|\tloss: 1486.04\n",
      "Training Epoch 13   5.3% | batch:         5 of        94\t|\tloss: 2442.83\n",
      "Training Epoch 13   6.4% | batch:         6 of        94\t|\tloss: 1304.09\n",
      "Training Epoch 13   7.4% | batch:         7 of        94\t|\tloss: 1594.23\n",
      "Training Epoch 13   8.5% | batch:         8 of        94\t|\tloss: 1369.03\n",
      "Training Epoch 13   9.6% | batch:         9 of        94\t|\tloss: 3072.53\n",
      "Training Epoch 13  10.6% | batch:        10 of        94\t|\tloss: 2605.46\n",
      "Training Epoch 13  11.7% | batch:        11 of        94\t|\tloss: 1856.63\n",
      "Training Epoch 13  12.8% | batch:        12 of        94\t|\tloss: 1621.79\n",
      "Training Epoch 13  13.8% | batch:        13 of        94\t|\tloss: 1967.3\n",
      "Training Epoch 13  14.9% | batch:        14 of        94\t|\tloss: 3653.21\n",
      "Training Epoch 13  16.0% | batch:        15 of        94\t|\tloss: 2419.09\n",
      "Training Epoch 13  17.0% | batch:        16 of        94\t|\tloss: 3309.51\n",
      "Training Epoch 13  18.1% | batch:        17 of        94\t|\tloss: 1174.42\n",
      "Training Epoch 13  19.1% | batch:        18 of        94\t|\tloss: 1684.63\n",
      "Training Epoch 13  20.2% | batch:        19 of        94\t|\tloss: 1378.02\n",
      "Training Epoch 13  21.3% | batch:        20 of        94\t|\tloss: 1763.55\n",
      "Training Epoch 13  22.3% | batch:        21 of        94\t|\tloss: 1664.76\n",
      "Training Epoch 13  23.4% | batch:        22 of        94\t|\tloss: 1632.66\n",
      "Training Epoch 13  24.5% | batch:        23 of        94\t|\tloss: 1910.31\n",
      "Training Epoch 13  25.5% | batch:        24 of        94\t|\tloss: 1951.7\n",
      "Training Epoch 13  26.6% | batch:        25 of        94\t|\tloss: 4203.63\n",
      "Training Epoch 13  27.7% | batch:        26 of        94\t|\tloss: 1716.42\n",
      "Training Epoch 13  28.7% | batch:        27 of        94\t|\tloss: 2293.3\n",
      "Training Epoch 13  29.8% | batch:        28 of        94\t|\tloss: 1200.42\n",
      "Training Epoch 13  30.9% | batch:        29 of        94\t|\tloss: 1619.39\n",
      "Training Epoch 13  31.9% | batch:        30 of        94\t|\tloss: 1234.82\n",
      "Training Epoch 13  33.0% | batch:        31 of        94\t|\tloss: 2514.7\n",
      "Training Epoch 13  34.0% | batch:        32 of        94\t|\tloss: 1366.74\n",
      "Training Epoch 13  35.1% | batch:        33 of        94\t|\tloss: 1223.86\n",
      "Training Epoch 13  36.2% | batch:        34 of        94\t|\tloss: 1909.24\n",
      "Training Epoch 13  37.2% | batch:        35 of        94\t|\tloss: 1776.73\n",
      "Training Epoch 13  38.3% | batch:        36 of        94\t|\tloss: 3210.2\n",
      "Training Epoch 13  39.4% | batch:        37 of        94\t|\tloss: 1884.88\n",
      "Training Epoch 13  40.4% | batch:        38 of        94\t|\tloss: 2144.95\n",
      "Training Epoch 13  41.5% | batch:        39 of        94\t|\tloss: 2028.58\n",
      "Training Epoch 13  42.6% | batch:        40 of        94\t|\tloss: 2377.82\n",
      "Training Epoch 13  43.6% | batch:        41 of        94\t|\tloss: 2322.68\n",
      "Training Epoch 13  44.7% | batch:        42 of        94\t|\tloss: 3327.4\n",
      "Training Epoch 13  45.7% | batch:        43 of        94\t|\tloss: 1874.93\n",
      "Training Epoch 13  46.8% | batch:        44 of        94\t|\tloss: 1990.1\n",
      "Training Epoch 13  47.9% | batch:        45 of        94\t|\tloss: 1783.48\n",
      "Training Epoch 13  48.9% | batch:        46 of        94\t|\tloss: 2249.9\n",
      "Training Epoch 13  50.0% | batch:        47 of        94\t|\tloss: 1793.97\n",
      "Training Epoch 13  51.1% | batch:        48 of        94\t|\tloss: 2654.71\n",
      "Training Epoch 13  52.1% | batch:        49 of        94\t|\tloss: 2285.48\n",
      "Training Epoch 13  53.2% | batch:        50 of        94\t|\tloss: 2173.6\n",
      "Training Epoch 13  54.3% | batch:        51 of        94\t|\tloss: 2831.87\n",
      "Training Epoch 13  55.3% | batch:        52 of        94\t|\tloss: 1534.73\n",
      "Training Epoch 13  56.4% | batch:        53 of        94\t|\tloss: 2096.24\n",
      "Training Epoch 13  57.4% | batch:        54 of        94\t|\tloss: 1722.03\n",
      "Training Epoch 13  58.5% | batch:        55 of        94\t|\tloss: 1386.08\n",
      "Training Epoch 13  59.6% | batch:        56 of        94\t|\tloss: 1742.91\n",
      "Training Epoch 13  60.6% | batch:        57 of        94\t|\tloss: 1720.34\n",
      "Training Epoch 13  61.7% | batch:        58 of        94\t|\tloss: 2629.57\n",
      "Training Epoch 13  62.8% | batch:        59 of        94\t|\tloss: 1564.99\n",
      "Training Epoch 13  63.8% | batch:        60 of        94\t|\tloss: 2406.75\n",
      "Training Epoch 13  64.9% | batch:        61 of        94\t|\tloss: 4260.21\n",
      "Training Epoch 13  66.0% | batch:        62 of        94\t|\tloss: 1998.45\n",
      "Training Epoch 13  67.0% | batch:        63 of        94\t|\tloss: 2436.18\n",
      "Training Epoch 13  68.1% | batch:        64 of        94\t|\tloss: 2475.64\n",
      "Training Epoch 13  69.1% | batch:        65 of        94\t|\tloss: 2654.95\n",
      "Training Epoch 13  70.2% | batch:        66 of        94\t|\tloss: 2227.8\n",
      "Training Epoch 13  71.3% | batch:        67 of        94\t|\tloss: 2864.46\n",
      "Training Epoch 13  72.3% | batch:        68 of        94\t|\tloss: 3603.49\n",
      "Training Epoch 13  73.4% | batch:        69 of        94\t|\tloss: 1305.8\n",
      "Training Epoch 13  74.5% | batch:        70 of        94\t|\tloss: 1632.59\n",
      "Training Epoch 13  75.5% | batch:        71 of        94\t|\tloss: 2398.02\n",
      "Training Epoch 13  76.6% | batch:        72 of        94\t|\tloss: 1418.62\n",
      "Training Epoch 13  77.7% | batch:        73 of        94\t|\tloss: 3069.25\n",
      "Training Epoch 13  78.7% | batch:        74 of        94\t|\tloss: 1064.12\n",
      "Training Epoch 13  79.8% | batch:        75 of        94\t|\tloss: 1639.26\n",
      "Training Epoch 13  80.9% | batch:        76 of        94\t|\tloss: 1483.44\n",
      "Training Epoch 13  81.9% | batch:        77 of        94\t|\tloss: 1814.85\n",
      "Training Epoch 13  83.0% | batch:        78 of        94\t|\tloss: 1288.92\n",
      "Training Epoch 13  84.0% | batch:        79 of        94\t|\tloss: 1910.77\n",
      "Training Epoch 13  85.1% | batch:        80 of        94\t|\tloss: 3348.21\n",
      "Training Epoch 13  86.2% | batch:        81 of        94\t|\tloss: 1563.66\n",
      "Training Epoch 13  87.2% | batch:        82 of        94\t|\tloss: 1626.24\n",
      "Training Epoch 13  88.3% | batch:        83 of        94\t|\tloss: 3390.47\n",
      "Training Epoch 13  89.4% | batch:        84 of        94\t|\tloss: 1911.64\n",
      "Training Epoch 13  90.4% | batch:        85 of        94\t|\tloss: 1279.67\n",
      "Training Epoch 13  91.5% | batch:        86 of        94\t|\tloss: 2485.46\n",
      "Training Epoch 13  92.6% | batch:        87 of        94\t|\tloss: 1456.14\n",
      "Training Epoch 13  93.6% | batch:        88 of        94\t|\tloss: 1378.88\n",
      "Training Epoch 13  94.7% | batch:        89 of        94\t|\tloss: 1665.8\n",
      "Training Epoch 13  95.7% | batch:        90 of        94\t|\tloss: 1807.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:45,034 | INFO : Epoch 13 Training Summary: epoch: 13.000000 | loss: 2068.946639 | \n",
      "2023-05-09 14:20:45,034 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8521897792816162 seconds\n",
      "\n",
      "2023-05-09 14:20:45,035 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8609213829040527 seconds\n",
      "2023-05-09 14:20:45,035 | INFO : Avg batch train. time: 0.019797035988340986 seconds\n",
      "2023-05-09 14:20:45,035 | INFO : Avg sample train. time: 0.000156143764298041 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 13  96.8% | batch:        91 of        94\t|\tloss: 2515.03\n",
      "Training Epoch 13  97.9% | batch:        92 of        94\t|\tloss: 2525.46\n",
      "Training Epoch 13  98.9% | batch:        93 of        94\t|\tloss: 2503.44\n",
      "\n",
      "Training Epoch 14   0.0% | batch:         0 of        94\t|\tloss: 1495.58\n",
      "Training Epoch 14   1.1% | batch:         1 of        94\t|\tloss: 2419.29\n",
      "Training Epoch 14   2.1% | batch:         2 of        94\t|\tloss: 2355.8\n",
      "Training Epoch 14   3.2% | batch:         3 of        94\t|\tloss: 1571.87\n",
      "Training Epoch 14   4.3% | batch:         4 of        94\t|\tloss: 2945.3\n",
      "Training Epoch 14   5.3% | batch:         5 of        94\t|\tloss: 1492.1\n",
      "Training Epoch 14   6.4% | batch:         6 of        94\t|\tloss: 2563.67\n",
      "Training Epoch 14   7.4% | batch:         7 of        94\t|\tloss: 1406.77\n",
      "Training Epoch 14   8.5% | batch:         8 of        94\t|\tloss: 1703.8\n",
      "Training Epoch 14   9.6% | batch:         9 of        94\t|\tloss: 1486.16\n",
      "Training Epoch 14  10.6% | batch:        10 of        94\t|\tloss: 1306.07\n",
      "Training Epoch 14  11.7% | batch:        11 of        94\t|\tloss: 1353.27\n",
      "Training Epoch 14  12.8% | batch:        12 of        94\t|\tloss: 1574.74\n",
      "Training Epoch 14  13.8% | batch:        13 of        94\t|\tloss: 1415.84\n",
      "Training Epoch 14  14.9% | batch:        14 of        94\t|\tloss: 2458.97\n",
      "Training Epoch 14  16.0% | batch:        15 of        94\t|\tloss: 1803.54\n",
      "Training Epoch 14  17.0% | batch:        16 of        94\t|\tloss: 3690.26\n",
      "Training Epoch 14  18.1% | batch:        17 of        94\t|\tloss: 1545.13\n",
      "Training Epoch 14  19.1% | batch:        18 of        94\t|\tloss: 1770.93\n",
      "Training Epoch 14  20.2% | batch:        19 of        94\t|\tloss: 1698.04\n",
      "Training Epoch 14  21.3% | batch:        20 of        94\t|\tloss: 1464.42\n",
      "Training Epoch 14  22.3% | batch:        21 of        94\t|\tloss: 1842.4\n",
      "Training Epoch 14  23.4% | batch:        22 of        94\t|\tloss: 1179.21\n",
      "Training Epoch 14  24.5% | batch:        23 of        94\t|\tloss: 2090.33\n",
      "Training Epoch 14  25.5% | batch:        24 of        94\t|\tloss: 1658.77\n",
      "Training Epoch 14  26.6% | batch:        25 of        94\t|\tloss: 1857.74\n",
      "Training Epoch 14  27.7% | batch:        26 of        94\t|\tloss: 1617.97\n",
      "Training Epoch 14  28.7% | batch:        27 of        94\t|\tloss: 2056.08\n",
      "Training Epoch 14  29.8% | batch:        28 of        94\t|\tloss: 2049.08\n",
      "Training Epoch 14  30.9% | batch:        29 of        94\t|\tloss: 2106.17\n",
      "Training Epoch 14  31.9% | batch:        30 of        94\t|\tloss: 2548.23\n",
      "Training Epoch 14  33.0% | batch:        31 of        94\t|\tloss: 1893.73\n",
      "Training Epoch 14  34.0% | batch:        32 of        94\t|\tloss: 3310.29\n",
      "Training Epoch 14  35.1% | batch:        33 of        94\t|\tloss: 1570.07\n",
      "Training Epoch 14  36.2% | batch:        34 of        94\t|\tloss: 3761.13\n",
      "Training Epoch 14  37.2% | batch:        35 of        94\t|\tloss: 2340.75\n",
      "Training Epoch 14  38.3% | batch:        36 of        94\t|\tloss: 1910.45\n",
      "Training Epoch 14  39.4% | batch:        37 of        94\t|\tloss: 1513.52\n",
      "Training Epoch 14  40.4% | batch:        38 of        94\t|\tloss: 2880.26\n",
      "Training Epoch 14  41.5% | batch:        39 of        94\t|\tloss: 1675.18\n",
      "Training Epoch 14  42.6% | batch:        40 of        94\t|\tloss: 3237.44\n",
      "Training Epoch 14  43.6% | batch:        41 of        94\t|\tloss: 1925.23\n",
      "Training Epoch 14  44.7% | batch:        42 of        94\t|\tloss: 4963.81\n",
      "Training Epoch 14  45.7% | batch:        43 of        94\t|\tloss: 1996.45\n",
      "Training Epoch 14  46.8% | batch:        44 of        94\t|\tloss: 2153.12\n",
      "Training Epoch 14  47.9% | batch:        45 of        94\t|\tloss: 2049.39\n",
      "Training Epoch 14  48.9% | batch:        46 of        94\t|\tloss: 1575.41\n",
      "Training Epoch 14  50.0% | batch:        47 of        94\t|\tloss: 1708.11\n",
      "Training Epoch 14  51.1% | batch:        48 of        94\t|\tloss: 1681.49\n",
      "Training Epoch 14  52.1% | batch:        49 of        94\t|\tloss: 2228.93\n",
      "Training Epoch 14  53.2% | batch:        50 of        94\t|\tloss: 1543.93\n",
      "Training Epoch 14  54.3% | batch:        51 of        94\t|\tloss: 2366.65\n",
      "Training Epoch 14  55.3% | batch:        52 of        94\t|\tloss: 1873.19\n",
      "Training Epoch 14  56.4% | batch:        53 of        94\t|\tloss: 1296.73\n",
      "Training Epoch 14  57.4% | batch:        54 of        94\t|\tloss: 1924.77\n",
      "Training Epoch 14  58.5% | batch:        55 of        94\t|\tloss: 2937.04\n",
      "Training Epoch 14  59.6% | batch:        56 of        94\t|\tloss: 2300.8\n",
      "Training Epoch 14  60.6% | batch:        57 of        94\t|\tloss: 2930.72\n",
      "Training Epoch 14  61.7% | batch:        58 of        94\t|\tloss: 1805.3\n",
      "Training Epoch 14  62.8% | batch:        59 of        94\t|\tloss: 3249.19\n",
      "Training Epoch 14  63.8% | batch:        60 of        94\t|\tloss: 2008.95\n",
      "Training Epoch 14  64.9% | batch:        61 of        94\t|\tloss: 1706.92\n",
      "Training Epoch 14  66.0% | batch:        62 of        94\t|\tloss: 1773.04\n",
      "Training Epoch 14  67.0% | batch:        63 of        94\t|\tloss: 2035.45\n",
      "Training Epoch 14  68.1% | batch:        64 of        94\t|\tloss: 2394.04\n",
      "Training Epoch 14  69.1% | batch:        65 of        94\t|\tloss: 1589.87\n",
      "Training Epoch 14  70.2% | batch:        66 of        94\t|\tloss: 1678.78\n",
      "Training Epoch 14  71.3% | batch:        67 of        94\t|\tloss: 2000.8\n",
      "Training Epoch 14  72.3% | batch:        68 of        94\t|\tloss: 2478.42\n",
      "Training Epoch 14  73.4% | batch:        69 of        94\t|\tloss: 2689.78\n",
      "Training Epoch 14  74.5% | batch:        70 of        94\t|\tloss: 2585.3\n",
      "Training Epoch 14  75.5% | batch:        71 of        94\t|\tloss: 2849.97\n",
      "Training Epoch 14  76.6% | batch:        72 of        94\t|\tloss: 2466.21\n",
      "Training Epoch 14  77.7% | batch:        73 of        94\t|\tloss: 2267.11\n",
      "Training Epoch 14  78.7% | batch:        74 of        94\t|\tloss: 1704.1\n",
      "Training Epoch 14  79.8% | batch:        75 of        94\t|\tloss: 1439.45\n",
      "Training Epoch 14  80.9% | batch:        76 of        94\t|\tloss: 1680.63\n",
      "Training Epoch 14  81.9% | batch:        77 of        94\t|\tloss: 1629.97\n",
      "Training Epoch 14  83.0% | batch:        78 of        94\t|\tloss: 2737.92\n",
      "Training Epoch 14  84.0% | batch:        79 of        94\t|\tloss: 2037.47\n",
      "Training Epoch 14  85.1% | batch:        80 of        94\t|\tloss: 1533.09\n",
      "Training Epoch 14  86.2% | batch:        81 of        94\t|\tloss: 2870.57\n",
      "Training Epoch 14  87.2% | batch:        82 of        94\t|\tloss: 1691.77\n",
      "Training Epoch 14  88.3% | batch:        83 of        94\t|\tloss: 1805.45\n",
      "Training Epoch 14  89.4% | batch:        84 of        94\t|\tloss: 2887.99\n",
      "Training Epoch 14  90.4% | batch:        85 of        94\t|\tloss: 1326.77\n",
      "Training Epoch 14  91.5% | batch:        86 of        94\t|\tloss: 1542.53\n",
      "Training Epoch 14  92.6% | batch:        87 of        94\t|\tloss: 1014.29\n",
      "Training Epoch 14  93.6% | batch:        88 of        94\t|\tloss: 2263.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:46,866 | INFO : Epoch 14 Training Summary: epoch: 14.000000 | loss: 2061.722193 | \n",
      "2023-05-09 14:20:46,867 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8182942867279053 seconds\n",
      "\n",
      "2023-05-09 14:20:46,867 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8578765903200423 seconds\n",
      "2023-05-09 14:20:46,868 | INFO : Avg batch train. time: 0.01976464457787279 seconds\n",
      "2023-05-09 14:20:46,868 | INFO : Avg sample train. time: 0.00015588828581305944 seconds\n",
      "2023-05-09 14:20:46,868 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 14  94.7% | batch:        89 of        94\t|\tloss: 2714.75\n",
      "Training Epoch 14  95.7% | batch:        90 of        94\t|\tloss: 2286.19\n",
      "Training Epoch 14  96.8% | batch:        91 of        94\t|\tloss: 1309.89\n",
      "Training Epoch 14  97.9% | batch:        92 of        94\t|\tloss: 1520.3\n",
      "Training Epoch 14  98.9% | batch:        93 of        94\t|\tloss: 2871.68\n",
      "\n",
      "Evaluating Epoch 14   0.0% | batch:         0 of        40\t|\tloss: 6153.85\n",
      "Evaluating Epoch 14   2.5% | batch:         1 of        40\t|\tloss: 1076.53\n",
      "Evaluating Epoch 14   5.0% | batch:         2 of        40\t|\tloss: 3672.68\n",
      "Evaluating Epoch 14   7.5% | batch:         3 of        40\t|\tloss: 6777.32\n",
      "Evaluating Epoch 14  10.0% | batch:         4 of        40\t|\tloss: 2268.63\n",
      "Evaluating Epoch 14  12.5% | batch:         5 of        40\t|\tloss: 2690.25\n",
      "Evaluating Epoch 14  15.0% | batch:         6 of        40\t|\tloss: 7516.11\n",
      "Evaluating Epoch 14  17.5% | batch:         7 of        40\t|\tloss: 2385.91\n",
      "Evaluating Epoch 14  20.0% | batch:         8 of        40\t|\tloss: 2856.91\n",
      "Evaluating Epoch 14  22.5% | batch:         9 of        40\t|\tloss: 1961.59\n",
      "Evaluating Epoch 14  25.0% | batch:        10 of        40\t|\tloss: 3708.08\n",
      "Evaluating Epoch 14  27.5% | batch:        11 of        40\t|\tloss: 1501.38\n",
      "Evaluating Epoch 14  30.0% | batch:        12 of        40\t|\tloss: 6972.11\n",
      "Evaluating Epoch 14  32.5% | batch:        13 of        40\t|\tloss: 2455.46\n",
      "Evaluating Epoch 14  35.0% | batch:        14 of        40\t|\tloss: 1699.6\n",
      "Evaluating Epoch 14  37.5% | batch:        15 of        40\t|\tloss: 4004.27\n",
      "Evaluating Epoch 14  40.0% | batch:        16 of        40\t|\tloss: 5130.93\n",
      "Evaluating Epoch 14  42.5% | batch:        17 of        40\t|\tloss: 2105.15\n",
      "Evaluating Epoch 14  45.0% | batch:        18 of        40\t|\tloss: 2465.66\n",
      "Evaluating Epoch 14  47.5% | batch:        19 of        40\t|\tloss: 5294.85\n",
      "Evaluating Epoch 14  50.0% | batch:        20 of        40\t|\tloss: 3919.19\n",
      "Evaluating Epoch 14  52.5% | batch:        21 of        40\t|\tloss: 1136.72\n",
      "Evaluating Epoch 14  55.0% | batch:        22 of        40\t|\tloss: 4275.12\n",
      "Evaluating Epoch 14  57.5% | batch:        23 of        40\t|\tloss: 2515.87\n",
      "Evaluating Epoch 14  60.0% | batch:        24 of        40\t|\tloss: 1582.89\n",
      "Evaluating Epoch 14  62.5% | batch:        25 of        40\t|\tloss: 3710.53\n",
      "Evaluating Epoch 14  65.0% | batch:        26 of        40\t|\tloss: 8020.87\n",
      "Evaluating Epoch 14  67.5% | batch:        27 of        40\t|\tloss: 2657.17\n",
      "Evaluating Epoch 14  70.0% | batch:        28 of        40\t|\tloss: 2030.35\n",
      "Evaluating Epoch 14  72.5% | batch:        29 of        40\t|\tloss: 8714.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:47,327 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4577450752258301 seconds\n",
      "\n",
      "2023-05-09 14:20:47,327 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5303298632303873 seconds\n",
      "2023-05-09 14:20:47,327 | INFO : Avg batch val. time: 0.013258246580759683 seconds\n",
      "2023-05-09 14:20:47,328 | INFO : Avg sample val. time: 0.00010505742140063141 seconds\n",
      "2023-05-09 14:20:47,328 | INFO : Epoch 14 Validation Summary: epoch: 14.000000 | loss: 3826.982143 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 14  75.0% | batch:        30 of        40\t|\tloss: 1526.92\n",
      "Evaluating Epoch 14  77.5% | batch:        31 of        40\t|\tloss: 2249.16\n",
      "Evaluating Epoch 14  80.0% | batch:        32 of        40\t|\tloss: 7175.45\n",
      "Evaluating Epoch 14  82.5% | batch:        33 of        40\t|\tloss: 6139.34\n",
      "Evaluating Epoch 14  85.0% | batch:        34 of        40\t|\tloss: 1080.17\n",
      "Evaluating Epoch 14  87.5% | batch:        35 of        40\t|\tloss: 5913.85\n",
      "Evaluating Epoch 14  90.0% | batch:        36 of        40\t|\tloss: 5018.38\n",
      "Evaluating Epoch 14  92.5% | batch:        37 of        40\t|\tloss: 2206.87\n",
      "Evaluating Epoch 14  95.0% | batch:        38 of        40\t|\tloss: 3750.17\n",
      "Evaluating Epoch 14  97.5% | batch:        39 of        40\t|\tloss: 10528.6\n",
      "\n",
      "Training Epoch 15   0.0% | batch:         0 of        94\t|\tloss: 1898.7\n",
      "Training Epoch 15   1.1% | batch:         1 of        94\t|\tloss: 2395.61\n",
      "Training Epoch 15   2.1% | batch:         2 of        94\t|\tloss: 1331.79\n",
      "Training Epoch 15   3.2% | batch:         3 of        94\t|\tloss: 2414.74\n",
      "Training Epoch 15   4.3% | batch:         4 of        94\t|\tloss: 1209.76\n",
      "Training Epoch 15   5.3% | batch:         5 of        94\t|\tloss: 3507\n",
      "Training Epoch 15   6.4% | batch:         6 of        94\t|\tloss: 1509.09\n",
      "Training Epoch 15   7.4% | batch:         7 of        94\t|\tloss: 1291.93\n",
      "Training Epoch 15   8.5% | batch:         8 of        94\t|\tloss: 1579\n",
      "Training Epoch 15   9.6% | batch:         9 of        94\t|\tloss: 5354.32\n",
      "Training Epoch 15  10.6% | batch:        10 of        94\t|\tloss: 1853.5\n",
      "Training Epoch 15  11.7% | batch:        11 of        94\t|\tloss: 3510.82\n",
      "Training Epoch 15  12.8% | batch:        12 of        94\t|\tloss: 1547.35\n",
      "Training Epoch 15  13.8% | batch:        13 of        94\t|\tloss: 1744.64\n",
      "Training Epoch 15  14.9% | batch:        14 of        94\t|\tloss: 2240.76\n",
      "Training Epoch 15  16.0% | batch:        15 of        94\t|\tloss: 2216.19\n",
      "Training Epoch 15  17.0% | batch:        16 of        94\t|\tloss: 2209.65\n",
      "Training Epoch 15  18.1% | batch:        17 of        94\t|\tloss: 2929.29\n",
      "Training Epoch 15  19.1% | batch:        18 of        94\t|\tloss: 1945.37\n",
      "Training Epoch 15  20.2% | batch:        19 of        94\t|\tloss: 1393.64\n",
      "Training Epoch 15  21.3% | batch:        20 of        94\t|\tloss: 1739.81\n",
      "Training Epoch 15  22.3% | batch:        21 of        94\t|\tloss: 1754.99\n",
      "Training Epoch 15  23.4% | batch:        22 of        94\t|\tloss: 2641.1\n",
      "Training Epoch 15  24.5% | batch:        23 of        94\t|\tloss: 1470.08\n",
      "Training Epoch 15  25.5% | batch:        24 of        94\t|\tloss: 1452.24\n",
      "Training Epoch 15  26.6% | batch:        25 of        94\t|\tloss: 1563.27\n",
      "Training Epoch 15  27.7% | batch:        26 of        94\t|\tloss: 1210.68\n",
      "Training Epoch 15  28.7% | batch:        27 of        94\t|\tloss: 2373.25\n",
      "Training Epoch 15  29.8% | batch:        28 of        94\t|\tloss: 1796.98\n",
      "Training Epoch 15  30.9% | batch:        29 of        94\t|\tloss: 1821.25\n",
      "Training Epoch 15  31.9% | batch:        30 of        94\t|\tloss: 1109.82\n",
      "Training Epoch 15  33.0% | batch:        31 of        94\t|\tloss: 1590.8\n",
      "Training Epoch 15  34.0% | batch:        32 of        94\t|\tloss: 1461.86\n",
      "Training Epoch 15  35.1% | batch:        33 of        94\t|\tloss: 1773.71\n",
      "Training Epoch 15  36.2% | batch:        34 of        94\t|\tloss: 1803.35\n",
      "Training Epoch 15  37.2% | batch:        35 of        94\t|\tloss: 1830.39\n",
      "Training Epoch 15  38.3% | batch:        36 of        94\t|\tloss: 1895.96\n",
      "Training Epoch 15  39.4% | batch:        37 of        94\t|\tloss: 1950.86\n",
      "Training Epoch 15  40.4% | batch:        38 of        94\t|\tloss: 3094.63\n",
      "Training Epoch 15  41.5% | batch:        39 of        94\t|\tloss: 2102.5\n",
      "Training Epoch 15  42.6% | batch:        40 of        94\t|\tloss: 3292.42\n",
      "Training Epoch 15  43.6% | batch:        41 of        94\t|\tloss: 1519.93\n",
      "Training Epoch 15  44.7% | batch:        42 of        94\t|\tloss: 2132.65\n",
      "Training Epoch 15  45.7% | batch:        43 of        94\t|\tloss: 1563.27\n",
      "Training Epoch 15  46.8% | batch:        44 of        94\t|\tloss: 2567.6\n",
      "Training Epoch 15  47.9% | batch:        45 of        94\t|\tloss: 2459.76\n",
      "Training Epoch 15  48.9% | batch:        46 of        94\t|\tloss: 3881.33\n",
      "Training Epoch 15  50.0% | batch:        47 of        94\t|\tloss: 3055.71\n",
      "Training Epoch 15  51.1% | batch:        48 of        94\t|\tloss: 2001.11\n",
      "Training Epoch 15  52.1% | batch:        49 of        94\t|\tloss: 1749.79\n",
      "Training Epoch 15  53.2% | batch:        50 of        94\t|\tloss: 1841.47\n",
      "Training Epoch 15  54.3% | batch:        51 of        94\t|\tloss: 4148.05\n",
      "Training Epoch 15  55.3% | batch:        52 of        94\t|\tloss: 1731.7\n",
      "Training Epoch 15  56.4% | batch:        53 of        94\t|\tloss: 1602.02\n",
      "Training Epoch 15  57.4% | batch:        54 of        94\t|\tloss: 1963.75\n",
      "Training Epoch 15  58.5% | batch:        55 of        94\t|\tloss: 2133.16\n",
      "Training Epoch 15  59.6% | batch:        56 of        94\t|\tloss: 3158.04\n",
      "Training Epoch 15  60.6% | batch:        57 of        94\t|\tloss: 1292.86\n",
      "Training Epoch 15  61.7% | batch:        58 of        94\t|\tloss: 1589.52\n",
      "Training Epoch 15  62.8% | batch:        59 of        94\t|\tloss: 1399.81\n",
      "Training Epoch 15  63.8% | batch:        60 of        94\t|\tloss: 1546.52\n",
      "Training Epoch 15  64.9% | batch:        61 of        94\t|\tloss: 1724.97\n",
      "Training Epoch 15  66.0% | batch:        62 of        94\t|\tloss: 1351.94\n",
      "Training Epoch 15  67.0% | batch:        63 of        94\t|\tloss: 1876.45\n",
      "Training Epoch 15  68.1% | batch:        64 of        94\t|\tloss: 1867.74\n",
      "Training Epoch 15  69.1% | batch:        65 of        94\t|\tloss: 4116.99\n",
      "Training Epoch 15  70.2% | batch:        66 of        94\t|\tloss: 1785.47\n",
      "Training Epoch 15  71.3% | batch:        67 of        94\t|\tloss: 1379.16\n",
      "Training Epoch 15  72.3% | batch:        68 of        94\t|\tloss: 1296.15\n",
      "Training Epoch 15  73.4% | batch:        69 of        94\t|\tloss: 2220.66\n",
      "Training Epoch 15  74.5% | batch:        70 of        94\t|\tloss: 1266.22\n",
      "Training Epoch 15  75.5% | batch:        71 of        94\t|\tloss: 2107.61\n",
      "Training Epoch 15  76.6% | batch:        72 of        94\t|\tloss: 2598.51\n",
      "Training Epoch 15  77.7% | batch:        73 of        94\t|\tloss: 1702.1\n",
      "Training Epoch 15  78.7% | batch:        74 of        94\t|\tloss: 1684.98\n",
      "Training Epoch 15  79.8% | batch:        75 of        94\t|\tloss: 1575.96\n",
      "Training Epoch 15  80.9% | batch:        76 of        94\t|\tloss: 1974.99\n",
      "Training Epoch 15  81.9% | batch:        77 of        94\t|\tloss: 1437.88\n",
      "Training Epoch 15  83.0% | batch:        78 of        94\t|\tloss: 1667.26\n",
      "Training Epoch 15  84.0% | batch:        79 of        94\t|\tloss: 1538.36\n",
      "Training Epoch 15  85.1% | batch:        80 of        94\t|\tloss: 1297.95\n",
      "Training Epoch 15  86.2% | batch:        81 of        94\t|\tloss: 1535.72\n",
      "Training Epoch 15  87.2% | batch:        82 of        94\t|\tloss: 2027.62\n",
      "Training Epoch 15  88.3% | batch:        83 of        94\t|\tloss: 2942.72\n",
      "Training Epoch 15  89.4% | batch:        84 of        94\t|\tloss: 1964.28\n",
      "Training Epoch 15  90.4% | batch:        85 of        94\t|\tloss: 4883.25\n",
      "Training Epoch 15  91.5% | batch:        86 of        94\t|\tloss: 1318.79\n",
      "Training Epoch 15  92.6% | batch:        87 of        94\t|\tloss: 2342.54\n",
      "Training Epoch 15  93.6% | batch:        88 of        94\t|\tloss: 3062.63\n",
      "Training Epoch 15  94.7% | batch:        89 of        94\t|\tloss: 2671.21\n",
      "Training Epoch 15  95.7% | batch:        90 of        94\t|\tloss: 1715.39\n",
      "Training Epoch 15  96.8% | batch:        91 of        94\t|\tloss: 2137.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:49,175 | INFO : Epoch 15 Training Summary: epoch: 15.000000 | loss: 2059.700606 | \n",
      "2023-05-09 14:20:49,176 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8255016803741455 seconds\n",
      "\n",
      "2023-05-09 14:20:49,176 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8557182629903157 seconds\n",
      "2023-05-09 14:20:49,177 | INFO : Avg batch train. time: 0.019741683648833146 seconds\n",
      "2023-05-09 14:20:49,177 | INFO : Avg sample train. time: 0.00015570718769846584 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 15  97.9% | batch:        92 of        94\t|\tloss: 1395.61\n",
      "Training Epoch 15  98.9% | batch:        93 of        94\t|\tloss: 1441.78\n",
      "\n",
      "Training Epoch 16   0.0% | batch:         0 of        94\t|\tloss: 1948.74\n",
      "Training Epoch 16   1.1% | batch:         1 of        94\t|\tloss: 1594.98\n",
      "Training Epoch 16   2.1% | batch:         2 of        94\t|\tloss: 2000.56\n",
      "Training Epoch 16   3.2% | batch:         3 of        94\t|\tloss: 1998.87\n",
      "Training Epoch 16   4.3% | batch:         4 of        94\t|\tloss: 2772.15\n",
      "Training Epoch 16   5.3% | batch:         5 of        94\t|\tloss: 1569.94\n",
      "Training Epoch 16   6.4% | batch:         6 of        94\t|\tloss: 1979.21\n",
      "Training Epoch 16   7.4% | batch:         7 of        94\t|\tloss: 1350.85\n",
      "Training Epoch 16   8.5% | batch:         8 of        94\t|\tloss: 1361.98\n",
      "Training Epoch 16   9.6% | batch:         9 of        94\t|\tloss: 1776.79\n",
      "Training Epoch 16  10.6% | batch:        10 of        94\t|\tloss: 2785.61\n",
      "Training Epoch 16  11.7% | batch:        11 of        94\t|\tloss: 1788.34\n",
      "Training Epoch 16  12.8% | batch:        12 of        94\t|\tloss: 2680.22\n",
      "Training Epoch 16  13.8% | batch:        13 of        94\t|\tloss: 1263.21\n",
      "Training Epoch 16  14.9% | batch:        14 of        94\t|\tloss: 1542.69\n",
      "Training Epoch 16  16.0% | batch:        15 of        94\t|\tloss: 2903.64\n",
      "Training Epoch 16  17.0% | batch:        16 of        94\t|\tloss: 1595.48\n",
      "Training Epoch 16  18.1% | batch:        17 of        94\t|\tloss: 2330.55\n",
      "Training Epoch 16  19.1% | batch:        18 of        94\t|\tloss: 2690.16\n",
      "Training Epoch 16  20.2% | batch:        19 of        94\t|\tloss: 1392.26\n",
      "Training Epoch 16  21.3% | batch:        20 of        94\t|\tloss: 1364.24\n",
      "Training Epoch 16  22.3% | batch:        21 of        94\t|\tloss: 1698.32\n",
      "Training Epoch 16  23.4% | batch:        22 of        94\t|\tloss: 1700.59\n",
      "Training Epoch 16  24.5% | batch:        23 of        94\t|\tloss: 2767.25\n",
      "Training Epoch 16  25.5% | batch:        24 of        94\t|\tloss: 2396.4\n",
      "Training Epoch 16  26.6% | batch:        25 of        94\t|\tloss: 2916.63\n",
      "Training Epoch 16  27.7% | batch:        26 of        94\t|\tloss: 1709.58\n",
      "Training Epoch 16  28.7% | batch:        27 of        94\t|\tloss: 1549.79\n",
      "Training Epoch 16  29.8% | batch:        28 of        94\t|\tloss: 2000.45\n",
      "Training Epoch 16  30.9% | batch:        29 of        94\t|\tloss: 1495.01\n",
      "Training Epoch 16  31.9% | batch:        30 of        94\t|\tloss: 1518.88\n",
      "Training Epoch 16  33.0% | batch:        31 of        94\t|\tloss: 1675.45\n",
      "Training Epoch 16  34.0% | batch:        32 of        94\t|\tloss: 1334.02\n",
      "Training Epoch 16  35.1% | batch:        33 of        94\t|\tloss: 1640.57\n",
      "Training Epoch 16  36.2% | batch:        34 of        94\t|\tloss: 1417.67\n",
      "Training Epoch 16  37.2% | batch:        35 of        94\t|\tloss: 2785.03\n",
      "Training Epoch 16  38.3% | batch:        36 of        94\t|\tloss: 3820.2\n",
      "Training Epoch 16  39.4% | batch:        37 of        94\t|\tloss: 2239.98\n",
      "Training Epoch 16  40.4% | batch:        38 of        94\t|\tloss: 1811.05\n",
      "Training Epoch 16  41.5% | batch:        39 of        94\t|\tloss: 2339.07\n",
      "Training Epoch 16  42.6% | batch:        40 of        94\t|\tloss: 3527.22\n",
      "Training Epoch 16  43.6% | batch:        41 of        94\t|\tloss: 1722.14\n",
      "Training Epoch 16  44.7% | batch:        42 of        94\t|\tloss: 1544.13\n",
      "Training Epoch 16  45.7% | batch:        43 of        94\t|\tloss: 2013.9\n",
      "Training Epoch 16  46.8% | batch:        44 of        94\t|\tloss: 1457.34\n",
      "Training Epoch 16  47.9% | batch:        45 of        94\t|\tloss: 2150.04\n",
      "Training Epoch 16  48.9% | batch:        46 of        94\t|\tloss: 1676.74\n",
      "Training Epoch 16  50.0% | batch:        47 of        94\t|\tloss: 2169.39\n",
      "Training Epoch 16  51.1% | batch:        48 of        94\t|\tloss: 3311.94\n",
      "Training Epoch 16  52.1% | batch:        49 of        94\t|\tloss: 1290.89\n",
      "Training Epoch 16  53.2% | batch:        50 of        94\t|\tloss: 2019.62\n",
      "Training Epoch 16  54.3% | batch:        51 of        94\t|\tloss: 1499.59\n",
      "Training Epoch 16  55.3% | batch:        52 of        94\t|\tloss: 1768.75\n",
      "Training Epoch 16  56.4% | batch:        53 of        94\t|\tloss: 1508.28\n",
      "Training Epoch 16  57.4% | batch:        54 of        94\t|\tloss: 1198.45\n",
      "Training Epoch 16  58.5% | batch:        55 of        94\t|\tloss: 1557.09\n",
      "Training Epoch 16  59.6% | batch:        56 of        94\t|\tloss: 2646.28\n",
      "Training Epoch 16  60.6% | batch:        57 of        94\t|\tloss: 1702.7\n",
      "Training Epoch 16  61.7% | batch:        58 of        94\t|\tloss: 2930.4\n",
      "Training Epoch 16  62.8% | batch:        59 of        94\t|\tloss: 1808.67\n",
      "Training Epoch 16  63.8% | batch:        60 of        94\t|\tloss: 2353.5\n",
      "Training Epoch 16  64.9% | batch:        61 of        94\t|\tloss: 1562.64\n",
      "Training Epoch 16  66.0% | batch:        62 of        94\t|\tloss: 2179.87\n",
      "Training Epoch 16  67.0% | batch:        63 of        94\t|\tloss: 1644.53\n",
      "Training Epoch 16  68.1% | batch:        64 of        94\t|\tloss: 2421.73\n",
      "Training Epoch 16  69.1% | batch:        65 of        94\t|\tloss: 2504.96\n",
      "Training Epoch 16  70.2% | batch:        66 of        94\t|\tloss: 2461.83\n",
      "Training Epoch 16  71.3% | batch:        67 of        94\t|\tloss: 1723.1\n",
      "Training Epoch 16  72.3% | batch:        68 of        94\t|\tloss: 2519.2\n",
      "Training Epoch 16  73.4% | batch:        69 of        94\t|\tloss: 1260.35\n",
      "Training Epoch 16  74.5% | batch:        70 of        94\t|\tloss: 953.919\n",
      "Training Epoch 16  75.5% | batch:        71 of        94\t|\tloss: 1616.35\n",
      "Training Epoch 16  76.6% | batch:        72 of        94\t|\tloss: 1279.95\n",
      "Training Epoch 16  77.7% | batch:        73 of        94\t|\tloss: 3229.7\n",
      "Training Epoch 16  78.7% | batch:        74 of        94\t|\tloss: 1606.18\n",
      "Training Epoch 16  79.8% | batch:        75 of        94\t|\tloss: 2248.28\n",
      "Training Epoch 16  80.9% | batch:        76 of        94\t|\tloss: 2609.51\n",
      "Training Epoch 16  81.9% | batch:        77 of        94\t|\tloss: 2388.07\n",
      "Training Epoch 16  83.0% | batch:        78 of        94\t|\tloss: 2280.51\n",
      "Training Epoch 16  84.0% | batch:        79 of        94\t|\tloss: 1034.52\n",
      "Training Epoch 16  85.1% | batch:        80 of        94\t|\tloss: 2428.08\n",
      "Training Epoch 16  86.2% | batch:        81 of        94\t|\tloss: 1272.14\n",
      "Training Epoch 16  87.2% | batch:        82 of        94\t|\tloss: 1604.66\n",
      "Training Epoch 16  88.3% | batch:        83 of        94\t|\tloss: 1262.68\n",
      "Training Epoch 16  89.4% | batch:        84 of        94\t|\tloss: 1992.78\n",
      "Training Epoch 16  90.4% | batch:        85 of        94\t|\tloss: 1769.15\n",
      "Training Epoch 16  91.5% | batch:        86 of        94\t|\tloss: 1063.86\n",
      "Training Epoch 16  92.6% | batch:        87 of        94\t|\tloss: 1915.87\n",
      "Training Epoch 16  93.6% | batch:        88 of        94\t|\tloss: 2023.79\n",
      "Training Epoch 16  94.7% | batch:        89 of        94\t|\tloss: 1986.86\n",
      "Training Epoch 16  95.7% | batch:        90 of        94\t|\tloss: 2521.98\n",
      "Training Epoch 16  96.8% | batch:        91 of        94\t|\tloss: 1788.37\n",
      "Training Epoch 16  97.9% | batch:        92 of        94\t|\tloss: 1497.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:51,042 | INFO : Epoch 16 Training Summary: epoch: 16.000000 | loss: 1956.263298 | \n",
      "2023-05-09 14:20:51,043 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8448069095611572 seconds\n",
      "\n",
      "2023-05-09 14:20:51,044 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8550363034009933 seconds\n",
      "2023-05-09 14:20:51,044 | INFO : Avg batch train. time: 0.019734428759585036 seconds\n",
      "2023-05-09 14:20:51,045 | INFO : Avg sample train. time: 0.00015564996672268782 seconds\n",
      "2023-05-09 14:20:51,045 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 16  98.9% | batch:        93 of        94\t|\tloss: 1186.91\n",
      "\n",
      "Evaluating Epoch 16   0.0% | batch:         0 of        40\t|\tloss: 5973.2\n",
      "Evaluating Epoch 16   2.5% | batch:         1 of        40\t|\tloss: 1100.38\n",
      "Evaluating Epoch 16   5.0% | batch:         2 of        40\t|\tloss: 2655.59\n",
      "Evaluating Epoch 16   7.5% | batch:         3 of        40\t|\tloss: 6238.82\n",
      "Evaluating Epoch 16  10.0% | batch:         4 of        40\t|\tloss: 2071.01\n",
      "Evaluating Epoch 16  12.5% | batch:         5 of        40\t|\tloss: 1523.81\n",
      "Evaluating Epoch 16  15.0% | batch:         6 of        40\t|\tloss: 7320.42\n",
      "Evaluating Epoch 16  17.5% | batch:         7 of        40\t|\tloss: 2789.04\n",
      "Evaluating Epoch 16  20.0% | batch:         8 of        40\t|\tloss: 2701.06\n",
      "Evaluating Epoch 16  22.5% | batch:         9 of        40\t|\tloss: 1440.36\n",
      "Evaluating Epoch 16  25.0% | batch:        10 of        40\t|\tloss: 4059.35\n",
      "Evaluating Epoch 16  27.5% | batch:        11 of        40\t|\tloss: 1628.94\n",
      "Evaluating Epoch 16  30.0% | batch:        12 of        40\t|\tloss: 5781.47\n",
      "Evaluating Epoch 16  32.5% | batch:        13 of        40\t|\tloss: 2886.28\n",
      "Evaluating Epoch 16  35.0% | batch:        14 of        40\t|\tloss: 1937.11\n",
      "Evaluating Epoch 16  37.5% | batch:        15 of        40\t|\tloss: 3265.81\n",
      "Evaluating Epoch 16  40.0% | batch:        16 of        40\t|\tloss: 4005.28\n",
      "Evaluating Epoch 16  42.5% | batch:        17 of        40\t|\tloss: 2410.44\n",
      "Evaluating Epoch 16  45.0% | batch:        18 of        40\t|\tloss: 2183.36\n",
      "Evaluating Epoch 16  47.5% | batch:        19 of        40\t|\tloss: 5190.49\n",
      "Evaluating Epoch 16  50.0% | batch:        20 of        40\t|\tloss: 4929.97\n",
      "Evaluating Epoch 16  52.5% | batch:        21 of        40\t|\tloss: 1256.19\n",
      "Evaluating Epoch 16  55.0% | batch:        22 of        40\t|\tloss: 2846.63\n",
      "Evaluating Epoch 16  57.5% | batch:        23 of        40\t|\tloss: 2524.28\n",
      "Evaluating Epoch 16  60.0% | batch:        24 of        40\t|\tloss: 1644.2\n",
      "Evaluating Epoch 16  62.5% | batch:        25 of        40\t|\tloss: 3121.79\n",
      "Evaluating Epoch 16  65.0% | batch:        26 of        40\t|\tloss: 8663.8\n",
      "Evaluating Epoch 16  67.5% | batch:        27 of        40\t|\tloss: 2725.91\n",
      "Evaluating Epoch 16  70.0% | batch:        28 of        40\t|\tloss: 1766.35\n",
      "Evaluating Epoch 16  72.5% | batch:        29 of        40\t|\tloss: 8615.64\n",
      "Evaluating Epoch 16  75.0% | batch:        30 of        40\t|\tloss: 1915.94\n",
      "Evaluating Epoch 16  77.5% | batch:        31 of        40\t|\tloss: 1435.3\n",
      "Evaluating Epoch 16  80.0% | batch:        32 of        40\t|\tloss: 6293.4\n",
      "Evaluating Epoch 16  82.5% | batch:        33 of        40\t|\tloss: 6250.33\n",
      "Evaluating Epoch 16  85.0% | batch:        34 of        40\t|\tloss: 1253.98\n",
      "Evaluating Epoch 16  87.5% | batch:        35 of        40\t|\tloss: 4353.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:51,501 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4554896354675293 seconds\n",
      "\n",
      "2023-05-09 14:20:51,502 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5228458404541015 seconds\n",
      "2023-05-09 14:20:51,502 | INFO : Avg batch val. time: 0.01307114601135254 seconds\n",
      "2023-05-09 14:20:51,503 | INFO : Avg sample val. time: 0.00010357484953528161 seconds\n",
      "2023-05-09 14:20:51,503 | INFO : Epoch 16 Validation Summary: epoch: 16.000000 | loss: 3627.609941 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 16  90.0% | batch:        36 of        40\t|\tloss: 5758.32\n",
      "Evaluating Epoch 16  92.5% | batch:        37 of        40\t|\tloss: 2452.94\n",
      "Evaluating Epoch 16  95.0% | batch:        38 of        40\t|\tloss: 3315.44\n",
      "Evaluating Epoch 16  97.5% | batch:        39 of        40\t|\tloss: 10920\n",
      "\n",
      "Training Epoch 17   0.0% | batch:         0 of        94\t|\tloss: 1166.54\n",
      "Training Epoch 17   1.1% | batch:         1 of        94\t|\tloss: 1652.23\n",
      "Training Epoch 17   2.1% | batch:         2 of        94\t|\tloss: 1514.48\n",
      "Training Epoch 17   3.2% | batch:         3 of        94\t|\tloss: 1464.17\n",
      "Training Epoch 17   4.3% | batch:         4 of        94\t|\tloss: 2220.85\n",
      "Training Epoch 17   5.3% | batch:         5 of        94\t|\tloss: 1372\n",
      "Training Epoch 17   6.4% | batch:         6 of        94\t|\tloss: 1613.21\n",
      "Training Epoch 17   7.4% | batch:         7 of        94\t|\tloss: 1369.7\n",
      "Training Epoch 17   8.5% | batch:         8 of        94\t|\tloss: 1988\n",
      "Training Epoch 17   9.6% | batch:         9 of        94\t|\tloss: 1813.41\n",
      "Training Epoch 17  10.6% | batch:        10 of        94\t|\tloss: 1668.32\n",
      "Training Epoch 17  11.7% | batch:        11 of        94\t|\tloss: 3242.65\n",
      "Training Epoch 17  12.8% | batch:        12 of        94\t|\tloss: 1252.15\n",
      "Training Epoch 17  13.8% | batch:        13 of        94\t|\tloss: 1403.77\n",
      "Training Epoch 17  14.9% | batch:        14 of        94\t|\tloss: 969.712\n",
      "Training Epoch 17  16.0% | batch:        15 of        94\t|\tloss: 4944.93\n",
      "Training Epoch 17  17.0% | batch:        16 of        94\t|\tloss: 1814.25\n",
      "Training Epoch 17  18.1% | batch:        17 of        94\t|\tloss: 4114.51\n",
      "Training Epoch 17  19.1% | batch:        18 of        94\t|\tloss: 1906.02\n",
      "Training Epoch 17  20.2% | batch:        19 of        94\t|\tloss: 3009.32\n",
      "Training Epoch 17  21.3% | batch:        20 of        94\t|\tloss: 1726.69\n",
      "Training Epoch 17  22.3% | batch:        21 of        94\t|\tloss: 1685\n",
      "Training Epoch 17  23.4% | batch:        22 of        94\t|\tloss: 1562.26\n",
      "Training Epoch 17  24.5% | batch:        23 of        94\t|\tloss: 1462.16\n",
      "Training Epoch 17  25.5% | batch:        24 of        94\t|\tloss: 1754.98\n",
      "Training Epoch 17  26.6% | batch:        25 of        94\t|\tloss: 2366.28\n",
      "Training Epoch 17  27.7% | batch:        26 of        94\t|\tloss: 1237.29\n",
      "Training Epoch 17  28.7% | batch:        27 of        94\t|\tloss: 2603.95\n",
      "Training Epoch 17  29.8% | batch:        28 of        94\t|\tloss: 2777.32\n",
      "Training Epoch 17  30.9% | batch:        29 of        94\t|\tloss: 1458.74\n",
      "Training Epoch 17  31.9% | batch:        30 of        94\t|\tloss: 2076.7\n",
      "Training Epoch 17  33.0% | batch:        31 of        94\t|\tloss: 1462.32\n",
      "Training Epoch 17  34.0% | batch:        32 of        94\t|\tloss: 1704.16\n",
      "Training Epoch 17  35.1% | batch:        33 of        94\t|\tloss: 2406.32\n",
      "Training Epoch 17  36.2% | batch:        34 of        94\t|\tloss: 1276.09\n",
      "Training Epoch 17  37.2% | batch:        35 of        94\t|\tloss: 1468.38\n",
      "Training Epoch 17  38.3% | batch:        36 of        94\t|\tloss: 2551.49\n",
      "Training Epoch 17  39.4% | batch:        37 of        94\t|\tloss: 1835.33\n",
      "Training Epoch 17  40.4% | batch:        38 of        94\t|\tloss: 2059.3\n",
      "Training Epoch 17  41.5% | batch:        39 of        94\t|\tloss: 1323.38\n",
      "Training Epoch 17  42.6% | batch:        40 of        94\t|\tloss: 2746.82\n",
      "Training Epoch 17  43.6% | batch:        41 of        94\t|\tloss: 1235.93\n",
      "Training Epoch 17  44.7% | batch:        42 of        94\t|\tloss: 1692.8\n",
      "Training Epoch 17  45.7% | batch:        43 of        94\t|\tloss: 1462.33\n",
      "Training Epoch 17  46.8% | batch:        44 of        94\t|\tloss: 1539.89\n",
      "Training Epoch 17  47.9% | batch:        45 of        94\t|\tloss: 2225.22\n",
      "Training Epoch 17  48.9% | batch:        46 of        94\t|\tloss: 2322.09\n",
      "Training Epoch 17  50.0% | batch:        47 of        94\t|\tloss: 2230.59\n",
      "Training Epoch 17  51.1% | batch:        48 of        94\t|\tloss: 1576.89\n",
      "Training Epoch 17  52.1% | batch:        49 of        94\t|\tloss: 1467.39\n",
      "Training Epoch 17  53.2% | batch:        50 of        94\t|\tloss: 1451.77\n",
      "Training Epoch 17  54.3% | batch:        51 of        94\t|\tloss: 2013.27\n",
      "Training Epoch 17  55.3% | batch:        52 of        94\t|\tloss: 1699.64\n",
      "Training Epoch 17  56.4% | batch:        53 of        94\t|\tloss: 1928.85\n",
      "Training Epoch 17  57.4% | batch:        54 of        94\t|\tloss: 4328.44\n",
      "Training Epoch 17  58.5% | batch:        55 of        94\t|\tloss: 1209.87\n",
      "Training Epoch 17  59.6% | batch:        56 of        94\t|\tloss: 1447.63\n",
      "Training Epoch 17  60.6% | batch:        57 of        94\t|\tloss: 2091.8\n",
      "Training Epoch 17  61.7% | batch:        58 of        94\t|\tloss: 2216.73\n",
      "Training Epoch 17  62.8% | batch:        59 of        94\t|\tloss: 1639.69\n",
      "Training Epoch 17  63.8% | batch:        60 of        94\t|\tloss: 1207.9\n",
      "Training Epoch 17  64.9% | batch:        61 of        94\t|\tloss: 1760.13\n",
      "Training Epoch 17  66.0% | batch:        62 of        94\t|\tloss: 1153.26\n",
      "Training Epoch 17  67.0% | batch:        63 of        94\t|\tloss: 1774.24\n",
      "Training Epoch 17  68.1% | batch:        64 of        94\t|\tloss: 1762.67\n",
      "Training Epoch 17  69.1% | batch:        65 of        94\t|\tloss: 1570.51\n",
      "Training Epoch 17  70.2% | batch:        66 of        94\t|\tloss: 2194.2\n",
      "Training Epoch 17  71.3% | batch:        67 of        94\t|\tloss: 2925.2\n",
      "Training Epoch 17  72.3% | batch:        68 of        94\t|\tloss: 1854.49\n",
      "Training Epoch 17  73.4% | batch:        69 of        94\t|\tloss: 1933.77\n",
      "Training Epoch 17  74.5% | batch:        70 of        94\t|\tloss: 1561.91\n",
      "Training Epoch 17  75.5% | batch:        71 of        94\t|\tloss: 2148.6\n",
      "Training Epoch 17  76.6% | batch:        72 of        94\t|\tloss: 1914.98\n",
      "Training Epoch 17  77.7% | batch:        73 of        94\t|\tloss: 2125.75\n",
      "Training Epoch 17  78.7% | batch:        74 of        94\t|\tloss: 1502.01\n",
      "Training Epoch 17  79.8% | batch:        75 of        94\t|\tloss: 2202.45\n",
      "Training Epoch 17  80.9% | batch:        76 of        94\t|\tloss: 1756.08\n",
      "Training Epoch 17  81.9% | batch:        77 of        94\t|\tloss: 1397.02\n",
      "Training Epoch 17  83.0% | batch:        78 of        94\t|\tloss: 1267.54\n",
      "Training Epoch 17  84.0% | batch:        79 of        94\t|\tloss: 1676.01\n",
      "Training Epoch 17  85.1% | batch:        80 of        94\t|\tloss: 2238.82\n",
      "Training Epoch 17  86.2% | batch:        81 of        94\t|\tloss: 1775.96\n",
      "Training Epoch 17  87.2% | batch:        82 of        94\t|\tloss: 2675.44\n",
      "Training Epoch 17  88.3% | batch:        83 of        94\t|\tloss: 2663.18\n",
      "Training Epoch 17  89.4% | batch:        84 of        94\t|\tloss: 2209.5\n",
      "Training Epoch 17  90.4% | batch:        85 of        94\t|\tloss: 2363.64\n",
      "Training Epoch 17  91.5% | batch:        86 of        94\t|\tloss: 2000.75\n",
      "Training Epoch 17  92.6% | batch:        87 of        94\t|\tloss: 2204.4\n",
      "Training Epoch 17  93.6% | batch:        88 of        94\t|\tloss: 1284.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:53,330 | INFO : Epoch 17 Training Summary: epoch: 17.000000 | loss: 1933.525532 | \n",
      "2023-05-09 14:20:53,331 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8059992790222168 seconds\n",
      "\n",
      "2023-05-09 14:20:53,332 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.852151772555183 seconds\n",
      "2023-05-09 14:20:53,332 | INFO : Avg batch train. time: 0.01970374226122535 seconds\n",
      "2023-05-09 14:20:53,333 | INFO : Avg sample train. time: 0.00015540793527061444 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 17  94.7% | batch:        89 of        94\t|\tloss: 3951.31\n",
      "Training Epoch 17  95.7% | batch:        90 of        94\t|\tloss: 1605.25\n",
      "Training Epoch 17  96.8% | batch:        91 of        94\t|\tloss: 1858.63\n",
      "Training Epoch 17  97.9% | batch:        92 of        94\t|\tloss: 1528.42\n",
      "Training Epoch 17  98.9% | batch:        93 of        94\t|\tloss: 1415.76\n",
      "\n",
      "Training Epoch 18   0.0% | batch:         0 of        94\t|\tloss: 1398.99\n",
      "Training Epoch 18   1.1% | batch:         1 of        94\t|\tloss: 1425.15\n",
      "Training Epoch 18   2.1% | batch:         2 of        94\t|\tloss: 1766.13\n",
      "Training Epoch 18   3.2% | batch:         3 of        94\t|\tloss: 1817.75\n",
      "Training Epoch 18   4.3% | batch:         4 of        94\t|\tloss: 2225.92\n",
      "Training Epoch 18   5.3% | batch:         5 of        94\t|\tloss: 1690.33\n",
      "Training Epoch 18   6.4% | batch:         6 of        94\t|\tloss: 2296.54\n",
      "Training Epoch 18   7.4% | batch:         7 of        94\t|\tloss: 1549.63\n",
      "Training Epoch 18   8.5% | batch:         8 of        94\t|\tloss: 2294.07\n",
      "Training Epoch 18   9.6% | batch:         9 of        94\t|\tloss: 3237.88\n",
      "Training Epoch 18  10.6% | batch:        10 of        94\t|\tloss: 2105.93\n",
      "Training Epoch 18  11.7% | batch:        11 of        94\t|\tloss: 1314.3\n",
      "Training Epoch 18  12.8% | batch:        12 of        94\t|\tloss: 1945.35\n",
      "Training Epoch 18  13.8% | batch:        13 of        94\t|\tloss: 1217.59\n",
      "Training Epoch 18  14.9% | batch:        14 of        94\t|\tloss: 2225.69\n",
      "Training Epoch 18  16.0% | batch:        15 of        94\t|\tloss: 1870.57\n",
      "Training Epoch 18  17.0% | batch:        16 of        94\t|\tloss: 3989.88\n",
      "Training Epoch 18  18.1% | batch:        17 of        94\t|\tloss: 1537.68\n",
      "Training Epoch 18  19.1% | batch:        18 of        94\t|\tloss: 1210.81\n",
      "Training Epoch 18  20.2% | batch:        19 of        94\t|\tloss: 1875.06\n",
      "Training Epoch 18  21.3% | batch:        20 of        94\t|\tloss: 2516.87\n",
      "Training Epoch 18  22.3% | batch:        21 of        94\t|\tloss: 1501.38\n",
      "Training Epoch 18  23.4% | batch:        22 of        94\t|\tloss: 2277.05\n",
      "Training Epoch 18  24.5% | batch:        23 of        94\t|\tloss: 1668.59\n",
      "Training Epoch 18  25.5% | batch:        24 of        94\t|\tloss: 1930.41\n",
      "Training Epoch 18  26.6% | batch:        25 of        94\t|\tloss: 3899.09\n",
      "Training Epoch 18  27.7% | batch:        26 of        94\t|\tloss: 4275.59\n",
      "Training Epoch 18  28.7% | batch:        27 of        94\t|\tloss: 1039.83\n",
      "Training Epoch 18  29.8% | batch:        28 of        94\t|\tloss: 2396.72\n",
      "Training Epoch 18  30.9% | batch:        29 of        94\t|\tloss: 1673.29\n",
      "Training Epoch 18  31.9% | batch:        30 of        94\t|\tloss: 1574.52\n",
      "Training Epoch 18  33.0% | batch:        31 of        94\t|\tloss: 1356.53\n",
      "Training Epoch 18  34.0% | batch:        32 of        94\t|\tloss: 1371.86\n",
      "Training Epoch 18  35.1% | batch:        33 of        94\t|\tloss: 2028.03\n",
      "Training Epoch 18  36.2% | batch:        34 of        94\t|\tloss: 3047.07\n",
      "Training Epoch 18  37.2% | batch:        35 of        94\t|\tloss: 1428.79\n",
      "Training Epoch 18  38.3% | batch:        36 of        94\t|\tloss: 1523.45\n",
      "Training Epoch 18  39.4% | batch:        37 of        94\t|\tloss: 1748.88\n",
      "Training Epoch 18  40.4% | batch:        38 of        94\t|\tloss: 1097.71\n",
      "Training Epoch 18  41.5% | batch:        39 of        94\t|\tloss: 1646.11\n",
      "Training Epoch 18  42.6% | batch:        40 of        94\t|\tloss: 1871.16\n",
      "Training Epoch 18  43.6% | batch:        41 of        94\t|\tloss: 3109.58\n",
      "Training Epoch 18  44.7% | batch:        42 of        94\t|\tloss: 1566.59\n",
      "Training Epoch 18  45.7% | batch:        43 of        94\t|\tloss: 1720.48\n",
      "Training Epoch 18  46.8% | batch:        44 of        94\t|\tloss: 1848.88\n",
      "Training Epoch 18  47.9% | batch:        45 of        94\t|\tloss: 1888.86\n",
      "Training Epoch 18  48.9% | batch:        46 of        94\t|\tloss: 2100.28\n",
      "Training Epoch 18  50.0% | batch:        47 of        94\t|\tloss: 3466.92\n",
      "Training Epoch 18  51.1% | batch:        48 of        94\t|\tloss: 1537.37\n",
      "Training Epoch 18  52.1% | batch:        49 of        94\t|\tloss: 1989.25\n",
      "Training Epoch 18  53.2% | batch:        50 of        94\t|\tloss: 1192.02\n",
      "Training Epoch 18  54.3% | batch:        51 of        94\t|\tloss: 1482.81\n",
      "Training Epoch 18  55.3% | batch:        52 of        94\t|\tloss: 1439.26\n",
      "Training Epoch 18  56.4% | batch:        53 of        94\t|\tloss: 1891.01\n",
      "Training Epoch 18  57.4% | batch:        54 of        94\t|\tloss: 1656.33\n",
      "Training Epoch 18  58.5% | batch:        55 of        94\t|\tloss: 1425.4\n",
      "Training Epoch 18  59.6% | batch:        56 of        94\t|\tloss: 1558.39\n",
      "Training Epoch 18  60.6% | batch:        57 of        94\t|\tloss: 1586.01\n",
      "Training Epoch 18  61.7% | batch:        58 of        94\t|\tloss: 1366.58\n",
      "Training Epoch 18  62.8% | batch:        59 of        94\t|\tloss: 973.669\n",
      "Training Epoch 18  63.8% | batch:        60 of        94\t|\tloss: 3741.98\n",
      "Training Epoch 18  64.9% | batch:        61 of        94\t|\tloss: 1828.06\n",
      "Training Epoch 18  66.0% | batch:        62 of        94\t|\tloss: 1737.56\n",
      "Training Epoch 18  67.0% | batch:        63 of        94\t|\tloss: 1539.57\n",
      "Training Epoch 18  68.1% | batch:        64 of        94\t|\tloss: 2080.3\n",
      "Training Epoch 18  69.1% | batch:        65 of        94\t|\tloss: 2133.04\n",
      "Training Epoch 18  70.2% | batch:        66 of        94\t|\tloss: 1943.23\n",
      "Training Epoch 18  71.3% | batch:        67 of        94\t|\tloss: 1755.17\n",
      "Training Epoch 18  72.3% | batch:        68 of        94\t|\tloss: 1259.31\n",
      "Training Epoch 18  73.4% | batch:        69 of        94\t|\tloss: 2152.7\n",
      "Training Epoch 18  74.5% | batch:        70 of        94\t|\tloss: 1572.01\n",
      "Training Epoch 18  75.5% | batch:        71 of        94\t|\tloss: 1490.41\n",
      "Training Epoch 18  76.6% | batch:        72 of        94\t|\tloss: 1856.28\n",
      "Training Epoch 18  77.7% | batch:        73 of        94\t|\tloss: 2919.25\n",
      "Training Epoch 18  78.7% | batch:        74 of        94\t|\tloss: 1354.96\n",
      "Training Epoch 18  79.8% | batch:        75 of        94\t|\tloss: 1669.19\n",
      "Training Epoch 18  80.9% | batch:        76 of        94\t|\tloss: 1821.88\n",
      "Training Epoch 18  81.9% | batch:        77 of        94\t|\tloss: 1292.81\n",
      "Training Epoch 18  83.0% | batch:        78 of        94\t|\tloss: 1446.91\n",
      "Training Epoch 18  84.0% | batch:        79 of        94\t|\tloss: 2424.66\n",
      "Training Epoch 18  85.1% | batch:        80 of        94\t|\tloss: 1440.82\n",
      "Training Epoch 18  86.2% | batch:        81 of        94\t|\tloss: 1295.42\n",
      "Training Epoch 18  87.2% | batch:        82 of        94\t|\tloss: 2276.24\n",
      "Training Epoch 18  88.3% | batch:        83 of        94\t|\tloss: 3665.06\n",
      "Training Epoch 18  89.4% | batch:        84 of        94\t|\tloss: 2051.41\n",
      "Training Epoch 18  90.4% | batch:        85 of        94\t|\tloss: 2162.66\n",
      "Training Epoch 18  91.5% | batch:        86 of        94\t|\tloss: 2469.51\n",
      "Training Epoch 18  92.6% | batch:        87 of        94\t|\tloss: 2034.1\n",
      "Training Epoch 18  93.6% | batch:        88 of        94\t|\tloss: 1924.36\n",
      "Training Epoch 18  94.7% | batch:        89 of        94\t|\tloss: 1716.44\n",
      "Training Epoch 18  95.7% | batch:        90 of        94\t|\tloss: 1565.37\n",
      "Training Epoch 18  96.8% | batch:        91 of        94\t|\tloss: 2225.46\n",
      "Training Epoch 18  97.9% | batch:        92 of        94\t|\tloss: 1452.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:55,196 | INFO : Epoch 18 Training Summary: epoch: 18.000000 | loss: 1925.625966 | \n",
      "2023-05-09 14:20:55,196 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8428575992584229 seconds\n",
      "\n",
      "2023-05-09 14:20:55,197 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8516354295942519 seconds\n",
      "2023-05-09 14:20:55,197 | INFO : Avg batch train. time: 0.019698249251002678 seconds\n",
      "2023-05-09 14:20:55,198 | INFO : Avg sample train. time: 0.00015536461063888672 seconds\n",
      "2023-05-09 14:20:55,198 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 18  98.9% | batch:        93 of        94\t|\tloss: 2989.87\n",
      "\n",
      "Evaluating Epoch 18   0.0% | batch:         0 of        40\t|\tloss: 5650.3\n",
      "Evaluating Epoch 18   2.5% | batch:         1 of        40\t|\tloss: 1115.64\n",
      "Evaluating Epoch 18   5.0% | batch:         2 of        40\t|\tloss: 2114.07\n",
      "Evaluating Epoch 18   7.5% | batch:         3 of        40\t|\tloss: 5678.9\n",
      "Evaluating Epoch 18  10.0% | batch:         4 of        40\t|\tloss: 2406.97\n",
      "Evaluating Epoch 18  12.5% | batch:         5 of        40\t|\tloss: 2293.58\n",
      "Evaluating Epoch 18  15.0% | batch:         6 of        40\t|\tloss: 6891.09\n",
      "Evaluating Epoch 18  17.5% | batch:         7 of        40\t|\tloss: 2638.14\n",
      "Evaluating Epoch 18  20.0% | batch:         8 of        40\t|\tloss: 2305.33\n",
      "Evaluating Epoch 18  22.5% | batch:         9 of        40\t|\tloss: 1578.08\n",
      "Evaluating Epoch 18  25.0% | batch:        10 of        40\t|\tloss: 3741.61\n",
      "Evaluating Epoch 18  27.5% | batch:        11 of        40\t|\tloss: 1407.99\n",
      "Evaluating Epoch 18  30.0% | batch:        12 of        40\t|\tloss: 6101.98\n",
      "Evaluating Epoch 18  32.5% | batch:        13 of        40\t|\tloss: 2889.7\n",
      "Evaluating Epoch 18  35.0% | batch:        14 of        40\t|\tloss: 1701.01\n",
      "Evaluating Epoch 18  37.5% | batch:        15 of        40\t|\tloss: 3435.88\n",
      "Evaluating Epoch 18  40.0% | batch:        16 of        40\t|\tloss: 3749.19\n",
      "Evaluating Epoch 18  42.5% | batch:        17 of        40\t|\tloss: 2115.14\n",
      "Evaluating Epoch 18  45.0% | batch:        18 of        40\t|\tloss: 1931.38\n",
      "Evaluating Epoch 18  47.5% | batch:        19 of        40\t|\tloss: 4815.62\n",
      "Evaluating Epoch 18  50.0% | batch:        20 of        40\t|\tloss: 4512.63\n",
      "Evaluating Epoch 18  52.5% | batch:        21 of        40\t|\tloss: 1093.49\n",
      "Evaluating Epoch 18  55.0% | batch:        22 of        40\t|\tloss: 2834.8\n",
      "Evaluating Epoch 18  57.5% | batch:        23 of        40\t|\tloss: 2775.39\n",
      "Evaluating Epoch 18  60.0% | batch:        24 of        40\t|\tloss: 1577.54\n",
      "Evaluating Epoch 18  62.5% | batch:        25 of        40\t|\tloss: 3029.62\n",
      "Evaluating Epoch 18  65.0% | batch:        26 of        40\t|\tloss: 8681.9\n",
      "Evaluating Epoch 18  67.5% | batch:        27 of        40\t|\tloss: 2415.8\n",
      "Evaluating Epoch 18  70.0% | batch:        28 of        40\t|\tloss: 1964.17\n",
      "Evaluating Epoch 18  72.5% | batch:        29 of        40\t|\tloss: 9042.04\n",
      "Evaluating Epoch 18  75.0% | batch:        30 of        40\t|\tloss: 1718.2\n",
      "Evaluating Epoch 18  77.5% | batch:        31 of        40\t|\tloss: 1497.83\n",
      "Evaluating Epoch 18  80.0% | batch:        32 of        40\t|\tloss: 6261.45\n",
      "Evaluating Epoch 18  82.5% | batch:        33 of        40\t|\tloss: 6208.77\n",
      "Evaluating Epoch 18  85.0% | batch:        34 of        40\t|\tloss: 987.571\n",
      "Evaluating Epoch 18  87.5% | batch:        35 of        40\t|\tloss: 4430.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:55,656 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4573805332183838 seconds\n",
      "\n",
      "2023-05-09 14:20:55,657 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5168944488872181 seconds\n",
      "2023-05-09 14:20:55,657 | INFO : Avg batch val. time: 0.012922361222180453 seconds\n",
      "2023-05-09 14:20:55,657 | INFO : Avg sample val. time: 0.0001023958892407326 seconds\n",
      "2023-05-09 14:20:55,658 | INFO : Epoch 18 Validation Summary: epoch: 18.000000 | loss: 3545.670039 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 18  90.0% | batch:        36 of        40\t|\tloss: 4984.35\n",
      "Evaluating Epoch 18  92.5% | batch:        37 of        40\t|\tloss: 2295.81\n",
      "Evaluating Epoch 18  95.0% | batch:        38 of        40\t|\tloss: 3572.92\n",
      "Evaluating Epoch 18  97.5% | batch:        39 of        40\t|\tloss: 12311.4\n",
      "\n",
      "Training Epoch 19   0.0% | batch:         0 of        94\t|\tloss: 1664.85\n",
      "Training Epoch 19   1.1% | batch:         1 of        94\t|\tloss: 1610.65\n",
      "Training Epoch 19   2.1% | batch:         2 of        94\t|\tloss: 1801.13\n",
      "Training Epoch 19   3.2% | batch:         3 of        94\t|\tloss: 1343.62\n",
      "Training Epoch 19   4.3% | batch:         4 of        94\t|\tloss: 1540.49\n",
      "Training Epoch 19   5.3% | batch:         5 of        94\t|\tloss: 1501.89\n",
      "Training Epoch 19   6.4% | batch:         6 of        94\t|\tloss: 1431.07\n",
      "Training Epoch 19   7.4% | batch:         7 of        94\t|\tloss: 1162.54\n",
      "Training Epoch 19   8.5% | batch:         8 of        94\t|\tloss: 1375.62\n",
      "Training Epoch 19   9.6% | batch:         9 of        94\t|\tloss: 1098.87\n",
      "Training Epoch 19  10.6% | batch:        10 of        94\t|\tloss: 2466.38\n",
      "Training Epoch 19  11.7% | batch:        11 of        94\t|\tloss: 2249\n",
      "Training Epoch 19  12.8% | batch:        12 of        94\t|\tloss: 1823.52\n",
      "Training Epoch 19  13.8% | batch:        13 of        94\t|\tloss: 1124.09\n",
      "Training Epoch 19  14.9% | batch:        14 of        94\t|\tloss: 2815.35\n",
      "Training Epoch 19  16.0% | batch:        15 of        94\t|\tloss: 1658.95\n",
      "Training Epoch 19  17.0% | batch:        16 of        94\t|\tloss: 1134.35\n",
      "Training Epoch 19  18.1% | batch:        17 of        94\t|\tloss: 2500.6\n",
      "Training Epoch 19  19.1% | batch:        18 of        94\t|\tloss: 1243\n",
      "Training Epoch 19  20.2% | batch:        19 of        94\t|\tloss: 3129.43\n",
      "Training Epoch 19  21.3% | batch:        20 of        94\t|\tloss: 1082.74\n",
      "Training Epoch 19  22.3% | batch:        21 of        94\t|\tloss: 1299.72\n",
      "Training Epoch 19  23.4% | batch:        22 of        94\t|\tloss: 1263.64\n",
      "Training Epoch 19  24.5% | batch:        23 of        94\t|\tloss: 2005.82\n",
      "Training Epoch 19  25.5% | batch:        24 of        94\t|\tloss: 1163.81\n",
      "Training Epoch 19  26.6% | batch:        25 of        94\t|\tloss: 1667.31\n",
      "Training Epoch 19  27.7% | batch:        26 of        94\t|\tloss: 1923.4\n",
      "Training Epoch 19  28.7% | batch:        27 of        94\t|\tloss: 1087.26\n",
      "Training Epoch 19  29.8% | batch:        28 of        94\t|\tloss: 3148.6\n",
      "Training Epoch 19  30.9% | batch:        29 of        94\t|\tloss: 2872.81\n",
      "Training Epoch 19  31.9% | batch:        30 of        94\t|\tloss: 2527.3\n",
      "Training Epoch 19  33.0% | batch:        31 of        94\t|\tloss: 1913.72\n",
      "Training Epoch 19  34.0% | batch:        32 of        94\t|\tloss: 1847.11\n",
      "Training Epoch 19  35.1% | batch:        33 of        94\t|\tloss: 2195.7\n",
      "Training Epoch 19  36.2% | batch:        34 of        94\t|\tloss: 2695.81\n",
      "Training Epoch 19  37.2% | batch:        35 of        94\t|\tloss: 2467.94\n",
      "Training Epoch 19  38.3% | batch:        36 of        94\t|\tloss: 2645.14\n",
      "Training Epoch 19  39.4% | batch:        37 of        94\t|\tloss: 1586.75\n",
      "Training Epoch 19  40.4% | batch:        38 of        94\t|\tloss: 1748.01\n",
      "Training Epoch 19  41.5% | batch:        39 of        94\t|\tloss: 2225.2\n",
      "Training Epoch 19  42.6% | batch:        40 of        94\t|\tloss: 976.371\n",
      "Training Epoch 19  43.6% | batch:        41 of        94\t|\tloss: 4738.23\n",
      "Training Epoch 19  44.7% | batch:        42 of        94\t|\tloss: 2881.47\n",
      "Training Epoch 19  45.7% | batch:        43 of        94\t|\tloss: 2495.59\n",
      "Training Epoch 19  46.8% | batch:        44 of        94\t|\tloss: 1799.83\n",
      "Training Epoch 19  47.9% | batch:        45 of        94\t|\tloss: 1442.5\n",
      "Training Epoch 19  48.9% | batch:        46 of        94\t|\tloss: 1288.27\n",
      "Training Epoch 19  50.0% | batch:        47 of        94\t|\tloss: 1281.93\n",
      "Training Epoch 19  51.1% | batch:        48 of        94\t|\tloss: 1882.33\n",
      "Training Epoch 19  52.1% | batch:        49 of        94\t|\tloss: 1424.11\n",
      "Training Epoch 19  53.2% | batch:        50 of        94\t|\tloss: 1372.78\n",
      "Training Epoch 19  54.3% | batch:        51 of        94\t|\tloss: 2074.61\n",
      "Training Epoch 19  55.3% | batch:        52 of        94\t|\tloss: 3862.46\n",
      "Training Epoch 19  56.4% | batch:        53 of        94\t|\tloss: 2009.24\n",
      "Training Epoch 19  57.4% | batch:        54 of        94\t|\tloss: 1046.29\n",
      "Training Epoch 19  58.5% | batch:        55 of        94\t|\tloss: 3070.77\n",
      "Training Epoch 19  59.6% | batch:        56 of        94\t|\tloss: 1916.87\n",
      "Training Epoch 19  60.6% | batch:        57 of        94\t|\tloss: 1321.71\n",
      "Training Epoch 19  61.7% | batch:        58 of        94\t|\tloss: 1829.4\n",
      "Training Epoch 19  62.8% | batch:        59 of        94\t|\tloss: 1280.28\n",
      "Training Epoch 19  63.8% | batch:        60 of        94\t|\tloss: 1369.07\n",
      "Training Epoch 19  64.9% | batch:        61 of        94\t|\tloss: 1268.72\n",
      "Training Epoch 19  66.0% | batch:        62 of        94\t|\tloss: 3111.67\n",
      "Training Epoch 19  67.0% | batch:        63 of        94\t|\tloss: 2279.07\n",
      "Training Epoch 19  68.1% | batch:        64 of        94\t|\tloss: 4641.5\n",
      "Training Epoch 19  69.1% | batch:        65 of        94\t|\tloss: 1523.45\n",
      "Training Epoch 19  70.2% | batch:        66 of        94\t|\tloss: 1679.7\n",
      "Training Epoch 19  71.3% | batch:        67 of        94\t|\tloss: 1799.06\n",
      "Training Epoch 19  72.3% | batch:        68 of        94\t|\tloss: 1784.13\n",
      "Training Epoch 19  73.4% | batch:        69 of        94\t|\tloss: 1214.25\n",
      "Training Epoch 19  74.5% | batch:        70 of        94\t|\tloss: 1662.06\n",
      "Training Epoch 19  75.5% | batch:        71 of        94\t|\tloss: 1509.18\n",
      "Training Epoch 19  76.6% | batch:        72 of        94\t|\tloss: 2043.97\n",
      "Training Epoch 19  77.7% | batch:        73 of        94\t|\tloss: 1529.61\n",
      "Training Epoch 19  78.7% | batch:        74 of        94\t|\tloss: 1501.79\n",
      "Training Epoch 19  79.8% | batch:        75 of        94\t|\tloss: 1105.66\n",
      "Training Epoch 19  80.9% | batch:        76 of        94\t|\tloss: 1992.07\n",
      "Training Epoch 19  81.9% | batch:        77 of        94\t|\tloss: 2173.35\n",
      "Training Epoch 19  83.0% | batch:        78 of        94\t|\tloss: 1431.81\n",
      "Training Epoch 19  84.0% | batch:        79 of        94\t|\tloss: 1130.22\n",
      "Training Epoch 19  85.1% | batch:        80 of        94\t|\tloss: 3130.59\n",
      "Training Epoch 19  86.2% | batch:        81 of        94\t|\tloss: 1795.31\n",
      "Training Epoch 19  87.2% | batch:        82 of        94\t|\tloss: 1848.41\n",
      "Training Epoch 19  88.3% | batch:        83 of        94\t|\tloss: 1192.05\n",
      "Training Epoch 19  89.4% | batch:        84 of        94\t|\tloss: 1656.76\n",
      "Training Epoch 19  90.4% | batch:        85 of        94\t|\tloss: 2938.51\n",
      "Training Epoch 19  91.5% | batch:        86 of        94\t|\tloss: 4649.94\n",
      "Training Epoch 19  92.6% | batch:        87 of        94\t|\tloss: 1932.62\n",
      "Training Epoch 19  93.6% | batch:        88 of        94\t|\tloss: 1309.35\n",
      "Training Epoch 19  94.7% | batch:        89 of        94\t|\tloss: 1669.44\n",
      "Training Epoch 19  95.7% | batch:        90 of        94\t|\tloss: 1315.12\n",
      "Training Epoch 19  96.8% | batch:        91 of        94\t|\tloss: 2227.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:57,496 | INFO : Epoch 19 Training Summary: epoch: 19.000000 | loss: 1913.148828 | \n",
      "2023-05-09 14:20:57,497 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8170428276062012 seconds\n",
      "\n",
      "2023-05-09 14:20:57,497 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8498147663317228 seconds\n",
      "2023-05-09 14:20:57,498 | INFO : Avg batch train. time: 0.01967888049289067 seconds\n",
      "2023-05-09 14:20:57,498 | INFO : Avg sample train. time: 0.00015521184480044663 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 19  97.9% | batch:        92 of        94\t|\tloss: 1445\n",
      "Training Epoch 19  98.9% | batch:        93 of        94\t|\tloss: 2133.49\n",
      "\n",
      "Training Epoch 20   0.0% | batch:         0 of        94\t|\tloss: 1637.87\n",
      "Training Epoch 20   1.1% | batch:         1 of        94\t|\tloss: 1705.42\n",
      "Training Epoch 20   2.1% | batch:         2 of        94\t|\tloss: 1445.53\n",
      "Training Epoch 20   3.2% | batch:         3 of        94\t|\tloss: 1575.43\n",
      "Training Epoch 20   4.3% | batch:         4 of        94\t|\tloss: 3269.62\n",
      "Training Epoch 20   5.3% | batch:         5 of        94\t|\tloss: 1539.36\n",
      "Training Epoch 20   6.4% | batch:         6 of        94\t|\tloss: 2100.83\n",
      "Training Epoch 20   7.4% | batch:         7 of        94\t|\tloss: 2566.98\n",
      "Training Epoch 20   8.5% | batch:         8 of        94\t|\tloss: 1467.47\n",
      "Training Epoch 20   9.6% | batch:         9 of        94\t|\tloss: 1683.43\n",
      "Training Epoch 20  10.6% | batch:        10 of        94\t|\tloss: 1316.6\n",
      "Training Epoch 20  11.7% | batch:        11 of        94\t|\tloss: 1422.16\n",
      "Training Epoch 20  12.8% | batch:        12 of        94\t|\tloss: 2108.27\n",
      "Training Epoch 20  13.8% | batch:        13 of        94\t|\tloss: 1628.29\n",
      "Training Epoch 20  14.9% | batch:        14 of        94\t|\tloss: 1630.28\n",
      "Training Epoch 20  16.0% | batch:        15 of        94\t|\tloss: 1835.88\n",
      "Training Epoch 20  17.0% | batch:        16 of        94\t|\tloss: 1652.88\n",
      "Training Epoch 20  18.1% | batch:        17 of        94\t|\tloss: 1570.1\n",
      "Training Epoch 20  19.1% | batch:        18 of        94\t|\tloss: 2607.69\n",
      "Training Epoch 20  20.2% | batch:        19 of        94\t|\tloss: 2792.21\n",
      "Training Epoch 20  21.3% | batch:        20 of        94\t|\tloss: 1165.2\n",
      "Training Epoch 20  22.3% | batch:        21 of        94\t|\tloss: 1605.23\n",
      "Training Epoch 20  23.4% | batch:        22 of        94\t|\tloss: 1312.21\n",
      "Training Epoch 20  24.5% | batch:        23 of        94\t|\tloss: 1412.58\n",
      "Training Epoch 20  25.5% | batch:        24 of        94\t|\tloss: 1871.39\n",
      "Training Epoch 20  26.6% | batch:        25 of        94\t|\tloss: 1507.46\n",
      "Training Epoch 20  27.7% | batch:        26 of        94\t|\tloss: 2741.65\n",
      "Training Epoch 20  28.7% | batch:        27 of        94\t|\tloss: 1531.02\n",
      "Training Epoch 20  29.8% | batch:        28 of        94\t|\tloss: 3948.09\n",
      "Training Epoch 20  30.9% | batch:        29 of        94\t|\tloss: 2448.89\n",
      "Training Epoch 20  31.9% | batch:        30 of        94\t|\tloss: 1852.78\n",
      "Training Epoch 20  33.0% | batch:        31 of        94\t|\tloss: 1951.34\n",
      "Training Epoch 20  34.0% | batch:        32 of        94\t|\tloss: 2235.41\n",
      "Training Epoch 20  35.1% | batch:        33 of        94\t|\tloss: 1881.6\n",
      "Training Epoch 20  36.2% | batch:        34 of        94\t|\tloss: 1575.4\n",
      "Training Epoch 20  37.2% | batch:        35 of        94\t|\tloss: 1525.38\n",
      "Training Epoch 20  38.3% | batch:        36 of        94\t|\tloss: 2401.36\n",
      "Training Epoch 20  39.4% | batch:        37 of        94\t|\tloss: 2198.71\n",
      "Training Epoch 20  40.4% | batch:        38 of        94\t|\tloss: 1221.51\n",
      "Training Epoch 20  41.5% | batch:        39 of        94\t|\tloss: 3100.35\n",
      "Training Epoch 20  42.6% | batch:        40 of        94\t|\tloss: 1265.45\n",
      "Training Epoch 20  43.6% | batch:        41 of        94\t|\tloss: 1377.17\n",
      "Training Epoch 20  44.7% | batch:        42 of        94\t|\tloss: 1501.31\n",
      "Training Epoch 20  45.7% | batch:        43 of        94\t|\tloss: 2037.6\n",
      "Training Epoch 20  46.8% | batch:        44 of        94\t|\tloss: 1477.96\n",
      "Training Epoch 20  47.9% | batch:        45 of        94\t|\tloss: 1834.76\n",
      "Training Epoch 20  48.9% | batch:        46 of        94\t|\tloss: 1280.55\n",
      "Training Epoch 20  50.0% | batch:        47 of        94\t|\tloss: 1765.59\n",
      "Training Epoch 20  51.1% | batch:        48 of        94\t|\tloss: 1306.31\n",
      "Training Epoch 20  52.1% | batch:        49 of        94\t|\tloss: 2873.7\n",
      "Training Epoch 20  53.2% | batch:        50 of        94\t|\tloss: 1515.34\n",
      "Training Epoch 20  54.3% | batch:        51 of        94\t|\tloss: 1056.01\n",
      "Training Epoch 20  55.3% | batch:        52 of        94\t|\tloss: 1955.27\n",
      "Training Epoch 20  56.4% | batch:        53 of        94\t|\tloss: 1735.68\n",
      "Training Epoch 20  57.4% | batch:        54 of        94\t|\tloss: 1459.72\n",
      "Training Epoch 20  58.5% | batch:        55 of        94\t|\tloss: 1381.07\n",
      "Training Epoch 20  59.6% | batch:        56 of        94\t|\tloss: 1358.59\n",
      "Training Epoch 20  60.6% | batch:        57 of        94\t|\tloss: 1381.95\n",
      "Training Epoch 20  61.7% | batch:        58 of        94\t|\tloss: 1383.61\n",
      "Training Epoch 20  62.8% | batch:        59 of        94\t|\tloss: 1988.4\n",
      "Training Epoch 20  63.8% | batch:        60 of        94\t|\tloss: 1737.67\n",
      "Training Epoch 20  64.9% | batch:        61 of        94\t|\tloss: 1620.36\n",
      "Training Epoch 20  66.0% | batch:        62 of        94\t|\tloss: 1464.07\n",
      "Training Epoch 20  67.0% | batch:        63 of        94\t|\tloss: 1240.29\n",
      "Training Epoch 20  68.1% | batch:        64 of        94\t|\tloss: 1661.7\n",
      "Training Epoch 20  69.1% | batch:        65 of        94\t|\tloss: 3800.84\n",
      "Training Epoch 20  70.2% | batch:        66 of        94\t|\tloss: 1328.81\n",
      "Training Epoch 20  71.3% | batch:        67 of        94\t|\tloss: 1965.35\n",
      "Training Epoch 20  72.3% | batch:        68 of        94\t|\tloss: 1316.7\n",
      "Training Epoch 20  73.4% | batch:        69 of        94\t|\tloss: 1687.81\n",
      "Training Epoch 20  74.5% | batch:        70 of        94\t|\tloss: 1650.97\n",
      "Training Epoch 20  75.5% | batch:        71 of        94\t|\tloss: 1770.24\n",
      "Training Epoch 20  76.6% | batch:        72 of        94\t|\tloss: 4253.25\n",
      "Training Epoch 20  77.7% | batch:        73 of        94\t|\tloss: 1761.22\n",
      "Training Epoch 20  78.7% | batch:        74 of        94\t|\tloss: 1410.28\n",
      "Training Epoch 20  79.8% | batch:        75 of        94\t|\tloss: 1711.23\n",
      "Training Epoch 20  80.9% | batch:        76 of        94\t|\tloss: 2319.59\n",
      "Training Epoch 20  81.9% | batch:        77 of        94\t|\tloss: 1337.88\n",
      "Training Epoch 20  83.0% | batch:        78 of        94\t|\tloss: 2096.78\n",
      "Training Epoch 20  84.0% | batch:        79 of        94\t|\tloss: 1519.82\n",
      "Training Epoch 20  85.1% | batch:        80 of        94\t|\tloss: 2616.08\n",
      "Training Epoch 20  86.2% | batch:        81 of        94\t|\tloss: 1898.21\n",
      "Training Epoch 20  87.2% | batch:        82 of        94\t|\tloss: 1727.41\n",
      "Training Epoch 20  88.3% | batch:        83 of        94\t|\tloss: 1782.74\n",
      "Training Epoch 20  89.4% | batch:        84 of        94\t|\tloss: 1295.15\n",
      "Training Epoch 20  90.4% | batch:        85 of        94\t|\tloss: 1343.1\n",
      "Training Epoch 20  91.5% | batch:        86 of        94\t|\tloss: 1422.35\n",
      "Training Epoch 20  92.6% | batch:        87 of        94\t|\tloss: 1268.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:59,360 | INFO : Epoch 20 Training Summary: epoch: 20.000000 | loss: 1828.699661 | \n",
      "2023-05-09 14:20:59,360 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8411824703216553 seconds\n",
      "\n",
      "2023-05-09 14:20:59,361 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8493831515312196 seconds\n",
      "2023-05-09 14:20:59,362 | INFO : Avg batch train. time: 0.019674288846076804 seconds\n",
      "2023-05-09 14:20:59,362 | INFO : Avg sample train. time: 0.00015517562942869774 seconds\n",
      "2023-05-09 14:20:59,362 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 20  93.6% | batch:        88 of        94\t|\tloss: 1769.63\n",
      "Training Epoch 20  94.7% | batch:        89 of        94\t|\tloss: 2469.34\n",
      "Training Epoch 20  95.7% | batch:        90 of        94\t|\tloss: 1430.88\n",
      "Training Epoch 20  96.8% | batch:        91 of        94\t|\tloss: 2003.87\n",
      "Training Epoch 20  97.9% | batch:        92 of        94\t|\tloss: 1862.16\n",
      "Training Epoch 20  98.9% | batch:        93 of        94\t|\tloss: 6806.69\n",
      "\n",
      "Evaluating Epoch 20   0.0% | batch:         0 of        40\t|\tloss: 4500.07\n",
      "Evaluating Epoch 20   2.5% | batch:         1 of        40\t|\tloss: 997.945\n",
      "Evaluating Epoch 20   5.0% | batch:         2 of        40\t|\tloss: 3821.73\n",
      "Evaluating Epoch 20   7.5% | batch:         3 of        40\t|\tloss: 5444.91\n",
      "Evaluating Epoch 20  10.0% | batch:         4 of        40\t|\tloss: 1753.27\n",
      "Evaluating Epoch 20  12.5% | batch:         5 of        40\t|\tloss: 1770.95\n",
      "Evaluating Epoch 20  15.0% | batch:         6 of        40\t|\tloss: 7368.51\n",
      "Evaluating Epoch 20  17.5% | batch:         7 of        40\t|\tloss: 2682.69\n",
      "Evaluating Epoch 20  20.0% | batch:         8 of        40\t|\tloss: 2812.32\n",
      "Evaluating Epoch 20  22.5% | batch:         9 of        40\t|\tloss: 2007.93\n",
      "Evaluating Epoch 20  25.0% | batch:        10 of        40\t|\tloss: 3414.53\n",
      "Evaluating Epoch 20  27.5% | batch:        11 of        40\t|\tloss: 1287.06\n",
      "Evaluating Epoch 20  30.0% | batch:        12 of        40\t|\tloss: 6370.73\n",
      "Evaluating Epoch 20  32.5% | batch:        13 of        40\t|\tloss: 2845.3\n",
      "Evaluating Epoch 20  35.0% | batch:        14 of        40\t|\tloss: 1719.51\n",
      "Evaluating Epoch 20  37.5% | batch:        15 of        40\t|\tloss: 3974.06\n",
      "Evaluating Epoch 20  40.0% | batch:        16 of        40\t|\tloss: 3153.98\n",
      "Evaluating Epoch 20  42.5% | batch:        17 of        40\t|\tloss: 2390.99\n",
      "Evaluating Epoch 20  45.0% | batch:        18 of        40\t|\tloss: 2751.76\n",
      "Evaluating Epoch 20  47.5% | batch:        19 of        40\t|\tloss: 5320.78\n",
      "Evaluating Epoch 20  50.0% | batch:        20 of        40\t|\tloss: 5006.45\n",
      "Evaluating Epoch 20  52.5% | batch:        21 of        40\t|\tloss: 904.518\n",
      "Evaluating Epoch 20  55.0% | batch:        22 of        40\t|\tloss: 4222.96\n",
      "Evaluating Epoch 20  57.5% | batch:        23 of        40\t|\tloss: 2590.02\n",
      "Evaluating Epoch 20  60.0% | batch:        24 of        40\t|\tloss: 1430.66\n",
      "Evaluating Epoch 20  62.5% | batch:        25 of        40\t|\tloss: 3642.74\n",
      "Evaluating Epoch 20  65.0% | batch:        26 of        40\t|\tloss: 7669.77\n",
      "Evaluating Epoch 20  67.5% | batch:        27 of        40\t|\tloss: 2393.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:20:59,820 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.457075834274292 seconds\n",
      "\n",
      "2023-05-09 14:20:59,820 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.511909564336141 seconds\n",
      "2023-05-09 14:20:59,821 | INFO : Avg batch val. time: 0.012797739108403525 seconds\n",
      "2023-05-09 14:20:59,821 | INFO : Avg sample val. time: 0.00010140839230113728 seconds\n",
      "2023-05-09 14:20:59,822 | INFO : Epoch 20 Validation Summary: epoch: 20.000000 | loss: 3617.755260 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 20  70.0% | batch:        28 of        40\t|\tloss: 2355.12\n",
      "Evaluating Epoch 20  72.5% | batch:        29 of        40\t|\tloss: 9253.82\n",
      "Evaluating Epoch 20  75.0% | batch:        30 of        40\t|\tloss: 1716.8\n",
      "Evaluating Epoch 20  77.5% | batch:        31 of        40\t|\tloss: 1477.44\n",
      "Evaluating Epoch 20  80.0% | batch:        32 of        40\t|\tloss: 7408.35\n",
      "Evaluating Epoch 20  82.5% | batch:        33 of        40\t|\tloss: 5155.12\n",
      "Evaluating Epoch 20  85.0% | batch:        34 of        40\t|\tloss: 1003.2\n",
      "Evaluating Epoch 20  87.5% | batch:        35 of        40\t|\tloss: 5101.1\n",
      "Evaluating Epoch 20  90.0% | batch:        36 of        40\t|\tloss: 3609.26\n",
      "Evaluating Epoch 20  92.5% | batch:        37 of        40\t|\tloss: 2329.21\n",
      "Evaluating Epoch 20  95.0% | batch:        38 of        40\t|\tloss: 3859.5\n",
      "Evaluating Epoch 20  97.5% | batch:        39 of        40\t|\tloss: 11786.8\n",
      "\n",
      "Training Epoch 21   0.0% | batch:         0 of        94\t|\tloss: 1821.81\n",
      "Training Epoch 21   1.1% | batch:         1 of        94\t|\tloss: 1536.73\n",
      "Training Epoch 21   2.1% | batch:         2 of        94\t|\tloss: 4175.56\n",
      "Training Epoch 21   3.2% | batch:         3 of        94\t|\tloss: 2339.57\n",
      "Training Epoch 21   4.3% | batch:         4 of        94\t|\tloss: 2476.46\n",
      "Training Epoch 21   5.3% | batch:         5 of        94\t|\tloss: 2164.37\n",
      "Training Epoch 21   6.4% | batch:         6 of        94\t|\tloss: 1544.58\n",
      "Training Epoch 21   7.4% | batch:         7 of        94\t|\tloss: 1225.4\n",
      "Training Epoch 21   8.5% | batch:         8 of        94\t|\tloss: 1543.5\n",
      "Training Epoch 21   9.6% | batch:         9 of        94\t|\tloss: 1202.31\n",
      "Training Epoch 21  10.6% | batch:        10 of        94\t|\tloss: 2989.97\n",
      "Training Epoch 21  11.7% | batch:        11 of        94\t|\tloss: 1072.61\n",
      "Training Epoch 21  12.8% | batch:        12 of        94\t|\tloss: 1342.34\n",
      "Training Epoch 21  13.8% | batch:        13 of        94\t|\tloss: 2118.84\n",
      "Training Epoch 21  14.9% | batch:        14 of        94\t|\tloss: 1562.24\n",
      "Training Epoch 21  16.0% | batch:        15 of        94\t|\tloss: 1681.61\n",
      "Training Epoch 21  17.0% | batch:        16 of        94\t|\tloss: 1799.72\n",
      "Training Epoch 21  18.1% | batch:        17 of        94\t|\tloss: 1281.99\n",
      "Training Epoch 21  19.1% | batch:        18 of        94\t|\tloss: 1308.8\n",
      "Training Epoch 21  20.2% | batch:        19 of        94\t|\tloss: 2460.57\n",
      "Training Epoch 21  21.3% | batch:        20 of        94\t|\tloss: 1666.23\n",
      "Training Epoch 21  22.3% | batch:        21 of        94\t|\tloss: 3297.64\n",
      "Training Epoch 21  23.4% | batch:        22 of        94\t|\tloss: 851.286\n",
      "Training Epoch 21  24.5% | batch:        23 of        94\t|\tloss: 1683.13\n",
      "Training Epoch 21  25.5% | batch:        24 of        94\t|\tloss: 1240.23\n",
      "Training Epoch 21  26.6% | batch:        25 of        94\t|\tloss: 1058.18\n",
      "Training Epoch 21  27.7% | batch:        26 of        94\t|\tloss: 1165.19\n",
      "Training Epoch 21  28.7% | batch:        27 of        94\t|\tloss: 1788.47\n",
      "Training Epoch 21  29.8% | batch:        28 of        94\t|\tloss: 1494.69\n",
      "Training Epoch 21  30.9% | batch:        29 of        94\t|\tloss: 1928.07\n",
      "Training Epoch 21  31.9% | batch:        30 of        94\t|\tloss: 2265.07\n",
      "Training Epoch 21  33.0% | batch:        31 of        94\t|\tloss: 3841.52\n",
      "Training Epoch 21  34.0% | batch:        32 of        94\t|\tloss: 1717.84\n",
      "Training Epoch 21  35.1% | batch:        33 of        94\t|\tloss: 2470\n",
      "Training Epoch 21  36.2% | batch:        34 of        94\t|\tloss: 3936.95\n",
      "Training Epoch 21  37.2% | batch:        35 of        94\t|\tloss: 3213.42\n",
      "Training Epoch 21  38.3% | batch:        36 of        94\t|\tloss: 1663.81\n",
      "Training Epoch 21  39.4% | batch:        37 of        94\t|\tloss: 1371.18\n",
      "Training Epoch 21  40.4% | batch:        38 of        94\t|\tloss: 1554.26\n",
      "Training Epoch 21  41.5% | batch:        39 of        94\t|\tloss: 1437.14\n",
      "Training Epoch 21  42.6% | batch:        40 of        94\t|\tloss: 1273.51\n",
      "Training Epoch 21  43.6% | batch:        41 of        94\t|\tloss: 1603.89\n",
      "Training Epoch 21  44.7% | batch:        42 of        94\t|\tloss: 1088.27\n",
      "Training Epoch 21  45.7% | batch:        43 of        94\t|\tloss: 1887.71\n",
      "Training Epoch 21  46.8% | batch:        44 of        94\t|\tloss: 1479.49\n",
      "Training Epoch 21  47.9% | batch:        45 of        94\t|\tloss: 1899.23\n",
      "Training Epoch 21  48.9% | batch:        46 of        94\t|\tloss: 1228.07\n",
      "Training Epoch 21  50.0% | batch:        47 of        94\t|\tloss: 1851.15\n",
      "Training Epoch 21  51.1% | batch:        48 of        94\t|\tloss: 1275.91\n",
      "Training Epoch 21  52.1% | batch:        49 of        94\t|\tloss: 1228.85\n",
      "Training Epoch 21  53.2% | batch:        50 of        94\t|\tloss: 1541.49\n",
      "Training Epoch 21  54.3% | batch:        51 of        94\t|\tloss: 1748.24\n",
      "Training Epoch 21  55.3% | batch:        52 of        94\t|\tloss: 2056.03\n",
      "Training Epoch 21  56.4% | batch:        53 of        94\t|\tloss: 1199.55\n",
      "Training Epoch 21  57.4% | batch:        54 of        94\t|\tloss: 1000.51\n",
      "Training Epoch 21  58.5% | batch:        55 of        94\t|\tloss: 2594.26\n",
      "Training Epoch 21  59.6% | batch:        56 of        94\t|\tloss: 1678.47\n",
      "Training Epoch 21  60.6% | batch:        57 of        94\t|\tloss: 2183.62\n",
      "Training Epoch 21  61.7% | batch:        58 of        94\t|\tloss: 2245.12\n",
      "Training Epoch 21  62.8% | batch:        59 of        94\t|\tloss: 2146.33\n",
      "Training Epoch 21  63.8% | batch:        60 of        94\t|\tloss: 1339.1\n",
      "Training Epoch 21  64.9% | batch:        61 of        94\t|\tloss: 1990.13\n",
      "Training Epoch 21  66.0% | batch:        62 of        94\t|\tloss: 1659.58\n",
      "Training Epoch 21  67.0% | batch:        63 of        94\t|\tloss: 1824.91\n",
      "Training Epoch 21  68.1% | batch:        64 of        94\t|\tloss: 1677.39\n",
      "Training Epoch 21  69.1% | batch:        65 of        94\t|\tloss: 1472.91\n",
      "Training Epoch 21  70.2% | batch:        66 of        94\t|\tloss: 1193.23\n",
      "Training Epoch 21  71.3% | batch:        67 of        94\t|\tloss: 1916.01\n",
      "Training Epoch 21  72.3% | batch:        68 of        94\t|\tloss: 2177.13\n",
      "Training Epoch 21  73.4% | batch:        69 of        94\t|\tloss: 1878.35\n",
      "Training Epoch 21  74.5% | batch:        70 of        94\t|\tloss: 1126.77\n",
      "Training Epoch 21  75.5% | batch:        71 of        94\t|\tloss: 1190.87\n",
      "Training Epoch 21  76.6% | batch:        72 of        94\t|\tloss: 1837.82\n",
      "Training Epoch 21  77.7% | batch:        73 of        94\t|\tloss: 2436.73\n",
      "Training Epoch 21  78.7% | batch:        74 of        94\t|\tloss: 2913.57\n",
      "Training Epoch 21  79.8% | batch:        75 of        94\t|\tloss: 1159.22\n",
      "Training Epoch 21  80.9% | batch:        76 of        94\t|\tloss: 1171.74\n",
      "Training Epoch 21  81.9% | batch:        77 of        94\t|\tloss: 2620.24\n",
      "Training Epoch 21  83.0% | batch:        78 of        94\t|\tloss: 2789.06\n",
      "Training Epoch 21  84.0% | batch:        79 of        94\t|\tloss: 2597.36\n",
      "Training Epoch 21  85.1% | batch:        80 of        94\t|\tloss: 1656.28\n",
      "Training Epoch 21  86.2% | batch:        81 of        94\t|\tloss: 2469.83\n",
      "Training Epoch 21  87.2% | batch:        82 of        94\t|\tloss: 3292.96\n",
      "Training Epoch 21  88.3% | batch:        83 of        94\t|\tloss: 1399.8\n",
      "Training Epoch 21  89.4% | batch:        84 of        94\t|\tloss: 1745.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:01,560 | INFO : Epoch 21 Training Summary: epoch: 21.000000 | loss: 1842.543330 | \n",
      "2023-05-09 14:21:01,561 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.716914415359497 seconds\n",
      "\n",
      "2023-05-09 14:21:01,561 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.843075116475423 seconds\n",
      "2023-05-09 14:21:01,562 | INFO : Avg batch train. time: 0.019607182090164075 seconds\n",
      "2023-05-09 14:21:01,562 | INFO : Avg sample train. time: 0.00015464634305046343 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 21  90.4% | batch:        85 of        94\t|\tloss: 1672.87\n",
      "Training Epoch 21  91.5% | batch:        86 of        94\t|\tloss: 1611.9\n",
      "Training Epoch 21  92.6% | batch:        87 of        94\t|\tloss: 2290.67\n",
      "Training Epoch 21  93.6% | batch:        88 of        94\t|\tloss: 1361.62\n",
      "Training Epoch 21  94.7% | batch:        89 of        94\t|\tloss: 1271.64\n",
      "Training Epoch 21  95.7% | batch:        90 of        94\t|\tloss: 1884.38\n",
      "Training Epoch 21  96.8% | batch:        91 of        94\t|\tloss: 2084.67\n",
      "Training Epoch 21  97.9% | batch:        92 of        94\t|\tloss: 1147.93\n",
      "Training Epoch 21  98.9% | batch:        93 of        94\t|\tloss: 1766.83\n",
      "\n",
      "Training Epoch 22   0.0% | batch:         0 of        94\t|\tloss: 1642.43\n",
      "Training Epoch 22   1.1% | batch:         1 of        94\t|\tloss: 1868.7\n",
      "Training Epoch 22   2.1% | batch:         2 of        94\t|\tloss: 1957.88\n",
      "Training Epoch 22   3.2% | batch:         3 of        94\t|\tloss: 1824.41\n",
      "Training Epoch 22   4.3% | batch:         4 of        94\t|\tloss: 1706.93\n",
      "Training Epoch 22   5.3% | batch:         5 of        94\t|\tloss: 4100.68\n",
      "Training Epoch 22   6.4% | batch:         6 of        94\t|\tloss: 1373.26\n",
      "Training Epoch 22   7.4% | batch:         7 of        94\t|\tloss: 1937.94\n",
      "Training Epoch 22   8.5% | batch:         8 of        94\t|\tloss: 1577.87\n",
      "Training Epoch 22   9.6% | batch:         9 of        94\t|\tloss: 2768.39\n",
      "Training Epoch 22  10.6% | batch:        10 of        94\t|\tloss: 1642.03\n",
      "Training Epoch 22  11.7% | batch:        11 of        94\t|\tloss: 1357.81\n",
      "Training Epoch 22  12.8% | batch:        12 of        94\t|\tloss: 1769.33\n",
      "Training Epoch 22  13.8% | batch:        13 of        94\t|\tloss: 1744.5\n",
      "Training Epoch 22  14.9% | batch:        14 of        94\t|\tloss: 1740.52\n",
      "Training Epoch 22  16.0% | batch:        15 of        94\t|\tloss: 1367.01\n",
      "Training Epoch 22  17.0% | batch:        16 of        94\t|\tloss: 2872.27\n",
      "Training Epoch 22  18.1% | batch:        17 of        94\t|\tloss: 1639.79\n",
      "Training Epoch 22  19.1% | batch:        18 of        94\t|\tloss: 1762.42\n",
      "Training Epoch 22  20.2% | batch:        19 of        94\t|\tloss: 1151.73\n",
      "Training Epoch 22  21.3% | batch:        20 of        94\t|\tloss: 1294.69\n",
      "Training Epoch 22  22.3% | batch:        21 of        94\t|\tloss: 2149.05\n",
      "Training Epoch 22  23.4% | batch:        22 of        94\t|\tloss: 1346.38\n",
      "Training Epoch 22  24.5% | batch:        23 of        94\t|\tloss: 1511.56\n",
      "Training Epoch 22  25.5% | batch:        24 of        94\t|\tloss: 3403.01\n",
      "Training Epoch 22  26.6% | batch:        25 of        94\t|\tloss: 1657.44\n",
      "Training Epoch 22  27.7% | batch:        26 of        94\t|\tloss: 2035.81\n",
      "Training Epoch 22  28.7% | batch:        27 of        94\t|\tloss: 1070.53\n",
      "Training Epoch 22  29.8% | batch:        28 of        94\t|\tloss: 2009.8\n",
      "Training Epoch 22  30.9% | batch:        29 of        94\t|\tloss: 2500.67\n",
      "Training Epoch 22  31.9% | batch:        30 of        94\t|\tloss: 1312.45\n",
      "Training Epoch 22  33.0% | batch:        31 of        94\t|\tloss: 1142.56\n",
      "Training Epoch 22  34.0% | batch:        32 of        94\t|\tloss: 1310.98\n",
      "Training Epoch 22  35.1% | batch:        33 of        94\t|\tloss: 1943.73\n",
      "Training Epoch 22  36.2% | batch:        34 of        94\t|\tloss: 1154.77\n",
      "Training Epoch 22  37.2% | batch:        35 of        94\t|\tloss: 1616.85\n",
      "Training Epoch 22  38.3% | batch:        36 of        94\t|\tloss: 1718.06\n",
      "Training Epoch 22  39.4% | batch:        37 of        94\t|\tloss: 3188.62\n",
      "Training Epoch 22  40.4% | batch:        38 of        94\t|\tloss: 3904.15\n",
      "Training Epoch 22  41.5% | batch:        39 of        94\t|\tloss: 1510.14\n",
      "Training Epoch 22  42.6% | batch:        40 of        94\t|\tloss: 1433.58\n",
      "Training Epoch 22  43.6% | batch:        41 of        94\t|\tloss: 1187.83\n",
      "Training Epoch 22  44.7% | batch:        42 of        94\t|\tloss: 1835.48\n",
      "Training Epoch 22  45.7% | batch:        43 of        94\t|\tloss: 1209.11\n",
      "Training Epoch 22  46.8% | batch:        44 of        94\t|\tloss: 1435.52\n",
      "Training Epoch 22  47.9% | batch:        45 of        94\t|\tloss: 1073.55\n",
      "Training Epoch 22  48.9% | batch:        46 of        94\t|\tloss: 2264.97\n",
      "Training Epoch 22  50.0% | batch:        47 of        94\t|\tloss: 2126.51\n",
      "Training Epoch 22  51.1% | batch:        48 of        94\t|\tloss: 1943.74\n",
      "Training Epoch 22  52.1% | batch:        49 of        94\t|\tloss: 1988.71\n",
      "Training Epoch 22  53.2% | batch:        50 of        94\t|\tloss: 1266.4\n",
      "Training Epoch 22  54.3% | batch:        51 of        94\t|\tloss: 2074.87\n",
      "Training Epoch 22  55.3% | batch:        52 of        94\t|\tloss: 1384.91\n",
      "Training Epoch 22  56.4% | batch:        53 of        94\t|\tloss: 2776.55\n",
      "Training Epoch 22  57.4% | batch:        54 of        94\t|\tloss: 2817.47\n",
      "Training Epoch 22  58.5% | batch:        55 of        94\t|\tloss: 1501.84\n",
      "Training Epoch 22  59.6% | batch:        56 of        94\t|\tloss: 1609.45\n",
      "Training Epoch 22  60.6% | batch:        57 of        94\t|\tloss: 2581.07\n",
      "Training Epoch 22  61.7% | batch:        58 of        94\t|\tloss: 1597.21\n",
      "Training Epoch 22  62.8% | batch:        59 of        94\t|\tloss: 1835.57\n",
      "Training Epoch 22  63.8% | batch:        60 of        94\t|\tloss: 3093.19\n",
      "Training Epoch 22  64.9% | batch:        61 of        94\t|\tloss: 1624.02\n",
      "Training Epoch 22  66.0% | batch:        62 of        94\t|\tloss: 1491.9\n",
      "Training Epoch 22  67.0% | batch:        63 of        94\t|\tloss: 1413.65\n",
      "Training Epoch 22  68.1% | batch:        64 of        94\t|\tloss: 1363.25\n",
      "Training Epoch 22  69.1% | batch:        65 of        94\t|\tloss: 1207.38\n",
      "Training Epoch 22  70.2% | batch:        66 of        94\t|\tloss: 1728.14\n",
      "Training Epoch 22  71.3% | batch:        67 of        94\t|\tloss: 1333.18\n",
      "Training Epoch 22  72.3% | batch:        68 of        94\t|\tloss: 1293.67\n",
      "Training Epoch 22  73.4% | batch:        69 of        94\t|\tloss: 1186.51\n",
      "Training Epoch 22  74.5% | batch:        70 of        94\t|\tloss: 2419.92\n",
      "Training Epoch 22  75.5% | batch:        71 of        94\t|\tloss: 2518.51\n",
      "Training Epoch 22  76.6% | batch:        72 of        94\t|\tloss: 2172.18\n",
      "Training Epoch 22  77.7% | batch:        73 of        94\t|\tloss: 1534.21\n",
      "Training Epoch 22  78.7% | batch:        74 of        94\t|\tloss: 1741.72\n",
      "Training Epoch 22  79.8% | batch:        75 of        94\t|\tloss: 3393.19\n",
      "Training Epoch 22  80.9% | batch:        76 of        94\t|\tloss: 1187.21\n",
      "Training Epoch 22  81.9% | batch:        77 of        94\t|\tloss: 1322.51\n",
      "Training Epoch 22  83.0% | batch:        78 of        94\t|\tloss: 1318.36\n",
      "Training Epoch 22  84.0% | batch:        79 of        94\t|\tloss: 1715.74\n",
      "Training Epoch 22  85.1% | batch:        80 of        94\t|\tloss: 1916.84\n",
      "Training Epoch 22  86.2% | batch:        81 of        94\t|\tloss: 1251.29\n",
      "Training Epoch 22  87.2% | batch:        82 of        94\t|\tloss: 2008.07\n",
      "Training Epoch 22  88.3% | batch:        83 of        94\t|\tloss: 1300.71\n",
      "Training Epoch 22  89.4% | batch:        84 of        94\t|\tloss: 2009.74\n",
      "Training Epoch 22  90.4% | batch:        85 of        94\t|\tloss: 1031.12\n",
      "Training Epoch 22  91.5% | batch:        86 of        94\t|\tloss: 1484.89\n",
      "Training Epoch 22  92.6% | batch:        87 of        94\t|\tloss: 1785.19\n",
      "Training Epoch 22  93.6% | batch:        88 of        94\t|\tloss: 1567.49\n",
      "Training Epoch 22  94.7% | batch:        89 of        94\t|\tloss: 1934.54\n",
      "Training Epoch 22  95.7% | batch:        90 of        94\t|\tloss: 1441.98\n",
      "Training Epoch 22  96.8% | batch:        91 of        94\t|\tloss: 1715.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:03,309 | INFO : Epoch 22 Training Summary: epoch: 22.000000 | loss: 1794.274699 | \n",
      "2023-05-09 14:21:03,310 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7266285419464111 seconds\n",
      "\n",
      "2023-05-09 14:21:03,311 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.837782090360468 seconds\n",
      "2023-05-09 14:21:03,312 | INFO : Avg batch train. time: 0.019550873301707107 seconds\n",
      "2023-05-09 14:21:03,312 | INFO : Avg sample train. time: 0.0001542022227186162 seconds\n",
      "2023-05-09 14:21:03,312 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 22  97.9% | batch:        92 of        94\t|\tloss: 887.395\n",
      "Training Epoch 22  98.9% | batch:        93 of        94\t|\tloss: 1267.65\n",
      "\n",
      "Evaluating Epoch 22   0.0% | batch:         0 of        40\t|\tloss: 5776.05\n",
      "Evaluating Epoch 22   2.5% | batch:         1 of        40\t|\tloss: 998.474\n",
      "Evaluating Epoch 22   5.0% | batch:         2 of        40\t|\tloss: 3430.64\n",
      "Evaluating Epoch 22   7.5% | batch:         3 of        40\t|\tloss: 5808.68\n",
      "Evaluating Epoch 22  10.0% | batch:         4 of        40\t|\tloss: 2121.32\n",
      "Evaluating Epoch 22  12.5% | batch:         5 of        40\t|\tloss: 1759.7\n",
      "Evaluating Epoch 22  15.0% | batch:         6 of        40\t|\tloss: 7729.3\n",
      "Evaluating Epoch 22  17.5% | batch:         7 of        40\t|\tloss: 2646.24\n",
      "Evaluating Epoch 22  20.0% | batch:         8 of        40\t|\tloss: 2523.32\n",
      "Evaluating Epoch 22  22.5% | batch:         9 of        40\t|\tloss: 1894.18\n",
      "Evaluating Epoch 22  25.0% | batch:        10 of        40\t|\tloss: 4013.01\n",
      "Evaluating Epoch 22  27.5% | batch:        11 of        40\t|\tloss: 1438.8\n",
      "Evaluating Epoch 22  30.0% | batch:        12 of        40\t|\tloss: 6254.51\n",
      "Evaluating Epoch 22  32.5% | batch:        13 of        40\t|\tloss: 2530.86\n",
      "Evaluating Epoch 22  35.0% | batch:        14 of        40\t|\tloss: 1949.83\n",
      "Evaluating Epoch 22  37.5% | batch:        15 of        40\t|\tloss: 3269.05\n",
      "Evaluating Epoch 22  40.0% | batch:        16 of        40\t|\tloss: 3321.13\n",
      "Evaluating Epoch 22  42.5% | batch:        17 of        40\t|\tloss: 2470.27\n",
      "Evaluating Epoch 22  45.0% | batch:        18 of        40\t|\tloss: 2094.11\n",
      "Evaluating Epoch 22  47.5% | batch:        19 of        40\t|\tloss: 5208.17\n",
      "Evaluating Epoch 22  50.0% | batch:        20 of        40\t|\tloss: 4344.57\n",
      "Evaluating Epoch 22  52.5% | batch:        21 of        40\t|\tloss: 1163.48\n",
      "Evaluating Epoch 22  55.0% | batch:        22 of        40\t|\tloss: 3547.54\n",
      "Evaluating Epoch 22  57.5% | batch:        23 of        40\t|\tloss: 2908.12\n",
      "Evaluating Epoch 22  60.0% | batch:        24 of        40\t|\tloss: 1517.57\n",
      "Evaluating Epoch 22  62.5% | batch:        25 of        40\t|\tloss: 3491.39\n",
      "Evaluating Epoch 22  65.0% | batch:        26 of        40\t|\tloss: 8355.31\n",
      "Evaluating Epoch 22  67.5% | batch:        27 of        40\t|\tloss: 2407.74\n",
      "Evaluating Epoch 22  70.0% | batch:        28 of        40\t|\tloss: 2038.25\n",
      "Evaluating Epoch 22  72.5% | batch:        29 of        40\t|\tloss: 9304.45\n",
      "Evaluating Epoch 22  75.0% | batch:        30 of        40\t|\tloss: 1625.66\n",
      "Evaluating Epoch 22  77.5% | batch:        31 of        40\t|\tloss: 1529.05\n",
      "Evaluating Epoch 22  80.0% | batch:        32 of        40\t|\tloss: 7334.85\n",
      "Evaluating Epoch 22  82.5% | batch:        33 of        40\t|\tloss: 4822.16\n",
      "Evaluating Epoch 22  85.0% | batch:        34 of        40\t|\tloss: 1155.1\n",
      "Evaluating Epoch 22  87.5% | batch:        35 of        40\t|\tloss: 4916.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:03,783 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.470294713973999 seconds\n",
      "\n",
      "2023-05-09 14:21:03,784 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5087084220005915 seconds\n",
      "2023-05-09 14:21:03,784 | INFO : Avg batch val. time: 0.012717710550014787 seconds\n",
      "2023-05-09 14:21:03,784 | INFO : Avg sample val. time: 0.00010077425158490323 seconds\n",
      "2023-05-09 14:21:03,785 | INFO : Epoch 22 Validation Summary: epoch: 22.000000 | loss: 3611.527067 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 22  90.0% | batch:        36 of        40\t|\tloss: 3811.06\n",
      "Evaluating Epoch 22  92.5% | batch:        37 of        40\t|\tloss: 2356.61\n",
      "Evaluating Epoch 22  95.0% | batch:        38 of        40\t|\tloss: 3701.37\n",
      "Evaluating Epoch 22  97.5% | batch:        39 of        40\t|\tloss: 11110.6\n",
      "\n",
      "Training Epoch 23   0.0% | batch:         0 of        94\t|\tloss: 1249.99\n",
      "Training Epoch 23   1.1% | batch:         1 of        94\t|\tloss: 1847.07\n",
      "Training Epoch 23   2.1% | batch:         2 of        94\t|\tloss: 2178.17\n",
      "Training Epoch 23   3.2% | batch:         3 of        94\t|\tloss: 2328.37\n",
      "Training Epoch 23   4.3% | batch:         4 of        94\t|\tloss: 1178.95\n",
      "Training Epoch 23   5.3% | batch:         5 of        94\t|\tloss: 1424.55\n",
      "Training Epoch 23   6.4% | batch:         6 of        94\t|\tloss: 1163.48\n",
      "Training Epoch 23   7.4% | batch:         7 of        94\t|\tloss: 1205.21\n",
      "Training Epoch 23   8.5% | batch:         8 of        94\t|\tloss: 2898.07\n",
      "Training Epoch 23   9.6% | batch:         9 of        94\t|\tloss: 1339.02\n",
      "Training Epoch 23  10.6% | batch:        10 of        94\t|\tloss: 1405.82\n",
      "Training Epoch 23  11.7% | batch:        11 of        94\t|\tloss: 1980.3\n",
      "Training Epoch 23  12.8% | batch:        12 of        94\t|\tloss: 1111.7\n",
      "Training Epoch 23  13.8% | batch:        13 of        94\t|\tloss: 1748.2\n",
      "Training Epoch 23  14.9% | batch:        14 of        94\t|\tloss: 1927.97\n",
      "Training Epoch 23  16.0% | batch:        15 of        94\t|\tloss: 1864.9\n",
      "Training Epoch 23  17.0% | batch:        16 of        94\t|\tloss: 2697.5\n",
      "Training Epoch 23  18.1% | batch:        17 of        94\t|\tloss: 1966.93\n",
      "Training Epoch 23  19.1% | batch:        18 of        94\t|\tloss: 1640.07\n",
      "Training Epoch 23  20.2% | batch:        19 of        94\t|\tloss: 1607.28\n",
      "Training Epoch 23  21.3% | batch:        20 of        94\t|\tloss: 1382.19\n",
      "Training Epoch 23  22.3% | batch:        21 of        94\t|\tloss: 1517.63\n",
      "Training Epoch 23  23.4% | batch:        22 of        94\t|\tloss: 3365.03\n",
      "Training Epoch 23  24.5% | batch:        23 of        94\t|\tloss: 1405.08\n",
      "Training Epoch 23  25.5% | batch:        24 of        94\t|\tloss: 1830.87\n",
      "Training Epoch 23  26.6% | batch:        25 of        94\t|\tloss: 1858.21\n",
      "Training Epoch 23  27.7% | batch:        26 of        94\t|\tloss: 1078.58\n",
      "Training Epoch 23  28.7% | batch:        27 of        94\t|\tloss: 2263.53\n",
      "Training Epoch 23  29.8% | batch:        28 of        94\t|\tloss: 1981.5\n",
      "Training Epoch 23  30.9% | batch:        29 of        94\t|\tloss: 936.281\n",
      "Training Epoch 23  31.9% | batch:        30 of        94\t|\tloss: 1834.83\n",
      "Training Epoch 23  33.0% | batch:        31 of        94\t|\tloss: 1797.07\n",
      "Training Epoch 23  34.0% | batch:        32 of        94\t|\tloss: 1048.34\n",
      "Training Epoch 23  35.1% | batch:        33 of        94\t|\tloss: 2309.46\n",
      "Training Epoch 23  36.2% | batch:        34 of        94\t|\tloss: 1242.68\n",
      "Training Epoch 23  37.2% | batch:        35 of        94\t|\tloss: 1206.66\n",
      "Training Epoch 23  38.3% | batch:        36 of        94\t|\tloss: 1655.22\n",
      "Training Epoch 23  39.4% | batch:        37 of        94\t|\tloss: 3007.11\n",
      "Training Epoch 23  40.4% | batch:        38 of        94\t|\tloss: 1546.67\n",
      "Training Epoch 23  41.5% | batch:        39 of        94\t|\tloss: 2163.16\n",
      "Training Epoch 23  42.6% | batch:        40 of        94\t|\tloss: 2252.8\n",
      "Training Epoch 23  43.6% | batch:        41 of        94\t|\tloss: 1510.87\n",
      "Training Epoch 23  44.7% | batch:        42 of        94\t|\tloss: 1118.2\n",
      "Training Epoch 23  45.7% | batch:        43 of        94\t|\tloss: 910.05\n",
      "Training Epoch 23  46.8% | batch:        44 of        94\t|\tloss: 1175.67\n",
      "Training Epoch 23  47.9% | batch:        45 of        94\t|\tloss: 1816.75\n",
      "Training Epoch 23  48.9% | batch:        46 of        94\t|\tloss: 1614.68\n",
      "Training Epoch 23  50.0% | batch:        47 of        94\t|\tloss: 950.367\n",
      "Training Epoch 23  51.1% | batch:        48 of        94\t|\tloss: 2070.88\n",
      "Training Epoch 23  52.1% | batch:        49 of        94\t|\tloss: 1553.66\n",
      "Training Epoch 23  53.2% | batch:        50 of        94\t|\tloss: 3104.99\n",
      "Training Epoch 23  54.3% | batch:        51 of        94\t|\tloss: 1489.91\n",
      "Training Epoch 23  55.3% | batch:        52 of        94\t|\tloss: 2287.74\n",
      "Training Epoch 23  56.4% | batch:        53 of        94\t|\tloss: 1389.66\n",
      "Training Epoch 23  57.4% | batch:        54 of        94\t|\tloss: 1219.65\n",
      "Training Epoch 23  58.5% | batch:        55 of        94\t|\tloss: 1425.1\n",
      "Training Epoch 23  59.6% | batch:        56 of        94\t|\tloss: 1996.56\n",
      "Training Epoch 23  60.6% | batch:        57 of        94\t|\tloss: 1513.54\n",
      "Training Epoch 23  61.7% | batch:        58 of        94\t|\tloss: 1163.08\n",
      "Training Epoch 23  62.8% | batch:        59 of        94\t|\tloss: 1083.37\n",
      "Training Epoch 23  63.8% | batch:        60 of        94\t|\tloss: 1815.64\n",
      "Training Epoch 23  64.9% | batch:        61 of        94\t|\tloss: 2571.18\n",
      "Training Epoch 23  66.0% | batch:        62 of        94\t|\tloss: 5254.22\n",
      "Training Epoch 23  67.0% | batch:        63 of        94\t|\tloss: 1551.25\n",
      "Training Epoch 23  68.1% | batch:        64 of        94\t|\tloss: 1524.44\n",
      "Training Epoch 23  69.1% | batch:        65 of        94\t|\tloss: 1528.68\n",
      "Training Epoch 23  70.2% | batch:        66 of        94\t|\tloss: 1269.17\n",
      "Training Epoch 23  71.3% | batch:        67 of        94\t|\tloss: 2602.09\n",
      "Training Epoch 23  72.3% | batch:        68 of        94\t|\tloss: 3947.01\n",
      "Training Epoch 23  73.4% | batch:        69 of        94\t|\tloss: 1584.81\n",
      "Training Epoch 23  74.5% | batch:        70 of        94\t|\tloss: 1435.78\n",
      "Training Epoch 23  75.5% | batch:        71 of        94\t|\tloss: 1440.65\n",
      "Training Epoch 23  76.6% | batch:        72 of        94\t|\tloss: 2657.76\n",
      "Training Epoch 23  77.7% | batch:        73 of        94\t|\tloss: 2332.23\n",
      "Training Epoch 23  78.7% | batch:        74 of        94\t|\tloss: 2991.03\n",
      "Training Epoch 23  79.8% | batch:        75 of        94\t|\tloss: 2113.46\n",
      "Training Epoch 23  80.9% | batch:        76 of        94\t|\tloss: 1753.95\n",
      "Training Epoch 23  81.9% | batch:        77 of        94\t|\tloss: 1101.06\n",
      "Training Epoch 23  83.0% | batch:        78 of        94\t|\tloss: 2232.03\n",
      "Training Epoch 23  84.0% | batch:        79 of        94\t|\tloss: 1332.2\n",
      "Training Epoch 23  85.1% | batch:        80 of        94\t|\tloss: 2264\n",
      "Training Epoch 23  86.2% | batch:        81 of        94\t|\tloss: 1005.91\n",
      "Training Epoch 23  87.2% | batch:        82 of        94\t|\tloss: 3248.59\n",
      "Training Epoch 23  88.3% | batch:        83 of        94\t|\tloss: 2079.37\n",
      "Training Epoch 23  89.4% | batch:        84 of        94\t|\tloss: 1312.59\n",
      "Training Epoch 23  90.4% | batch:        85 of        94\t|\tloss: 1445.78\n",
      "Training Epoch 23  91.5% | batch:        86 of        94\t|\tloss: 1754.53\n",
      "Training Epoch 23  92.6% | batch:        87 of        94\t|\tloss: 3204.26\n",
      "Training Epoch 23  93.6% | batch:        88 of        94\t|\tloss: 1298.63\n",
      "Training Epoch 23  94.7% | batch:        89 of        94\t|\tloss: 2618.45\n",
      "Training Epoch 23  95.7% | batch:        90 of        94\t|\tloss: 2285.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:05,673 | INFO : Epoch 23 Training Summary: epoch: 23.000000 | loss: 1858.116403 | \n",
      "2023-05-09 14:21:05,674 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.867095947265625 seconds\n",
      "\n",
      "2023-05-09 14:21:05,675 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8390566058780835 seconds\n",
      "2023-05-09 14:21:05,675 | INFO : Avg batch train. time: 0.01956443197742642 seconds\n",
      "2023-05-09 14:21:05,675 | INFO : Avg sample train. time: 0.00015430916310438695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 23  96.8% | batch:        91 of        94\t|\tloss: 3891.11\n",
      "Training Epoch 23  97.9% | batch:        92 of        94\t|\tloss: 1578.02\n",
      "Training Epoch 23  98.9% | batch:        93 of        94\t|\tloss: 1297.17\n",
      "\n",
      "Training Epoch 24   0.0% | batch:         0 of        94\t|\tloss: 895.885\n",
      "Training Epoch 24   1.1% | batch:         1 of        94\t|\tloss: 1877.07\n",
      "Training Epoch 24   2.1% | batch:         2 of        94\t|\tloss: 1754.71\n",
      "Training Epoch 24   3.2% | batch:         3 of        94\t|\tloss: 1592.63\n",
      "Training Epoch 24   4.3% | batch:         4 of        94\t|\tloss: 3628.09\n",
      "Training Epoch 24   5.3% | batch:         5 of        94\t|\tloss: 1726.06\n",
      "Training Epoch 24   6.4% | batch:         6 of        94\t|\tloss: 1894.42\n",
      "Training Epoch 24   7.4% | batch:         7 of        94\t|\tloss: 1726.51\n",
      "Training Epoch 24   8.5% | batch:         8 of        94\t|\tloss: 1032.12\n",
      "Training Epoch 24   9.6% | batch:         9 of        94\t|\tloss: 1578.45\n",
      "Training Epoch 24  10.6% | batch:        10 of        94\t|\tloss: 2467.99\n",
      "Training Epoch 24  11.7% | batch:        11 of        94\t|\tloss: 2565.34\n",
      "Training Epoch 24  12.8% | batch:        12 of        94\t|\tloss: 1007.28\n",
      "Training Epoch 24  13.8% | batch:        13 of        94\t|\tloss: 1134.35\n",
      "Training Epoch 24  14.9% | batch:        14 of        94\t|\tloss: 1590.57\n",
      "Training Epoch 24  16.0% | batch:        15 of        94\t|\tloss: 1228.62\n",
      "Training Epoch 24  17.0% | batch:        16 of        94\t|\tloss: 1712.81\n",
      "Training Epoch 24  18.1% | batch:        17 of        94\t|\tloss: 1485.87\n",
      "Training Epoch 24  19.1% | batch:        18 of        94\t|\tloss: 1150.45\n",
      "Training Epoch 24  20.2% | batch:        19 of        94\t|\tloss: 2547.98\n",
      "Training Epoch 24  21.3% | batch:        20 of        94\t|\tloss: 1684.56\n",
      "Training Epoch 24  22.3% | batch:        21 of        94\t|\tloss: 3035.69\n",
      "Training Epoch 24  23.4% | batch:        22 of        94\t|\tloss: 2360.04\n",
      "Training Epoch 24  24.5% | batch:        23 of        94\t|\tloss: 1628.44\n",
      "Training Epoch 24  25.5% | batch:        24 of        94\t|\tloss: 1280.2\n",
      "Training Epoch 24  26.6% | batch:        25 of        94\t|\tloss: 1162.5\n",
      "Training Epoch 24  27.7% | batch:        26 of        94\t|\tloss: 1083.06\n",
      "Training Epoch 24  28.7% | batch:        27 of        94\t|\tloss: 1600.62\n",
      "Training Epoch 24  29.8% | batch:        28 of        94\t|\tloss: 2305.16\n",
      "Training Epoch 24  30.9% | batch:        29 of        94\t|\tloss: 3570.44\n",
      "Training Epoch 24  31.9% | batch:        30 of        94\t|\tloss: 1705.11\n",
      "Training Epoch 24  33.0% | batch:        31 of        94\t|\tloss: 1668.53\n",
      "Training Epoch 24  34.0% | batch:        32 of        94\t|\tloss: 1052.15\n",
      "Training Epoch 24  35.1% | batch:        33 of        94\t|\tloss: 1333.09\n",
      "Training Epoch 24  36.2% | batch:        34 of        94\t|\tloss: 1917.56\n",
      "Training Epoch 24  37.2% | batch:        35 of        94\t|\tloss: 1851.41\n",
      "Training Epoch 24  38.3% | batch:        36 of        94\t|\tloss: 1054.73\n",
      "Training Epoch 24  39.4% | batch:        37 of        94\t|\tloss: 908.76\n",
      "Training Epoch 24  40.4% | batch:        38 of        94\t|\tloss: 1227.09\n",
      "Training Epoch 24  41.5% | batch:        39 of        94\t|\tloss: 2520.94\n",
      "Training Epoch 24  42.6% | batch:        40 of        94\t|\tloss: 1144.4\n",
      "Training Epoch 24  43.6% | batch:        41 of        94\t|\tloss: 1066\n",
      "Training Epoch 24  44.7% | batch:        42 of        94\t|\tloss: 1819.24\n",
      "Training Epoch 24  45.7% | batch:        43 of        94\t|\tloss: 1501.06\n",
      "Training Epoch 24  46.8% | batch:        44 of        94\t|\tloss: 1601.53\n",
      "Training Epoch 24  47.9% | batch:        45 of        94\t|\tloss: 2555.99\n",
      "Training Epoch 24  48.9% | batch:        46 of        94\t|\tloss: 1697.54\n",
      "Training Epoch 24  50.0% | batch:        47 of        94\t|\tloss: 1251.76\n",
      "Training Epoch 24  51.1% | batch:        48 of        94\t|\tloss: 2009.26\n",
      "Training Epoch 24  52.1% | batch:        49 of        94\t|\tloss: 1652.06\n",
      "Training Epoch 24  53.2% | batch:        50 of        94\t|\tloss: 2875.87\n",
      "Training Epoch 24  54.3% | batch:        51 of        94\t|\tloss: 1368.22\n",
      "Training Epoch 24  55.3% | batch:        52 of        94\t|\tloss: 1596.62\n",
      "Training Epoch 24  56.4% | batch:        53 of        94\t|\tloss: 3555.24\n",
      "Training Epoch 24  57.4% | batch:        54 of        94\t|\tloss: 1633.62\n",
      "Training Epoch 24  58.5% | batch:        55 of        94\t|\tloss: 1519.1\n",
      "Training Epoch 24  59.6% | batch:        56 of        94\t|\tloss: 1381.13\n",
      "Training Epoch 24  60.6% | batch:        57 of        94\t|\tloss: 1982.63\n",
      "Training Epoch 24  61.7% | batch:        58 of        94\t|\tloss: 1099.78\n",
      "Training Epoch 24  62.8% | batch:        59 of        94\t|\tloss: 1844.65\n",
      "Training Epoch 24  63.8% | batch:        60 of        94\t|\tloss: 2921.94\n",
      "Training Epoch 24  64.9% | batch:        61 of        94\t|\tloss: 1896.07\n",
      "Training Epoch 24  66.0% | batch:        62 of        94\t|\tloss: 1585.96\n",
      "Training Epoch 24  67.0% | batch:        63 of        94\t|\tloss: 1780.94\n",
      "Training Epoch 24  68.1% | batch:        64 of        94\t|\tloss: 1156.16\n",
      "Training Epoch 24  69.1% | batch:        65 of        94\t|\tloss: 1942.97\n",
      "Training Epoch 24  70.2% | batch:        66 of        94\t|\tloss: 1187.35\n",
      "Training Epoch 24  71.3% | batch:        67 of        94\t|\tloss: 1347.02\n",
      "Training Epoch 24  72.3% | batch:        68 of        94\t|\tloss: 1243.26\n",
      "Training Epoch 24  73.4% | batch:        69 of        94\t|\tloss: 1520.92\n",
      "Training Epoch 24  74.5% | batch:        70 of        94\t|\tloss: 1694.93\n",
      "Training Epoch 24  75.5% | batch:        71 of        94\t|\tloss: 1494.83\n",
      "Training Epoch 24  76.6% | batch:        72 of        94\t|\tloss: 1630.57\n",
      "Training Epoch 24  77.7% | batch:        73 of        94\t|\tloss: 1335.29\n",
      "Training Epoch 24  78.7% | batch:        74 of        94\t|\tloss: 1943.71\n",
      "Training Epoch 24  79.8% | batch:        75 of        94\t|\tloss: 1562.28\n",
      "Training Epoch 24  80.9% | batch:        76 of        94\t|\tloss: 1221.81\n",
      "Training Epoch 24  81.9% | batch:        77 of        94\t|\tloss: 1878.4\n",
      "Training Epoch 24  83.0% | batch:        78 of        94\t|\tloss: 2174.44\n",
      "Training Epoch 24  84.0% | batch:        79 of        94\t|\tloss: 1591.03\n",
      "Training Epoch 24  85.1% | batch:        80 of        94\t|\tloss: 1262.56\n",
      "Training Epoch 24  86.2% | batch:        81 of        94\t|\tloss: 1740.89\n",
      "Training Epoch 24  87.2% | batch:        82 of        94\t|\tloss: 2378.75\n",
      "Training Epoch 24  88.3% | batch:        83 of        94\t|\tloss: 1691.08\n",
      "Training Epoch 24  89.4% | batch:        84 of        94\t|\tloss: 1265.01\n",
      "Training Epoch 24  90.4% | batch:        85 of        94\t|\tloss: 1109.06\n",
      "Training Epoch 24  91.5% | batch:        86 of        94\t|\tloss: 2081.72\n",
      "Training Epoch 24  92.6% | batch:        87 of        94\t|\tloss: 2727.76\n",
      "Training Epoch 24  93.6% | batch:        88 of        94\t|\tloss: 1688.13\n",
      "Training Epoch 24  94.7% | batch:        89 of        94\t|\tloss: 2452.81\n",
      "Training Epoch 24  95.7% | batch:        90 of        94\t|\tloss: 1959.33\n",
      "Training Epoch 24  96.8% | batch:        91 of        94\t|\tloss: 1719.89\n",
      "Training Epoch 24  97.9% | batch:        92 of        94\t|\tloss: 2268.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:07,411 | INFO : Epoch 24 Training Summary: epoch: 24.000000 | loss: 1757.406711 | \n",
      "2023-05-09 14:21:07,412 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7148089408874512 seconds\n",
      "\n",
      "2023-05-09 14:21:07,412 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8338796198368073 seconds\n",
      "2023-05-09 14:21:07,413 | INFO : Avg batch train. time: 0.019509357657838376 seconds\n",
      "2023-05-09 14:21:07,414 | INFO : Avg sample train. time: 0.0001538747793116972 seconds\n",
      "2023-05-09 14:21:07,414 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 24  98.9% | batch:        93 of        94\t|\tloss: 13468.1\n",
      "\n",
      "Evaluating Epoch 24   0.0% | batch:         0 of        40\t|\tloss: 5889.6\n",
      "Evaluating Epoch 24   2.5% | batch:         1 of        40\t|\tloss: 1194.05\n",
      "Evaluating Epoch 24   5.0% | batch:         2 of        40\t|\tloss: 3506.11\n",
      "Evaluating Epoch 24   7.5% | batch:         3 of        40\t|\tloss: 6127.48\n",
      "Evaluating Epoch 24  10.0% | batch:         4 of        40\t|\tloss: 2575.44\n",
      "Evaluating Epoch 24  12.5% | batch:         5 of        40\t|\tloss: 2097.08\n",
      "Evaluating Epoch 24  15.0% | batch:         6 of        40\t|\tloss: 8379.67\n",
      "Evaluating Epoch 24  17.5% | batch:         7 of        40\t|\tloss: 3134.84\n",
      "Evaluating Epoch 24  20.0% | batch:         8 of        40\t|\tloss: 2881.32\n",
      "Evaluating Epoch 24  22.5% | batch:         9 of        40\t|\tloss: 2356.6\n",
      "Evaluating Epoch 24  25.0% | batch:        10 of        40\t|\tloss: 4326.75\n",
      "Evaluating Epoch 24  27.5% | batch:        11 of        40\t|\tloss: 1472.69\n",
      "Evaluating Epoch 24  30.0% | batch:        12 of        40\t|\tloss: 5768\n",
      "Evaluating Epoch 24  32.5% | batch:        13 of        40\t|\tloss: 2917.71\n",
      "Evaluating Epoch 24  35.0% | batch:        14 of        40\t|\tloss: 1973.35\n",
      "Evaluating Epoch 24  37.5% | batch:        15 of        40\t|\tloss: 3467.37\n",
      "Evaluating Epoch 24  40.0% | batch:        16 of        40\t|\tloss: 3773.5\n",
      "Evaluating Epoch 24  42.5% | batch:        17 of        40\t|\tloss: 2368.51\n",
      "Evaluating Epoch 24  45.0% | batch:        18 of        40\t|\tloss: 2310.2\n",
      "Evaluating Epoch 24  47.5% | batch:        19 of        40\t|\tloss: 5301.85\n",
      "Evaluating Epoch 24  50.0% | batch:        20 of        40\t|\tloss: 5431\n",
      "Evaluating Epoch 24  52.5% | batch:        21 of        40\t|\tloss: 1172.76\n",
      "Evaluating Epoch 24  55.0% | batch:        22 of        40\t|\tloss: 4005.96\n",
      "Evaluating Epoch 24  57.5% | batch:        23 of        40\t|\tloss: 2449.74\n",
      "Evaluating Epoch 24  60.0% | batch:        24 of        40\t|\tloss: 1866.14\n",
      "Evaluating Epoch 24  62.5% | batch:        25 of        40\t|\tloss: 3639.67\n",
      "Evaluating Epoch 24  65.0% | batch:        26 of        40\t|\tloss: 8581.63\n",
      "Evaluating Epoch 24  67.5% | batch:        27 of        40\t|\tloss: 2955.6\n",
      "Evaluating Epoch 24  70.0% | batch:        28 of        40\t|\tloss: 2040.22\n",
      "Evaluating Epoch 24  72.5% | batch:        29 of        40\t|\tloss: 8128.93\n",
      "Evaluating Epoch 24  75.0% | batch:        30 of        40\t|\tloss: 1802.24\n",
      "Evaluating Epoch 24  77.5% | batch:        31 of        40\t|\tloss: 1695.96\n",
      "Evaluating Epoch 24  80.0% | batch:        32 of        40\t|\tloss: 7729.39\n",
      "Evaluating Epoch 24  82.5% | batch:        33 of        40\t|\tloss: 5881.47\n",
      "Evaluating Epoch 24  85.0% | batch:        34 of        40\t|\tloss: 1121.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:07,879 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4644451141357422 seconds\n",
      "\n",
      "2023-05-09 14:21:07,879 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5055467571531024 seconds\n",
      "2023-05-09 14:21:07,880 | INFO : Avg batch val. time: 0.012638668928827559 seconds\n",
      "2023-05-09 14:21:07,880 | INFO : Avg sample val. time: 0.00010014793129023422 seconds\n",
      "2023-05-09 14:21:07,881 | INFO : Epoch 24 Validation Summary: epoch: 24.000000 | loss: 3839.363520 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 24  87.5% | batch:        35 of        40\t|\tloss: 4960.38\n",
      "Evaluating Epoch 24  90.0% | batch:        36 of        40\t|\tloss: 5122.44\n",
      "Evaluating Epoch 24  92.5% | batch:        37 of        40\t|\tloss: 2650.17\n",
      "Evaluating Epoch 24  95.0% | batch:        38 of        40\t|\tloss: 4113.06\n",
      "Evaluating Epoch 24  97.5% | batch:        39 of        40\t|\tloss: 9700.66\n",
      "\n",
      "Training Epoch 25   0.0% | batch:         0 of        94\t|\tloss: 1221.83\n",
      "Training Epoch 25   1.1% | batch:         1 of        94\t|\tloss: 2218.03\n",
      "Training Epoch 25   2.1% | batch:         2 of        94\t|\tloss: 1500.95\n",
      "Training Epoch 25   3.2% | batch:         3 of        94\t|\tloss: 1236.98\n",
      "Training Epoch 25   4.3% | batch:         4 of        94\t|\tloss: 2029.63\n",
      "Training Epoch 25   5.3% | batch:         5 of        94\t|\tloss: 1101.01\n",
      "Training Epoch 25   6.4% | batch:         6 of        94\t|\tloss: 1741.51\n",
      "Training Epoch 25   7.4% | batch:         7 of        94\t|\tloss: 1276.09\n",
      "Training Epoch 25   8.5% | batch:         8 of        94\t|\tloss: 1563.94\n",
      "Training Epoch 25   9.6% | batch:         9 of        94\t|\tloss: 1574.83\n",
      "Training Epoch 25  10.6% | batch:        10 of        94\t|\tloss: 1083.88\n",
      "Training Epoch 25  11.7% | batch:        11 of        94\t|\tloss: 1819.43\n",
      "Training Epoch 25  12.8% | batch:        12 of        94\t|\tloss: 1673.32\n",
      "Training Epoch 25  13.8% | batch:        13 of        94\t|\tloss: 3928.43\n",
      "Training Epoch 25  14.9% | batch:        14 of        94\t|\tloss: 1511.61\n",
      "Training Epoch 25  16.0% | batch:        15 of        94\t|\tloss: 2555.23\n",
      "Training Epoch 25  17.0% | batch:        16 of        94\t|\tloss: 1911.18\n",
      "Training Epoch 25  18.1% | batch:        17 of        94\t|\tloss: 1654.96\n",
      "Training Epoch 25  19.1% | batch:        18 of        94\t|\tloss: 1582.33\n",
      "Training Epoch 25  20.2% | batch:        19 of        94\t|\tloss: 1443.46\n",
      "Training Epoch 25  21.3% | batch:        20 of        94\t|\tloss: 1348.52\n",
      "Training Epoch 25  22.3% | batch:        21 of        94\t|\tloss: 2395.92\n",
      "Training Epoch 25  23.4% | batch:        22 of        94\t|\tloss: 1721.91\n",
      "Training Epoch 25  24.5% | batch:        23 of        94\t|\tloss: 2275.13\n",
      "Training Epoch 25  25.5% | batch:        24 of        94\t|\tloss: 1497.19\n",
      "Training Epoch 25  26.6% | batch:        25 of        94\t|\tloss: 1873.92\n",
      "Training Epoch 25  27.7% | batch:        26 of        94\t|\tloss: 2632.58\n",
      "Training Epoch 25  28.7% | batch:        27 of        94\t|\tloss: 1454.75\n",
      "Training Epoch 25  29.8% | batch:        28 of        94\t|\tloss: 2276.12\n",
      "Training Epoch 25  30.9% | batch:        29 of        94\t|\tloss: 1585.03\n",
      "Training Epoch 25  31.9% | batch:        30 of        94\t|\tloss: 2012.92\n",
      "Training Epoch 25  33.0% | batch:        31 of        94\t|\tloss: 3075.48\n",
      "Training Epoch 25  34.0% | batch:        32 of        94\t|\tloss: 1821.48\n",
      "Training Epoch 25  35.1% | batch:        33 of        94\t|\tloss: 1269.49\n",
      "Training Epoch 25  36.2% | batch:        34 of        94\t|\tloss: 1312.78\n",
      "Training Epoch 25  37.2% | batch:        35 of        94\t|\tloss: 2064.52\n",
      "Training Epoch 25  38.3% | batch:        36 of        94\t|\tloss: 1881\n",
      "Training Epoch 25  39.4% | batch:        37 of        94\t|\tloss: 2830.4\n",
      "Training Epoch 25  40.4% | batch:        38 of        94\t|\tloss: 2136.46\n",
      "Training Epoch 25  41.5% | batch:        39 of        94\t|\tloss: 1018.2\n",
      "Training Epoch 25  42.6% | batch:        40 of        94\t|\tloss: 1845.03\n",
      "Training Epoch 25  43.6% | batch:        41 of        94\t|\tloss: 1664.79\n",
      "Training Epoch 25  44.7% | batch:        42 of        94\t|\tloss: 1638.46\n",
      "Training Epoch 25  45.7% | batch:        43 of        94\t|\tloss: 1971.7\n",
      "Training Epoch 25  46.8% | batch:        44 of        94\t|\tloss: 2345.41\n",
      "Training Epoch 25  47.9% | batch:        45 of        94\t|\tloss: 1817.01\n",
      "Training Epoch 25  48.9% | batch:        46 of        94\t|\tloss: 1665.36\n",
      "Training Epoch 25  50.0% | batch:        47 of        94\t|\tloss: 2436.44\n",
      "Training Epoch 25  51.1% | batch:        48 of        94\t|\tloss: 1345\n",
      "Training Epoch 25  52.1% | batch:        49 of        94\t|\tloss: 1270.97\n",
      "Training Epoch 25  53.2% | batch:        50 of        94\t|\tloss: 3355.51\n",
      "Training Epoch 25  54.3% | batch:        51 of        94\t|\tloss: 777.742\n",
      "Training Epoch 25  55.3% | batch:        52 of        94\t|\tloss: 1318.66\n",
      "Training Epoch 25  56.4% | batch:        53 of        94\t|\tloss: 1071.93\n",
      "Training Epoch 25  57.4% | batch:        54 of        94\t|\tloss: 1173.1\n",
      "Training Epoch 25  58.5% | batch:        55 of        94\t|\tloss: 1452.02\n",
      "Training Epoch 25  59.6% | batch:        56 of        94\t|\tloss: 1693.89\n",
      "Training Epoch 25  60.6% | batch:        57 of        94\t|\tloss: 1734.66\n",
      "Training Epoch 25  61.7% | batch:        58 of        94\t|\tloss: 1200.12\n",
      "Training Epoch 25  62.8% | batch:        59 of        94\t|\tloss: 1536.64\n",
      "Training Epoch 25  63.8% | batch:        60 of        94\t|\tloss: 2219.02\n",
      "Training Epoch 25  64.9% | batch:        61 of        94\t|\tloss: 1147.75\n",
      "Training Epoch 25  66.0% | batch:        62 of        94\t|\tloss: 2440.48\n",
      "Training Epoch 25  67.0% | batch:        63 of        94\t|\tloss: 975.512\n",
      "Training Epoch 25  68.1% | batch:        64 of        94\t|\tloss: 963.96\n",
      "Training Epoch 25  69.1% | batch:        65 of        94\t|\tloss: 1844.78\n",
      "Training Epoch 25  70.2% | batch:        66 of        94\t|\tloss: 1115.78\n",
      "Training Epoch 25  71.3% | batch:        67 of        94\t|\tloss: 1238.71\n",
      "Training Epoch 25  72.3% | batch:        68 of        94\t|\tloss: 1270.23\n",
      "Training Epoch 25  73.4% | batch:        69 of        94\t|\tloss: 1692.64\n",
      "Training Epoch 25  74.5% | batch:        70 of        94\t|\tloss: 1986.04\n",
      "Training Epoch 25  75.5% | batch:        71 of        94\t|\tloss: 1307.35\n",
      "Training Epoch 25  76.6% | batch:        72 of        94\t|\tloss: 1790.71\n",
      "Training Epoch 25  77.7% | batch:        73 of        94\t|\tloss: 1829.69\n",
      "Training Epoch 25  78.7% | batch:        74 of        94\t|\tloss: 1826.14\n",
      "Training Epoch 25  79.8% | batch:        75 of        94\t|\tloss: 1318.75\n",
      "Training Epoch 25  80.9% | batch:        76 of        94\t|\tloss: 2573.97\n",
      "Training Epoch 25  81.9% | batch:        77 of        94\t|\tloss: 2392.25\n",
      "Training Epoch 25  83.0% | batch:        78 of        94\t|\tloss: 2382.57\n",
      "Training Epoch 25  84.0% | batch:        79 of        94\t|\tloss: 1143.33\n",
      "Training Epoch 25  85.1% | batch:        80 of        94\t|\tloss: 2236.22\n",
      "Training Epoch 25  86.2% | batch:        81 of        94\t|\tloss: 1980.71\n",
      "Training Epoch 25  87.2% | batch:        82 of        94\t|\tloss: 1331.6\n",
      "Training Epoch 25  88.3% | batch:        83 of        94\t|\tloss: 1593.41\n",
      "Training Epoch 25  89.4% | batch:        84 of        94\t|\tloss: 1058.83\n",
      "Training Epoch 25  90.4% | batch:        85 of        94\t|\tloss: 1995.15\n",
      "Training Epoch 25  91.5% | batch:        86 of        94\t|\tloss: 2265.29\n",
      "Training Epoch 25  92.6% | batch:        87 of        94\t|\tloss: 1188.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:09,762 | INFO : Epoch 25 Training Summary: epoch: 25.000000 | loss: 1751.100930 | \n",
      "2023-05-09 14:21:09,763 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8687808513641357 seconds\n",
      "\n",
      "2023-05-09 14:21:09,764 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8352756690979004 seconds\n",
      "2023-05-09 14:21:09,764 | INFO : Avg batch train. time: 0.019524209245722346 seconds\n",
      "2023-05-09 14:21:09,765 | INFO : Avg sample train. time: 0.0001539919171923058 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 25  93.6% | batch:        88 of        94\t|\tloss: 2433.42\n",
      "Training Epoch 25  94.7% | batch:        89 of        94\t|\tloss: 1230.85\n",
      "Training Epoch 25  95.7% | batch:        90 of        94\t|\tloss: 1729.1\n",
      "Training Epoch 25  96.8% | batch:        91 of        94\t|\tloss: 1816.58\n",
      "Training Epoch 25  97.9% | batch:        92 of        94\t|\tloss: 2123.22\n",
      "Training Epoch 25  98.9% | batch:        93 of        94\t|\tloss: 1592.29\n",
      "\n",
      "Training Epoch 26   0.0% | batch:         0 of        94\t|\tloss: 2440.38\n",
      "Training Epoch 26   1.1% | batch:         1 of        94\t|\tloss: 994.201\n",
      "Training Epoch 26   2.1% | batch:         2 of        94\t|\tloss: 2172.42\n",
      "Training Epoch 26   3.2% | batch:         3 of        94\t|\tloss: 1425\n",
      "Training Epoch 26   4.3% | batch:         4 of        94\t|\tloss: 1425.3\n",
      "Training Epoch 26   5.3% | batch:         5 of        94\t|\tloss: 1141.69\n",
      "Training Epoch 26   6.4% | batch:         6 of        94\t|\tloss: 986.55\n",
      "Training Epoch 26   7.4% | batch:         7 of        94\t|\tloss: 1940\n",
      "Training Epoch 26   8.5% | batch:         8 of        94\t|\tloss: 1627.36\n",
      "Training Epoch 26   9.6% | batch:         9 of        94\t|\tloss: 1206.57\n",
      "Training Epoch 26  10.6% | batch:        10 of        94\t|\tloss: 2498.9\n",
      "Training Epoch 26  11.7% | batch:        11 of        94\t|\tloss: 2513.21\n",
      "Training Epoch 26  12.8% | batch:        12 of        94\t|\tloss: 2724.88\n",
      "Training Epoch 26  13.8% | batch:        13 of        94\t|\tloss: 1377.07\n",
      "Training Epoch 26  14.9% | batch:        14 of        94\t|\tloss: 1814.3\n",
      "Training Epoch 26  16.0% | batch:        15 of        94\t|\tloss: 1536.16\n",
      "Training Epoch 26  17.0% | batch:        16 of        94\t|\tloss: 2053.96\n",
      "Training Epoch 26  18.1% | batch:        17 of        94\t|\tloss: 1402.41\n",
      "Training Epoch 26  19.1% | batch:        18 of        94\t|\tloss: 1060.68\n",
      "Training Epoch 26  20.2% | batch:        19 of        94\t|\tloss: 2022.56\n",
      "Training Epoch 26  21.3% | batch:        20 of        94\t|\tloss: 1762.12\n",
      "Training Epoch 26  22.3% | batch:        21 of        94\t|\tloss: 2425.18\n",
      "Training Epoch 26  23.4% | batch:        22 of        94\t|\tloss: 1468.44\n",
      "Training Epoch 26  24.5% | batch:        23 of        94\t|\tloss: 1023.35\n",
      "Training Epoch 26  25.5% | batch:        24 of        94\t|\tloss: 1385.67\n",
      "Training Epoch 26  26.6% | batch:        25 of        94\t|\tloss: 2546.54\n",
      "Training Epoch 26  27.7% | batch:        26 of        94\t|\tloss: 1198.12\n",
      "Training Epoch 26  28.7% | batch:        27 of        94\t|\tloss: 1267.82\n",
      "Training Epoch 26  29.8% | batch:        28 of        94\t|\tloss: 1092.08\n",
      "Training Epoch 26  30.9% | batch:        29 of        94\t|\tloss: 1674.99\n",
      "Training Epoch 26  31.9% | batch:        30 of        94\t|\tloss: 2101.54\n",
      "Training Epoch 26  33.0% | batch:        31 of        94\t|\tloss: 1253.1\n",
      "Training Epoch 26  34.0% | batch:        32 of        94\t|\tloss: 1638.6\n",
      "Training Epoch 26  35.1% | batch:        33 of        94\t|\tloss: 1096.72\n",
      "Training Epoch 26  36.2% | batch:        34 of        94\t|\tloss: 1212.7\n",
      "Training Epoch 26  37.2% | batch:        35 of        94\t|\tloss: 1157.3\n",
      "Training Epoch 26  38.3% | batch:        36 of        94\t|\tloss: 837.177\n",
      "Training Epoch 26  39.4% | batch:        37 of        94\t|\tloss: 2676.41\n",
      "Training Epoch 26  40.4% | batch:        38 of        94\t|\tloss: 1007.91\n",
      "Training Epoch 26  41.5% | batch:        39 of        94\t|\tloss: 876.525\n",
      "Training Epoch 26  42.6% | batch:        40 of        94\t|\tloss: 1372.17\n",
      "Training Epoch 26  43.6% | batch:        41 of        94\t|\tloss: 1332.03\n",
      "Training Epoch 26  44.7% | batch:        42 of        94\t|\tloss: 1837.29\n",
      "Training Epoch 26  45.7% | batch:        43 of        94\t|\tloss: 1512.1\n",
      "Training Epoch 26  46.8% | batch:        44 of        94\t|\tloss: 4191.13\n",
      "Training Epoch 26  47.9% | batch:        45 of        94\t|\tloss: 1098.58\n",
      "Training Epoch 26  48.9% | batch:        46 of        94\t|\tloss: 2644.01\n",
      "Training Epoch 26  50.0% | batch:        47 of        94\t|\tloss: 1048.94\n",
      "Training Epoch 26  51.1% | batch:        48 of        94\t|\tloss: 911.12\n",
      "Training Epoch 26  52.1% | batch:        49 of        94\t|\tloss: 2797.26\n",
      "Training Epoch 26  53.2% | batch:        50 of        94\t|\tloss: 2355.14\n",
      "Training Epoch 26  54.3% | batch:        51 of        94\t|\tloss: 1193.02\n",
      "Training Epoch 26  55.3% | batch:        52 of        94\t|\tloss: 1461.78\n",
      "Training Epoch 26  56.4% | batch:        53 of        94\t|\tloss: 1106.84\n",
      "Training Epoch 26  57.4% | batch:        54 of        94\t|\tloss: 1478.76\n",
      "Training Epoch 26  58.5% | batch:        55 of        94\t|\tloss: 2149.45\n",
      "Training Epoch 26  59.6% | batch:        56 of        94\t|\tloss: 1283.33\n",
      "Training Epoch 26  60.6% | batch:        57 of        94\t|\tloss: 1934.82\n",
      "Training Epoch 26  61.7% | batch:        58 of        94\t|\tloss: 1705.11\n",
      "Training Epoch 26  62.8% | batch:        59 of        94\t|\tloss: 985.606\n",
      "Training Epoch 26  63.8% | batch:        60 of        94\t|\tloss: 1418.03\n",
      "Training Epoch 26  64.9% | batch:        61 of        94\t|\tloss: 1150.45\n",
      "Training Epoch 26  66.0% | batch:        62 of        94\t|\tloss: 1261.23\n",
      "Training Epoch 26  67.0% | batch:        63 of        94\t|\tloss: 5601.52\n",
      "Training Epoch 26  68.1% | batch:        64 of        94\t|\tloss: 1101.13\n",
      "Training Epoch 26  69.1% | batch:        65 of        94\t|\tloss: 1138.01\n",
      "Training Epoch 26  70.2% | batch:        66 of        94\t|\tloss: 1137.07\n",
      "Training Epoch 26  71.3% | batch:        67 of        94\t|\tloss: 1065.54\n",
      "Training Epoch 26  72.3% | batch:        68 of        94\t|\tloss: 1076.04\n",
      "Training Epoch 26  73.4% | batch:        69 of        94\t|\tloss: 2031.08\n",
      "Training Epoch 26  74.5% | batch:        70 of        94\t|\tloss: 2244.69\n",
      "Training Epoch 26  75.5% | batch:        71 of        94\t|\tloss: 1596.15\n",
      "Training Epoch 26  76.6% | batch:        72 of        94\t|\tloss: 1736.93\n",
      "Training Epoch 26  77.7% | batch:        73 of        94\t|\tloss: 2135.39\n",
      "Training Epoch 26  78.7% | batch:        74 of        94\t|\tloss: 3213.26\n",
      "Training Epoch 26  79.8% | batch:        75 of        94\t|\tloss: 1739.14\n",
      "Training Epoch 26  80.9% | batch:        76 of        94\t|\tloss: 1488.44\n",
      "Training Epoch 26  81.9% | batch:        77 of        94\t|\tloss: 1566.74\n",
      "Training Epoch 26  83.0% | batch:        78 of        94\t|\tloss: 2566.47\n",
      "Training Epoch 26  84.0% | batch:        79 of        94\t|\tloss: 1426.35\n",
      "Training Epoch 26  85.1% | batch:        80 of        94\t|\tloss: 938.495\n",
      "Training Epoch 26  86.2% | batch:        81 of        94\t|\tloss: 1519.96\n",
      "Training Epoch 26  87.2% | batch:        82 of        94\t|\tloss: 2478.35\n",
      "Training Epoch 26  88.3% | batch:        83 of        94\t|\tloss: 1656.59\n",
      "Training Epoch 26  89.4% | batch:        84 of        94\t|\tloss: 1345.77\n",
      "Training Epoch 26  90.4% | batch:        85 of        94\t|\tloss: 1345.92\n",
      "Training Epoch 26  91.5% | batch:        86 of        94\t|\tloss: 1456.68\n",
      "Training Epoch 26  92.6% | batch:        87 of        94\t|\tloss: 1819.3\n",
      "Training Epoch 26  93.6% | batch:        88 of        94\t|\tloss: 3228.63\n",
      "Training Epoch 26  94.7% | batch:        89 of        94\t|\tloss: 1632.52\n",
      "Training Epoch 26  95.7% | batch:        90 of        94\t|\tloss: 1673.08\n",
      "Training Epoch 26  96.8% | batch:        91 of        94\t|\tloss: 1030.58\n",
      "Training Epoch 26  97.9% | batch:        92 of        94\t|\tloss: 2195.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:11,609 | INFO : Epoch 26 Training Summary: epoch: 26.000000 | loss: 1692.378161 | \n",
      "2023-05-09 14:21:11,610 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8232886791229248 seconds\n",
      "\n",
      "2023-05-09 14:21:11,610 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8348146310219398 seconds\n",
      "2023-05-09 14:21:11,611 | INFO : Avg batch train. time: 0.019519304585339785 seconds\n",
      "2023-05-09 14:21:11,612 | INFO : Avg sample train. time: 0.000153953233010735 seconds\n",
      "2023-05-09 14:21:11,613 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 26  98.9% | batch:        93 of        94\t|\tloss: 886.045\n",
      "\n",
      "Evaluating Epoch 26   0.0% | batch:         0 of        40\t|\tloss: 6159.87\n",
      "Evaluating Epoch 26   2.5% | batch:         1 of        40\t|\tloss: 1091.31\n",
      "Evaluating Epoch 26   5.0% | batch:         2 of        40\t|\tloss: 2759.62\n",
      "Evaluating Epoch 26   7.5% | batch:         3 of        40\t|\tloss: 6502.94\n",
      "Evaluating Epoch 26  10.0% | batch:         4 of        40\t|\tloss: 1948.31\n",
      "Evaluating Epoch 26  12.5% | batch:         5 of        40\t|\tloss: 1767.17\n",
      "Evaluating Epoch 26  15.0% | batch:         6 of        40\t|\tloss: 7409.35\n",
      "Evaluating Epoch 26  17.5% | batch:         7 of        40\t|\tloss: 2563.88\n",
      "Evaluating Epoch 26  20.0% | batch:         8 of        40\t|\tloss: 2447.57\n",
      "Evaluating Epoch 26  22.5% | batch:         9 of        40\t|\tloss: 1785.68\n",
      "Evaluating Epoch 26  25.0% | batch:        10 of        40\t|\tloss: 4038.3\n",
      "Evaluating Epoch 26  27.5% | batch:        11 of        40\t|\tloss: 1177.82\n",
      "Evaluating Epoch 26  30.0% | batch:        12 of        40\t|\tloss: 6198.99\n",
      "Evaluating Epoch 26  32.5% | batch:        13 of        40\t|\tloss: 2878.71\n",
      "Evaluating Epoch 26  35.0% | batch:        14 of        40\t|\tloss: 1660.41\n",
      "Evaluating Epoch 26  37.5% | batch:        15 of        40\t|\tloss: 3116.69\n",
      "Evaluating Epoch 26  40.0% | batch:        16 of        40\t|\tloss: 4094.67\n",
      "Evaluating Epoch 26  42.5% | batch:        17 of        40\t|\tloss: 2340.17\n",
      "Evaluating Epoch 26  45.0% | batch:        18 of        40\t|\tloss: 1904.62\n",
      "Evaluating Epoch 26  47.5% | batch:        19 of        40\t|\tloss: 5521.84\n",
      "Evaluating Epoch 26  50.0% | batch:        20 of        40\t|\tloss: 4767.49\n",
      "Evaluating Epoch 26  52.5% | batch:        21 of        40\t|\tloss: 1097.1\n",
      "Evaluating Epoch 26  55.0% | batch:        22 of        40\t|\tloss: 3425.01\n",
      "Evaluating Epoch 26  57.5% | batch:        23 of        40\t|\tloss: 2565.52\n",
      "Evaluating Epoch 26  60.0% | batch:        24 of        40\t|\tloss: 1276.03\n",
      "Evaluating Epoch 26  62.5% | batch:        25 of        40\t|\tloss: 2739.98\n",
      "Evaluating Epoch 26  65.0% | batch:        26 of        40\t|\tloss: 8424.18\n",
      "Evaluating Epoch 26  67.5% | batch:        27 of        40\t|\tloss: 2403.44\n",
      "Evaluating Epoch 26  70.0% | batch:        28 of        40\t|\tloss: 1584.3\n",
      "Evaluating Epoch 26  72.5% | batch:        29 of        40\t|\tloss: 8805.69\n",
      "Evaluating Epoch 26  75.0% | batch:        30 of        40\t|\tloss: 1850.16\n",
      "Evaluating Epoch 26  77.5% | batch:        31 of        40\t|\tloss: 1551.18\n",
      "Evaluating Epoch 26  80.0% | batch:        32 of        40\t|\tloss: 6658.62\n",
      "Evaluating Epoch 26  82.5% | batch:        33 of        40\t|\tloss: 5826.56\n",
      "Evaluating Epoch 26  85.0% | batch:        34 of        40\t|\tloss: 969.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:12,071 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4579660892486572 seconds\n",
      "\n",
      "2023-05-09 14:21:12,072 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.5023747126261393 seconds\n",
      "2023-05-09 14:21:12,072 | INFO : Avg batch val. time: 0.012559367815653482 seconds\n",
      "2023-05-09 14:21:12,072 | INFO : Avg sample val. time: 9.951955479915596e-05 seconds\n",
      "2023-05-09 14:21:12,073 | INFO : Epoch 26 Validation Summary: epoch: 26.000000 | loss: 3611.675702 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 26  87.5% | batch:        35 of        40\t|\tloss: 4805.17\n",
      "Evaluating Epoch 26  90.0% | batch:        36 of        40\t|\tloss: 5595.2\n",
      "Evaluating Epoch 26  92.5% | batch:        37 of        40\t|\tloss: 2396.64\n",
      "Evaluating Epoch 26  95.0% | batch:        38 of        40\t|\tloss: 3517.79\n",
      "Evaluating Epoch 26  97.5% | batch:        39 of        40\t|\tloss: 10989.6\n",
      "\n",
      "Training Epoch 27   0.0% | batch:         0 of        94\t|\tloss: 1614.1\n",
      "Training Epoch 27   1.1% | batch:         1 of        94\t|\tloss: 1313.53\n",
      "Training Epoch 27   2.1% | batch:         2 of        94\t|\tloss: 1661.54\n",
      "Training Epoch 27   3.2% | batch:         3 of        94\t|\tloss: 1886.05\n",
      "Training Epoch 27   4.3% | batch:         4 of        94\t|\tloss: 1738.36\n",
      "Training Epoch 27   5.3% | batch:         5 of        94\t|\tloss: 1586.04\n",
      "Training Epoch 27   6.4% | batch:         6 of        94\t|\tloss: 1967.52\n",
      "Training Epoch 27   7.4% | batch:         7 of        94\t|\tloss: 1293.79\n",
      "Training Epoch 27   8.5% | batch:         8 of        94\t|\tloss: 3234.28\n",
      "Training Epoch 27   9.6% | batch:         9 of        94\t|\tloss: 1588.73\n",
      "Training Epoch 27  10.6% | batch:        10 of        94\t|\tloss: 1233.45\n",
      "Training Epoch 27  11.7% | batch:        11 of        94\t|\tloss: 2502.93\n",
      "Training Epoch 27  12.8% | batch:        12 of        94\t|\tloss: 2022.68\n",
      "Training Epoch 27  13.8% | batch:        13 of        94\t|\tloss: 1091.31\n",
      "Training Epoch 27  14.9% | batch:        14 of        94\t|\tloss: 1063.86\n",
      "Training Epoch 27  16.0% | batch:        15 of        94\t|\tloss: 1127.57\n",
      "Training Epoch 27  17.0% | batch:        16 of        94\t|\tloss: 1182.62\n",
      "Training Epoch 27  18.1% | batch:        17 of        94\t|\tloss: 1026.48\n",
      "Training Epoch 27  19.1% | batch:        18 of        94\t|\tloss: 2905.21\n",
      "Training Epoch 27  20.2% | batch:        19 of        94\t|\tloss: 1557.69\n",
      "Training Epoch 27  21.3% | batch:        20 of        94\t|\tloss: 3772.47\n",
      "Training Epoch 27  22.3% | batch:        21 of        94\t|\tloss: 1051.51\n",
      "Training Epoch 27  23.4% | batch:        22 of        94\t|\tloss: 1289.59\n",
      "Training Epoch 27  24.5% | batch:        23 of        94\t|\tloss: 1689.54\n",
      "Training Epoch 27  25.5% | batch:        24 of        94\t|\tloss: 1050.84\n",
      "Training Epoch 27  26.6% | batch:        25 of        94\t|\tloss: 1555.69\n",
      "Training Epoch 27  27.7% | batch:        26 of        94\t|\tloss: 847.809\n",
      "Training Epoch 27  28.7% | batch:        27 of        94\t|\tloss: 1782.52\n",
      "Training Epoch 27  29.8% | batch:        28 of        94\t|\tloss: 1979.28\n",
      "Training Epoch 27  30.9% | batch:        29 of        94\t|\tloss: 2736.19\n",
      "Training Epoch 27  31.9% | batch:        30 of        94\t|\tloss: 1434.34\n",
      "Training Epoch 27  33.0% | batch:        31 of        94\t|\tloss: 1737.02\n",
      "Training Epoch 27  34.0% | batch:        32 of        94\t|\tloss: 1623.65\n",
      "Training Epoch 27  35.1% | batch:        33 of        94\t|\tloss: 1503.2\n",
      "Training Epoch 27  36.2% | batch:        34 of        94\t|\tloss: 1403.59\n",
      "Training Epoch 27  37.2% | batch:        35 of        94\t|\tloss: 3825.76\n",
      "Training Epoch 27  38.3% | batch:        36 of        94\t|\tloss: 1174.69\n",
      "Training Epoch 27  39.4% | batch:        37 of        94\t|\tloss: 1112.69\n",
      "Training Epoch 27  40.4% | batch:        38 of        94\t|\tloss: 1915.56\n",
      "Training Epoch 27  41.5% | batch:        39 of        94\t|\tloss: 1194.03\n",
      "Training Epoch 27  42.6% | batch:        40 of        94\t|\tloss: 1961.37\n",
      "Training Epoch 27  43.6% | batch:        41 of        94\t|\tloss: 1445.15\n",
      "Training Epoch 27  44.7% | batch:        42 of        94\t|\tloss: 1412.36\n",
      "Training Epoch 27  45.7% | batch:        43 of        94\t|\tloss: 2404.49\n",
      "Training Epoch 27  46.8% | batch:        44 of        94\t|\tloss: 963.672\n",
      "Training Epoch 27  47.9% | batch:        45 of        94\t|\tloss: 1736.71\n",
      "Training Epoch 27  48.9% | batch:        46 of        94\t|\tloss: 1444.72\n",
      "Training Epoch 27  50.0% | batch:        47 of        94\t|\tloss: 2682.86\n",
      "Training Epoch 27  51.1% | batch:        48 of        94\t|\tloss: 1067.29\n",
      "Training Epoch 27  52.1% | batch:        49 of        94\t|\tloss: 1802.71\n",
      "Training Epoch 27  53.2% | batch:        50 of        94\t|\tloss: 3903.23\n",
      "Training Epoch 27  54.3% | batch:        51 of        94\t|\tloss: 1363.2\n",
      "Training Epoch 27  55.3% | batch:        52 of        94\t|\tloss: 1492.7\n",
      "Training Epoch 27  56.4% | batch:        53 of        94\t|\tloss: 970.85\n",
      "Training Epoch 27  57.4% | batch:        54 of        94\t|\tloss: 1081.6\n",
      "Training Epoch 27  58.5% | batch:        55 of        94\t|\tloss: 2058.89\n",
      "Training Epoch 27  59.6% | batch:        56 of        94\t|\tloss: 1289.34\n",
      "Training Epoch 27  60.6% | batch:        57 of        94\t|\tloss: 1346.5\n",
      "Training Epoch 27  61.7% | batch:        58 of        94\t|\tloss: 1564.47\n",
      "Training Epoch 27  62.8% | batch:        59 of        94\t|\tloss: 1547.42\n",
      "Training Epoch 27  63.8% | batch:        60 of        94\t|\tloss: 2247.31\n",
      "Training Epoch 27  64.9% | batch:        61 of        94\t|\tloss: 1028.98\n",
      "Training Epoch 27  66.0% | batch:        62 of        94\t|\tloss: 1695.17\n",
      "Training Epoch 27  67.0% | batch:        63 of        94\t|\tloss: 2109.99\n",
      "Training Epoch 27  68.1% | batch:        64 of        94\t|\tloss: 1546.32\n",
      "Training Epoch 27  69.1% | batch:        65 of        94\t|\tloss: 1902.66\n",
      "Training Epoch 27  70.2% | batch:        66 of        94\t|\tloss: 1730.41\n",
      "Training Epoch 27  71.3% | batch:        67 of        94\t|\tloss: 1727.79\n",
      "Training Epoch 27  72.3% | batch:        68 of        94\t|\tloss: 1177.25\n",
      "Training Epoch 27  73.4% | batch:        69 of        94\t|\tloss: 2008.44\n",
      "Training Epoch 27  74.5% | batch:        70 of        94\t|\tloss: 2606.75\n",
      "Training Epoch 27  75.5% | batch:        71 of        94\t|\tloss: 2070.84\n",
      "Training Epoch 27  76.6% | batch:        72 of        94\t|\tloss: 2556.08\n",
      "Training Epoch 27  77.7% | batch:        73 of        94\t|\tloss: 1781.06\n",
      "Training Epoch 27  78.7% | batch:        74 of        94\t|\tloss: 1839.45\n",
      "Training Epoch 27  79.8% | batch:        75 of        94\t|\tloss: 1733.96\n",
      "Training Epoch 27  80.9% | batch:        76 of        94\t|\tloss: 1391.85\n",
      "Training Epoch 27  81.9% | batch:        77 of        94\t|\tloss: 1554.81\n",
      "Training Epoch 27  83.0% | batch:        78 of        94\t|\tloss: 1525.84\n",
      "Training Epoch 27  84.0% | batch:        79 of        94\t|\tloss: 1435.51\n",
      "Training Epoch 27  85.1% | batch:        80 of        94\t|\tloss: 1314.12\n",
      "Training Epoch 27  86.2% | batch:        81 of        94\t|\tloss: 1335.65\n",
      "Training Epoch 27  87.2% | batch:        82 of        94\t|\tloss: 2168.54\n",
      "Training Epoch 27  88.3% | batch:        83 of        94\t|\tloss: 1020.3\n",
      "Training Epoch 27  89.4% | batch:        84 of        94\t|\tloss: 1340.11\n",
      "Training Epoch 27  90.4% | batch:        85 of        94\t|\tloss: 1420.26\n",
      "Training Epoch 27  91.5% | batch:        86 of        94\t|\tloss: 1274.67\n",
      "Training Epoch 27  92.6% | batch:        87 of        94\t|\tloss: 1097.91\n",
      "Training Epoch 27  93.6% | batch:        88 of        94\t|\tloss: 1767.17\n",
      "Training Epoch 27  94.7% | batch:        89 of        94\t|\tloss: 1559.01\n",
      "Training Epoch 27  95.7% | batch:        90 of        94\t|\tloss: 1296.17\n",
      "Training Epoch 27  96.8% | batch:        91 of        94\t|\tloss: 1663.07\n",
      "Training Epoch 27  97.9% | batch:        92 of        94\t|\tloss: 1685.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:13,959 | INFO : Epoch 27 Training Summary: epoch: 27.000000 | loss: 1682.413005 | \n",
      "2023-05-09 14:21:13,959 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8645470142364502 seconds\n",
      "\n",
      "2023-05-09 14:21:13,960 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.835915830400255 seconds\n",
      "2023-05-09 14:21:13,961 | INFO : Avg batch train. time: 0.019531019472343137 seconds\n",
      "2023-05-09 14:21:13,962 | INFO : Avg sample train. time: 0.00015404563101193615 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 27  98.9% | batch:        93 of        94\t|\tloss: 1993.63\n",
      "\n",
      "Training Epoch 28   0.0% | batch:         0 of        94\t|\tloss: 1309.29\n",
      "Training Epoch 28   1.1% | batch:         1 of        94\t|\tloss: 957.735\n",
      "Training Epoch 28   2.1% | batch:         2 of        94\t|\tloss: 1237.61\n",
      "Training Epoch 28   3.2% | batch:         3 of        94\t|\tloss: 670.791\n",
      "Training Epoch 28   4.3% | batch:         4 of        94\t|\tloss: 1271.3\n",
      "Training Epoch 28   5.3% | batch:         5 of        94\t|\tloss: 1697.35\n",
      "Training Epoch 28   6.4% | batch:         6 of        94\t|\tloss: 1437.01\n",
      "Training Epoch 28   7.4% | batch:         7 of        94\t|\tloss: 1899.99\n",
      "Training Epoch 28   8.5% | batch:         8 of        94\t|\tloss: 1234.58\n",
      "Training Epoch 28   9.6% | batch:         9 of        94\t|\tloss: 1299.43\n",
      "Training Epoch 28  10.6% | batch:        10 of        94\t|\tloss: 2531.18\n",
      "Training Epoch 28  11.7% | batch:        11 of        94\t|\tloss: 1793.73\n",
      "Training Epoch 28  12.8% | batch:        12 of        94\t|\tloss: 1289.28\n",
      "Training Epoch 28  13.8% | batch:        13 of        94\t|\tloss: 1287.69\n",
      "Training Epoch 28  14.9% | batch:        14 of        94\t|\tloss: 1670.61\n",
      "Training Epoch 28  16.0% | batch:        15 of        94\t|\tloss: 1356.09\n",
      "Training Epoch 28  17.0% | batch:        16 of        94\t|\tloss: 2331.73\n",
      "Training Epoch 28  18.1% | batch:        17 of        94\t|\tloss: 2426.38\n",
      "Training Epoch 28  19.1% | batch:        18 of        94\t|\tloss: 1399.64\n",
      "Training Epoch 28  20.2% | batch:        19 of        94\t|\tloss: 1885.93\n",
      "Training Epoch 28  21.3% | batch:        20 of        94\t|\tloss: 1634.95\n",
      "Training Epoch 28  22.3% | batch:        21 of        94\t|\tloss: 1577.93\n",
      "Training Epoch 28  23.4% | batch:        22 of        94\t|\tloss: 1077.87\n",
      "Training Epoch 28  24.5% | batch:        23 of        94\t|\tloss: 1253.8\n",
      "Training Epoch 28  25.5% | batch:        24 of        94\t|\tloss: 2261.33\n",
      "Training Epoch 28  26.6% | batch:        25 of        94\t|\tloss: 1288.57\n",
      "Training Epoch 28  27.7% | batch:        26 of        94\t|\tloss: 1744.04\n",
      "Training Epoch 28  28.7% | batch:        27 of        94\t|\tloss: 1389.43\n",
      "Training Epoch 28  29.8% | batch:        28 of        94\t|\tloss: 1563.27\n",
      "Training Epoch 28  30.9% | batch:        29 of        94\t|\tloss: 1071.59\n",
      "Training Epoch 28  31.9% | batch:        30 of        94\t|\tloss: 1998.27\n",
      "Training Epoch 28  33.0% | batch:        31 of        94\t|\tloss: 1689.99\n",
      "Training Epoch 28  34.0% | batch:        32 of        94\t|\tloss: 1554.45\n",
      "Training Epoch 28  35.1% | batch:        33 of        94\t|\tloss: 2252.7\n",
      "Training Epoch 28  36.2% | batch:        34 of        94\t|\tloss: 1535.88\n",
      "Training Epoch 28  37.2% | batch:        35 of        94\t|\tloss: 1759.81\n",
      "Training Epoch 28  38.3% | batch:        36 of        94\t|\tloss: 1735.71\n",
      "Training Epoch 28  39.4% | batch:        37 of        94\t|\tloss: 2888.46\n",
      "Training Epoch 28  40.4% | batch:        38 of        94\t|\tloss: 1139.74\n",
      "Training Epoch 28  41.5% | batch:        39 of        94\t|\tloss: 2546.53\n",
      "Training Epoch 28  42.6% | batch:        40 of        94\t|\tloss: 2136.08\n",
      "Training Epoch 28  43.6% | batch:        41 of        94\t|\tloss: 2317.09\n",
      "Training Epoch 28  44.7% | batch:        42 of        94\t|\tloss: 1529.13\n",
      "Training Epoch 28  45.7% | batch:        43 of        94\t|\tloss: 1325.87\n",
      "Training Epoch 28  46.8% | batch:        44 of        94\t|\tloss: 2146.74\n",
      "Training Epoch 28  47.9% | batch:        45 of        94\t|\tloss: 1863.82\n",
      "Training Epoch 28  48.9% | batch:        46 of        94\t|\tloss: 1210.29\n",
      "Training Epoch 28  50.0% | batch:        47 of        94\t|\tloss: 1562.55\n",
      "Training Epoch 28  51.1% | batch:        48 of        94\t|\tloss: 1343.23\n",
      "Training Epoch 28  52.1% | batch:        49 of        94\t|\tloss: 1782.96\n",
      "Training Epoch 28  53.2% | batch:        50 of        94\t|\tloss: 1989.07\n",
      "Training Epoch 28  54.3% | batch:        51 of        94\t|\tloss: 1284.34\n",
      "Training Epoch 28  55.3% | batch:        52 of        94\t|\tloss: 3104.08\n",
      "Training Epoch 28  56.4% | batch:        53 of        94\t|\tloss: 2183.66\n",
      "Training Epoch 28  57.4% | batch:        54 of        94\t|\tloss: 2304.17\n",
      "Training Epoch 28  58.5% | batch:        55 of        94\t|\tloss: 1217.6\n",
      "Training Epoch 28  59.6% | batch:        56 of        94\t|\tloss: 1619.27\n",
      "Training Epoch 28  60.6% | batch:        57 of        94\t|\tloss: 3882.36\n",
      "Training Epoch 28  61.7% | batch:        58 of        94\t|\tloss: 1005.68\n",
      "Training Epoch 28  62.8% | batch:        59 of        94\t|\tloss: 2602.34\n",
      "Training Epoch 28  63.8% | batch:        60 of        94\t|\tloss: 1785.41\n",
      "Training Epoch 28  64.9% | batch:        61 of        94\t|\tloss: 2268.2\n",
      "Training Epoch 28  66.0% | batch:        62 of        94\t|\tloss: 1553.48\n",
      "Training Epoch 28  67.0% | batch:        63 of        94\t|\tloss: 1806.21\n",
      "Training Epoch 28  68.1% | batch:        64 of        94\t|\tloss: 1568.5\n",
      "Training Epoch 28  69.1% | batch:        65 of        94\t|\tloss: 1101.71\n",
      "Training Epoch 28  70.2% | batch:        66 of        94\t|\tloss: 1204.57\n",
      "Training Epoch 28  71.3% | batch:        67 of        94\t|\tloss: 1504.54\n",
      "Training Epoch 28  72.3% | batch:        68 of        94\t|\tloss: 1212.07\n",
      "Training Epoch 28  73.4% | batch:        69 of        94\t|\tloss: 1719.07\n",
      "Training Epoch 28  74.5% | batch:        70 of        94\t|\tloss: 1957.2\n",
      "Training Epoch 28  75.5% | batch:        71 of        94\t|\tloss: 1470.26\n",
      "Training Epoch 28  76.6% | batch:        72 of        94\t|\tloss: 1622.33\n",
      "Training Epoch 28  77.7% | batch:        73 of        94\t|\tloss: 1700.17\n",
      "Training Epoch 28  78.7% | batch:        74 of        94\t|\tloss: 2502.67\n",
      "Training Epoch 28  79.8% | batch:        75 of        94\t|\tloss: 2285.15\n",
      "Training Epoch 28  80.9% | batch:        76 of        94\t|\tloss: 1373.74\n",
      "Training Epoch 28  81.9% | batch:        77 of        94\t|\tloss: 1250.2\n",
      "Training Epoch 28  83.0% | batch:        78 of        94\t|\tloss: 1500.71\n",
      "Training Epoch 28  84.0% | batch:        79 of        94\t|\tloss: 1563.78\n",
      "Training Epoch 28  85.1% | batch:        80 of        94\t|\tloss: 1570.31\n",
      "Training Epoch 28  86.2% | batch:        81 of        94\t|\tloss: 1588.56\n",
      "Training Epoch 28  87.2% | batch:        82 of        94\t|\tloss: 1209.14\n",
      "Training Epoch 28  88.3% | batch:        83 of        94\t|\tloss: 1182.84\n",
      "Training Epoch 28  89.4% | batch:        84 of        94\t|\tloss: 1153.52\n",
      "Training Epoch 28  90.4% | batch:        85 of        94\t|\tloss: 1239.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:15,781 | INFO : Epoch 28 Training Summary: epoch: 28.000000 | loss: 1659.811641 | \n",
      "2023-05-09 14:21:15,782 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7985703945159912 seconds\n",
      "\n",
      "2023-05-09 14:21:15,782 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8345820648329598 seconds\n",
      "2023-05-09 14:21:15,783 | INFO : Avg batch train. time: 0.01951683047694638 seconds\n",
      "2023-05-09 14:21:15,783 | INFO : Avg sample train. time: 0.00015393371915027352 seconds\n",
      "2023-05-09 14:21:15,783 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 28  91.5% | batch:        86 of        94\t|\tloss: 779.721\n",
      "Training Epoch 28  92.6% | batch:        87 of        94\t|\tloss: 1499.37\n",
      "Training Epoch 28  93.6% | batch:        88 of        94\t|\tloss: 1357.43\n",
      "Training Epoch 28  94.7% | batch:        89 of        94\t|\tloss: 1542.7\n",
      "Training Epoch 28  95.7% | batch:        90 of        94\t|\tloss: 1384.26\n",
      "Training Epoch 28  96.8% | batch:        91 of        94\t|\tloss: 1890.97\n",
      "Training Epoch 28  97.9% | batch:        92 of        94\t|\tloss: 1702.46\n",
      "Training Epoch 28  98.9% | batch:        93 of        94\t|\tloss: 1202.05\n",
      "\n",
      "Evaluating Epoch 28   0.0% | batch:         0 of        40\t|\tloss: 4075.7\n",
      "Evaluating Epoch 28   2.5% | batch:         1 of        40\t|\tloss: 985.149\n",
      "Evaluating Epoch 28   5.0% | batch:         2 of        40\t|\tloss: 3417.85\n",
      "Evaluating Epoch 28   7.5% | batch:         3 of        40\t|\tloss: 4957.81\n",
      "Evaluating Epoch 28  10.0% | batch:         4 of        40\t|\tloss: 1834.88\n",
      "Evaluating Epoch 28  12.5% | batch:         5 of        40\t|\tloss: 1910.26\n",
      "Evaluating Epoch 28  15.0% | batch:         6 of        40\t|\tloss: 7041.91\n",
      "Evaluating Epoch 28  17.5% | batch:         7 of        40\t|\tloss: 2596.69\n",
      "Evaluating Epoch 28  20.0% | batch:         8 of        40\t|\tloss: 2356.27\n",
      "Evaluating Epoch 28  22.5% | batch:         9 of        40\t|\tloss: 2006.84\n",
      "Evaluating Epoch 28  25.0% | batch:        10 of        40\t|\tloss: 3579.71\n",
      "Evaluating Epoch 28  27.5% | batch:        11 of        40\t|\tloss: 1407.53\n",
      "Evaluating Epoch 28  30.0% | batch:        12 of        40\t|\tloss: 5744.5\n",
      "Evaluating Epoch 28  32.5% | batch:        13 of        40\t|\tloss: 1934.77\n",
      "Evaluating Epoch 28  35.0% | batch:        14 of        40\t|\tloss: 1820.11\n",
      "Evaluating Epoch 28  37.5% | batch:        15 of        40\t|\tloss: 3614.45\n",
      "Evaluating Epoch 28  40.0% | batch:        16 of        40\t|\tloss: 3990.38\n",
      "Evaluating Epoch 28  42.5% | batch:        17 of        40\t|\tloss: 2436.06\n",
      "Evaluating Epoch 28  45.0% | batch:        18 of        40\t|\tloss: 2197.19\n",
      "Evaluating Epoch 28  47.5% | batch:        19 of        40\t|\tloss: 4261.13\n",
      "Evaluating Epoch 28  50.0% | batch:        20 of        40\t|\tloss: 4269.21\n",
      "Evaluating Epoch 28  52.5% | batch:        21 of        40\t|\tloss: 1017.06\n",
      "Evaluating Epoch 28  55.0% | batch:        22 of        40\t|\tloss: 4143.23\n",
      "Evaluating Epoch 28  57.5% | batch:        23 of        40\t|\tloss: 2569.25\n",
      "Evaluating Epoch 28  60.0% | batch:        24 of        40\t|\tloss: 1441.71\n",
      "Evaluating Epoch 28  62.5% | batch:        25 of        40\t|\tloss: 3490.74\n",
      "Evaluating Epoch 28  65.0% | batch:        26 of        40\t|\tloss: 5548.34\n",
      "Evaluating Epoch 28  67.5% | batch:        27 of        40\t|\tloss: 2537.67\n",
      "Evaluating Epoch 28  70.0% | batch:        28 of        40\t|\tloss: 1677.01\n",
      "Evaluating Epoch 28  72.5% | batch:        29 of        40\t|\tloss: 8445.72\n",
      "Evaluating Epoch 28  75.0% | batch:        30 of        40\t|\tloss: 1830.62\n",
      "Evaluating Epoch 28  77.5% | batch:        31 of        40\t|\tloss: 1582.63\n",
      "Evaluating Epoch 28  80.0% | batch:        32 of        40\t|\tloss: 7498.76\n",
      "Evaluating Epoch 28  82.5% | batch:        33 of        40\t|\tloss: 3751.49\n",
      "Evaluating Epoch 28  85.0% | batch:        34 of        40\t|\tloss: 1110.33\n",
      "Evaluating Epoch 28  87.5% | batch:        35 of        40\t|\tloss: 5047.5\n",
      "Evaluating Epoch 28  90.0% | batch:        36 of        40\t|\tloss: 3309.45\n",
      "Evaluating Epoch 28  92.5% | batch:        37 of        40\t|\tloss: 2401.8\n",
      "Evaluating Epoch 28  95.0% | batch:        38 of        40\t|\tloss: 3837.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:16,242 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4585692882537842 seconds\n",
      "\n",
      "2023-05-09 14:21:16,243 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4996368736028671 seconds\n",
      "2023-05-09 14:21:16,243 | INFO : Avg batch val. time: 0.012490921840071677 seconds\n",
      "2023-05-09 14:21:16,244 | INFO : Avg sample val. time: 9.897719366142376e-05 seconds\n",
      "2023-05-09 14:21:16,244 | INFO : Epoch 28 Validation Summary: epoch: 28.000000 | loss: 3337.196120 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 28  97.5% | batch:        39 of        40\t|\tloss: 8986.92\n",
      "\n",
      "Training Epoch 29   0.0% | batch:         0 of        94\t|\tloss: 1153.32\n",
      "Training Epoch 29   1.1% | batch:         1 of        94\t|\tloss: 1824.22\n",
      "Training Epoch 29   2.1% | batch:         2 of        94\t|\tloss: 2025.56\n",
      "Training Epoch 29   3.2% | batch:         3 of        94\t|\tloss: 866.164\n",
      "Training Epoch 29   4.3% | batch:         4 of        94\t|\tloss: 2226.85\n",
      "Training Epoch 29   5.3% | batch:         5 of        94\t|\tloss: 1234.79\n",
      "Training Epoch 29   6.4% | batch:         6 of        94\t|\tloss: 1221.99\n",
      "Training Epoch 29   7.4% | batch:         7 of        94\t|\tloss: 860.842\n",
      "Training Epoch 29   8.5% | batch:         8 of        94\t|\tloss: 1182.19\n",
      "Training Epoch 29   9.6% | batch:         9 of        94\t|\tloss: 979.327\n",
      "Training Epoch 29  10.6% | batch:        10 of        94\t|\tloss: 1193.63\n",
      "Training Epoch 29  11.7% | batch:        11 of        94\t|\tloss: 1592.14\n",
      "Training Epoch 29  12.8% | batch:        12 of        94\t|\tloss: 1840.33\n",
      "Training Epoch 29  13.8% | batch:        13 of        94\t|\tloss: 1868.27\n",
      "Training Epoch 29  14.9% | batch:        14 of        94\t|\tloss: 2053.13\n",
      "Training Epoch 29  16.0% | batch:        15 of        94\t|\tloss: 995.626\n",
      "Training Epoch 29  17.0% | batch:        16 of        94\t|\tloss: 1609.86\n",
      "Training Epoch 29  18.1% | batch:        17 of        94\t|\tloss: 1366.73\n",
      "Training Epoch 29  19.1% | batch:        18 of        94\t|\tloss: 1417.39\n",
      "Training Epoch 29  20.2% | batch:        19 of        94\t|\tloss: 2012.12\n",
      "Training Epoch 29  21.3% | batch:        20 of        94\t|\tloss: 1581.38\n",
      "Training Epoch 29  22.3% | batch:        21 of        94\t|\tloss: 1827.07\n",
      "Training Epoch 29  23.4% | batch:        22 of        94\t|\tloss: 2070.83\n",
      "Training Epoch 29  24.5% | batch:        23 of        94\t|\tloss: 1372.77\n",
      "Training Epoch 29  25.5% | batch:        24 of        94\t|\tloss: 1743.92\n",
      "Training Epoch 29  26.6% | batch:        25 of        94\t|\tloss: 1931.46\n",
      "Training Epoch 29  27.7% | batch:        26 of        94\t|\tloss: 1517.78\n",
      "Training Epoch 29  28.7% | batch:        27 of        94\t|\tloss: 1915.63\n",
      "Training Epoch 29  29.8% | batch:        28 of        94\t|\tloss: 2258.22\n",
      "Training Epoch 29  30.9% | batch:        29 of        94\t|\tloss: 1412.5\n",
      "Training Epoch 29  31.9% | batch:        30 of        94\t|\tloss: 2333.09\n",
      "Training Epoch 29  33.0% | batch:        31 of        94\t|\tloss: 3395.22\n",
      "Training Epoch 29  34.0% | batch:        32 of        94\t|\tloss: 1893.54\n",
      "Training Epoch 29  35.1% | batch:        33 of        94\t|\tloss: 1762.85\n",
      "Training Epoch 29  36.2% | batch:        34 of        94\t|\tloss: 1675.42\n",
      "Training Epoch 29  37.2% | batch:        35 of        94\t|\tloss: 1465.77\n",
      "Training Epoch 29  38.3% | batch:        36 of        94\t|\tloss: 1764.9\n",
      "Training Epoch 29  39.4% | batch:        37 of        94\t|\tloss: 1226.16\n",
      "Training Epoch 29  40.4% | batch:        38 of        94\t|\tloss: 2066.07\n",
      "Training Epoch 29  41.5% | batch:        39 of        94\t|\tloss: 1433.19\n",
      "Training Epoch 29  42.6% | batch:        40 of        94\t|\tloss: 1462.81\n",
      "Training Epoch 29  43.6% | batch:        41 of        94\t|\tloss: 2502.86\n",
      "Training Epoch 29  44.7% | batch:        42 of        94\t|\tloss: 1406.98\n",
      "Training Epoch 29  45.7% | batch:        43 of        94\t|\tloss: 1821.21\n",
      "Training Epoch 29  46.8% | batch:        44 of        94\t|\tloss: 1440.42\n",
      "Training Epoch 29  47.9% | batch:        45 of        94\t|\tloss: 1528.47\n",
      "Training Epoch 29  48.9% | batch:        46 of        94\t|\tloss: 1271.66\n",
      "Training Epoch 29  50.0% | batch:        47 of        94\t|\tloss: 1525.88\n",
      "Training Epoch 29  51.1% | batch:        48 of        94\t|\tloss: 3423.82\n",
      "Training Epoch 29  52.1% | batch:        49 of        94\t|\tloss: 1103.35\n",
      "Training Epoch 29  53.2% | batch:        50 of        94\t|\tloss: 5666.46\n",
      "Training Epoch 29  54.3% | batch:        51 of        94\t|\tloss: 1657.73\n",
      "Training Epoch 29  55.3% | batch:        52 of        94\t|\tloss: 1303.03\n",
      "Training Epoch 29  56.4% | batch:        53 of        94\t|\tloss: 1577.57\n",
      "Training Epoch 29  57.4% | batch:        54 of        94\t|\tloss: 2098.94\n",
      "Training Epoch 29  58.5% | batch:        55 of        94\t|\tloss: 1760.13\n",
      "Training Epoch 29  59.6% | batch:        56 of        94\t|\tloss: 1369.8\n",
      "Training Epoch 29  60.6% | batch:        57 of        94\t|\tloss: 1458.81\n",
      "Training Epoch 29  61.7% | batch:        58 of        94\t|\tloss: 1073.71\n",
      "Training Epoch 29  62.8% | batch:        59 of        94\t|\tloss: 1883.94\n",
      "Training Epoch 29  63.8% | batch:        60 of        94\t|\tloss: 1440.86\n",
      "Training Epoch 29  64.9% | batch:        61 of        94\t|\tloss: 992.182\n",
      "Training Epoch 29  66.0% | batch:        62 of        94\t|\tloss: 1694.84\n",
      "Training Epoch 29  67.0% | batch:        63 of        94\t|\tloss: 2010.61\n",
      "Training Epoch 29  68.1% | batch:        64 of        94\t|\tloss: 1341.15\n",
      "Training Epoch 29  69.1% | batch:        65 of        94\t|\tloss: 1069.01\n",
      "Training Epoch 29  70.2% | batch:        66 of        94\t|\tloss: 1272.45\n",
      "Training Epoch 29  71.3% | batch:        67 of        94\t|\tloss: 1338.61\n",
      "Training Epoch 29  72.3% | batch:        68 of        94\t|\tloss: 1890.65\n",
      "Training Epoch 29  73.4% | batch:        69 of        94\t|\tloss: 1613.8\n",
      "Training Epoch 29  74.5% | batch:        70 of        94\t|\tloss: 1541.59\n",
      "Training Epoch 29  75.5% | batch:        71 of        94\t|\tloss: 1299.4\n",
      "Training Epoch 29  76.6% | batch:        72 of        94\t|\tloss: 1451.51\n",
      "Training Epoch 29  77.7% | batch:        73 of        94\t|\tloss: 1675.28\n",
      "Training Epoch 29  78.7% | batch:        74 of        94\t|\tloss: 1880.41\n",
      "Training Epoch 29  79.8% | batch:        75 of        94\t|\tloss: 985.699\n",
      "Training Epoch 29  80.9% | batch:        76 of        94\t|\tloss: 1384.86\n",
      "Training Epoch 29  81.9% | batch:        77 of        94\t|\tloss: 1468.22\n",
      "Training Epoch 29  83.0% | batch:        78 of        94\t|\tloss: 1672.53\n",
      "Training Epoch 29  84.0% | batch:        79 of        94\t|\tloss: 1124.01\n",
      "Training Epoch 29  85.1% | batch:        80 of        94\t|\tloss: 1401.26\n",
      "Training Epoch 29  86.2% | batch:        81 of        94\t|\tloss: 1247.76\n",
      "Training Epoch 29  87.2% | batch:        82 of        94\t|\tloss: 1928.57\n",
      "Training Epoch 29  88.3% | batch:        83 of        94\t|\tloss: 998.266\n",
      "Training Epoch 29  89.4% | batch:        84 of        94\t|\tloss: 1531.57\n",
      "Training Epoch 29  90.4% | batch:        85 of        94\t|\tloss: 1616.56\n",
      "Training Epoch 29  91.5% | batch:        86 of        94\t|\tloss: 1044.87\n",
      "Training Epoch 29  92.6% | batch:        87 of        94\t|\tloss: 1907.38\n",
      "Training Epoch 29  93.6% | batch:        88 of        94\t|\tloss: 2753.65\n",
      "Training Epoch 29  94.7% | batch:        89 of        94\t|\tloss: 1526.07\n",
      "Training Epoch 29  95.7% | batch:        90 of        94\t|\tloss: 2766.25\n",
      "Training Epoch 29  96.8% | batch:        91 of        94\t|\tloss: 1205.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:18,030 | INFO : Epoch 29 Training Summary: epoch: 29.000000 | loss: 1665.165962 | \n",
      "2023-05-09 14:21:18,031 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7540786266326904 seconds\n",
      "\n",
      "2023-05-09 14:21:18,031 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8318060842053643 seconds\n",
      "2023-05-09 14:21:18,032 | INFO : Avg batch train. time: 0.01948729876814217 seconds\n",
      "2023-05-09 14:21:18,032 | INFO : Avg sample train. time: 0.00015370079578833396 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 29  97.9% | batch:        92 of        94\t|\tloss: 2121.28\n",
      "Training Epoch 29  98.9% | batch:        93 of        94\t|\tloss: 3068.92\n",
      "\n",
      "Training Epoch 30   0.0% | batch:         0 of        94\t|\tloss: 1167.5\n",
      "Training Epoch 30   1.1% | batch:         1 of        94\t|\tloss: 2320.48\n",
      "Training Epoch 30   2.1% | batch:         2 of        94\t|\tloss: 1527.13\n",
      "Training Epoch 30   3.2% | batch:         3 of        94\t|\tloss: 1471.34\n",
      "Training Epoch 30   4.3% | batch:         4 of        94\t|\tloss: 1159.76\n",
      "Training Epoch 30   5.3% | batch:         5 of        94\t|\tloss: 1922.31\n",
      "Training Epoch 30   6.4% | batch:         6 of        94\t|\tloss: 1313.46\n",
      "Training Epoch 30   7.4% | batch:         7 of        94\t|\tloss: 1486.22\n",
      "Training Epoch 30   8.5% | batch:         8 of        94\t|\tloss: 1189.43\n",
      "Training Epoch 30   9.6% | batch:         9 of        94\t|\tloss: 1532.58\n",
      "Training Epoch 30  10.6% | batch:        10 of        94\t|\tloss: 1607.67\n",
      "Training Epoch 30  11.7% | batch:        11 of        94\t|\tloss: 1604.83\n",
      "Training Epoch 30  12.8% | batch:        12 of        94\t|\tloss: 1212.62\n",
      "Training Epoch 30  13.8% | batch:        13 of        94\t|\tloss: 1812.46\n",
      "Training Epoch 30  14.9% | batch:        14 of        94\t|\tloss: 1401.82\n",
      "Training Epoch 30  16.0% | batch:        15 of        94\t|\tloss: 1508.17\n",
      "Training Epoch 30  17.0% | batch:        16 of        94\t|\tloss: 1615.31\n",
      "Training Epoch 30  18.1% | batch:        17 of        94\t|\tloss: 1986.26\n",
      "Training Epoch 30  19.1% | batch:        18 of        94\t|\tloss: 1884.62\n",
      "Training Epoch 30  20.2% | batch:        19 of        94\t|\tloss: 1652.37\n",
      "Training Epoch 30  21.3% | batch:        20 of        94\t|\tloss: 2246.41\n",
      "Training Epoch 30  22.3% | batch:        21 of        94\t|\tloss: 3104.43\n",
      "Training Epoch 30  23.4% | batch:        22 of        94\t|\tloss: 1124.64\n",
      "Training Epoch 30  24.5% | batch:        23 of        94\t|\tloss: 2056.72\n",
      "Training Epoch 30  25.5% | batch:        24 of        94\t|\tloss: 1083.19\n",
      "Training Epoch 30  26.6% | batch:        25 of        94\t|\tloss: 982.727\n",
      "Training Epoch 30  27.7% | batch:        26 of        94\t|\tloss: 805.943\n",
      "Training Epoch 30  28.7% | batch:        27 of        94\t|\tloss: 1488.55\n",
      "Training Epoch 30  29.8% | batch:        28 of        94\t|\tloss: 1676.9\n",
      "Training Epoch 30  30.9% | batch:        29 of        94\t|\tloss: 1836.4\n",
      "Training Epoch 30  31.9% | batch:        30 of        94\t|\tloss: 2359.2\n",
      "Training Epoch 30  33.0% | batch:        31 of        94\t|\tloss: 1375.66\n",
      "Training Epoch 30  34.0% | batch:        32 of        94\t|\tloss: 1577.48\n",
      "Training Epoch 30  35.1% | batch:        33 of        94\t|\tloss: 1120.39\n",
      "Training Epoch 30  36.2% | batch:        34 of        94\t|\tloss: 1044.07\n",
      "Training Epoch 30  37.2% | batch:        35 of        94\t|\tloss: 1210.69\n",
      "Training Epoch 30  38.3% | batch:        36 of        94\t|\tloss: 2266.55\n",
      "Training Epoch 30  39.4% | batch:        37 of        94\t|\tloss: 1410.75\n",
      "Training Epoch 30  40.4% | batch:        38 of        94\t|\tloss: 2439.61\n",
      "Training Epoch 30  41.5% | batch:        39 of        94\t|\tloss: 1649.58\n",
      "Training Epoch 30  42.6% | batch:        40 of        94\t|\tloss: 1269.93\n",
      "Training Epoch 30  43.6% | batch:        41 of        94\t|\tloss: 953.207\n",
      "Training Epoch 30  44.7% | batch:        42 of        94\t|\tloss: 1846.81\n",
      "Training Epoch 30  45.7% | batch:        43 of        94\t|\tloss: 1456.4\n",
      "Training Epoch 30  46.8% | batch:        44 of        94\t|\tloss: 1140.64\n",
      "Training Epoch 30  47.9% | batch:        45 of        94\t|\tloss: 1276.71\n",
      "Training Epoch 30  48.9% | batch:        46 of        94\t|\tloss: 2047.84\n",
      "Training Epoch 30  50.0% | batch:        47 of        94\t|\tloss: 1949.07\n",
      "Training Epoch 30  51.1% | batch:        48 of        94\t|\tloss: 1761.06\n",
      "Training Epoch 30  52.1% | batch:        49 of        94\t|\tloss: 1587.84\n",
      "Training Epoch 30  53.2% | batch:        50 of        94\t|\tloss: 1495.14\n",
      "Training Epoch 30  54.3% | batch:        51 of        94\t|\tloss: 1379.27\n",
      "Training Epoch 30  55.3% | batch:        52 of        94\t|\tloss: 1838.27\n",
      "Training Epoch 30  56.4% | batch:        53 of        94\t|\tloss: 1114.89\n",
      "Training Epoch 30  57.4% | batch:        54 of        94\t|\tloss: 1332.07\n",
      "Training Epoch 30  58.5% | batch:        55 of        94\t|\tloss: 1278.9\n",
      "Training Epoch 30  59.6% | batch:        56 of        94\t|\tloss: 1352.83\n",
      "Training Epoch 30  60.6% | batch:        57 of        94\t|\tloss: 886.708\n",
      "Training Epoch 30  61.7% | batch:        58 of        94\t|\tloss: 1413.73\n",
      "Training Epoch 30  62.8% | batch:        59 of        94\t|\tloss: 1279.99\n",
      "Training Epoch 30  63.8% | batch:        60 of        94\t|\tloss: 1305.25\n",
      "Training Epoch 30  64.9% | batch:        61 of        94\t|\tloss: 1261.96\n",
      "Training Epoch 30  66.0% | batch:        62 of        94\t|\tloss: 1245.57\n",
      "Training Epoch 30  67.0% | batch:        63 of        94\t|\tloss: 1211.41\n",
      "Training Epoch 30  68.1% | batch:        64 of        94\t|\tloss: 1272.29\n",
      "Training Epoch 30  69.1% | batch:        65 of        94\t|\tloss: 1305.13\n",
      "Training Epoch 30  70.2% | batch:        66 of        94\t|\tloss: 1397.73\n",
      "Training Epoch 30  71.3% | batch:        67 of        94\t|\tloss: 1485.3\n",
      "Training Epoch 30  72.3% | batch:        68 of        94\t|\tloss: 2929.69\n",
      "Training Epoch 30  73.4% | batch:        69 of        94\t|\tloss: 1398.27\n",
      "Training Epoch 30  74.5% | batch:        70 of        94\t|\tloss: 2318.22\n",
      "Training Epoch 30  75.5% | batch:        71 of        94\t|\tloss: 1872.35\n",
      "Training Epoch 30  76.6% | batch:        72 of        94\t|\tloss: 1268.84\n",
      "Training Epoch 30  77.7% | batch:        73 of        94\t|\tloss: 1645.13\n",
      "Training Epoch 30  78.7% | batch:        74 of        94\t|\tloss: 3493.14\n",
      "Training Epoch 30  79.8% | batch:        75 of        94\t|\tloss: 1635.77\n",
      "Training Epoch 30  80.9% | batch:        76 of        94\t|\tloss: 1523.2\n",
      "Training Epoch 30  81.9% | batch:        77 of        94\t|\tloss: 3123.26\n",
      "Training Epoch 30  83.0% | batch:        78 of        94\t|\tloss: 1175.66\n",
      "Training Epoch 30  84.0% | batch:        79 of        94\t|\tloss: 2214.87\n",
      "Training Epoch 30  85.1% | batch:        80 of        94\t|\tloss: 1491.9\n",
      "Training Epoch 30  86.2% | batch:        81 of        94\t|\tloss: 1527.7\n",
      "Training Epoch 30  87.2% | batch:        82 of        94\t|\tloss: 2038.54\n",
      "Training Epoch 30  88.3% | batch:        83 of        94\t|\tloss: 2042.16\n",
      "Training Epoch 30  89.4% | batch:        84 of        94\t|\tloss: 1366.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:19,868 | INFO : Epoch 30 Training Summary: epoch: 30.000000 | loss: 1631.098799 | \n",
      "2023-05-09 14:21:19,869 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8152692317962646 seconds\n",
      "\n",
      "2023-05-09 14:21:19,869 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8312548557917276 seconds\n",
      "2023-05-09 14:21:19,870 | INFO : Avg batch train. time: 0.01948143463608221 seconds\n",
      "2023-05-09 14:21:19,871 | INFO : Avg sample train. time: 0.00015365454403353982 seconds\n",
      "2023-05-09 14:21:19,871 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 30  90.4% | batch:        85 of        94\t|\tloss: 1324.47\n",
      "Training Epoch 30  91.5% | batch:        86 of        94\t|\tloss: 1378.77\n",
      "Training Epoch 30  92.6% | batch:        87 of        94\t|\tloss: 1525.12\n",
      "Training Epoch 30  93.6% | batch:        88 of        94\t|\tloss: 1063.61\n",
      "Training Epoch 30  94.7% | batch:        89 of        94\t|\tloss: 3949.88\n",
      "Training Epoch 30  95.7% | batch:        90 of        94\t|\tloss: 1495.98\n",
      "Training Epoch 30  96.8% | batch:        91 of        94\t|\tloss: 2631.91\n",
      "Training Epoch 30  97.9% | batch:        92 of        94\t|\tloss: 1399.05\n",
      "Training Epoch 30  98.9% | batch:        93 of        94\t|\tloss: 5981.15\n",
      "\n",
      "Evaluating Epoch 30   0.0% | batch:         0 of        40\t|\tloss: 5435.22\n",
      "Evaluating Epoch 30   2.5% | batch:         1 of        40\t|\tloss: 1116.4\n",
      "Evaluating Epoch 30   5.0% | batch:         2 of        40\t|\tloss: 2860.9\n",
      "Evaluating Epoch 30   7.5% | batch:         3 of        40\t|\tloss: 5970.54\n",
      "Evaluating Epoch 30  10.0% | batch:         4 of        40\t|\tloss: 2940.47\n",
      "Evaluating Epoch 30  12.5% | batch:         5 of        40\t|\tloss: 2332.7\n",
      "Evaluating Epoch 30  15.0% | batch:         6 of        40\t|\tloss: 7954.13\n",
      "Evaluating Epoch 30  17.5% | batch:         7 of        40\t|\tloss: 3211.32\n",
      "Evaluating Epoch 30  20.0% | batch:         8 of        40\t|\tloss: 3093.6\n",
      "Evaluating Epoch 30  22.5% | batch:         9 of        40\t|\tloss: 2455.77\n",
      "Evaluating Epoch 30  25.0% | batch:        10 of        40\t|\tloss: 4204.94\n",
      "Evaluating Epoch 30  27.5% | batch:        11 of        40\t|\tloss: 1244.53\n",
      "Evaluating Epoch 30  30.0% | batch:        12 of        40\t|\tloss: 6423.17\n",
      "Evaluating Epoch 30  32.5% | batch:        13 of        40\t|\tloss: 3003.02\n",
      "Evaluating Epoch 30  35.0% | batch:        14 of        40\t|\tloss: 1849.89\n",
      "Evaluating Epoch 30  37.5% | batch:        15 of        40\t|\tloss: 3570.41\n",
      "Evaluating Epoch 30  40.0% | batch:        16 of        40\t|\tloss: 3748.34\n",
      "Evaluating Epoch 30  42.5% | batch:        17 of        40\t|\tloss: 2520.6\n",
      "Evaluating Epoch 30  45.0% | batch:        18 of        40\t|\tloss: 2229.1\n",
      "Evaluating Epoch 30  47.5% | batch:        19 of        40\t|\tloss: 5497.57\n",
      "Evaluating Epoch 30  50.0% | batch:        20 of        40\t|\tloss: 5260.25\n",
      "Evaluating Epoch 30  52.5% | batch:        21 of        40\t|\tloss: 1149.22\n",
      "Evaluating Epoch 30  55.0% | batch:        22 of        40\t|\tloss: 3956.25\n",
      "Evaluating Epoch 30  57.5% | batch:        23 of        40\t|\tloss: 3250.42\n",
      "Evaluating Epoch 30  60.0% | batch:        24 of        40\t|\tloss: 1503.8\n",
      "Evaluating Epoch 30  62.5% | batch:        25 of        40\t|\tloss: 3377.73\n",
      "Evaluating Epoch 30  65.0% | batch:        26 of        40\t|\tloss: 8154.89\n",
      "Evaluating Epoch 30  67.5% | batch:        27 of        40\t|\tloss: 2556.96\n",
      "Evaluating Epoch 30  70.0% | batch:        28 of        40\t|\tloss: 1817.53\n",
      "Evaluating Epoch 30  72.5% | batch:        29 of        40\t|\tloss: 9820.67\n",
      "Evaluating Epoch 30  75.0% | batch:        30 of        40\t|\tloss: 1961.57\n",
      "Evaluating Epoch 30  77.5% | batch:        31 of        40\t|\tloss: 1521.32\n",
      "Evaluating Epoch 30  80.0% | batch:        32 of        40\t|\tloss: 7513.65\n",
      "Evaluating Epoch 30  82.5% | batch:        33 of        40\t|\tloss: 4977.74\n",
      "Evaluating Epoch 30  85.0% | batch:        34 of        40\t|\tloss: 1092.91\n",
      "Evaluating Epoch 30  87.5% | batch:        35 of        40\t|\tloss: 4715.28\n",
      "Evaluating Epoch 30  90.0% | batch:        36 of        40\t|\tloss: 4362.64\n",
      "Evaluating Epoch 30  92.5% | batch:        37 of        40\t|\tloss: 2452.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:20,330 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45896482467651367 seconds\n",
      "\n",
      "2023-05-09 14:21:20,331 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.49724440013661103 seconds\n",
      "2023-05-09 14:21:20,331 | INFO : Avg batch val. time: 0.012431110003415275 seconds\n",
      "2023-05-09 14:21:20,331 | INFO : Avg sample val. time: 9.850324883847287e-05 seconds\n",
      "2023-05-09 14:21:20,332 | INFO : Epoch 30 Validation Summary: epoch: 30.000000 | loss: 3791.511477 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 30  95.0% | batch:        38 of        40\t|\tloss: 3339.73\n",
      "Evaluating Epoch 30  97.5% | batch:        39 of        40\t|\tloss: 11611.7\n",
      "\n",
      "Training Epoch 31   0.0% | batch:         0 of        94\t|\tloss: 1215.68\n",
      "Training Epoch 31   1.1% | batch:         1 of        94\t|\tloss: 1073.35\n",
      "Training Epoch 31   2.1% | batch:         2 of        94\t|\tloss: 1983.3\n",
      "Training Epoch 31   3.2% | batch:         3 of        94\t|\tloss: 1226.15\n",
      "Training Epoch 31   4.3% | batch:         4 of        94\t|\tloss: 1022.29\n",
      "Training Epoch 31   5.3% | batch:         5 of        94\t|\tloss: 2083.91\n",
      "Training Epoch 31   6.4% | batch:         6 of        94\t|\tloss: 2385.54\n",
      "Training Epoch 31   7.4% | batch:         7 of        94\t|\tloss: 1156.21\n",
      "Training Epoch 31   8.5% | batch:         8 of        94\t|\tloss: 1158.12\n",
      "Training Epoch 31   9.6% | batch:         9 of        94\t|\tloss: 994.695\n",
      "Training Epoch 31  10.6% | batch:        10 of        94\t|\tloss: 1289.05\n",
      "Training Epoch 31  11.7% | batch:        11 of        94\t|\tloss: 1227.96\n",
      "Training Epoch 31  12.8% | batch:        12 of        94\t|\tloss: 1453.1\n",
      "Training Epoch 31  13.8% | batch:        13 of        94\t|\tloss: 1527.46\n",
      "Training Epoch 31  14.9% | batch:        14 of        94\t|\tloss: 976.956\n",
      "Training Epoch 31  16.0% | batch:        15 of        94\t|\tloss: 976.714\n",
      "Training Epoch 31  17.0% | batch:        16 of        94\t|\tloss: 1025.81\n",
      "Training Epoch 31  18.1% | batch:        17 of        94\t|\tloss: 3166.25\n",
      "Training Epoch 31  19.1% | batch:        18 of        94\t|\tloss: 1442.62\n",
      "Training Epoch 31  20.2% | batch:        19 of        94\t|\tloss: 2291.54\n",
      "Training Epoch 31  21.3% | batch:        20 of        94\t|\tloss: 1917.21\n",
      "Training Epoch 31  22.3% | batch:        21 of        94\t|\tloss: 1245.18\n",
      "Training Epoch 31  23.4% | batch:        22 of        94\t|\tloss: 2356.3\n",
      "Training Epoch 31  24.5% | batch:        23 of        94\t|\tloss: 978.21\n",
      "Training Epoch 31  25.5% | batch:        24 of        94\t|\tloss: 1592.23\n",
      "Training Epoch 31  26.6% | batch:        25 of        94\t|\tloss: 1630.7\n",
      "Training Epoch 31  27.7% | batch:        26 of        94\t|\tloss: 926.908\n",
      "Training Epoch 31  28.7% | batch:        27 of        94\t|\tloss: 1298.94\n",
      "Training Epoch 31  29.8% | batch:        28 of        94\t|\tloss: 1403.4\n",
      "Training Epoch 31  30.9% | batch:        29 of        94\t|\tloss: 1797.64\n",
      "Training Epoch 31  31.9% | batch:        30 of        94\t|\tloss: 1481.59\n",
      "Training Epoch 31  33.0% | batch:        31 of        94\t|\tloss: 1971.43\n",
      "Training Epoch 31  34.0% | batch:        32 of        94\t|\tloss: 2154.3\n",
      "Training Epoch 31  35.1% | batch:        33 of        94\t|\tloss: 1528\n",
      "Training Epoch 31  36.2% | batch:        34 of        94\t|\tloss: 2815.83\n",
      "Training Epoch 31  37.2% | batch:        35 of        94\t|\tloss: 1383.95\n",
      "Training Epoch 31  38.3% | batch:        36 of        94\t|\tloss: 2028.77\n",
      "Training Epoch 31  39.4% | batch:        37 of        94\t|\tloss: 1381.21\n",
      "Training Epoch 31  40.4% | batch:        38 of        94\t|\tloss: 1149.61\n",
      "Training Epoch 31  41.5% | batch:        39 of        94\t|\tloss: 3236.7\n",
      "Training Epoch 31  42.6% | batch:        40 of        94\t|\tloss: 1293.22\n",
      "Training Epoch 31  43.6% | batch:        41 of        94\t|\tloss: 2007.96\n",
      "Training Epoch 31  44.7% | batch:        42 of        94\t|\tloss: 2330.65\n",
      "Training Epoch 31  45.7% | batch:        43 of        94\t|\tloss: 1892.24\n",
      "Training Epoch 31  46.8% | batch:        44 of        94\t|\tloss: 2429.97\n",
      "Training Epoch 31  47.9% | batch:        45 of        94\t|\tloss: 1703.07\n",
      "Training Epoch 31  48.9% | batch:        46 of        94\t|\tloss: 1235.74\n",
      "Training Epoch 31  50.0% | batch:        47 of        94\t|\tloss: 1453.29\n",
      "Training Epoch 31  51.1% | batch:        48 of        94\t|\tloss: 956.708\n",
      "Training Epoch 31  52.1% | batch:        49 of        94\t|\tloss: 1231.65\n",
      "Training Epoch 31  53.2% | batch:        50 of        94\t|\tloss: 1719.08\n",
      "Training Epoch 31  54.3% | batch:        51 of        94\t|\tloss: 1359.39\n",
      "Training Epoch 31  55.3% | batch:        52 of        94\t|\tloss: 1473.03\n",
      "Training Epoch 31  56.4% | batch:        53 of        94\t|\tloss: 1222.67\n",
      "Training Epoch 31  57.4% | batch:        54 of        94\t|\tloss: 1270.25\n",
      "Training Epoch 31  58.5% | batch:        55 of        94\t|\tloss: 1676.05\n",
      "Training Epoch 31  59.6% | batch:        56 of        94\t|\tloss: 1851.53\n",
      "Training Epoch 31  60.6% | batch:        57 of        94\t|\tloss: 1472.06\n",
      "Training Epoch 31  61.7% | batch:        58 of        94\t|\tloss: 1932.8\n",
      "Training Epoch 31  62.8% | batch:        59 of        94\t|\tloss: 1006.74\n",
      "Training Epoch 31  63.8% | batch:        60 of        94\t|\tloss: 1626.81\n",
      "Training Epoch 31  64.9% | batch:        61 of        94\t|\tloss: 1066.82\n",
      "Training Epoch 31  66.0% | batch:        62 of        94\t|\tloss: 1905.99\n",
      "Training Epoch 31  67.0% | batch:        63 of        94\t|\tloss: 1461.95\n",
      "Training Epoch 31  68.1% | batch:        64 of        94\t|\tloss: 1703.89\n",
      "Training Epoch 31  69.1% | batch:        65 of        94\t|\tloss: 1230.46\n",
      "Training Epoch 31  70.2% | batch:        66 of        94\t|\tloss: 1199.8\n",
      "Training Epoch 31  71.3% | batch:        67 of        94\t|\tloss: 4128.42\n",
      "Training Epoch 31  72.3% | batch:        68 of        94\t|\tloss: 1191.28\n",
      "Training Epoch 31  73.4% | batch:        69 of        94\t|\tloss: 2296.57\n",
      "Training Epoch 31  74.5% | batch:        70 of        94\t|\tloss: 1406.6\n",
      "Training Epoch 31  75.5% | batch:        71 of        94\t|\tloss: 1120.57\n",
      "Training Epoch 31  76.6% | batch:        72 of        94\t|\tloss: 1297.8\n",
      "Training Epoch 31  77.7% | batch:        73 of        94\t|\tloss: 1673.59\n",
      "Training Epoch 31  78.7% | batch:        74 of        94\t|\tloss: 1747.29\n",
      "Training Epoch 31  79.8% | batch:        75 of        94\t|\tloss: 1853.25\n",
      "Training Epoch 31  80.9% | batch:        76 of        94\t|\tloss: 1863.59\n",
      "Training Epoch 31  81.9% | batch:        77 of        94\t|\tloss: 1699.42\n",
      "Training Epoch 31  83.0% | batch:        78 of        94\t|\tloss: 1182.71\n",
      "Training Epoch 31  84.0% | batch:        79 of        94\t|\tloss: 1965.68\n",
      "Training Epoch 31  85.1% | batch:        80 of        94\t|\tloss: 1372.71\n",
      "Training Epoch 31  86.2% | batch:        81 of        94\t|\tloss: 1934.24\n",
      "Training Epoch 31  87.2% | batch:        82 of        94\t|\tloss: 1188.56\n",
      "Training Epoch 31  88.3% | batch:        83 of        94\t|\tloss: 1269.78\n",
      "Training Epoch 31  89.4% | batch:        84 of        94\t|\tloss: 2138.89\n",
      "Training Epoch 31  90.4% | batch:        85 of        94\t|\tloss: 1542.01\n",
      "Training Epoch 31  91.5% | batch:        86 of        94\t|\tloss: 3724.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:22,209 | INFO : Epoch 31 Training Summary: epoch: 31.000000 | loss: 1643.868917 | \n",
      "2023-05-09 14:21:22,210 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8564095497131348 seconds\n",
      "\n",
      "2023-05-09 14:21:22,211 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.832066297531128 seconds\n",
      "2023-05-09 14:21:22,211 | INFO : Avg batch train. time: 0.019490066995012 seconds\n",
      "2023-05-09 14:21:22,212 | INFO : Avg sample train. time: 0.00015372262942869004 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 31  92.6% | batch:        87 of        94\t|\tloss: 1910.2\n",
      "Training Epoch 31  93.6% | batch:        88 of        94\t|\tloss: 3241.65\n",
      "Training Epoch 31  94.7% | batch:        89 of        94\t|\tloss: 1055.47\n",
      "Training Epoch 31  95.7% | batch:        90 of        94\t|\tloss: 1306.23\n",
      "Training Epoch 31  96.8% | batch:        91 of        94\t|\tloss: 1741.63\n",
      "Training Epoch 31  97.9% | batch:        92 of        94\t|\tloss: 1361.97\n",
      "Training Epoch 31  98.9% | batch:        93 of        94\t|\tloss: 1609.28\n",
      "\n",
      "Training Epoch 32   0.0% | batch:         0 of        94\t|\tloss: 1427.66\n",
      "Training Epoch 32   1.1% | batch:         1 of        94\t|\tloss: 1433.97\n",
      "Training Epoch 32   2.1% | batch:         2 of        94\t|\tloss: 1010.65\n",
      "Training Epoch 32   3.2% | batch:         3 of        94\t|\tloss: 2519.21\n",
      "Training Epoch 32   4.3% | batch:         4 of        94\t|\tloss: 1100.32\n",
      "Training Epoch 32   5.3% | batch:         5 of        94\t|\tloss: 1793.56\n",
      "Training Epoch 32   6.4% | batch:         6 of        94\t|\tloss: 1599.18\n",
      "Training Epoch 32   7.4% | batch:         7 of        94\t|\tloss: 859.844\n",
      "Training Epoch 32   8.5% | batch:         8 of        94\t|\tloss: 1004.18\n",
      "Training Epoch 32   9.6% | batch:         9 of        94\t|\tloss: 3733.05\n",
      "Training Epoch 32  10.6% | batch:        10 of        94\t|\tloss: 1111.97\n",
      "Training Epoch 32  11.7% | batch:        11 of        94\t|\tloss: 1353.21\n",
      "Training Epoch 32  12.8% | batch:        12 of        94\t|\tloss: 986.933\n",
      "Training Epoch 32  13.8% | batch:        13 of        94\t|\tloss: 2124.94\n",
      "Training Epoch 32  14.9% | batch:        14 of        94\t|\tloss: 1489.11\n",
      "Training Epoch 32  16.0% | batch:        15 of        94\t|\tloss: 1511.75\n",
      "Training Epoch 32  17.0% | batch:        16 of        94\t|\tloss: 1701.84\n",
      "Training Epoch 32  18.1% | batch:        17 of        94\t|\tloss: 1475.18\n",
      "Training Epoch 32  19.1% | batch:        18 of        94\t|\tloss: 1695.93\n",
      "Training Epoch 32  20.2% | batch:        19 of        94\t|\tloss: 1305.37\n",
      "Training Epoch 32  21.3% | batch:        20 of        94\t|\tloss: 862.748\n",
      "Training Epoch 32  22.3% | batch:        21 of        94\t|\tloss: 2907.54\n",
      "Training Epoch 32  23.4% | batch:        22 of        94\t|\tloss: 1200.69\n",
      "Training Epoch 32  24.5% | batch:        23 of        94\t|\tloss: 915.231\n",
      "Training Epoch 32  25.5% | batch:        24 of        94\t|\tloss: 1250.39\n",
      "Training Epoch 32  26.6% | batch:        25 of        94\t|\tloss: 1355.31\n",
      "Training Epoch 32  27.7% | batch:        26 of        94\t|\tloss: 966.526\n",
      "Training Epoch 32  28.7% | batch:        27 of        94\t|\tloss: 1174.83\n",
      "Training Epoch 32  29.8% | batch:        28 of        94\t|\tloss: 944.315\n",
      "Training Epoch 32  30.9% | batch:        29 of        94\t|\tloss: 817.571\n",
      "Training Epoch 32  31.9% | batch:        30 of        94\t|\tloss: 1449.27\n",
      "Training Epoch 32  33.0% | batch:        31 of        94\t|\tloss: 1508.8\n",
      "Training Epoch 32  34.0% | batch:        32 of        94\t|\tloss: 1574.55\n",
      "Training Epoch 32  35.1% | batch:        33 of        94\t|\tloss: 1648.21\n",
      "Training Epoch 32  36.2% | batch:        34 of        94\t|\tloss: 1391.84\n",
      "Training Epoch 32  37.2% | batch:        35 of        94\t|\tloss: 1460.53\n",
      "Training Epoch 32  38.3% | batch:        36 of        94\t|\tloss: 1659.38\n",
      "Training Epoch 32  39.4% | batch:        37 of        94\t|\tloss: 1137.94\n",
      "Training Epoch 32  40.4% | batch:        38 of        94\t|\tloss: 2948.52\n",
      "Training Epoch 32  41.5% | batch:        39 of        94\t|\tloss: 1716.02\n",
      "Training Epoch 32  42.6% | batch:        40 of        94\t|\tloss: 2120.08\n",
      "Training Epoch 32  43.6% | batch:        41 of        94\t|\tloss: 1096.64\n",
      "Training Epoch 32  44.7% | batch:        42 of        94\t|\tloss: 1796.33\n",
      "Training Epoch 32  45.7% | batch:        43 of        94\t|\tloss: 1454.42\n",
      "Training Epoch 32  46.8% | batch:        44 of        94\t|\tloss: 1215.54\n",
      "Training Epoch 32  47.9% | batch:        45 of        94\t|\tloss: 980.77\n",
      "Training Epoch 32  48.9% | batch:        46 of        94\t|\tloss: 1362.59\n",
      "Training Epoch 32  50.0% | batch:        47 of        94\t|\tloss: 1713.04\n",
      "Training Epoch 32  51.1% | batch:        48 of        94\t|\tloss: 1398.47\n",
      "Training Epoch 32  52.1% | batch:        49 of        94\t|\tloss: 2305.05\n",
      "Training Epoch 32  53.2% | batch:        50 of        94\t|\tloss: 1182.38\n",
      "Training Epoch 32  54.3% | batch:        51 of        94\t|\tloss: 1776.09\n",
      "Training Epoch 32  55.3% | batch:        52 of        94\t|\tloss: 1533.35\n",
      "Training Epoch 32  56.4% | batch:        53 of        94\t|\tloss: 2091.58\n",
      "Training Epoch 32  57.4% | batch:        54 of        94\t|\tloss: 1069.27\n",
      "Training Epoch 32  58.5% | batch:        55 of        94\t|\tloss: 1332.25\n",
      "Training Epoch 32  59.6% | batch:        56 of        94\t|\tloss: 3543.42\n",
      "Training Epoch 32  60.6% | batch:        57 of        94\t|\tloss: 1856.03\n",
      "Training Epoch 32  61.7% | batch:        58 of        94\t|\tloss: 1399\n",
      "Training Epoch 32  62.8% | batch:        59 of        94\t|\tloss: 1630.02\n",
      "Training Epoch 32  63.8% | batch:        60 of        94\t|\tloss: 1137.51\n",
      "Training Epoch 32  64.9% | batch:        61 of        94\t|\tloss: 1314.21\n",
      "Training Epoch 32  66.0% | batch:        62 of        94\t|\tloss: 1465.4\n",
      "Training Epoch 32  67.0% | batch:        63 of        94\t|\tloss: 1085.88\n",
      "Training Epoch 32  68.1% | batch:        64 of        94\t|\tloss: 2216.48\n",
      "Training Epoch 32  69.1% | batch:        65 of        94\t|\tloss: 1581.64\n",
      "Training Epoch 32  70.2% | batch:        66 of        94\t|\tloss: 1598.71\n",
      "Training Epoch 32  71.3% | batch:        67 of        94\t|\tloss: 1554.58\n",
      "Training Epoch 32  72.3% | batch:        68 of        94\t|\tloss: 1036.11\n",
      "Training Epoch 32  73.4% | batch:        69 of        94\t|\tloss: 2166.33\n",
      "Training Epoch 32  74.5% | batch:        70 of        94\t|\tloss: 1255.7\n",
      "Training Epoch 32  75.5% | batch:        71 of        94\t|\tloss: 1157.13\n",
      "Training Epoch 32  76.6% | batch:        72 of        94\t|\tloss: 1037.24\n",
      "Training Epoch 32  77.7% | batch:        73 of        94\t|\tloss: 1055.38\n",
      "Training Epoch 32  78.7% | batch:        74 of        94\t|\tloss: 2101.61\n",
      "Training Epoch 32  79.8% | batch:        75 of        94\t|\tloss: 1598.16\n",
      "Training Epoch 32  80.9% | batch:        76 of        94\t|\tloss: 1494.85\n",
      "Training Epoch 32  81.9% | batch:        77 of        94\t|\tloss: 1274.57\n",
      "Training Epoch 32  83.0% | batch:        78 of        94\t|\tloss: 1250.54\n",
      "Training Epoch 32  84.0% | batch:        79 of        94\t|\tloss: 1124.33\n",
      "Training Epoch 32  85.1% | batch:        80 of        94\t|\tloss: 1452.5\n",
      "Training Epoch 32  86.2% | batch:        81 of        94\t|\tloss: 2101.41\n",
      "Training Epoch 32  87.2% | batch:        82 of        94\t|\tloss: 1189.51\n",
      "Training Epoch 32  88.3% | batch:        83 of        94\t|\tloss: 1006.88\n",
      "Training Epoch 32  89.4% | batch:        84 of        94\t|\tloss: 1542.74\n",
      "Training Epoch 32  90.4% | batch:        85 of        94\t|\tloss: 1178.87\n",
      "Training Epoch 32  91.5% | batch:        86 of        94\t|\tloss: 1872.48\n",
      "Training Epoch 32  92.6% | batch:        87 of        94\t|\tloss: 1554.23\n",
      "Training Epoch 32  93.6% | batch:        88 of        94\t|\tloss: 1987.63\n",
      "Training Epoch 32  94.7% | batch:        89 of        94\t|\tloss: 1617\n",
      "Training Epoch 32  95.7% | batch:        90 of        94\t|\tloss: 1770.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:24,074 | INFO : Epoch 32 Training Summary: epoch: 32.000000 | loss: 1526.448097 | \n",
      "2023-05-09 14:21:24,075 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.841855764389038 seconds\n",
      "\n",
      "2023-05-09 14:21:24,075 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8323722183704376 seconds\n",
      "2023-05-09 14:21:24,076 | INFO : Avg batch train. time: 0.019493321472025933 seconds\n",
      "2023-05-09 14:21:24,076 | INFO : Avg sample train. time: 0.00015374829823547892 seconds\n",
      "2023-05-09 14:21:24,077 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 32  96.8% | batch:        91 of        94\t|\tloss: 1808.1\n",
      "Training Epoch 32  97.9% | batch:        92 of        94\t|\tloss: 1438.42\n",
      "Training Epoch 32  98.9% | batch:        93 of        94\t|\tloss: 1056.36\n",
      "\n",
      "Evaluating Epoch 32   0.0% | batch:         0 of        40\t|\tloss: 6552.03\n",
      "Evaluating Epoch 32   2.5% | batch:         1 of        40\t|\tloss: 1048.06\n",
      "Evaluating Epoch 32   5.0% | batch:         2 of        40\t|\tloss: 3111.46\n",
      "Evaluating Epoch 32   7.5% | batch:         3 of        40\t|\tloss: 6490.85\n",
      "Evaluating Epoch 32  10.0% | batch:         4 of        40\t|\tloss: 2142.8\n",
      "Evaluating Epoch 32  12.5% | batch:         5 of        40\t|\tloss: 2009.85\n",
      "Evaluating Epoch 32  15.0% | batch:         6 of        40\t|\tloss: 8474.92\n",
      "Evaluating Epoch 32  17.5% | batch:         7 of        40\t|\tloss: 3250.89\n",
      "Evaluating Epoch 32  20.0% | batch:         8 of        40\t|\tloss: 2521.44\n",
      "Evaluating Epoch 32  22.5% | batch:         9 of        40\t|\tloss: 1707.08\n",
      "Evaluating Epoch 32  25.0% | batch:        10 of        40\t|\tloss: 4939.5\n",
      "Evaluating Epoch 32  27.5% | batch:        11 of        40\t|\tloss: 1571.73\n",
      "Evaluating Epoch 32  30.0% | batch:        12 of        40\t|\tloss: 5690.71\n",
      "Evaluating Epoch 32  32.5% | batch:        13 of        40\t|\tloss: 3416.99\n",
      "Evaluating Epoch 32  35.0% | batch:        14 of        40\t|\tloss: 2327.85\n",
      "Evaluating Epoch 32  37.5% | batch:        15 of        40\t|\tloss: 3049.29\n",
      "Evaluating Epoch 32  40.0% | batch:        16 of        40\t|\tloss: 4235.55\n",
      "Evaluating Epoch 32  42.5% | batch:        17 of        40\t|\tloss: 3233.03\n",
      "Evaluating Epoch 32  45.0% | batch:        18 of        40\t|\tloss: 2101.69\n",
      "Evaluating Epoch 32  47.5% | batch:        19 of        40\t|\tloss: 6050.97\n",
      "Evaluating Epoch 32  50.0% | batch:        20 of        40\t|\tloss: 5374.28\n",
      "Evaluating Epoch 32  52.5% | batch:        21 of        40\t|\tloss: 944.334\n",
      "Evaluating Epoch 32  55.0% | batch:        22 of        40\t|\tloss: 3564.39\n",
      "Evaluating Epoch 32  57.5% | batch:        23 of        40\t|\tloss: 3264.8\n",
      "Evaluating Epoch 32  60.0% | batch:        24 of        40\t|\tloss: 1601.8\n",
      "Evaluating Epoch 32  62.5% | batch:        25 of        40\t|\tloss: 3179.44\n",
      "Evaluating Epoch 32  65.0% | batch:        26 of        40\t|\tloss: 10491.2\n",
      "Evaluating Epoch 32  67.5% | batch:        27 of        40\t|\tloss: 2960.19\n",
      "Evaluating Epoch 32  70.0% | batch:        28 of        40\t|\tloss: 1855.74\n",
      "Evaluating Epoch 32  72.5% | batch:        29 of        40\t|\tloss: 8990.49\n",
      "Evaluating Epoch 32  75.0% | batch:        30 of        40\t|\tloss: 2020.13\n",
      "Evaluating Epoch 32  77.5% | batch:        31 of        40\t|\tloss: 1804.81\n",
      "Evaluating Epoch 32  80.0% | batch:        32 of        40\t|\tloss: 6541.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:24,533 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45612597465515137 seconds\n",
      "\n",
      "2023-05-09 14:21:24,533 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.49496004316541886 seconds\n",
      "2023-05-09 14:21:24,534 | INFO : Avg batch val. time: 0.012374001079135472 seconds\n",
      "2023-05-09 14:21:24,534 | INFO : Avg sample val. time: 9.805072170471847e-05 seconds\n",
      "2023-05-09 14:21:24,535 | INFO : Epoch 32 Validation Summary: epoch: 32.000000 | loss: 3973.292915 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 32  82.5% | batch:        33 of        40\t|\tloss: 6654.84\n",
      "Evaluating Epoch 32  85.0% | batch:        34 of        40\t|\tloss: 1175.18\n",
      "Evaluating Epoch 32  87.5% | batch:        35 of        40\t|\tloss: 4875.43\n",
      "Evaluating Epoch 32  90.0% | batch:        36 of        40\t|\tloss: 6240.18\n",
      "Evaluating Epoch 32  92.5% | batch:        37 of        40\t|\tloss: 2725.85\n",
      "Evaluating Epoch 32  95.0% | batch:        38 of        40\t|\tloss: 3313.17\n",
      "Evaluating Epoch 32  97.5% | batch:        39 of        40\t|\tloss: 11868.4\n",
      "\n",
      "Training Epoch 33   0.0% | batch:         0 of        94\t|\tloss: 1444.65\n",
      "Training Epoch 33   1.1% | batch:         1 of        94\t|\tloss: 1052.97\n",
      "Training Epoch 33   2.1% | batch:         2 of        94\t|\tloss: 1631.8\n",
      "Training Epoch 33   3.2% | batch:         3 of        94\t|\tloss: 1891.37\n",
      "Training Epoch 33   4.3% | batch:         4 of        94\t|\tloss: 1868.03\n",
      "Training Epoch 33   5.3% | batch:         5 of        94\t|\tloss: 2175.72\n",
      "Training Epoch 33   6.4% | batch:         6 of        94\t|\tloss: 847.874\n",
      "Training Epoch 33   7.4% | batch:         7 of        94\t|\tloss: 1053.45\n",
      "Training Epoch 33   8.5% | batch:         8 of        94\t|\tloss: 1329.51\n",
      "Training Epoch 33   9.6% | batch:         9 of        94\t|\tloss: 1070.36\n",
      "Training Epoch 33  10.6% | batch:        10 of        94\t|\tloss: 1575.99\n",
      "Training Epoch 33  11.7% | batch:        11 of        94\t|\tloss: 1485.34\n",
      "Training Epoch 33  12.8% | batch:        12 of        94\t|\tloss: 1604.34\n",
      "Training Epoch 33  13.8% | batch:        13 of        94\t|\tloss: 1367.6\n",
      "Training Epoch 33  14.9% | batch:        14 of        94\t|\tloss: 2437.45\n",
      "Training Epoch 33  16.0% | batch:        15 of        94\t|\tloss: 1110.68\n",
      "Training Epoch 33  17.0% | batch:        16 of        94\t|\tloss: 2069.48\n",
      "Training Epoch 33  18.1% | batch:        17 of        94\t|\tloss: 1117.95\n",
      "Training Epoch 33  19.1% | batch:        18 of        94\t|\tloss: 1491.48\n",
      "Training Epoch 33  20.2% | batch:        19 of        94\t|\tloss: 1505.87\n",
      "Training Epoch 33  21.3% | batch:        20 of        94\t|\tloss: 883.318\n",
      "Training Epoch 33  22.3% | batch:        21 of        94\t|\tloss: 1403.87\n",
      "Training Epoch 33  23.4% | batch:        22 of        94\t|\tloss: 1588.19\n",
      "Training Epoch 33  24.5% | batch:        23 of        94\t|\tloss: 1332.38\n",
      "Training Epoch 33  25.5% | batch:        24 of        94\t|\tloss: 912.384\n",
      "Training Epoch 33  26.6% | batch:        25 of        94\t|\tloss: 3337.17\n",
      "Training Epoch 33  27.7% | batch:        26 of        94\t|\tloss: 1162.72\n",
      "Training Epoch 33  28.7% | batch:        27 of        94\t|\tloss: 1404.72\n",
      "Training Epoch 33  29.8% | batch:        28 of        94\t|\tloss: 1309.69\n",
      "Training Epoch 33  30.9% | batch:        29 of        94\t|\tloss: 1425.85\n",
      "Training Epoch 33  31.9% | batch:        30 of        94\t|\tloss: 2093.85\n",
      "Training Epoch 33  33.0% | batch:        31 of        94\t|\tloss: 969.714\n",
      "Training Epoch 33  34.0% | batch:        32 of        94\t|\tloss: 1400.31\n",
      "Training Epoch 33  35.1% | batch:        33 of        94\t|\tloss: 1899.51\n",
      "Training Epoch 33  36.2% | batch:        34 of        94\t|\tloss: 1280.57\n",
      "Training Epoch 33  37.2% | batch:        35 of        94\t|\tloss: 1769\n",
      "Training Epoch 33  38.3% | batch:        36 of        94\t|\tloss: 1621.49\n",
      "Training Epoch 33  39.4% | batch:        37 of        94\t|\tloss: 935.14\n",
      "Training Epoch 33  40.4% | batch:        38 of        94\t|\tloss: 2725.65\n",
      "Training Epoch 33  41.5% | batch:        39 of        94\t|\tloss: 1452.95\n",
      "Training Epoch 33  42.6% | batch:        40 of        94\t|\tloss: 1616.61\n",
      "Training Epoch 33  43.6% | batch:        41 of        94\t|\tloss: 1191.42\n",
      "Training Epoch 33  44.7% | batch:        42 of        94\t|\tloss: 1315.74\n",
      "Training Epoch 33  45.7% | batch:        43 of        94\t|\tloss: 1611.81\n",
      "Training Epoch 33  46.8% | batch:        44 of        94\t|\tloss: 2069.78\n",
      "Training Epoch 33  47.9% | batch:        45 of        94\t|\tloss: 2421.73\n",
      "Training Epoch 33  48.9% | batch:        46 of        94\t|\tloss: 1483.14\n",
      "Training Epoch 33  50.0% | batch:        47 of        94\t|\tloss: 1252.16\n",
      "Training Epoch 33  51.1% | batch:        48 of        94\t|\tloss: 891.174\n",
      "Training Epoch 33  52.1% | batch:        49 of        94\t|\tloss: 2355.72\n",
      "Training Epoch 33  53.2% | batch:        50 of        94\t|\tloss: 1104.21\n",
      "Training Epoch 33  54.3% | batch:        51 of        94\t|\tloss: 1446.79\n",
      "Training Epoch 33  55.3% | batch:        52 of        94\t|\tloss: 1111.73\n",
      "Training Epoch 33  56.4% | batch:        53 of        94\t|\tloss: 1220.72\n",
      "Training Epoch 33  57.4% | batch:        54 of        94\t|\tloss: 1901.42\n",
      "Training Epoch 33  58.5% | batch:        55 of        94\t|\tloss: 1525.18\n",
      "Training Epoch 33  59.6% | batch:        56 of        94\t|\tloss: 1243.5\n",
      "Training Epoch 33  60.6% | batch:        57 of        94\t|\tloss: 1457.16\n",
      "Training Epoch 33  61.7% | batch:        58 of        94\t|\tloss: 1656.4\n",
      "Training Epoch 33  62.8% | batch:        59 of        94\t|\tloss: 2550.53\n",
      "Training Epoch 33  63.8% | batch:        60 of        94\t|\tloss: 998.805\n",
      "Training Epoch 33  64.9% | batch:        61 of        94\t|\tloss: 2296.82\n",
      "Training Epoch 33  66.0% | batch:        62 of        94\t|\tloss: 1391.33\n",
      "Training Epoch 33  67.0% | batch:        63 of        94\t|\tloss: 841.333\n",
      "Training Epoch 33  68.1% | batch:        64 of        94\t|\tloss: 1587.04\n",
      "Training Epoch 33  69.1% | batch:        65 of        94\t|\tloss: 1250.73\n",
      "Training Epoch 33  70.2% | batch:        66 of        94\t|\tloss: 1513.05\n",
      "Training Epoch 33  71.3% | batch:        67 of        94\t|\tloss: 1604.91\n",
      "Training Epoch 33  72.3% | batch:        68 of        94\t|\tloss: 2136.89\n",
      "Training Epoch 33  73.4% | batch:        69 of        94\t|\tloss: 3744.58\n",
      "Training Epoch 33  74.5% | batch:        70 of        94\t|\tloss: 3351.52\n",
      "Training Epoch 33  75.5% | batch:        71 of        94\t|\tloss: 2883.76\n",
      "Training Epoch 33  76.6% | batch:        72 of        94\t|\tloss: 1832.04\n",
      "Training Epoch 33  77.7% | batch:        73 of        94\t|\tloss: 1494.48\n",
      "Training Epoch 33  78.7% | batch:        74 of        94\t|\tloss: 1447.36\n",
      "Training Epoch 33  79.8% | batch:        75 of        94\t|\tloss: 1793.22\n",
      "Training Epoch 33  80.9% | batch:        76 of        94\t|\tloss: 873.147\n",
      "Training Epoch 33  81.9% | batch:        77 of        94\t|\tloss: 1197.3\n",
      "Training Epoch 33  83.0% | batch:        78 of        94\t|\tloss: 1274.4\n",
      "Training Epoch 33  84.0% | batch:        79 of        94\t|\tloss: 2182.08\n",
      "Training Epoch 33  85.1% | batch:        80 of        94\t|\tloss: 1384.91\n",
      "Training Epoch 33  86.2% | batch:        81 of        94\t|\tloss: 1948.98\n",
      "Training Epoch 33  87.2% | batch:        82 of        94\t|\tloss: 1675.54\n",
      "Training Epoch 33  88.3% | batch:        83 of        94\t|\tloss: 1229.71\n",
      "Training Epoch 33  89.4% | batch:        84 of        94\t|\tloss: 2599.79\n",
      "Training Epoch 33  90.4% | batch:        85 of        94\t|\tloss: 1806.1\n",
      "Training Epoch 33  91.5% | batch:        86 of        94\t|\tloss: 1976.3\n",
      "Training Epoch 33  92.6% | batch:        87 of        94\t|\tloss: 1153.29\n",
      "Training Epoch 33  93.6% | batch:        88 of        94\t|\tloss: 3018.59\n",
      "Training Epoch 33  94.7% | batch:        89 of        94\t|\tloss: 1146.3\n",
      "Training Epoch 33  95.7% | batch:        90 of        94\t|\tloss: 1166.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:26,369 | INFO : Epoch 33 Training Summary: epoch: 33.000000 | loss: 1628.049081 | \n",
      "2023-05-09 14:21:26,370 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8133912086486816 seconds\n",
      "\n",
      "2023-05-09 14:21:26,370 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8317970362576572 seconds\n",
      "2023-05-09 14:21:26,371 | INFO : Avg batch train. time: 0.01948720251337933 seconds\n",
      "2023-05-09 14:21:26,371 | INFO : Avg sample train. time: 0.0001537000366049385 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 33  96.8% | batch:        91 of        94\t|\tloss: 1613.29\n",
      "Training Epoch 33  97.9% | batch:        92 of        94\t|\tloss: 2375.41\n",
      "Training Epoch 33  98.9% | batch:        93 of        94\t|\tloss: 3017.48\n",
      "\n",
      "Training Epoch 34   0.0% | batch:         0 of        94\t|\tloss: 955.756\n",
      "Training Epoch 34   1.1% | batch:         1 of        94\t|\tloss: 2142.04\n",
      "Training Epoch 34   2.1% | batch:         2 of        94\t|\tloss: 1416.75\n",
      "Training Epoch 34   3.2% | batch:         3 of        94\t|\tloss: 1353\n",
      "Training Epoch 34   4.3% | batch:         4 of        94\t|\tloss: 1366.69\n",
      "Training Epoch 34   5.3% | batch:         5 of        94\t|\tloss: 3363.2\n",
      "Training Epoch 34   6.4% | batch:         6 of        94\t|\tloss: 1813.03\n",
      "Training Epoch 34   7.4% | batch:         7 of        94\t|\tloss: 1181.91\n",
      "Training Epoch 34   8.5% | batch:         8 of        94\t|\tloss: 2317.75\n",
      "Training Epoch 34   9.6% | batch:         9 of        94\t|\tloss: 1104.91\n",
      "Training Epoch 34  10.6% | batch:        10 of        94\t|\tloss: 3390.89\n",
      "Training Epoch 34  11.7% | batch:        11 of        94\t|\tloss: 1325.26\n",
      "Training Epoch 34  12.8% | batch:        12 of        94\t|\tloss: 1270.84\n",
      "Training Epoch 34  13.8% | batch:        13 of        94\t|\tloss: 1976.96\n",
      "Training Epoch 34  14.9% | batch:        14 of        94\t|\tloss: 1416.93\n",
      "Training Epoch 34  16.0% | batch:        15 of        94\t|\tloss: 1594.8\n",
      "Training Epoch 34  17.0% | batch:        16 of        94\t|\tloss: 2441.55\n",
      "Training Epoch 34  18.1% | batch:        17 of        94\t|\tloss: 918.242\n",
      "Training Epoch 34  19.1% | batch:        18 of        94\t|\tloss: 2025.13\n",
      "Training Epoch 34  20.2% | batch:        19 of        94\t|\tloss: 1178.72\n",
      "Training Epoch 34  21.3% | batch:        20 of        94\t|\tloss: 4247.48\n",
      "Training Epoch 34  22.3% | batch:        21 of        94\t|\tloss: 1913.62\n",
      "Training Epoch 34  23.4% | batch:        22 of        94\t|\tloss: 1041.97\n",
      "Training Epoch 34  24.5% | batch:        23 of        94\t|\tloss: 1849.4\n",
      "Training Epoch 34  25.5% | batch:        24 of        94\t|\tloss: 1358.79\n",
      "Training Epoch 34  26.6% | batch:        25 of        94\t|\tloss: 1206.66\n",
      "Training Epoch 34  27.7% | batch:        26 of        94\t|\tloss: 1332.98\n",
      "Training Epoch 34  28.7% | batch:        27 of        94\t|\tloss: 2164.68\n",
      "Training Epoch 34  29.8% | batch:        28 of        94\t|\tloss: 1865.13\n",
      "Training Epoch 34  30.9% | batch:        29 of        94\t|\tloss: 1378.81\n",
      "Training Epoch 34  31.9% | batch:        30 of        94\t|\tloss: 1407.62\n",
      "Training Epoch 34  33.0% | batch:        31 of        94\t|\tloss: 1806.43\n",
      "Training Epoch 34  34.0% | batch:        32 of        94\t|\tloss: 1354.46\n",
      "Training Epoch 34  35.1% | batch:        33 of        94\t|\tloss: 947.222\n",
      "Training Epoch 34  36.2% | batch:        34 of        94\t|\tloss: 1176.77\n",
      "Training Epoch 34  37.2% | batch:        35 of        94\t|\tloss: 1525.99\n",
      "Training Epoch 34  38.3% | batch:        36 of        94\t|\tloss: 989.195\n",
      "Training Epoch 34  39.4% | batch:        37 of        94\t|\tloss: 1335.9\n",
      "Training Epoch 34  40.4% | batch:        38 of        94\t|\tloss: 1216.63\n",
      "Training Epoch 34  41.5% | batch:        39 of        94\t|\tloss: 1509.35\n",
      "Training Epoch 34  42.6% | batch:        40 of        94\t|\tloss: 1573.78\n",
      "Training Epoch 34  43.6% | batch:        41 of        94\t|\tloss: 1739.5\n",
      "Training Epoch 34  44.7% | batch:        42 of        94\t|\tloss: 1802.99\n",
      "Training Epoch 34  45.7% | batch:        43 of        94\t|\tloss: 1474.13\n",
      "Training Epoch 34  46.8% | batch:        44 of        94\t|\tloss: 1334.48\n",
      "Training Epoch 34  47.9% | batch:        45 of        94\t|\tloss: 1785.44\n",
      "Training Epoch 34  48.9% | batch:        46 of        94\t|\tloss: 976.677\n",
      "Training Epoch 34  50.0% | batch:        47 of        94\t|\tloss: 2890.71\n",
      "Training Epoch 34  51.1% | batch:        48 of        94\t|\tloss: 2802.94\n",
      "Training Epoch 34  52.1% | batch:        49 of        94\t|\tloss: 1755.22\n",
      "Training Epoch 34  53.2% | batch:        50 of        94\t|\tloss: 1389.73\n",
      "Training Epoch 34  54.3% | batch:        51 of        94\t|\tloss: 1600.41\n",
      "Training Epoch 34  55.3% | batch:        52 of        94\t|\tloss: 1707.73\n",
      "Training Epoch 34  56.4% | batch:        53 of        94\t|\tloss: 1339.83\n",
      "Training Epoch 34  57.4% | batch:        54 of        94\t|\tloss: 2142.37\n",
      "Training Epoch 34  58.5% | batch:        55 of        94\t|\tloss: 995.183\n",
      "Training Epoch 34  59.6% | batch:        56 of        94\t|\tloss: 1030.84\n",
      "Training Epoch 34  60.6% | batch:        57 of        94\t|\tloss: 1215.08\n",
      "Training Epoch 34  61.7% | batch:        58 of        94\t|\tloss: 1085.21\n",
      "Training Epoch 34  62.8% | batch:        59 of        94\t|\tloss: 1485.43\n",
      "Training Epoch 34  63.8% | batch:        60 of        94\t|\tloss: 1174.67\n",
      "Training Epoch 34  64.9% | batch:        61 of        94\t|\tloss: 1150.82\n",
      "Training Epoch 34  66.0% | batch:        62 of        94\t|\tloss: 1571.81\n",
      "Training Epoch 34  67.0% | batch:        63 of        94\t|\tloss: 2418.7\n",
      "Training Epoch 34  68.1% | batch:        64 of        94\t|\tloss: 1241.02\n",
      "Training Epoch 34  69.1% | batch:        65 of        94\t|\tloss: 1277.61\n",
      "Training Epoch 34  70.2% | batch:        66 of        94\t|\tloss: 1493.01\n",
      "Training Epoch 34  71.3% | batch:        67 of        94\t|\tloss: 1186.28\n",
      "Training Epoch 34  72.3% | batch:        68 of        94\t|\tloss: 2483.98\n",
      "Training Epoch 34  73.4% | batch:        69 of        94\t|\tloss: 1604.81\n",
      "Training Epoch 34  74.5% | batch:        70 of        94\t|\tloss: 2120.29\n",
      "Training Epoch 34  75.5% | batch:        71 of        94\t|\tloss: 1585.61\n",
      "Training Epoch 34  76.6% | batch:        72 of        94\t|\tloss: 1148.99\n",
      "Training Epoch 34  77.7% | batch:        73 of        94\t|\tloss: 1344.9\n",
      "Training Epoch 34  78.7% | batch:        74 of        94\t|\tloss: 936.355\n",
      "Training Epoch 34  79.8% | batch:        75 of        94\t|\tloss: 1650.31\n",
      "Training Epoch 34  80.9% | batch:        76 of        94\t|\tloss: 911.074\n",
      "Training Epoch 34  81.9% | batch:        77 of        94\t|\tloss: 1321.55\n",
      "Training Epoch 34  83.0% | batch:        78 of        94\t|\tloss: 980.362\n",
      "Training Epoch 34  84.0% | batch:        79 of        94\t|\tloss: 1930.13\n",
      "Training Epoch 34  85.1% | batch:        80 of        94\t|\tloss: 1238.67\n",
      "Training Epoch 34  86.2% | batch:        81 of        94\t|\tloss: 1237.76\n",
      "Training Epoch 34  87.2% | batch:        82 of        94\t|\tloss: 1341.99\n",
      "Training Epoch 34  88.3% | batch:        83 of        94\t|\tloss: 1328.99\n",
      "Training Epoch 34  89.4% | batch:        84 of        94\t|\tloss: 1333.98\n",
      "Training Epoch 34  90.4% | batch:        85 of        94\t|\tloss: 803.093\n",
      "Training Epoch 34  91.5% | batch:        86 of        94\t|\tloss: 2172\n",
      "Training Epoch 34  92.6% | batch:        87 of        94\t|\tloss: 1627.61\n",
      "Training Epoch 34  93.6% | batch:        88 of        94\t|\tloss: 1422.49\n",
      "Training Epoch 34  94.7% | batch:        89 of        94\t|\tloss: 1032.84\n",
      "Training Epoch 34  95.7% | batch:        90 of        94\t|\tloss: 1545.23\n",
      "Training Epoch 34  96.8% | batch:        91 of        94\t|\tloss: 828.342\n",
      "Training Epoch 34  97.9% | batch:        92 of        94\t|\tloss: 921.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:28,257 | INFO : Epoch 34 Training Summary: epoch: 34.000000 | loss: 1554.434086 | \n",
      "2023-05-09 14:21:28,258 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8651864528656006 seconds\n",
      "\n",
      "2023-05-09 14:21:28,258 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8327790779225968 seconds\n",
      "2023-05-09 14:21:28,259 | INFO : Avg batch train. time: 0.019497649765134007 seconds\n",
      "2023-05-09 14:21:28,259 | INFO : Avg sample train. time: 0.00015378243647613666 seconds\n",
      "2023-05-09 14:21:28,259 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 34  98.9% | batch:        93 of        94\t|\tloss: 495.702\n",
      "\n",
      "Evaluating Epoch 34   0.0% | batch:         0 of        40\t|\tloss: 5578.81\n",
      "Evaluating Epoch 34   2.5% | batch:         1 of        40\t|\tloss: 1138.75\n",
      "Evaluating Epoch 34   5.0% | batch:         2 of        40\t|\tloss: 3278.77\n",
      "Evaluating Epoch 34   7.5% | batch:         3 of        40\t|\tloss: 6235.1\n",
      "Evaluating Epoch 34  10.0% | batch:         4 of        40\t|\tloss: 2503.69\n",
      "Evaluating Epoch 34  12.5% | batch:         5 of        40\t|\tloss: 2507.32\n",
      "Evaluating Epoch 34  15.0% | batch:         6 of        40\t|\tloss: 8406.16\n",
      "Evaluating Epoch 34  17.5% | batch:         7 of        40\t|\tloss: 2947.08\n",
      "Evaluating Epoch 34  20.0% | batch:         8 of        40\t|\tloss: 2434.88\n",
      "Evaluating Epoch 34  22.5% | batch:         9 of        40\t|\tloss: 2028.99\n",
      "Evaluating Epoch 34  25.0% | batch:        10 of        40\t|\tloss: 3836.67\n",
      "Evaluating Epoch 34  27.5% | batch:        11 of        40\t|\tloss: 1317.64\n",
      "Evaluating Epoch 34  30.0% | batch:        12 of        40\t|\tloss: 5152.4\n",
      "Evaluating Epoch 34  32.5% | batch:        13 of        40\t|\tloss: 2782.07\n",
      "Evaluating Epoch 34  35.0% | batch:        14 of        40\t|\tloss: 1922.38\n",
      "Evaluating Epoch 34  37.5% | batch:        15 of        40\t|\tloss: 3101.05\n",
      "Evaluating Epoch 34  40.0% | batch:        16 of        40\t|\tloss: 3833.22\n",
      "Evaluating Epoch 34  42.5% | batch:        17 of        40\t|\tloss: 2523.75\n",
      "Evaluating Epoch 34  45.0% | batch:        18 of        40\t|\tloss: 1998.64\n",
      "Evaluating Epoch 34  47.5% | batch:        19 of        40\t|\tloss: 4936.95\n",
      "Evaluating Epoch 34  50.0% | batch:        20 of        40\t|\tloss: 4803.8\n",
      "Evaluating Epoch 34  52.5% | batch:        21 of        40\t|\tloss: 913.68\n",
      "Evaluating Epoch 34  55.0% | batch:        22 of        40\t|\tloss: 3703.58\n",
      "Evaluating Epoch 34  57.5% | batch:        23 of        40\t|\tloss: 2907.43\n",
      "Evaluating Epoch 34  60.0% | batch:        24 of        40\t|\tloss: 1575.64\n",
      "Evaluating Epoch 34  62.5% | batch:        25 of        40\t|\tloss: 2859.13\n",
      "Evaluating Epoch 34  65.0% | batch:        26 of        40\t|\tloss: 8546.33\n",
      "Evaluating Epoch 34  67.5% | batch:        27 of        40\t|\tloss: 2598.4\n",
      "Evaluating Epoch 34  70.0% | batch:        28 of        40\t|\tloss: 1854.7\n",
      "Evaluating Epoch 34  72.5% | batch:        29 of        40\t|\tloss: 8665.28\n",
      "Evaluating Epoch 34  75.0% | batch:        30 of        40\t|\tloss: 1825.62\n",
      "Evaluating Epoch 34  77.5% | batch:        31 of        40\t|\tloss: 1696.89\n",
      "Evaluating Epoch 34  80.0% | batch:        32 of        40\t|\tloss: 6286.86\n",
      "Evaluating Epoch 34  82.5% | batch:        33 of        40\t|\tloss: 6069.15\n",
      "Evaluating Epoch 34  85.0% | batch:        34 of        40\t|\tloss: 1007.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:28,726 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4661717414855957 seconds\n",
      "\n",
      "2023-05-09 14:21:28,726 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4934448693927966 seconds\n",
      "2023-05-09 14:21:28,727 | INFO : Avg batch val. time: 0.012336121734819915 seconds\n",
      "2023-05-09 14:21:28,727 | INFO : Avg sample val. time: 9.77505684217109e-05 seconds\n",
      "2023-05-09 14:21:28,728 | INFO : Epoch 34 Validation Summary: epoch: 34.000000 | loss: 3634.907123 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 34  87.5% | batch:        35 of        40\t|\tloss: 4970.74\n",
      "Evaluating Epoch 34  90.0% | batch:        36 of        40\t|\tloss: 4839.91\n",
      "Evaluating Epoch 34  92.5% | batch:        37 of        40\t|\tloss: 2532.16\n",
      "Evaluating Epoch 34  95.0% | batch:        38 of        40\t|\tloss: 2971.67\n",
      "Evaluating Epoch 34  97.5% | batch:        39 of        40\t|\tloss: 9733.85\n",
      "\n",
      "Training Epoch 35   0.0% | batch:         0 of        94\t|\tloss: 775.379\n",
      "Training Epoch 35   1.1% | batch:         1 of        94\t|\tloss: 763.743\n",
      "Training Epoch 35   2.1% | batch:         2 of        94\t|\tloss: 1180.25\n",
      "Training Epoch 35   3.2% | batch:         3 of        94\t|\tloss: 1047.19\n",
      "Training Epoch 35   4.3% | batch:         4 of        94\t|\tloss: 1031.9\n",
      "Training Epoch 35   5.3% | batch:         5 of        94\t|\tloss: 1978.88\n",
      "Training Epoch 35   6.4% | batch:         6 of        94\t|\tloss: 1920.03\n",
      "Training Epoch 35   7.4% | batch:         7 of        94\t|\tloss: 1004.13\n",
      "Training Epoch 35   8.5% | batch:         8 of        94\t|\tloss: 1047.03\n",
      "Training Epoch 35   9.6% | batch:         9 of        94\t|\tloss: 1565.22\n",
      "Training Epoch 35  10.6% | batch:        10 of        94\t|\tloss: 1673.72\n",
      "Training Epoch 35  11.7% | batch:        11 of        94\t|\tloss: 1509.79\n",
      "Training Epoch 35  12.8% | batch:        12 of        94\t|\tloss: 1352.26\n",
      "Training Epoch 35  13.8% | batch:        13 of        94\t|\tloss: 1418.92\n",
      "Training Epoch 35  14.9% | batch:        14 of        94\t|\tloss: 1190.33\n",
      "Training Epoch 35  16.0% | batch:        15 of        94\t|\tloss: 1602.01\n",
      "Training Epoch 35  17.0% | batch:        16 of        94\t|\tloss: 2533.09\n",
      "Training Epoch 35  18.1% | batch:        17 of        94\t|\tloss: 1051.36\n",
      "Training Epoch 35  19.1% | batch:        18 of        94\t|\tloss: 1134.98\n",
      "Training Epoch 35  20.2% | batch:        19 of        94\t|\tloss: 1477.59\n",
      "Training Epoch 35  21.3% | batch:        20 of        94\t|\tloss: 1208.7\n",
      "Training Epoch 35  22.3% | batch:        21 of        94\t|\tloss: 2398.05\n",
      "Training Epoch 35  23.4% | batch:        22 of        94\t|\tloss: 1812.8\n",
      "Training Epoch 35  24.5% | batch:        23 of        94\t|\tloss: 1473.49\n",
      "Training Epoch 35  25.5% | batch:        24 of        94\t|\tloss: 1451.96\n",
      "Training Epoch 35  26.6% | batch:        25 of        94\t|\tloss: 1341.93\n",
      "Training Epoch 35  27.7% | batch:        26 of        94\t|\tloss: 1279.56\n",
      "Training Epoch 35  28.7% | batch:        27 of        94\t|\tloss: 1514.35\n",
      "Training Epoch 35  29.8% | batch:        28 of        94\t|\tloss: 1596.47\n",
      "Training Epoch 35  30.9% | batch:        29 of        94\t|\tloss: 1754.65\n",
      "Training Epoch 35  31.9% | batch:        30 of        94\t|\tloss: 944.496\n",
      "Training Epoch 35  33.0% | batch:        31 of        94\t|\tloss: 1593.79\n",
      "Training Epoch 35  34.0% | batch:        32 of        94\t|\tloss: 1072.89\n",
      "Training Epoch 35  35.1% | batch:        33 of        94\t|\tloss: 3468.56\n",
      "Training Epoch 35  36.2% | batch:        34 of        94\t|\tloss: 2063.95\n",
      "Training Epoch 35  37.2% | batch:        35 of        94\t|\tloss: 1339.49\n",
      "Training Epoch 35  38.3% | batch:        36 of        94\t|\tloss: 1654.38\n",
      "Training Epoch 35  39.4% | batch:        37 of        94\t|\tloss: 1231.4\n",
      "Training Epoch 35  40.4% | batch:        38 of        94\t|\tloss: 1100.03\n",
      "Training Epoch 35  41.5% | batch:        39 of        94\t|\tloss: 962.449\n",
      "Training Epoch 35  42.6% | batch:        40 of        94\t|\tloss: 881.788\n",
      "Training Epoch 35  43.6% | batch:        41 of        94\t|\tloss: 1445.27\n",
      "Training Epoch 35  44.7% | batch:        42 of        94\t|\tloss: 1307.34\n",
      "Training Epoch 35  45.7% | batch:        43 of        94\t|\tloss: 2356.1\n",
      "Training Epoch 35  46.8% | batch:        44 of        94\t|\tloss: 1730.63\n",
      "Training Epoch 35  47.9% | batch:        45 of        94\t|\tloss: 1270.08\n",
      "Training Epoch 35  48.9% | batch:        46 of        94\t|\tloss: 1250.45\n",
      "Training Epoch 35  50.0% | batch:        47 of        94\t|\tloss: 1400.85\n",
      "Training Epoch 35  51.1% | batch:        48 of        94\t|\tloss: 1423.08\n",
      "Training Epoch 35  52.1% | batch:        49 of        94\t|\tloss: 1346.25\n",
      "Training Epoch 35  53.2% | batch:        50 of        94\t|\tloss: 1280.54\n",
      "Training Epoch 35  54.3% | batch:        51 of        94\t|\tloss: 1145.13\n",
      "Training Epoch 35  55.3% | batch:        52 of        94\t|\tloss: 3090.97\n",
      "Training Epoch 35  56.4% | batch:        53 of        94\t|\tloss: 1887.73\n",
      "Training Epoch 35  57.4% | batch:        54 of        94\t|\tloss: 1370.61\n",
      "Training Epoch 35  58.5% | batch:        55 of        94\t|\tloss: 1670.12\n",
      "Training Epoch 35  59.6% | batch:        56 of        94\t|\tloss: 3770.78\n",
      "Training Epoch 35  60.6% | batch:        57 of        94\t|\tloss: 1503.96\n",
      "Training Epoch 35  61.7% | batch:        58 of        94\t|\tloss: 1580.27\n",
      "Training Epoch 35  62.8% | batch:        59 of        94\t|\tloss: 1424.56\n",
      "Training Epoch 35  63.8% | batch:        60 of        94\t|\tloss: 1221.95\n",
      "Training Epoch 35  64.9% | batch:        61 of        94\t|\tloss: 1626.36\n",
      "Training Epoch 35  66.0% | batch:        62 of        94\t|\tloss: 1432.21\n",
      "Training Epoch 35  67.0% | batch:        63 of        94\t|\tloss: 5626.61\n",
      "Training Epoch 35  68.1% | batch:        64 of        94\t|\tloss: 1527.52\n",
      "Training Epoch 35  69.1% | batch:        65 of        94\t|\tloss: 1214.63\n",
      "Training Epoch 35  70.2% | batch:        66 of        94\t|\tloss: 1263.22\n",
      "Training Epoch 35  71.3% | batch:        67 of        94\t|\tloss: 1466.07\n",
      "Training Epoch 35  72.3% | batch:        68 of        94\t|\tloss: 2284.52\n",
      "Training Epoch 35  73.4% | batch:        69 of        94\t|\tloss: 2771.82\n",
      "Training Epoch 35  74.5% | batch:        70 of        94\t|\tloss: 1648.93\n",
      "Training Epoch 35  75.5% | batch:        71 of        94\t|\tloss: 1585.04\n",
      "Training Epoch 35  76.6% | batch:        72 of        94\t|\tloss: 3539.47\n",
      "Training Epoch 35  77.7% | batch:        73 of        94\t|\tloss: 1337.93\n",
      "Training Epoch 35  78.7% | batch:        74 of        94\t|\tloss: 1462.14\n",
      "Training Epoch 35  79.8% | batch:        75 of        94\t|\tloss: 1282.02\n",
      "Training Epoch 35  80.9% | batch:        76 of        94\t|\tloss: 1469.44\n",
      "Training Epoch 35  81.9% | batch:        77 of        94\t|\tloss: 1506.15\n",
      "Training Epoch 35  83.0% | batch:        78 of        94\t|\tloss: 1207.8\n",
      "Training Epoch 35  84.0% | batch:        79 of        94\t|\tloss: 1776.71\n",
      "Training Epoch 35  85.1% | batch:        80 of        94\t|\tloss: 1571.54\n",
      "Training Epoch 35  86.2% | batch:        81 of        94\t|\tloss: 1655.78\n",
      "Training Epoch 35  87.2% | batch:        82 of        94\t|\tloss: 1160.83\n",
      "Training Epoch 35  88.3% | batch:        83 of        94\t|\tloss: 1203.59\n",
      "Training Epoch 35  89.4% | batch:        84 of        94\t|\tloss: 1400.55\n",
      "Training Epoch 35  90.4% | batch:        85 of        94\t|\tloss: 1699.84\n",
      "Training Epoch 35  91.5% | batch:        86 of        94\t|\tloss: 1341.36\n",
      "Training Epoch 35  92.6% | batch:        87 of        94\t|\tloss: 1497.1\n",
      "Training Epoch 35  93.6% | batch:        88 of        94\t|\tloss: 1116.43\n",
      "Training Epoch 35  94.7% | batch:        89 of        94\t|\tloss: 1725.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:30,467 | INFO : Epoch 35 Training Summary: epoch: 35.000000 | loss: 1578.866863 | \n",
      "2023-05-09 14:21:30,468 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.718108892440796 seconds\n",
      "\n",
      "2023-05-09 14:21:30,468 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.829502786908831 seconds\n",
      "2023-05-09 14:21:30,469 | INFO : Avg batch train. time: 0.019462795605413096 seconds\n",
      "2023-05-09 14:21:30,469 | INFO : Avg sample train. time: 0.000153507533722842 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 35  95.7% | batch:        90 of        94\t|\tloss: 1397.66\n",
      "Training Epoch 35  96.8% | batch:        91 of        94\t|\tloss: 953.332\n",
      "Training Epoch 35  97.9% | batch:        92 of        94\t|\tloss: 1079.38\n",
      "Training Epoch 35  98.9% | batch:        93 of        94\t|\tloss: 2705.22\n",
      "\n",
      "Training Epoch 36   0.0% | batch:         0 of        94\t|\tloss: 2091.52\n",
      "Training Epoch 36   1.1% | batch:         1 of        94\t|\tloss: 1405.24\n",
      "Training Epoch 36   2.1% | batch:         2 of        94\t|\tloss: 1150.07\n",
      "Training Epoch 36   3.2% | batch:         3 of        94\t|\tloss: 1476.85\n",
      "Training Epoch 36   4.3% | batch:         4 of        94\t|\tloss: 1023.24\n",
      "Training Epoch 36   5.3% | batch:         5 of        94\t|\tloss: 766.311\n",
      "Training Epoch 36   6.4% | batch:         6 of        94\t|\tloss: 1102.76\n",
      "Training Epoch 36   7.4% | batch:         7 of        94\t|\tloss: 1033.47\n",
      "Training Epoch 36   8.5% | batch:         8 of        94\t|\tloss: 1939.59\n",
      "Training Epoch 36   9.6% | batch:         9 of        94\t|\tloss: 1407.35\n",
      "Training Epoch 36  10.6% | batch:        10 of        94\t|\tloss: 978.097\n",
      "Training Epoch 36  11.7% | batch:        11 of        94\t|\tloss: 2355.47\n",
      "Training Epoch 36  12.8% | batch:        12 of        94\t|\tloss: 1942.82\n",
      "Training Epoch 36  13.8% | batch:        13 of        94\t|\tloss: 4196.63\n",
      "Training Epoch 36  14.9% | batch:        14 of        94\t|\tloss: 1837.13\n",
      "Training Epoch 36  16.0% | batch:        15 of        94\t|\tloss: 965.952\n",
      "Training Epoch 36  17.0% | batch:        16 of        94\t|\tloss: 1249.45\n",
      "Training Epoch 36  18.1% | batch:        17 of        94\t|\tloss: 1367.48\n",
      "Training Epoch 36  19.1% | batch:        18 of        94\t|\tloss: 1281.51\n",
      "Training Epoch 36  20.2% | batch:        19 of        94\t|\tloss: 1414.8\n",
      "Training Epoch 36  21.3% | batch:        20 of        94\t|\tloss: 1161.65\n",
      "Training Epoch 36  22.3% | batch:        21 of        94\t|\tloss: 1470.99\n",
      "Training Epoch 36  23.4% | batch:        22 of        94\t|\tloss: 1057.17\n",
      "Training Epoch 36  24.5% | batch:        23 of        94\t|\tloss: 2844.58\n",
      "Training Epoch 36  25.5% | batch:        24 of        94\t|\tloss: 4737.06\n",
      "Training Epoch 36  26.6% | batch:        25 of        94\t|\tloss: 1525.22\n",
      "Training Epoch 36  27.7% | batch:        26 of        94\t|\tloss: 1801.13\n",
      "Training Epoch 36  28.7% | batch:        27 of        94\t|\tloss: 1027.76\n",
      "Training Epoch 36  29.8% | batch:        28 of        94\t|\tloss: 1632.67\n",
      "Training Epoch 36  30.9% | batch:        29 of        94\t|\tloss: 1329.87\n",
      "Training Epoch 36  31.9% | batch:        30 of        94\t|\tloss: 1239.77\n",
      "Training Epoch 36  33.0% | batch:        31 of        94\t|\tloss: 2298.27\n",
      "Training Epoch 36  34.0% | batch:        32 of        94\t|\tloss: 901.677\n",
      "Training Epoch 36  35.1% | batch:        33 of        94\t|\tloss: 1092.68\n",
      "Training Epoch 36  36.2% | batch:        34 of        94\t|\tloss: 1370.03\n",
      "Training Epoch 36  37.2% | batch:        35 of        94\t|\tloss: 1147.91\n",
      "Training Epoch 36  38.3% | batch:        36 of        94\t|\tloss: 1251.26\n",
      "Training Epoch 36  39.4% | batch:        37 of        94\t|\tloss: 1093.67\n",
      "Training Epoch 36  40.4% | batch:        38 of        94\t|\tloss: 2821.01\n",
      "Training Epoch 36  41.5% | batch:        39 of        94\t|\tloss: 1152.86\n",
      "Training Epoch 36  42.6% | batch:        40 of        94\t|\tloss: 961.364\n",
      "Training Epoch 36  43.6% | batch:        41 of        94\t|\tloss: 1532.97\n",
      "Training Epoch 36  44.7% | batch:        42 of        94\t|\tloss: 945.689\n",
      "Training Epoch 36  45.7% | batch:        43 of        94\t|\tloss: 1494.67\n",
      "Training Epoch 36  46.8% | batch:        44 of        94\t|\tloss: 1252.28\n",
      "Training Epoch 36  47.9% | batch:        45 of        94\t|\tloss: 1623.95\n",
      "Training Epoch 36  48.9% | batch:        46 of        94\t|\tloss: 2892.29\n",
      "Training Epoch 36  50.0% | batch:        47 of        94\t|\tloss: 1477.91\n",
      "Training Epoch 36  51.1% | batch:        48 of        94\t|\tloss: 2028.6\n",
      "Training Epoch 36  52.1% | batch:        49 of        94\t|\tloss: 2746.41\n",
      "Training Epoch 36  53.2% | batch:        50 of        94\t|\tloss: 1458.31\n",
      "Training Epoch 36  54.3% | batch:        51 of        94\t|\tloss: 1604.42\n",
      "Training Epoch 36  55.3% | batch:        52 of        94\t|\tloss: 1673.11\n",
      "Training Epoch 36  56.4% | batch:        53 of        94\t|\tloss: 764.216\n",
      "Training Epoch 36  57.4% | batch:        54 of        94\t|\tloss: 1092.29\n",
      "Training Epoch 36  58.5% | batch:        55 of        94\t|\tloss: 1606.86\n",
      "Training Epoch 36  59.6% | batch:        56 of        94\t|\tloss: 1625.97\n",
      "Training Epoch 36  60.6% | batch:        57 of        94\t|\tloss: 824.14\n",
      "Training Epoch 36  61.7% | batch:        58 of        94\t|\tloss: 1308.88\n",
      "Training Epoch 36  62.8% | batch:        59 of        94\t|\tloss: 1241.98\n",
      "Training Epoch 36  63.8% | batch:        60 of        94\t|\tloss: 1229.99\n",
      "Training Epoch 36  64.9% | batch:        61 of        94\t|\tloss: 1392.9\n",
      "Training Epoch 36  66.0% | batch:        62 of        94\t|\tloss: 1302.42\n",
      "Training Epoch 36  67.0% | batch:        63 of        94\t|\tloss: 1059.12\n",
      "Training Epoch 36  68.1% | batch:        64 of        94\t|\tloss: 1509.73\n",
      "Training Epoch 36  69.1% | batch:        65 of        94\t|\tloss: 1689.64\n",
      "Training Epoch 36  70.2% | batch:        66 of        94\t|\tloss: 1122.4\n",
      "Training Epoch 36  71.3% | batch:        67 of        94\t|\tloss: 1300.42\n",
      "Training Epoch 36  72.3% | batch:        68 of        94\t|\tloss: 2233.56\n",
      "Training Epoch 36  73.4% | batch:        69 of        94\t|\tloss: 1610.31\n",
      "Training Epoch 36  74.5% | batch:        70 of        94\t|\tloss: 1071.98\n",
      "Training Epoch 36  75.5% | batch:        71 of        94\t|\tloss: 1581\n",
      "Training Epoch 36  76.6% | batch:        72 of        94\t|\tloss: 1066.12\n",
      "Training Epoch 36  77.7% | batch:        73 of        94\t|\tloss: 992.982\n",
      "Training Epoch 36  78.7% | batch:        74 of        94\t|\tloss: 1314.2\n",
      "Training Epoch 36  79.8% | batch:        75 of        94\t|\tloss: 1191.51\n",
      "Training Epoch 36  80.9% | batch:        76 of        94\t|\tloss: 1524.84\n",
      "Training Epoch 36  81.9% | batch:        77 of        94\t|\tloss: 3436.92\n",
      "Training Epoch 36  83.0% | batch:        78 of        94\t|\tloss: 1955.55\n",
      "Training Epoch 36  84.0% | batch:        79 of        94\t|\tloss: 1737.04\n",
      "Training Epoch 36  85.1% | batch:        80 of        94\t|\tloss: 1300.15\n",
      "Training Epoch 36  86.2% | batch:        81 of        94\t|\tloss: 1395.69\n",
      "Training Epoch 36  87.2% | batch:        82 of        94\t|\tloss: 2606.69\n",
      "Training Epoch 36  88.3% | batch:        83 of        94\t|\tloss: 1028.68\n",
      "Training Epoch 36  89.4% | batch:        84 of        94\t|\tloss: 874.289\n",
      "Training Epoch 36  90.4% | batch:        85 of        94\t|\tloss: 1222.93\n",
      "Training Epoch 36  91.5% | batch:        86 of        94\t|\tloss: 1604.73\n",
      "Training Epoch 36  92.6% | batch:        87 of        94\t|\tloss: 1665.67\n",
      "Training Epoch 36  93.6% | batch:        88 of        94\t|\tloss: 1251.19\n",
      "Training Epoch 36  94.7% | batch:        89 of        94\t|\tloss: 879.809\n",
      "Training Epoch 36  95.7% | batch:        90 of        94\t|\tloss: 2393.48\n",
      "Training Epoch 36  96.8% | batch:        91 of        94\t|\tloss: 1132.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:32,254 | INFO : Epoch 36 Training Summary: epoch: 36.000000 | loss: 1544.396222 | \n",
      "2023-05-09 14:21:32,255 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.763822078704834 seconds\n",
      "\n",
      "2023-05-09 14:21:32,256 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8276783227920532 seconds\n",
      "2023-05-09 14:21:32,256 | INFO : Avg batch train. time: 0.019443386412681417 seconds\n",
      "2023-05-09 14:21:32,256 | INFO : Avg sample train. time: 0.00015335444896728086 seconds\n",
      "2023-05-09 14:21:32,257 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 36  97.9% | batch:        92 of        94\t|\tloss: 1350.04\n",
      "Training Epoch 36  98.9% | batch:        93 of        94\t|\tloss: 6122.44\n",
      "\n",
      "Evaluating Epoch 36   0.0% | batch:         0 of        40\t|\tloss: 6905.48\n",
      "Evaluating Epoch 36   2.5% | batch:         1 of        40\t|\tloss: 1044.3\n",
      "Evaluating Epoch 36   5.0% | batch:         2 of        40\t|\tloss: 3972.79\n",
      "Evaluating Epoch 36   7.5% | batch:         3 of        40\t|\tloss: 7179.74\n",
      "Evaluating Epoch 36  10.0% | batch:         4 of        40\t|\tloss: 2575.97\n",
      "Evaluating Epoch 36  12.5% | batch:         5 of        40\t|\tloss: 2542.83\n",
      "Evaluating Epoch 36  15.0% | batch:         6 of        40\t|\tloss: 8779.09\n",
      "Evaluating Epoch 36  17.5% | batch:         7 of        40\t|\tloss: 3111.82\n",
      "Evaluating Epoch 36  20.0% | batch:         8 of        40\t|\tloss: 2844.44\n",
      "Evaluating Epoch 36  22.5% | batch:         9 of        40\t|\tloss: 2056.84\n",
      "Evaluating Epoch 36  25.0% | batch:        10 of        40\t|\tloss: 4891.61\n",
      "Evaluating Epoch 36  27.5% | batch:        11 of        40\t|\tloss: 1440.25\n",
      "Evaluating Epoch 36  30.0% | batch:        12 of        40\t|\tloss: 6224.74\n",
      "Evaluating Epoch 36  32.5% | batch:        13 of        40\t|\tloss: 3149.13\n",
      "Evaluating Epoch 36  35.0% | batch:        14 of        40\t|\tloss: 2000.91\n",
      "Evaluating Epoch 36  37.5% | batch:        15 of        40\t|\tloss: 3164.39\n",
      "Evaluating Epoch 36  40.0% | batch:        16 of        40\t|\tloss: 4835.81\n",
      "Evaluating Epoch 36  42.5% | batch:        17 of        40\t|\tloss: 2515.41\n",
      "Evaluating Epoch 36  45.0% | batch:        18 of        40\t|\tloss: 2448.35\n",
      "Evaluating Epoch 36  47.5% | batch:        19 of        40\t|\tloss: 4685.32\n",
      "Evaluating Epoch 36  50.0% | batch:        20 of        40\t|\tloss: 5201.97\n",
      "Evaluating Epoch 36  52.5% | batch:        21 of        40\t|\tloss: 895.25\n",
      "Evaluating Epoch 36  55.0% | batch:        22 of        40\t|\tloss: 3958.43\n",
      "Evaluating Epoch 36  57.5% | batch:        23 of        40\t|\tloss: 3490.83\n",
      "Evaluating Epoch 36  60.0% | batch:        24 of        40\t|\tloss: 1625.7\n",
      "Evaluating Epoch 36  62.5% | batch:        25 of        40\t|\tloss: 3447.29\n",
      "Evaluating Epoch 36  65.0% | batch:        26 of        40\t|\tloss: 9620.51\n",
      "Evaluating Epoch 36  67.5% | batch:        27 of        40\t|\tloss: 3046.01\n",
      "Evaluating Epoch 36  70.0% | batch:        28 of        40\t|\tloss: 2056.28\n",
      "Evaluating Epoch 36  72.5% | batch:        29 of        40\t|\tloss: 9231.18\n",
      "Evaluating Epoch 36  75.0% | batch:        30 of        40\t|\tloss: 1931.95\n",
      "Evaluating Epoch 36  77.5% | batch:        31 of        40\t|\tloss: 2220.94\n",
      "Evaluating Epoch 36  80.0% | batch:        32 of        40\t|\tloss: 6282.05\n",
      "Evaluating Epoch 36  82.5% | batch:        33 of        40\t|\tloss: 5804.2\n",
      "Evaluating Epoch 36  85.0% | batch:        34 of        40\t|\tloss: 1094.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:32,715 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45741796493530273 seconds\n",
      "\n",
      "2023-05-09 14:21:32,715 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.49164352416992185 seconds\n",
      "2023-05-09 14:21:32,716 | INFO : Avg batch val. time: 0.012291088104248046 seconds\n",
      "2023-05-09 14:21:32,716 | INFO : Avg sample val. time: 9.739372507328087e-05 seconds\n",
      "2023-05-09 14:21:32,716 | INFO : Epoch 36 Validation Summary: epoch: 36.000000 | loss: 4031.420498 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 36  87.5% | batch:        35 of        40\t|\tloss: 5887.87\n",
      "Evaluating Epoch 36  90.0% | batch:        36 of        40\t|\tloss: 5665\n",
      "Evaluating Epoch 36  92.5% | batch:        37 of        40\t|\tloss: 2598.61\n",
      "Evaluating Epoch 36  95.0% | batch:        38 of        40\t|\tloss: 3670.39\n",
      "Evaluating Epoch 36  97.5% | batch:        39 of        40\t|\tloss: 11179.2\n",
      "\n",
      "Training Epoch 37   0.0% | batch:         0 of        94\t|\tloss: 2649.64\n",
      "Training Epoch 37   1.1% | batch:         1 of        94\t|\tloss: 1875.38\n",
      "Training Epoch 37   2.1% | batch:         2 of        94\t|\tloss: 2302.22\n",
      "Training Epoch 37   3.2% | batch:         3 of        94\t|\tloss: 1521.66\n",
      "Training Epoch 37   4.3% | batch:         4 of        94\t|\tloss: 1127.84\n",
      "Training Epoch 37   5.3% | batch:         5 of        94\t|\tloss: 988.9\n",
      "Training Epoch 37   6.4% | batch:         6 of        94\t|\tloss: 1563.7\n",
      "Training Epoch 37   7.4% | batch:         7 of        94\t|\tloss: 944.022\n",
      "Training Epoch 37   8.5% | batch:         8 of        94\t|\tloss: 1116.05\n",
      "Training Epoch 37   9.6% | batch:         9 of        94\t|\tloss: 1233.29\n",
      "Training Epoch 37  10.6% | batch:        10 of        94\t|\tloss: 2029.11\n",
      "Training Epoch 37  11.7% | batch:        11 of        94\t|\tloss: 1055.07\n",
      "Training Epoch 37  12.8% | batch:        12 of        94\t|\tloss: 1743.96\n",
      "Training Epoch 37  13.8% | batch:        13 of        94\t|\tloss: 1190.86\n",
      "Training Epoch 37  14.9% | batch:        14 of        94\t|\tloss: 791.151\n",
      "Training Epoch 37  16.0% | batch:        15 of        94\t|\tloss: 2200.88\n",
      "Training Epoch 37  17.0% | batch:        16 of        94\t|\tloss: 1472.55\n",
      "Training Epoch 37  18.1% | batch:        17 of        94\t|\tloss: 1302.9\n",
      "Training Epoch 37  19.1% | batch:        18 of        94\t|\tloss: 2015.13\n",
      "Training Epoch 37  20.2% | batch:        19 of        94\t|\tloss: 1608.08\n",
      "Training Epoch 37  21.3% | batch:        20 of        94\t|\tloss: 1234.75\n",
      "Training Epoch 37  22.3% | batch:        21 of        94\t|\tloss: 4432.42\n",
      "Training Epoch 37  23.4% | batch:        22 of        94\t|\tloss: 1292.67\n",
      "Training Epoch 37  24.5% | batch:        23 of        94\t|\tloss: 974.116\n",
      "Training Epoch 37  25.5% | batch:        24 of        94\t|\tloss: 1094.42\n",
      "Training Epoch 37  26.6% | batch:        25 of        94\t|\tloss: 1517.77\n",
      "Training Epoch 37  27.7% | batch:        26 of        94\t|\tloss: 1339.9\n",
      "Training Epoch 37  28.7% | batch:        27 of        94\t|\tloss: 1785.81\n",
      "Training Epoch 37  29.8% | batch:        28 of        94\t|\tloss: 1235.28\n",
      "Training Epoch 37  30.9% | batch:        29 of        94\t|\tloss: 1024\n",
      "Training Epoch 37  31.9% | batch:        30 of        94\t|\tloss: 2225.92\n",
      "Training Epoch 37  33.0% | batch:        31 of        94\t|\tloss: 1515.72\n",
      "Training Epoch 37  34.0% | batch:        32 of        94\t|\tloss: 1797.73\n",
      "Training Epoch 37  35.1% | batch:        33 of        94\t|\tloss: 1572.44\n",
      "Training Epoch 37  36.2% | batch:        34 of        94\t|\tloss: 893.198\n",
      "Training Epoch 37  37.2% | batch:        35 of        94\t|\tloss: 1075.38\n",
      "Training Epoch 37  38.3% | batch:        36 of        94\t|\tloss: 2315.41\n",
      "Training Epoch 37  39.4% | batch:        37 of        94\t|\tloss: 1111.9\n",
      "Training Epoch 37  40.4% | batch:        38 of        94\t|\tloss: 1318.53\n",
      "Training Epoch 37  41.5% | batch:        39 of        94\t|\tloss: 844.524\n",
      "Training Epoch 37  42.6% | batch:        40 of        94\t|\tloss: 1760.47\n",
      "Training Epoch 37  43.6% | batch:        41 of        94\t|\tloss: 1223\n",
      "Training Epoch 37  44.7% | batch:        42 of        94\t|\tloss: 878.291\n",
      "Training Epoch 37  45.7% | batch:        43 of        94\t|\tloss: 1262.3\n",
      "Training Epoch 37  46.8% | batch:        44 of        94\t|\tloss: 2731.93\n",
      "Training Epoch 37  47.9% | batch:        45 of        94\t|\tloss: 2039.52\n",
      "Training Epoch 37  48.9% | batch:        46 of        94\t|\tloss: 1487.52\n",
      "Training Epoch 37  50.0% | batch:        47 of        94\t|\tloss: 1620.82\n",
      "Training Epoch 37  51.1% | batch:        48 of        94\t|\tloss: 4065.61\n",
      "Training Epoch 37  52.1% | batch:        49 of        94\t|\tloss: 1215.68\n",
      "Training Epoch 37  53.2% | batch:        50 of        94\t|\tloss: 1134.23\n",
      "Training Epoch 37  54.3% | batch:        51 of        94\t|\tloss: 889.355\n",
      "Training Epoch 37  55.3% | batch:        52 of        94\t|\tloss: 2003.47\n",
      "Training Epoch 37  56.4% | batch:        53 of        94\t|\tloss: 973.347\n",
      "Training Epoch 37  57.4% | batch:        54 of        94\t|\tloss: 2155.01\n",
      "Training Epoch 37  58.5% | batch:        55 of        94\t|\tloss: 1433.04\n",
      "Training Epoch 37  59.6% | batch:        56 of        94\t|\tloss: 1458.41\n",
      "Training Epoch 37  60.6% | batch:        57 of        94\t|\tloss: 1402.6\n",
      "Training Epoch 37  61.7% | batch:        58 of        94\t|\tloss: 2214.41\n",
      "Training Epoch 37  62.8% | batch:        59 of        94\t|\tloss: 1310.63\n",
      "Training Epoch 37  63.8% | batch:        60 of        94\t|\tloss: 1005.88\n",
      "Training Epoch 37  64.9% | batch:        61 of        94\t|\tloss: 1184.87\n",
      "Training Epoch 37  66.0% | batch:        62 of        94\t|\tloss: 1340.55\n",
      "Training Epoch 37  67.0% | batch:        63 of        94\t|\tloss: 1198.47\n",
      "Training Epoch 37  68.1% | batch:        64 of        94\t|\tloss: 868.422\n",
      "Training Epoch 37  69.1% | batch:        65 of        94\t|\tloss: 1490.4\n",
      "Training Epoch 37  70.2% | batch:        66 of        94\t|\tloss: 2129.27\n",
      "Training Epoch 37  71.3% | batch:        67 of        94\t|\tloss: 1001.17\n",
      "Training Epoch 37  72.3% | batch:        68 of        94\t|\tloss: 1027.56\n",
      "Training Epoch 37  73.4% | batch:        69 of        94\t|\tloss: 1821.14\n",
      "Training Epoch 37  74.5% | batch:        70 of        94\t|\tloss: 1089.35\n",
      "Training Epoch 37  75.5% | batch:        71 of        94\t|\tloss: 922.062\n",
      "Training Epoch 37  76.6% | batch:        72 of        94\t|\tloss: 1258.45\n",
      "Training Epoch 37  77.7% | batch:        73 of        94\t|\tloss: 1288.33\n",
      "Training Epoch 37  78.7% | batch:        74 of        94\t|\tloss: 1173.31\n",
      "Training Epoch 37  79.8% | batch:        75 of        94\t|\tloss: 2078.55\n",
      "Training Epoch 37  80.9% | batch:        76 of        94\t|\tloss: 1536.85\n",
      "Training Epoch 37  81.9% | batch:        77 of        94\t|\tloss: 1273.49\n",
      "Training Epoch 37  83.0% | batch:        78 of        94\t|\tloss: 1402.99\n",
      "Training Epoch 37  84.0% | batch:        79 of        94\t|\tloss: 1950.8\n",
      "Training Epoch 37  85.1% | batch:        80 of        94\t|\tloss: 1882.05\n",
      "Training Epoch 37  86.2% | batch:        81 of        94\t|\tloss: 1544.09\n",
      "Training Epoch 37  87.2% | batch:        82 of        94\t|\tloss: 1351.79\n",
      "Training Epoch 37  88.3% | batch:        83 of        94\t|\tloss: 2170.16\n",
      "Training Epoch 37  89.4% | batch:        84 of        94\t|\tloss: 2084.35\n",
      "Training Epoch 37  90.4% | batch:        85 of        94\t|\tloss: 1443.35\n",
      "Training Epoch 37  91.5% | batch:        86 of        94\t|\tloss: 1473.94\n",
      "Training Epoch 37  92.6% | batch:        87 of        94\t|\tloss: 3712.37\n",
      "Training Epoch 37  93.6% | batch:        88 of        94\t|\tloss: 1082.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:34,582 | INFO : Epoch 37 Training Summary: epoch: 37.000000 | loss: 1533.000220 | \n",
      "2023-05-09 14:21:34,582 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8438360691070557 seconds\n",
      "\n",
      "2023-05-09 14:21:34,583 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8281150186384045 seconds\n",
      "2023-05-09 14:21:34,583 | INFO : Avg batch train. time: 0.019448032113174515 seconds\n",
      "2023-05-09 14:21:34,584 | INFO : Avg sample train. time: 0.00015339109067279784 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 37  94.7% | batch:        89 of        94\t|\tloss: 1229.34\n",
      "Training Epoch 37  95.7% | batch:        90 of        94\t|\tloss: 1197.72\n",
      "Training Epoch 37  96.8% | batch:        91 of        94\t|\tloss: 990.35\n",
      "Training Epoch 37  97.9% | batch:        92 of        94\t|\tloss: 811.093\n",
      "Training Epoch 37  98.9% | batch:        93 of        94\t|\tloss: 1172.1\n",
      "\n",
      "Training Epoch 38   0.0% | batch:         0 of        94\t|\tloss: 1359.33\n",
      "Training Epoch 38   1.1% | batch:         1 of        94\t|\tloss: 1566.63\n",
      "Training Epoch 38   2.1% | batch:         2 of        94\t|\tloss: 1222.53\n",
      "Training Epoch 38   3.2% | batch:         3 of        94\t|\tloss: 1375.27\n",
      "Training Epoch 38   4.3% | batch:         4 of        94\t|\tloss: 1065.55\n",
      "Training Epoch 38   5.3% | batch:         5 of        94\t|\tloss: 1480.35\n",
      "Training Epoch 38   6.4% | batch:         6 of        94\t|\tloss: 3065.99\n",
      "Training Epoch 38   7.4% | batch:         7 of        94\t|\tloss: 1457.21\n",
      "Training Epoch 38   8.5% | batch:         8 of        94\t|\tloss: 1174.55\n",
      "Training Epoch 38   9.6% | batch:         9 of        94\t|\tloss: 932.367\n",
      "Training Epoch 38  10.6% | batch:        10 of        94\t|\tloss: 1781.81\n",
      "Training Epoch 38  11.7% | batch:        11 of        94\t|\tloss: 1534.11\n",
      "Training Epoch 38  12.8% | batch:        12 of        94\t|\tloss: 1910.07\n",
      "Training Epoch 38  13.8% | batch:        13 of        94\t|\tloss: 1213.35\n",
      "Training Epoch 38  14.9% | batch:        14 of        94\t|\tloss: 2105.98\n",
      "Training Epoch 38  16.0% | batch:        15 of        94\t|\tloss: 1632.18\n",
      "Training Epoch 38  17.0% | batch:        16 of        94\t|\tloss: 1144.13\n",
      "Training Epoch 38  18.1% | batch:        17 of        94\t|\tloss: 899.505\n",
      "Training Epoch 38  19.1% | batch:        18 of        94\t|\tloss: 1045.11\n",
      "Training Epoch 38  20.2% | batch:        19 of        94\t|\tloss: 1401.13\n",
      "Training Epoch 38  21.3% | batch:        20 of        94\t|\tloss: 1506.17\n",
      "Training Epoch 38  22.3% | batch:        21 of        94\t|\tloss: 1160.97\n",
      "Training Epoch 38  23.4% | batch:        22 of        94\t|\tloss: 1126.57\n",
      "Training Epoch 38  24.5% | batch:        23 of        94\t|\tloss: 1281.12\n",
      "Training Epoch 38  25.5% | batch:        24 of        94\t|\tloss: 947.098\n",
      "Training Epoch 38  26.6% | batch:        25 of        94\t|\tloss: 838.592\n",
      "Training Epoch 38  27.7% | batch:        26 of        94\t|\tloss: 4021.09\n",
      "Training Epoch 38  28.7% | batch:        27 of        94\t|\tloss: 1099.54\n",
      "Training Epoch 38  29.8% | batch:        28 of        94\t|\tloss: 935.625\n",
      "Training Epoch 38  30.9% | batch:        29 of        94\t|\tloss: 1057.59\n",
      "Training Epoch 38  31.9% | batch:        30 of        94\t|\tloss: 1019.42\n",
      "Training Epoch 38  33.0% | batch:        31 of        94\t|\tloss: 947.637\n",
      "Training Epoch 38  34.0% | batch:        32 of        94\t|\tloss: 1364.94\n",
      "Training Epoch 38  35.1% | batch:        33 of        94\t|\tloss: 1317.85\n",
      "Training Epoch 38  36.2% | batch:        34 of        94\t|\tloss: 2139.16\n",
      "Training Epoch 38  37.2% | batch:        35 of        94\t|\tloss: 706.269\n",
      "Training Epoch 38  38.3% | batch:        36 of        94\t|\tloss: 1367.49\n",
      "Training Epoch 38  39.4% | batch:        37 of        94\t|\tloss: 1262.44\n",
      "Training Epoch 38  40.4% | batch:        38 of        94\t|\tloss: 1458.8\n",
      "Training Epoch 38  41.5% | batch:        39 of        94\t|\tloss: 1104.17\n",
      "Training Epoch 38  42.6% | batch:        40 of        94\t|\tloss: 1196.37\n",
      "Training Epoch 38  43.6% | batch:        41 of        94\t|\tloss: 1456.66\n",
      "Training Epoch 38  44.7% | batch:        42 of        94\t|\tloss: 1271.2\n",
      "Training Epoch 38  45.7% | batch:        43 of        94\t|\tloss: 2088.64\n",
      "Training Epoch 38  46.8% | batch:        44 of        94\t|\tloss: 1282.24\n",
      "Training Epoch 38  47.9% | batch:        45 of        94\t|\tloss: 1432.49\n",
      "Training Epoch 38  48.9% | batch:        46 of        94\t|\tloss: 2347.41\n",
      "Training Epoch 38  50.0% | batch:        47 of        94\t|\tloss: 2219.71\n",
      "Training Epoch 38  51.1% | batch:        48 of        94\t|\tloss: 1162.83\n",
      "Training Epoch 38  52.1% | batch:        49 of        94\t|\tloss: 3048.16\n",
      "Training Epoch 38  53.2% | batch:        50 of        94\t|\tloss: 932.534\n",
      "Training Epoch 38  54.3% | batch:        51 of        94\t|\tloss: 1737.92\n",
      "Training Epoch 38  55.3% | batch:        52 of        94\t|\tloss: 1666\n",
      "Training Epoch 38  56.4% | batch:        53 of        94\t|\tloss: 958.843\n",
      "Training Epoch 38  57.4% | batch:        54 of        94\t|\tloss: 1306.88\n",
      "Training Epoch 38  58.5% | batch:        55 of        94\t|\tloss: 1418.94\n",
      "Training Epoch 38  59.6% | batch:        56 of        94\t|\tloss: 2050.49\n",
      "Training Epoch 38  60.6% | batch:        57 of        94\t|\tloss: 1753.69\n",
      "Training Epoch 38  61.7% | batch:        58 of        94\t|\tloss: 853.68\n",
      "Training Epoch 38  62.8% | batch:        59 of        94\t|\tloss: 1441.7\n",
      "Training Epoch 38  63.8% | batch:        60 of        94\t|\tloss: 1243.03\n",
      "Training Epoch 38  64.9% | batch:        61 of        94\t|\tloss: 1625.84\n",
      "Training Epoch 38  66.0% | batch:        62 of        94\t|\tloss: 1852.28\n",
      "Training Epoch 38  67.0% | batch:        63 of        94\t|\tloss: 2879.41\n",
      "Training Epoch 38  68.1% | batch:        64 of        94\t|\tloss: 1641.43\n",
      "Training Epoch 38  69.1% | batch:        65 of        94\t|\tloss: 1824.31\n",
      "Training Epoch 38  70.2% | batch:        66 of        94\t|\tloss: 1204.21\n",
      "Training Epoch 38  71.3% | batch:        67 of        94\t|\tloss: 1473.05\n",
      "Training Epoch 38  72.3% | batch:        68 of        94\t|\tloss: 943.11\n",
      "Training Epoch 38  73.4% | batch:        69 of        94\t|\tloss: 1114.53\n",
      "Training Epoch 38  74.5% | batch:        70 of        94\t|\tloss: 1418.09\n",
      "Training Epoch 38  75.5% | batch:        71 of        94\t|\tloss: 1165.31\n",
      "Training Epoch 38  76.6% | batch:        72 of        94\t|\tloss: 978.34\n",
      "Training Epoch 38  77.7% | batch:        73 of        94\t|\tloss: 1356.64\n",
      "Training Epoch 38  78.7% | batch:        74 of        94\t|\tloss: 1803.03\n",
      "Training Epoch 38  79.8% | batch:        75 of        94\t|\tloss: 1444.3\n",
      "Training Epoch 38  80.9% | batch:        76 of        94\t|\tloss: 1238.22\n",
      "Training Epoch 38  81.9% | batch:        77 of        94\t|\tloss: 1243.26\n",
      "Training Epoch 38  83.0% | batch:        78 of        94\t|\tloss: 2208.13\n",
      "Training Epoch 38  84.0% | batch:        79 of        94\t|\tloss: 1280.9\n",
      "Training Epoch 38  85.1% | batch:        80 of        94\t|\tloss: 1606.61\n",
      "Training Epoch 38  86.2% | batch:        81 of        94\t|\tloss: 2484.32\n",
      "Training Epoch 38  87.2% | batch:        82 of        94\t|\tloss: 1395.65\n",
      "Training Epoch 38  88.3% | batch:        83 of        94\t|\tloss: 1428.79\n",
      "Training Epoch 38  89.4% | batch:        84 of        94\t|\tloss: 930.513\n",
      "Training Epoch 38  90.4% | batch:        85 of        94\t|\tloss: 2884.9\n",
      "Training Epoch 38  91.5% | batch:        86 of        94\t|\tloss: 1830.24\n",
      "Training Epoch 38  92.6% | batch:        87 of        94\t|\tloss: 1657.71\n",
      "Training Epoch 38  93.6% | batch:        88 of        94\t|\tloss: 2205.55\n",
      "Training Epoch 38  94.7% | batch:        89 of        94\t|\tloss: 2163.43\n",
      "Training Epoch 38  95.7% | batch:        90 of        94\t|\tloss: 1087.13\n",
      "Training Epoch 38  96.8% | batch:        91 of        94\t|\tloss: 2508.21\n",
      "Training Epoch 38  97.9% | batch:        92 of        94\t|\tloss: 1824.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:36,438 | INFO : Epoch 38 Training Summary: epoch: 38.000000 | loss: 1522.916530 | \n",
      "2023-05-09 14:21:36,438 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8338062763214111 seconds\n",
      "\n",
      "2023-05-09 14:21:36,439 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.828264788577431 seconds\n",
      "2023-05-09 14:21:36,440 | INFO : Avg batch train. time: 0.019449625410398203 seconds\n",
      "2023-05-09 14:21:36,440 | INFO : Avg sample train. time: 0.00015340365737350487 seconds\n",
      "2023-05-09 14:21:36,441 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 38  98.9% | batch:        93 of        94\t|\tloss: 1802.18\n",
      "\n",
      "Evaluating Epoch 38   0.0% | batch:         0 of        40\t|\tloss: 5395.86\n",
      "Evaluating Epoch 38   2.5% | batch:         1 of        40\t|\tloss: 1033.69\n",
      "Evaluating Epoch 38   5.0% | batch:         2 of        40\t|\tloss: 3506.13\n",
      "Evaluating Epoch 38   7.5% | batch:         3 of        40\t|\tloss: 5607.99\n",
      "Evaluating Epoch 38  10.0% | batch:         4 of        40\t|\tloss: 2466.75\n",
      "Evaluating Epoch 38  12.5% | batch:         5 of        40\t|\tloss: 2710.83\n",
      "Evaluating Epoch 38  15.0% | batch:         6 of        40\t|\tloss: 8340.88\n",
      "Evaluating Epoch 38  17.5% | batch:         7 of        40\t|\tloss: 2866.51\n",
      "Evaluating Epoch 38  20.0% | batch:         8 of        40\t|\tloss: 2890.28\n",
      "Evaluating Epoch 38  22.5% | batch:         9 of        40\t|\tloss: 2278.18\n",
      "Evaluating Epoch 38  25.0% | batch:        10 of        40\t|\tloss: 4192.55\n",
      "Evaluating Epoch 38  27.5% | batch:        11 of        40\t|\tloss: 1405.12\n",
      "Evaluating Epoch 38  30.0% | batch:        12 of        40\t|\tloss: 5268.33\n",
      "Evaluating Epoch 38  32.5% | batch:        13 of        40\t|\tloss: 2762.84\n",
      "Evaluating Epoch 38  35.0% | batch:        14 of        40\t|\tloss: 1936.29\n",
      "Evaluating Epoch 38  37.5% | batch:        15 of        40\t|\tloss: 3102.69\n",
      "Evaluating Epoch 38  40.0% | batch:        16 of        40\t|\tloss: 5931.14\n",
      "Evaluating Epoch 38  42.5% | batch:        17 of        40\t|\tloss: 2454.37\n",
      "Evaluating Epoch 38  45.0% | batch:        18 of        40\t|\tloss: 2232.24\n",
      "Evaluating Epoch 38  47.5% | batch:        19 of        40\t|\tloss: 4076.18\n",
      "Evaluating Epoch 38  50.0% | batch:        20 of        40\t|\tloss: 4723.42\n",
      "Evaluating Epoch 38  52.5% | batch:        21 of        40\t|\tloss: 1099.89\n",
      "Evaluating Epoch 38  55.0% | batch:        22 of        40\t|\tloss: 4332.2\n",
      "Evaluating Epoch 38  57.5% | batch:        23 of        40\t|\tloss: 3101.09\n",
      "Evaluating Epoch 38  60.0% | batch:        24 of        40\t|\tloss: 1509.99\n",
      "Evaluating Epoch 38  62.5% | batch:        25 of        40\t|\tloss: 3201.84\n",
      "Evaluating Epoch 38  65.0% | batch:        26 of        40\t|\tloss: 6040.41\n",
      "Evaluating Epoch 38  67.5% | batch:        27 of        40\t|\tloss: 2817.04\n",
      "Evaluating Epoch 38  70.0% | batch:        28 of        40\t|\tloss: 1947.45\n",
      "Evaluating Epoch 38  72.5% | batch:        29 of        40\t|\tloss: 7433.83\n",
      "Evaluating Epoch 38  75.0% | batch:        30 of        40\t|\tloss: 1953.55\n",
      "Evaluating Epoch 38  77.5% | batch:        31 of        40\t|\tloss: 2195.83\n",
      "Evaluating Epoch 38  80.0% | batch:        32 of        40\t|\tloss: 5691.13\n",
      "Evaluating Epoch 38  82.5% | batch:        33 of        40\t|\tloss: 4984.06\n",
      "Evaluating Epoch 38  85.0% | batch:        34 of        40\t|\tloss: 1008.2\n",
      "Evaluating Epoch 38  87.5% | batch:        35 of        40\t|\tloss: 5143.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:36,897 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45575404167175293 seconds\n",
      "\n",
      "2023-05-09 14:21:36,897 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4899345011938186 seconds\n",
      "2023-05-09 14:21:36,898 | INFO : Avg batch val. time: 0.012248362529845465 seconds\n",
      "2023-05-09 14:21:36,898 | INFO : Avg sample val. time: 9.705517060099417e-05 seconds\n",
      "2023-05-09 14:21:36,898 | INFO : Epoch 38 Validation Summary: epoch: 38.000000 | loss: 3599.174868 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 38  90.0% | batch:        36 of        40\t|\tloss: 4454.67\n",
      "Evaluating Epoch 38  92.5% | batch:        37 of        40\t|\tloss: 2538.9\n",
      "Evaluating Epoch 38  95.0% | batch:        38 of        40\t|\tloss: 3580.54\n",
      "Evaluating Epoch 38  97.5% | batch:        39 of        40\t|\tloss: 8515.98\n",
      "\n",
      "Training Epoch 39   0.0% | batch:         0 of        94\t|\tloss: 1196.55\n",
      "Training Epoch 39   1.1% | batch:         1 of        94\t|\tloss: 1404.07\n",
      "Training Epoch 39   2.1% | batch:         2 of        94\t|\tloss: 1275.34\n",
      "Training Epoch 39   3.2% | batch:         3 of        94\t|\tloss: 1073.59\n",
      "Training Epoch 39   4.3% | batch:         4 of        94\t|\tloss: 1287.04\n",
      "Training Epoch 39   5.3% | batch:         5 of        94\t|\tloss: 2265.99\n",
      "Training Epoch 39   6.4% | batch:         6 of        94\t|\tloss: 1980.27\n",
      "Training Epoch 39   7.4% | batch:         7 of        94\t|\tloss: 1508.44\n",
      "Training Epoch 39   8.5% | batch:         8 of        94\t|\tloss: 967.038\n",
      "Training Epoch 39   9.6% | batch:         9 of        94\t|\tloss: 1378.99\n",
      "Training Epoch 39  10.6% | batch:        10 of        94\t|\tloss: 1104.23\n",
      "Training Epoch 39  11.7% | batch:        11 of        94\t|\tloss: 1797.74\n",
      "Training Epoch 39  12.8% | batch:        12 of        94\t|\tloss: 1045.59\n",
      "Training Epoch 39  13.8% | batch:        13 of        94\t|\tloss: 1051.41\n",
      "Training Epoch 39  14.9% | batch:        14 of        94\t|\tloss: 1524\n",
      "Training Epoch 39  16.0% | batch:        15 of        94\t|\tloss: 1328.55\n",
      "Training Epoch 39  17.0% | batch:        16 of        94\t|\tloss: 1194.45\n",
      "Training Epoch 39  18.1% | batch:        17 of        94\t|\tloss: 1497.18\n",
      "Training Epoch 39  19.1% | batch:        18 of        94\t|\tloss: 879.611\n",
      "Training Epoch 39  20.2% | batch:        19 of        94\t|\tloss: 1473.77\n",
      "Training Epoch 39  21.3% | batch:        20 of        94\t|\tloss: 1059.76\n",
      "Training Epoch 39  22.3% | batch:        21 of        94\t|\tloss: 1645.59\n",
      "Training Epoch 39  23.4% | batch:        22 of        94\t|\tloss: 1300.54\n",
      "Training Epoch 39  24.5% | batch:        23 of        94\t|\tloss: 1199.24\n",
      "Training Epoch 39  25.5% | batch:        24 of        94\t|\tloss: 1639.56\n",
      "Training Epoch 39  26.6% | batch:        25 of        94\t|\tloss: 1384.14\n",
      "Training Epoch 39  27.7% | batch:        26 of        94\t|\tloss: 1174.95\n",
      "Training Epoch 39  28.7% | batch:        27 of        94\t|\tloss: 760.186\n",
      "Training Epoch 39  29.8% | batch:        28 of        94\t|\tloss: 1080.86\n",
      "Training Epoch 39  30.9% | batch:        29 of        94\t|\tloss: 1191.13\n",
      "Training Epoch 39  31.9% | batch:        30 of        94\t|\tloss: 3244.94\n",
      "Training Epoch 39  33.0% | batch:        31 of        94\t|\tloss: 2092.73\n",
      "Training Epoch 39  34.0% | batch:        32 of        94\t|\tloss: 1158.95\n",
      "Training Epoch 39  35.1% | batch:        33 of        94\t|\tloss: 829.551\n",
      "Training Epoch 39  36.2% | batch:        34 of        94\t|\tloss: 1354.38\n",
      "Training Epoch 39  37.2% | batch:        35 of        94\t|\tloss: 2403.05\n",
      "Training Epoch 39  38.3% | batch:        36 of        94\t|\tloss: 1189.61\n",
      "Training Epoch 39  39.4% | batch:        37 of        94\t|\tloss: 1557.1\n",
      "Training Epoch 39  40.4% | batch:        38 of        94\t|\tloss: 1386.95\n",
      "Training Epoch 39  41.5% | batch:        39 of        94\t|\tloss: 969.827\n",
      "Training Epoch 39  42.6% | batch:        40 of        94\t|\tloss: 1029.78\n",
      "Training Epoch 39  43.6% | batch:        41 of        94\t|\tloss: 1103.35\n",
      "Training Epoch 39  44.7% | batch:        42 of        94\t|\tloss: 1429.14\n",
      "Training Epoch 39  45.7% | batch:        43 of        94\t|\tloss: 2431.15\n",
      "Training Epoch 39  46.8% | batch:        44 of        94\t|\tloss: 1587.81\n",
      "Training Epoch 39  47.9% | batch:        45 of        94\t|\tloss: 2555.47\n",
      "Training Epoch 39  48.9% | batch:        46 of        94\t|\tloss: 1337.92\n",
      "Training Epoch 39  50.0% | batch:        47 of        94\t|\tloss: 932.452\n",
      "Training Epoch 39  51.1% | batch:        48 of        94\t|\tloss: 3494.06\n",
      "Training Epoch 39  52.1% | batch:        49 of        94\t|\tloss: 1708.01\n",
      "Training Epoch 39  53.2% | batch:        50 of        94\t|\tloss: 1423.96\n",
      "Training Epoch 39  54.3% | batch:        51 of        94\t|\tloss: 941.465\n",
      "Training Epoch 39  55.3% | batch:        52 of        94\t|\tloss: 1044.04\n",
      "Training Epoch 39  56.4% | batch:        53 of        94\t|\tloss: 1898.06\n",
      "Training Epoch 39  57.4% | batch:        54 of        94\t|\tloss: 1305\n",
      "Training Epoch 39  58.5% | batch:        55 of        94\t|\tloss: 3330.58\n",
      "Training Epoch 39  59.6% | batch:        56 of        94\t|\tloss: 1921.43\n",
      "Training Epoch 39  60.6% | batch:        57 of        94\t|\tloss: 1313.76\n",
      "Training Epoch 39  61.7% | batch:        58 of        94\t|\tloss: 2027.64\n",
      "Training Epoch 39  62.8% | batch:        59 of        94\t|\tloss: 1553.42\n",
      "Training Epoch 39  63.8% | batch:        60 of        94\t|\tloss: 1936.79\n",
      "Training Epoch 39  64.9% | batch:        61 of        94\t|\tloss: 2062.16\n",
      "Training Epoch 39  66.0% | batch:        62 of        94\t|\tloss: 1346.28\n",
      "Training Epoch 39  67.0% | batch:        63 of        94\t|\tloss: 1782.16\n",
      "Training Epoch 39  68.1% | batch:        64 of        94\t|\tloss: 1589.12\n",
      "Training Epoch 39  69.1% | batch:        65 of        94\t|\tloss: 2065.77\n",
      "Training Epoch 39  70.2% | batch:        66 of        94\t|\tloss: 1531.03\n",
      "Training Epoch 39  71.3% | batch:        67 of        94\t|\tloss: 2946.91\n",
      "Training Epoch 39  72.3% | batch:        68 of        94\t|\tloss: 1542.56\n",
      "Training Epoch 39  73.4% | batch:        69 of        94\t|\tloss: 1366.4\n",
      "Training Epoch 39  74.5% | batch:        70 of        94\t|\tloss: 945.118\n",
      "Training Epoch 39  75.5% | batch:        71 of        94\t|\tloss: 1134.5\n",
      "Training Epoch 39  76.6% | batch:        72 of        94\t|\tloss: 1154.28\n",
      "Training Epoch 39  77.7% | batch:        73 of        94\t|\tloss: 2296.8\n",
      "Training Epoch 39  78.7% | batch:        74 of        94\t|\tloss: 1054.76\n",
      "Training Epoch 39  79.8% | batch:        75 of        94\t|\tloss: 1136.61\n",
      "Training Epoch 39  80.9% | batch:        76 of        94\t|\tloss: 1685.45\n",
      "Training Epoch 39  81.9% | batch:        77 of        94\t|\tloss: 2648.94\n",
      "Training Epoch 39  83.0% | batch:        78 of        94\t|\tloss: 825.731\n",
      "Training Epoch 39  84.0% | batch:        79 of        94\t|\tloss: 830.094\n",
      "Training Epoch 39  85.1% | batch:        80 of        94\t|\tloss: 1418.77\n",
      "Training Epoch 39  86.2% | batch:        81 of        94\t|\tloss: 1444.44\n",
      "Training Epoch 39  87.2% | batch:        82 of        94\t|\tloss: 1760.46\n",
      "Training Epoch 39  88.3% | batch:        83 of        94\t|\tloss: 1397.8\n",
      "Training Epoch 39  89.4% | batch:        84 of        94\t|\tloss: 1052.81\n",
      "Training Epoch 39  90.4% | batch:        85 of        94\t|\tloss: 1122.54\n",
      "Training Epoch 39  91.5% | batch:        86 of        94\t|\tloss: 827.655\n",
      "Training Epoch 39  92.6% | batch:        87 of        94\t|\tloss: 1457.36\n",
      "Training Epoch 39  93.6% | batch:        88 of        94\t|\tloss: 1513.44\n",
      "Training Epoch 39  94.7% | batch:        89 of        94\t|\tloss: 1031.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:38,748 | INFO : Epoch 39 Training Summary: epoch: 39.000000 | loss: 1502.764999 | \n",
      "2023-05-09 14:21:38,749 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8368914127349854 seconds\n",
      "\n",
      "2023-05-09 14:21:38,750 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8284859840686505 seconds\n",
      "2023-05-09 14:21:38,750 | INFO : Avg batch train. time: 0.019451978553921813 seconds\n",
      "2023-05-09 14:21:38,751 | INFO : Avg sample train. time: 0.00015342221715628884 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 39  95.7% | batch:        90 of        94\t|\tloss: 1248.48\n",
      "Training Epoch 39  96.8% | batch:        91 of        94\t|\tloss: 1373.39\n",
      "Training Epoch 39  97.9% | batch:        92 of        94\t|\tloss: 2051.31\n",
      "Training Epoch 39  98.9% | batch:        93 of        94\t|\tloss: 1051.63\n",
      "\n",
      "Training Epoch 40   0.0% | batch:         0 of        94\t|\tloss: 1313.25\n",
      "Training Epoch 40   1.1% | batch:         1 of        94\t|\tloss: 1061.38\n",
      "Training Epoch 40   2.1% | batch:         2 of        94\t|\tloss: 1189.94\n",
      "Training Epoch 40   3.2% | batch:         3 of        94\t|\tloss: 1280.8\n",
      "Training Epoch 40   4.3% | batch:         4 of        94\t|\tloss: 850.949\n",
      "Training Epoch 40   5.3% | batch:         5 of        94\t|\tloss: 1401.46\n",
      "Training Epoch 40   6.4% | batch:         6 of        94\t|\tloss: 1063.64\n",
      "Training Epoch 40   7.4% | batch:         7 of        94\t|\tloss: 2307.79\n",
      "Training Epoch 40   8.5% | batch:         8 of        94\t|\tloss: 1762.9\n",
      "Training Epoch 40   9.6% | batch:         9 of        94\t|\tloss: 4183.11\n",
      "Training Epoch 40  10.6% | batch:        10 of        94\t|\tloss: 1530.69\n",
      "Training Epoch 40  11.7% | batch:        11 of        94\t|\tloss: 1223.39\n",
      "Training Epoch 40  12.8% | batch:        12 of        94\t|\tloss: 1113.33\n",
      "Training Epoch 40  13.8% | batch:        13 of        94\t|\tloss: 1476.01\n",
      "Training Epoch 40  14.9% | batch:        14 of        94\t|\tloss: 1666.46\n",
      "Training Epoch 40  16.0% | batch:        15 of        94\t|\tloss: 1722.68\n",
      "Training Epoch 40  17.0% | batch:        16 of        94\t|\tloss: 1146.09\n",
      "Training Epoch 40  18.1% | batch:        17 of        94\t|\tloss: 1095.69\n",
      "Training Epoch 40  19.1% | batch:        18 of        94\t|\tloss: 1028.87\n",
      "Training Epoch 40  20.2% | batch:        19 of        94\t|\tloss: 2085.25\n",
      "Training Epoch 40  21.3% | batch:        20 of        94\t|\tloss: 1122.72\n",
      "Training Epoch 40  22.3% | batch:        21 of        94\t|\tloss: 1468.14\n",
      "Training Epoch 40  23.4% | batch:        22 of        94\t|\tloss: 1309.3\n",
      "Training Epoch 40  24.5% | batch:        23 of        94\t|\tloss: 1110.16\n",
      "Training Epoch 40  25.5% | batch:        24 of        94\t|\tloss: 3030.73\n",
      "Training Epoch 40  26.6% | batch:        25 of        94\t|\tloss: 1221.14\n",
      "Training Epoch 40  27.7% | batch:        26 of        94\t|\tloss: 1779.58\n",
      "Training Epoch 40  28.7% | batch:        27 of        94\t|\tloss: 1316.17\n",
      "Training Epoch 40  29.8% | batch:        28 of        94\t|\tloss: 1659.91\n",
      "Training Epoch 40  30.9% | batch:        29 of        94\t|\tloss: 966.19\n",
      "Training Epoch 40  31.9% | batch:        30 of        94\t|\tloss: 1035.33\n",
      "Training Epoch 40  33.0% | batch:        31 of        94\t|\tloss: 1023.19\n",
      "Training Epoch 40  34.0% | batch:        32 of        94\t|\tloss: 1443.03\n",
      "Training Epoch 40  35.1% | batch:        33 of        94\t|\tloss: 1403.93\n",
      "Training Epoch 40  36.2% | batch:        34 of        94\t|\tloss: 784.324\n",
      "Training Epoch 40  37.2% | batch:        35 of        94\t|\tloss: 948.351\n",
      "Training Epoch 40  38.3% | batch:        36 of        94\t|\tloss: 1229.48\n",
      "Training Epoch 40  39.4% | batch:        37 of        94\t|\tloss: 1077.09\n",
      "Training Epoch 40  40.4% | batch:        38 of        94\t|\tloss: 1445.07\n",
      "Training Epoch 40  41.5% | batch:        39 of        94\t|\tloss: 816.219\n",
      "Training Epoch 40  42.6% | batch:        40 of        94\t|\tloss: 1213.23\n",
      "Training Epoch 40  43.6% | batch:        41 of        94\t|\tloss: 2123.83\n",
      "Training Epoch 40  44.7% | batch:        42 of        94\t|\tloss: 1222.39\n",
      "Training Epoch 40  45.7% | batch:        43 of        94\t|\tloss: 1648.3\n",
      "Training Epoch 40  46.8% | batch:        44 of        94\t|\tloss: 1275.04\n",
      "Training Epoch 40  47.9% | batch:        45 of        94\t|\tloss: 1414.1\n",
      "Training Epoch 40  48.9% | batch:        46 of        94\t|\tloss: 1067.3\n",
      "Training Epoch 40  50.0% | batch:        47 of        94\t|\tloss: 1187.91\n",
      "Training Epoch 40  51.1% | batch:        48 of        94\t|\tloss: 913.234\n",
      "Training Epoch 40  52.1% | batch:        49 of        94\t|\tloss: 1956.15\n",
      "Training Epoch 40  53.2% | batch:        50 of        94\t|\tloss: 1618.59\n",
      "Training Epoch 40  54.3% | batch:        51 of        94\t|\tloss: 1247.88\n",
      "Training Epoch 40  55.3% | batch:        52 of        94\t|\tloss: 2051.99\n",
      "Training Epoch 40  56.4% | batch:        53 of        94\t|\tloss: 1539.1\n",
      "Training Epoch 40  57.4% | batch:        54 of        94\t|\tloss: 1418.25\n",
      "Training Epoch 40  58.5% | batch:        55 of        94\t|\tloss: 1262.68\n",
      "Training Epoch 40  59.6% | batch:        56 of        94\t|\tloss: 1576.63\n",
      "Training Epoch 40  60.6% | batch:        57 of        94\t|\tloss: 1542.73\n",
      "Training Epoch 40  61.7% | batch:        58 of        94\t|\tloss: 1177.22\n",
      "Training Epoch 40  62.8% | batch:        59 of        94\t|\tloss: 986.963\n",
      "Training Epoch 40  63.8% | batch:        60 of        94\t|\tloss: 1616.33\n",
      "Training Epoch 40  64.9% | batch:        61 of        94\t|\tloss: 935.182\n",
      "Training Epoch 40  66.0% | batch:        62 of        94\t|\tloss: 1313.53\n",
      "Training Epoch 40  67.0% | batch:        63 of        94\t|\tloss: 1204.99\n",
      "Training Epoch 40  68.1% | batch:        64 of        94\t|\tloss: 1234.4\n",
      "Training Epoch 40  69.1% | batch:        65 of        94\t|\tloss: 4399.6\n",
      "Training Epoch 40  70.2% | batch:        66 of        94\t|\tloss: 1596.13\n",
      "Training Epoch 40  71.3% | batch:        67 of        94\t|\tloss: 2144.29\n",
      "Training Epoch 40  72.3% | batch:        68 of        94\t|\tloss: 1963.36\n",
      "Training Epoch 40  73.4% | batch:        69 of        94\t|\tloss: 3260.77\n",
      "Training Epoch 40  74.5% | batch:        70 of        94\t|\tloss: 2620.25\n",
      "Training Epoch 40  75.5% | batch:        71 of        94\t|\tloss: 1142.82\n",
      "Training Epoch 40  76.6% | batch:        72 of        94\t|\tloss: 1121.73\n",
      "Training Epoch 40  77.7% | batch:        73 of        94\t|\tloss: 1122.17\n",
      "Training Epoch 40  78.7% | batch:        74 of        94\t|\tloss: 1649.3\n",
      "Training Epoch 40  79.8% | batch:        75 of        94\t|\tloss: 1120.91\n",
      "Training Epoch 40  80.9% | batch:        76 of        94\t|\tloss: 1237.97\n",
      "Training Epoch 40  81.9% | batch:        77 of        94\t|\tloss: 838.462\n",
      "Training Epoch 40  83.0% | batch:        78 of        94\t|\tloss: 1425.23\n",
      "Training Epoch 40  84.0% | batch:        79 of        94\t|\tloss: 1581.2\n",
      "Training Epoch 40  85.1% | batch:        80 of        94\t|\tloss: 1271.03\n",
      "Training Epoch 40  86.2% | batch:        81 of        94\t|\tloss: 1773.69\n",
      "Training Epoch 40  87.2% | batch:        82 of        94\t|\tloss: 1316.77\n",
      "Training Epoch 40  88.3% | batch:        83 of        94\t|\tloss: 2394.16\n",
      "Training Epoch 40  89.4% | batch:        84 of        94\t|\tloss: 1437.67\n",
      "Training Epoch 40  90.4% | batch:        85 of        94\t|\tloss: 1352.22\n",
      "Training Epoch 40  91.5% | batch:        86 of        94\t|\tloss: 1152.83\n",
      "Training Epoch 40  92.6% | batch:        87 of        94\t|\tloss: 2530.31\n",
      "Training Epoch 40  93.6% | batch:        88 of        94\t|\tloss: 2551.16\n",
      "Training Epoch 40  94.7% | batch:        89 of        94\t|\tloss: 1274.52\n",
      "Training Epoch 40  95.7% | batch:        90 of        94\t|\tloss: 1177.14\n",
      "Training Epoch 40  96.8% | batch:        91 of        94\t|\tloss: 1328.6\n",
      "Training Epoch 40  97.9% | batch:        92 of        94\t|\tloss: 2180.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:40,623 | INFO : Epoch 40 Training Summary: epoch: 40.000000 | loss: 1510.350383 | \n",
      "2023-05-09 14:21:40,623 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8514723777770996 seconds\n",
      "\n",
      "2023-05-09 14:21:40,624 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8290606439113617 seconds\n",
      "2023-05-09 14:21:40,624 | INFO : Avg batch train. time: 0.01945809195650385 seconds\n",
      "2023-05-09 14:21:40,625 | INFO : Avg sample train. time: 0.00015347043496487345 seconds\n",
      "2023-05-09 14:21:40,625 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 40  98.9% | batch:        93 of        94\t|\tloss: 2021.46\n",
      "\n",
      "Evaluating Epoch 40   0.0% | batch:         0 of        40\t|\tloss: 7187.83\n",
      "Evaluating Epoch 40   2.5% | batch:         1 of        40\t|\tloss: 1309.27\n",
      "Evaluating Epoch 40   5.0% | batch:         2 of        40\t|\tloss: 4630.02\n",
      "Evaluating Epoch 40   7.5% | batch:         3 of        40\t|\tloss: 7025.88\n",
      "Evaluating Epoch 40  10.0% | batch:         4 of        40\t|\tloss: 1856.16\n",
      "Evaluating Epoch 40  12.5% | batch:         5 of        40\t|\tloss: 1832.28\n",
      "Evaluating Epoch 40  15.0% | batch:         6 of        40\t|\tloss: 9008.28\n",
      "Evaluating Epoch 40  17.5% | batch:         7 of        40\t|\tloss: 2940.39\n",
      "Evaluating Epoch 40  20.0% | batch:         8 of        40\t|\tloss: 2996.46\n",
      "Evaluating Epoch 40  22.5% | batch:         9 of        40\t|\tloss: 2620.37\n",
      "Evaluating Epoch 40  25.0% | batch:        10 of        40\t|\tloss: 5010.08\n",
      "Evaluating Epoch 40  27.5% | batch:        11 of        40\t|\tloss: 1475.93\n",
      "Evaluating Epoch 40  30.0% | batch:        12 of        40\t|\tloss: 5505.8\n",
      "Evaluating Epoch 40  32.5% | batch:        13 of        40\t|\tloss: 3685.31\n",
      "Evaluating Epoch 40  35.0% | batch:        14 of        40\t|\tloss: 2018.21\n",
      "Evaluating Epoch 40  37.5% | batch:        15 of        40\t|\tloss: 3617.89\n",
      "Evaluating Epoch 40  40.0% | batch:        16 of        40\t|\tloss: 5044.68\n",
      "Evaluating Epoch 40  42.5% | batch:        17 of        40\t|\tloss: 2799.21\n",
      "Evaluating Epoch 40  45.0% | batch:        18 of        40\t|\tloss: 2152.97\n",
      "Evaluating Epoch 40  47.5% | batch:        19 of        40\t|\tloss: 6308.37\n",
      "Evaluating Epoch 40  50.0% | batch:        20 of        40\t|\tloss: 5089.84\n",
      "Evaluating Epoch 40  52.5% | batch:        21 of        40\t|\tloss: 1206.13\n",
      "Evaluating Epoch 40  55.0% | batch:        22 of        40\t|\tloss: 5739.69\n",
      "Evaluating Epoch 40  57.5% | batch:        23 of        40\t|\tloss: 3162.38\n",
      "Evaluating Epoch 40  60.0% | batch:        24 of        40\t|\tloss: 1570.14\n",
      "Evaluating Epoch 40  62.5% | batch:        25 of        40\t|\tloss: 3352.89\n",
      "Evaluating Epoch 40  65.0% | batch:        26 of        40\t|\tloss: 10401.7\n",
      "Evaluating Epoch 40  67.5% | batch:        27 of        40\t|\tloss: 3094.44\n",
      "Evaluating Epoch 40  70.0% | batch:        28 of        40\t|\tloss: 2269.4\n",
      "Evaluating Epoch 40  72.5% | batch:        29 of        40\t|\tloss: 9896.29\n",
      "Evaluating Epoch 40  75.0% | batch:        30 of        40\t|\tloss: 1887.87\n",
      "Evaluating Epoch 40  77.5% | batch:        31 of        40\t|\tloss: 2027.82\n",
      "Evaluating Epoch 40  80.0% | batch:        32 of        40\t|\tloss: 8330.57\n",
      "Evaluating Epoch 40  82.5% | batch:        33 of        40\t|\tloss: 6555.83\n",
      "Evaluating Epoch 40  85.0% | batch:        34 of        40\t|\tloss: 1244.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:41,081 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45580267906188965 seconds\n",
      "\n",
      "2023-05-09 14:21:41,082 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48838305473327637 seconds\n",
      "2023-05-09 14:21:41,082 | INFO : Avg batch val. time: 0.01220957636833191 seconds\n",
      "2023-05-09 14:21:41,083 | INFO : Avg sample val. time: 9.674783176174254e-05 seconds\n",
      "2023-05-09 14:21:41,083 | INFO : Epoch 40 Validation Summary: epoch: 40.000000 | loss: 4266.321182 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 40  87.5% | batch:        35 of        40\t|\tloss: 5991.72\n",
      "Evaluating Epoch 40  90.0% | batch:        36 of        40\t|\tloss: 6674.43\n",
      "Evaluating Epoch 40  92.5% | batch:        37 of        40\t|\tloss: 2673.5\n",
      "Evaluating Epoch 40  95.0% | batch:        38 of        40\t|\tloss: 3407.19\n",
      "Evaluating Epoch 40  97.5% | batch:        39 of        40\t|\tloss: 10630.7\n",
      "\n",
      "Training Epoch 41   0.0% | batch:         0 of        94\t|\tloss: 1071.63\n",
      "Training Epoch 41   1.1% | batch:         1 of        94\t|\tloss: 1294.38\n",
      "Training Epoch 41   2.1% | batch:         2 of        94\t|\tloss: 793.11\n",
      "Training Epoch 41   3.2% | batch:         3 of        94\t|\tloss: 896.063\n",
      "Training Epoch 41   4.3% | batch:         4 of        94\t|\tloss: 1780.61\n",
      "Training Epoch 41   5.3% | batch:         5 of        94\t|\tloss: 977.707\n",
      "Training Epoch 41   6.4% | batch:         6 of        94\t|\tloss: 1071.01\n",
      "Training Epoch 41   7.4% | batch:         7 of        94\t|\tloss: 1078.13\n",
      "Training Epoch 41   8.5% | batch:         8 of        94\t|\tloss: 1868.95\n",
      "Training Epoch 41   9.6% | batch:         9 of        94\t|\tloss: 1354.94\n",
      "Training Epoch 41  10.6% | batch:        10 of        94\t|\tloss: 3765.52\n",
      "Training Epoch 41  11.7% | batch:        11 of        94\t|\tloss: 1129.07\n",
      "Training Epoch 41  12.8% | batch:        12 of        94\t|\tloss: 1769.16\n",
      "Training Epoch 41  13.8% | batch:        13 of        94\t|\tloss: 866.349\n",
      "Training Epoch 41  14.9% | batch:        14 of        94\t|\tloss: 1284.28\n",
      "Training Epoch 41  16.0% | batch:        15 of        94\t|\tloss: 1215.09\n",
      "Training Epoch 41  17.0% | batch:        16 of        94\t|\tloss: 1001.62\n",
      "Training Epoch 41  18.1% | batch:        17 of        94\t|\tloss: 1344.06\n",
      "Training Epoch 41  19.1% | batch:        18 of        94\t|\tloss: 1212.96\n",
      "Training Epoch 41  20.2% | batch:        19 of        94\t|\tloss: 1570.56\n",
      "Training Epoch 41  21.3% | batch:        20 of        94\t|\tloss: 1210.05\n",
      "Training Epoch 41  22.3% | batch:        21 of        94\t|\tloss: 1143.71\n",
      "Training Epoch 41  23.4% | batch:        22 of        94\t|\tloss: 1501.56\n",
      "Training Epoch 41  24.5% | batch:        23 of        94\t|\tloss: 854.85\n",
      "Training Epoch 41  25.5% | batch:        24 of        94\t|\tloss: 1233.26\n",
      "Training Epoch 41  26.6% | batch:        25 of        94\t|\tloss: 1366.25\n",
      "Training Epoch 41  27.7% | batch:        26 of        94\t|\tloss: 1547.78\n",
      "Training Epoch 41  28.7% | batch:        27 of        94\t|\tloss: 2009.31\n",
      "Training Epoch 41  29.8% | batch:        28 of        94\t|\tloss: 1249.22\n",
      "Training Epoch 41  30.9% | batch:        29 of        94\t|\tloss: 980.268\n",
      "Training Epoch 41  31.9% | batch:        30 of        94\t|\tloss: 1970.38\n",
      "Training Epoch 41  33.0% | batch:        31 of        94\t|\tloss: 1404.97\n",
      "Training Epoch 41  34.0% | batch:        32 of        94\t|\tloss: 1840.2\n",
      "Training Epoch 41  35.1% | batch:        33 of        94\t|\tloss: 1369.15\n",
      "Training Epoch 41  36.2% | batch:        34 of        94\t|\tloss: 3039.34\n",
      "Training Epoch 41  37.2% | batch:        35 of        94\t|\tloss: 819.003\n",
      "Training Epoch 41  38.3% | batch:        36 of        94\t|\tloss: 925.041\n",
      "Training Epoch 41  39.4% | batch:        37 of        94\t|\tloss: 1666.8\n",
      "Training Epoch 41  40.4% | batch:        38 of        94\t|\tloss: 2399.49\n",
      "Training Epoch 41  41.5% | batch:        39 of        94\t|\tloss: 1388.06\n",
      "Training Epoch 41  42.6% | batch:        40 of        94\t|\tloss: 2054.67\n",
      "Training Epoch 41  43.6% | batch:        41 of        94\t|\tloss: 1033.65\n",
      "Training Epoch 41  44.7% | batch:        42 of        94\t|\tloss: 1498.39\n",
      "Training Epoch 41  45.7% | batch:        43 of        94\t|\tloss: 1172.89\n",
      "Training Epoch 41  46.8% | batch:        44 of        94\t|\tloss: 1363.68\n",
      "Training Epoch 41  47.9% | batch:        45 of        94\t|\tloss: 901.61\n",
      "Training Epoch 41  48.9% | batch:        46 of        94\t|\tloss: 1158.95\n",
      "Training Epoch 41  50.0% | batch:        47 of        94\t|\tloss: 1617.99\n",
      "Training Epoch 41  51.1% | batch:        48 of        94\t|\tloss: 1108.73\n",
      "Training Epoch 41  52.1% | batch:        49 of        94\t|\tloss: 1458.92\n",
      "Training Epoch 41  53.2% | batch:        50 of        94\t|\tloss: 2077.71\n",
      "Training Epoch 41  54.3% | batch:        51 of        94\t|\tloss: 1433.72\n",
      "Training Epoch 41  55.3% | batch:        52 of        94\t|\tloss: 820.329\n",
      "Training Epoch 41  56.4% | batch:        53 of        94\t|\tloss: 2240.98\n",
      "Training Epoch 41  57.4% | batch:        54 of        94\t|\tloss: 1331.25\n",
      "Training Epoch 41  58.5% | batch:        55 of        94\t|\tloss: 1368.76\n",
      "Training Epoch 41  59.6% | batch:        56 of        94\t|\tloss: 3395.65\n",
      "Training Epoch 41  60.6% | batch:        57 of        94\t|\tloss: 1721.79\n",
      "Training Epoch 41  61.7% | batch:        58 of        94\t|\tloss: 1711.78\n",
      "Training Epoch 41  62.8% | batch:        59 of        94\t|\tloss: 1469.42\n",
      "Training Epoch 41  63.8% | batch:        60 of        94\t|\tloss: 1327.75\n",
      "Training Epoch 41  64.9% | batch:        61 of        94\t|\tloss: 1353.48\n",
      "Training Epoch 41  66.0% | batch:        62 of        94\t|\tloss: 2931.95\n",
      "Training Epoch 41  67.0% | batch:        63 of        94\t|\tloss: 1985.94\n",
      "Training Epoch 41  68.1% | batch:        64 of        94\t|\tloss: 1324.98\n",
      "Training Epoch 41  69.1% | batch:        65 of        94\t|\tloss: 1300.41\n",
      "Training Epoch 41  70.2% | batch:        66 of        94\t|\tloss: 1409.34\n",
      "Training Epoch 41  71.3% | batch:        67 of        94\t|\tloss: 1512.89\n",
      "Training Epoch 41  72.3% | batch:        68 of        94\t|\tloss: 1298.36\n",
      "Training Epoch 41  73.4% | batch:        69 of        94\t|\tloss: 2068.86\n",
      "Training Epoch 41  74.5% | batch:        70 of        94\t|\tloss: 1486.72\n",
      "Training Epoch 41  75.5% | batch:        71 of        94\t|\tloss: 1344.3\n",
      "Training Epoch 41  76.6% | batch:        72 of        94\t|\tloss: 2086.76\n",
      "Training Epoch 41  77.7% | batch:        73 of        94\t|\tloss: 1898.67\n",
      "Training Epoch 41  78.7% | batch:        74 of        94\t|\tloss: 1676.88\n",
      "Training Epoch 41  79.8% | batch:        75 of        94\t|\tloss: 1109.83\n",
      "Training Epoch 41  80.9% | batch:        76 of        94\t|\tloss: 1461.46\n",
      "Training Epoch 41  81.9% | batch:        77 of        94\t|\tloss: 999.016\n",
      "Training Epoch 41  83.0% | batch:        78 of        94\t|\tloss: 1072.44\n",
      "Training Epoch 41  84.0% | batch:        79 of        94\t|\tloss: 1107.29\n",
      "Training Epoch 41  85.1% | batch:        80 of        94\t|\tloss: 1745.1\n",
      "Training Epoch 41  86.2% | batch:        81 of        94\t|\tloss: 1202.54\n",
      "Training Epoch 41  87.2% | batch:        82 of        94\t|\tloss: 1377.2\n",
      "Training Epoch 41  88.3% | batch:        83 of        94\t|\tloss: 1046.56\n",
      "Training Epoch 41  89.4% | batch:        84 of        94\t|\tloss: 1090.7\n",
      "Training Epoch 41  90.4% | batch:        85 of        94\t|\tloss: 1418.76\n",
      "Training Epoch 41  91.5% | batch:        86 of        94\t|\tloss: 1108.01\n",
      "Training Epoch 41  92.6% | batch:        87 of        94\t|\tloss: 855.528\n",
      "Training Epoch 41  93.6% | batch:        88 of        94\t|\tloss: 1329.59\n",
      "Training Epoch 41  94.7% | batch:        89 of        94\t|\tloss: 1447\n",
      "Training Epoch 41  95.7% | batch:        90 of        94\t|\tloss: 1194.9\n",
      "Training Epoch 41  96.8% | batch:        91 of        94\t|\tloss: 1127.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:42,935 | INFO : Epoch 41 Training Summary: epoch: 41.000000 | loss: 1458.027415 | \n",
      "2023-05-09 14:21:42,936 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.838867425918579 seconds\n",
      "\n",
      "2023-05-09 14:21:42,936 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8292998337164157 seconds\n",
      "2023-05-09 14:21:42,937 | INFO : Avg batch train. time: 0.01946063652889804 seconds\n",
      "2023-05-09 14:21:42,937 | INFO : Avg sample train. time: 0.00015349050459107365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 41  97.9% | batch:        92 of        94\t|\tloss: 1695.02\n",
      "Training Epoch 41  98.9% | batch:        93 of        94\t|\tloss: 1422.68\n",
      "\n",
      "Training Epoch 42   0.0% | batch:         0 of        94\t|\tloss: 1297.41\n",
      "Training Epoch 42   1.1% | batch:         1 of        94\t|\tloss: 1281.84\n",
      "Training Epoch 42   2.1% | batch:         2 of        94\t|\tloss: 3550.84\n",
      "Training Epoch 42   3.2% | batch:         3 of        94\t|\tloss: 1877.13\n",
      "Training Epoch 42   4.3% | batch:         4 of        94\t|\tloss: 1113.46\n",
      "Training Epoch 42   5.3% | batch:         5 of        94\t|\tloss: 3280.33\n",
      "Training Epoch 42   6.4% | batch:         6 of        94\t|\tloss: 1110.33\n",
      "Training Epoch 42   7.4% | batch:         7 of        94\t|\tloss: 1354.96\n",
      "Training Epoch 42   8.5% | batch:         8 of        94\t|\tloss: 1567.75\n",
      "Training Epoch 42   9.6% | batch:         9 of        94\t|\tloss: 818.519\n",
      "Training Epoch 42  10.6% | batch:        10 of        94\t|\tloss: 976.269\n",
      "Training Epoch 42  11.7% | batch:        11 of        94\t|\tloss: 1171.44\n",
      "Training Epoch 42  12.8% | batch:        12 of        94\t|\tloss: 1156.33\n",
      "Training Epoch 42  13.8% | batch:        13 of        94\t|\tloss: 1065.75\n",
      "Training Epoch 42  14.9% | batch:        14 of        94\t|\tloss: 934.092\n",
      "Training Epoch 42  16.0% | batch:        15 of        94\t|\tloss: 2102.76\n",
      "Training Epoch 42  17.0% | batch:        16 of        94\t|\tloss: 1061.34\n",
      "Training Epoch 42  18.1% | batch:        17 of        94\t|\tloss: 1273.25\n",
      "Training Epoch 42  19.1% | batch:        18 of        94\t|\tloss: 1716.2\n",
      "Training Epoch 42  20.2% | batch:        19 of        94\t|\tloss: 2351.26\n",
      "Training Epoch 42  21.3% | batch:        20 of        94\t|\tloss: 1580.01\n",
      "Training Epoch 42  22.3% | batch:        21 of        94\t|\tloss: 1592.1\n",
      "Training Epoch 42  23.4% | batch:        22 of        94\t|\tloss: 1149.6\n",
      "Training Epoch 42  24.5% | batch:        23 of        94\t|\tloss: 1095.21\n",
      "Training Epoch 42  25.5% | batch:        24 of        94\t|\tloss: 2118.14\n",
      "Training Epoch 42  26.6% | batch:        25 of        94\t|\tloss: 987.645\n",
      "Training Epoch 42  27.7% | batch:        26 of        94\t|\tloss: 1466.73\n",
      "Training Epoch 42  28.7% | batch:        27 of        94\t|\tloss: 1440.96\n",
      "Training Epoch 42  29.8% | batch:        28 of        94\t|\tloss: 1487.98\n",
      "Training Epoch 42  30.9% | batch:        29 of        94\t|\tloss: 2906.94\n",
      "Training Epoch 42  31.9% | batch:        30 of        94\t|\tloss: 1585.29\n",
      "Training Epoch 42  33.0% | batch:        31 of        94\t|\tloss: 1695.37\n",
      "Training Epoch 42  34.0% | batch:        32 of        94\t|\tloss: 881.747\n",
      "Training Epoch 42  35.1% | batch:        33 of        94\t|\tloss: 1097.8\n",
      "Training Epoch 42  36.2% | batch:        34 of        94\t|\tloss: 1317.28\n",
      "Training Epoch 42  37.2% | batch:        35 of        94\t|\tloss: 1133.18\n",
      "Training Epoch 42  38.3% | batch:        36 of        94\t|\tloss: 906.354\n",
      "Training Epoch 42  39.4% | batch:        37 of        94\t|\tloss: 1230.56\n",
      "Training Epoch 42  40.4% | batch:        38 of        94\t|\tloss: 1167.68\n",
      "Training Epoch 42  41.5% | batch:        39 of        94\t|\tloss: 1019.96\n",
      "Training Epoch 42  42.6% | batch:        40 of        94\t|\tloss: 1016.86\n",
      "Training Epoch 42  43.6% | batch:        41 of        94\t|\tloss: 1086.96\n",
      "Training Epoch 42  44.7% | batch:        42 of        94\t|\tloss: 2221.66\n",
      "Training Epoch 42  45.7% | batch:        43 of        94\t|\tloss: 2061.98\n",
      "Training Epoch 42  46.8% | batch:        44 of        94\t|\tloss: 1104.43\n",
      "Training Epoch 42  47.9% | batch:        45 of        94\t|\tloss: 857.883\n",
      "Training Epoch 42  48.9% | batch:        46 of        94\t|\tloss: 1891.7\n",
      "Training Epoch 42  50.0% | batch:        47 of        94\t|\tloss: 1310.44\n",
      "Training Epoch 42  51.1% | batch:        48 of        94\t|\tloss: 1606.23\n",
      "Training Epoch 42  52.1% | batch:        49 of        94\t|\tloss: 1276.94\n",
      "Training Epoch 42  53.2% | batch:        50 of        94\t|\tloss: 1001.77\n",
      "Training Epoch 42  54.3% | batch:        51 of        94\t|\tloss: 1250.88\n",
      "Training Epoch 42  55.3% | batch:        52 of        94\t|\tloss: 882.605\n",
      "Training Epoch 42  56.4% | batch:        53 of        94\t|\tloss: 1797.09\n",
      "Training Epoch 42  57.4% | batch:        54 of        94\t|\tloss: 2405.92\n",
      "Training Epoch 42  58.5% | batch:        55 of        94\t|\tloss: 1043.79\n",
      "Training Epoch 42  59.6% | batch:        56 of        94\t|\tloss: 1986.58\n",
      "Training Epoch 42  60.6% | batch:        57 of        94\t|\tloss: 1470.81\n",
      "Training Epoch 42  61.7% | batch:        58 of        94\t|\tloss: 1539.34\n",
      "Training Epoch 42  62.8% | batch:        59 of        94\t|\tloss: 1442.8\n",
      "Training Epoch 42  63.8% | batch:        60 of        94\t|\tloss: 1377.55\n",
      "Training Epoch 42  64.9% | batch:        61 of        94\t|\tloss: 1103.09\n",
      "Training Epoch 42  66.0% | batch:        62 of        94\t|\tloss: 1096.47\n",
      "Training Epoch 42  67.0% | batch:        63 of        94\t|\tloss: 1130.69\n",
      "Training Epoch 42  68.1% | batch:        64 of        94\t|\tloss: 1041.2\n",
      "Training Epoch 42  69.1% | batch:        65 of        94\t|\tloss: 1040.13\n",
      "Training Epoch 42  70.2% | batch:        66 of        94\t|\tloss: 1088.32\n",
      "Training Epoch 42  71.3% | batch:        67 of        94\t|\tloss: 1393.77\n",
      "Training Epoch 42  72.3% | batch:        68 of        94\t|\tloss: 1032.01\n",
      "Training Epoch 42  73.4% | batch:        69 of        94\t|\tloss: 1063.35\n",
      "Training Epoch 42  74.5% | batch:        70 of        94\t|\tloss: 982.275\n",
      "Training Epoch 42  75.5% | batch:        71 of        94\t|\tloss: 1400.67\n",
      "Training Epoch 42  76.6% | batch:        72 of        94\t|\tloss: 961.099\n",
      "Training Epoch 42  77.7% | batch:        73 of        94\t|\tloss: 836.059\n",
      "Training Epoch 42  78.7% | batch:        74 of        94\t|\tloss: 1087.7\n",
      "Training Epoch 42  79.8% | batch:        75 of        94\t|\tloss: 1221.02\n",
      "Training Epoch 42  80.9% | batch:        76 of        94\t|\tloss: 1399.23\n",
      "Training Epoch 42  81.9% | batch:        77 of        94\t|\tloss: 1566.02\n",
      "Training Epoch 42  83.0% | batch:        78 of        94\t|\tloss: 3870.47\n",
      "Training Epoch 42  84.0% | batch:        79 of        94\t|\tloss: 1575.67\n",
      "Training Epoch 42  85.1% | batch:        80 of        94\t|\tloss: 1481.61\n",
      "Training Epoch 42  86.2% | batch:        81 of        94\t|\tloss: 1589.71\n",
      "Training Epoch 42  87.2% | batch:        82 of        94\t|\tloss: 920.205\n",
      "Training Epoch 42  88.3% | batch:        83 of        94\t|\tloss: 1117.66\n",
      "Training Epoch 42  89.4% | batch:        84 of        94\t|\tloss: 885.67\n",
      "Training Epoch 42  90.4% | batch:        85 of        94\t|\tloss: 2554.72\n",
      "Training Epoch 42  91.5% | batch:        86 of        94\t|\tloss: 975.283\n",
      "Training Epoch 42  92.6% | batch:        87 of        94\t|\tloss: 1057.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:44,794 | INFO : Epoch 42 Training Summary: epoch: 42.000000 | loss: 1423.555139 | \n",
      "2023-05-09 14:21:44,795 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8359766006469727 seconds\n",
      "\n",
      "2023-05-09 14:21:44,796 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8294588043576194 seconds\n",
      "2023-05-09 14:21:44,796 | INFO : Avg batch train. time: 0.019462327705932123 seconds\n",
      "2023-05-09 14:21:44,797 | INFO : Avg sample train. time: 0.00015350384329229898 seconds\n",
      "2023-05-09 14:21:44,797 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 42  93.6% | batch:        88 of        94\t|\tloss: 1801.92\n",
      "Training Epoch 42  94.7% | batch:        89 of        94\t|\tloss: 1642.79\n",
      "Training Epoch 42  95.7% | batch:        90 of        94\t|\tloss: 1807.24\n",
      "Training Epoch 42  96.8% | batch:        91 of        94\t|\tloss: 927.033\n",
      "Training Epoch 42  97.9% | batch:        92 of        94\t|\tloss: 1242.71\n",
      "Training Epoch 42  98.9% | batch:        93 of        94\t|\tloss: 890.465\n",
      "\n",
      "Evaluating Epoch 42   0.0% | batch:         0 of        40\t|\tloss: 7454.08\n",
      "Evaluating Epoch 42   2.5% | batch:         1 of        40\t|\tloss: 1028.61\n",
      "Evaluating Epoch 42   5.0% | batch:         2 of        40\t|\tloss: 2802.54\n",
      "Evaluating Epoch 42   7.5% | batch:         3 of        40\t|\tloss: 6507.16\n",
      "Evaluating Epoch 42  10.0% | batch:         4 of        40\t|\tloss: 2596.76\n",
      "Evaluating Epoch 42  12.5% | batch:         5 of        40\t|\tloss: 2127.35\n",
      "Evaluating Epoch 42  15.0% | batch:         6 of        40\t|\tloss: 7835.64\n",
      "Evaluating Epoch 42  17.5% | batch:         7 of        40\t|\tloss: 2890.3\n",
      "Evaluating Epoch 42  20.0% | batch:         8 of        40\t|\tloss: 2821.64\n",
      "Evaluating Epoch 42  22.5% | batch:         9 of        40\t|\tloss: 1564.81\n",
      "Evaluating Epoch 42  25.0% | batch:        10 of        40\t|\tloss: 4800.16\n",
      "Evaluating Epoch 42  27.5% | batch:        11 of        40\t|\tloss: 1391.64\n",
      "Evaluating Epoch 42  30.0% | batch:        12 of        40\t|\tloss: 6441.32\n",
      "Evaluating Epoch 42  32.5% | batch:        13 of        40\t|\tloss: 3730.59\n",
      "Evaluating Epoch 42  35.0% | batch:        14 of        40\t|\tloss: 1827.95\n",
      "Evaluating Epoch 42  37.5% | batch:        15 of        40\t|\tloss: 3243.65\n",
      "Evaluating Epoch 42  40.0% | batch:        16 of        40\t|\tloss: 4019.11\n",
      "Evaluating Epoch 42  42.5% | batch:        17 of        40\t|\tloss: 2630.1\n",
      "Evaluating Epoch 42  45.0% | batch:        18 of        40\t|\tloss: 2267.99\n",
      "Evaluating Epoch 42  47.5% | batch:        19 of        40\t|\tloss: 5444.59\n",
      "Evaluating Epoch 42  50.0% | batch:        20 of        40\t|\tloss: 5160.59\n",
      "Evaluating Epoch 42  52.5% | batch:        21 of        40\t|\tloss: 1265.23\n",
      "Evaluating Epoch 42  55.0% | batch:        22 of        40\t|\tloss: 3102.05\n",
      "Evaluating Epoch 42  57.5% | batch:        23 of        40\t|\tloss: 3535.91\n",
      "Evaluating Epoch 42  60.0% | batch:        24 of        40\t|\tloss: 1391.12\n",
      "Evaluating Epoch 42  62.5% | batch:        25 of        40\t|\tloss: 3198.15\n",
      "Evaluating Epoch 42  65.0% | batch:        26 of        40\t|\tloss: 10485.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:45,256 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4579653739929199 seconds\n",
      "\n",
      "2023-05-09 14:21:45,256 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.487060546875 seconds\n",
      "2023-05-09 14:21:45,257 | INFO : Avg batch val. time: 0.012176513671875 seconds\n",
      "2023-05-09 14:21:45,257 | INFO : Avg sample val. time: 9.64858452604992e-05 seconds\n",
      "2023-05-09 14:21:45,257 | INFO : Epoch 42 Validation Summary: epoch: 42.000000 | loss: 3928.913194 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 42  67.5% | batch:        27 of        40\t|\tloss: 2741.83\n",
      "Evaluating Epoch 42  70.0% | batch:        28 of        40\t|\tloss: 1906.85\n",
      "Evaluating Epoch 42  72.5% | batch:        29 of        40\t|\tloss: 9190.43\n",
      "Evaluating Epoch 42  75.0% | batch:        30 of        40\t|\tloss: 1707.06\n",
      "Evaluating Epoch 42  77.5% | batch:        31 of        40\t|\tloss: 1405.9\n",
      "Evaluating Epoch 42  80.0% | batch:        32 of        40\t|\tloss: 6463.91\n",
      "Evaluating Epoch 42  82.5% | batch:        33 of        40\t|\tloss: 6580.96\n",
      "Evaluating Epoch 42  85.0% | batch:        34 of        40\t|\tloss: 1007.9\n",
      "Evaluating Epoch 42  87.5% | batch:        35 of        40\t|\tloss: 4641.17\n",
      "Evaluating Epoch 42  90.0% | batch:        36 of        40\t|\tloss: 6830.02\n",
      "Evaluating Epoch 42  92.5% | batch:        37 of        40\t|\tloss: 2410.49\n",
      "Evaluating Epoch 42  95.0% | batch:        38 of        40\t|\tloss: 3363.17\n",
      "Evaluating Epoch 42  97.5% | batch:        39 of        40\t|\tloss: 11730.2\n",
      "\n",
      "Training Epoch 43   0.0% | batch:         0 of        94\t|\tloss: 1536.99\n",
      "Training Epoch 43   1.1% | batch:         1 of        94\t|\tloss: 1125.66\n",
      "Training Epoch 43   2.1% | batch:         2 of        94\t|\tloss: 1718.2\n",
      "Training Epoch 43   3.2% | batch:         3 of        94\t|\tloss: 1070.16\n",
      "Training Epoch 43   4.3% | batch:         4 of        94\t|\tloss: 1081.27\n",
      "Training Epoch 43   5.3% | batch:         5 of        94\t|\tloss: 720.535\n",
      "Training Epoch 43   6.4% | batch:         6 of        94\t|\tloss: 1182.4\n",
      "Training Epoch 43   7.4% | batch:         7 of        94\t|\tloss: 1046.22\n",
      "Training Epoch 43   8.5% | batch:         8 of        94\t|\tloss: 907.51\n",
      "Training Epoch 43   9.6% | batch:         9 of        94\t|\tloss: 1223.03\n",
      "Training Epoch 43  10.6% | batch:        10 of        94\t|\tloss: 1012.79\n",
      "Training Epoch 43  11.7% | batch:        11 of        94\t|\tloss: 2513.32\n",
      "Training Epoch 43  12.8% | batch:        12 of        94\t|\tloss: 929.508\n",
      "Training Epoch 43  13.8% | batch:        13 of        94\t|\tloss: 1702.49\n",
      "Training Epoch 43  14.9% | batch:        14 of        94\t|\tloss: 1770.6\n",
      "Training Epoch 43  16.0% | batch:        15 of        94\t|\tloss: 2863.5\n",
      "Training Epoch 43  17.0% | batch:        16 of        94\t|\tloss: 859.871\n",
      "Training Epoch 43  18.1% | batch:        17 of        94\t|\tloss: 1153.31\n",
      "Training Epoch 43  19.1% | batch:        18 of        94\t|\tloss: 1141.76\n",
      "Training Epoch 43  20.2% | batch:        19 of        94\t|\tloss: 1326.91\n",
      "Training Epoch 43  21.3% | batch:        20 of        94\t|\tloss: 1737.88\n",
      "Training Epoch 43  22.3% | batch:        21 of        94\t|\tloss: 1008.43\n",
      "Training Epoch 43  23.4% | batch:        22 of        94\t|\tloss: 1260.63\n",
      "Training Epoch 43  24.5% | batch:        23 of        94\t|\tloss: 1325.26\n",
      "Training Epoch 43  25.5% | batch:        24 of        94\t|\tloss: 1720.98\n",
      "Training Epoch 43  26.6% | batch:        25 of        94\t|\tloss: 1363.52\n",
      "Training Epoch 43  27.7% | batch:        26 of        94\t|\tloss: 1261.52\n",
      "Training Epoch 43  28.7% | batch:        27 of        94\t|\tloss: 3148.5\n",
      "Training Epoch 43  29.8% | batch:        28 of        94\t|\tloss: 939.991\n",
      "Training Epoch 43  30.9% | batch:        29 of        94\t|\tloss: 1215.5\n",
      "Training Epoch 43  31.9% | batch:        30 of        94\t|\tloss: 1286.46\n",
      "Training Epoch 43  33.0% | batch:        31 of        94\t|\tloss: 1034.4\n",
      "Training Epoch 43  34.0% | batch:        32 of        94\t|\tloss: 987.64\n",
      "Training Epoch 43  35.1% | batch:        33 of        94\t|\tloss: 1225.35\n",
      "Training Epoch 43  36.2% | batch:        34 of        94\t|\tloss: 1380.71\n",
      "Training Epoch 43  37.2% | batch:        35 of        94\t|\tloss: 785.177\n",
      "Training Epoch 43  38.3% | batch:        36 of        94\t|\tloss: 1168.15\n",
      "Training Epoch 43  39.4% | batch:        37 of        94\t|\tloss: 1457.91\n",
      "Training Epoch 43  40.4% | batch:        38 of        94\t|\tloss: 1036.66\n",
      "Training Epoch 43  41.5% | batch:        39 of        94\t|\tloss: 1001.63\n",
      "Training Epoch 43  42.6% | batch:        40 of        94\t|\tloss: 1088.33\n",
      "Training Epoch 43  43.6% | batch:        41 of        94\t|\tloss: 1621.48\n",
      "Training Epoch 43  44.7% | batch:        42 of        94\t|\tloss: 987.201\n",
      "Training Epoch 43  45.7% | batch:        43 of        94\t|\tloss: 1283.04\n",
      "Training Epoch 43  46.8% | batch:        44 of        94\t|\tloss: 754.269\n",
      "Training Epoch 43  47.9% | batch:        45 of        94\t|\tloss: 1078.63\n",
      "Training Epoch 43  48.9% | batch:        46 of        94\t|\tloss: 1107.27\n",
      "Training Epoch 43  50.0% | batch:        47 of        94\t|\tloss: 2364.98\n",
      "Training Epoch 43  51.1% | batch:        48 of        94\t|\tloss: 1345.64\n",
      "Training Epoch 43  52.1% | batch:        49 of        94\t|\tloss: 3298.38\n",
      "Training Epoch 43  53.2% | batch:        50 of        94\t|\tloss: 2196.52\n",
      "Training Epoch 43  54.3% | batch:        51 of        94\t|\tloss: 2135.3\n",
      "Training Epoch 43  55.3% | batch:        52 of        94\t|\tloss: 1399.5\n",
      "Training Epoch 43  56.4% | batch:        53 of        94\t|\tloss: 1695.77\n",
      "Training Epoch 43  57.4% | batch:        54 of        94\t|\tloss: 932.257\n",
      "Training Epoch 43  58.5% | batch:        55 of        94\t|\tloss: 1266.76\n",
      "Training Epoch 43  59.6% | batch:        56 of        94\t|\tloss: 1121.86\n",
      "Training Epoch 43  60.6% | batch:        57 of        94\t|\tloss: 1007.86\n",
      "Training Epoch 43  61.7% | batch:        58 of        94\t|\tloss: 983.318\n",
      "Training Epoch 43  62.8% | batch:        59 of        94\t|\tloss: 1280.42\n",
      "Training Epoch 43  63.8% | batch:        60 of        94\t|\tloss: 1547.6\n",
      "Training Epoch 43  64.9% | batch:        61 of        94\t|\tloss: 2062.27\n",
      "Training Epoch 43  66.0% | batch:        62 of        94\t|\tloss: 1054.23\n",
      "Training Epoch 43  67.0% | batch:        63 of        94\t|\tloss: 1397.47\n",
      "Training Epoch 43  68.1% | batch:        64 of        94\t|\tloss: 1373.46\n",
      "Training Epoch 43  69.1% | batch:        65 of        94\t|\tloss: 735.653\n",
      "Training Epoch 43  70.2% | batch:        66 of        94\t|\tloss: 1564.51\n",
      "Training Epoch 43  71.3% | batch:        67 of        94\t|\tloss: 1688.53\n",
      "Training Epoch 43  72.3% | batch:        68 of        94\t|\tloss: 1401\n",
      "Training Epoch 43  73.4% | batch:        69 of        94\t|\tloss: 1194.64\n",
      "Training Epoch 43  74.5% | batch:        70 of        94\t|\tloss: 1782.09\n",
      "Training Epoch 43  75.5% | batch:        71 of        94\t|\tloss: 2198.65\n",
      "Training Epoch 43  76.6% | batch:        72 of        94\t|\tloss: 1025.93\n",
      "Training Epoch 43  77.7% | batch:        73 of        94\t|\tloss: 1557.63\n",
      "Training Epoch 43  78.7% | batch:        74 of        94\t|\tloss: 3264.22\n",
      "Training Epoch 43  79.8% | batch:        75 of        94\t|\tloss: 1123.4\n",
      "Training Epoch 43  80.9% | batch:        76 of        94\t|\tloss: 1050.17\n",
      "Training Epoch 43  81.9% | batch:        77 of        94\t|\tloss: 1148\n",
      "Training Epoch 43  83.0% | batch:        78 of        94\t|\tloss: 1703.24\n",
      "Training Epoch 43  84.0% | batch:        79 of        94\t|\tloss: 1618.25\n",
      "Training Epoch 43  85.1% | batch:        80 of        94\t|\tloss: 1787.38\n",
      "Training Epoch 43  86.2% | batch:        81 of        94\t|\tloss: 1099.8\n",
      "Training Epoch 43  87.2% | batch:        82 of        94\t|\tloss: 1338.78\n",
      "Training Epoch 43  88.3% | batch:        83 of        94\t|\tloss: 1229.08\n",
      "Training Epoch 43  89.4% | batch:        84 of        94\t|\tloss: 1720.71\n",
      "Training Epoch 43  90.4% | batch:        85 of        94\t|\tloss: 2823.7\n",
      "Training Epoch 43  91.5% | batch:        86 of        94\t|\tloss: 2908.27\n",
      "Training Epoch 43  92.6% | batch:        87 of        94\t|\tloss: 1132.16\n",
      "Training Epoch 43  93.6% | batch:        88 of        94\t|\tloss: 1151.49\n",
      "Training Epoch 43  94.7% | batch:        89 of        94\t|\tloss: 1934.53\n",
      "Training Epoch 43  95.7% | batch:        90 of        94\t|\tloss: 1255.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:47,108 | INFO : Epoch 43 Training Summary: epoch: 43.000000 | loss: 1438.488922 | \n",
      "2023-05-09 14:21:47,109 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8294572830200195 seconds\n",
      "\n",
      "2023-05-09 14:21:47,109 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8294587689776753 seconds\n",
      "2023-05-09 14:21:47,110 | INFO : Avg batch train. time: 0.019462327329549736 seconds\n",
      "2023-05-09 14:21:47,111 | INFO : Avg sample train. time: 0.00015350384032368478 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 43  96.8% | batch:        91 of        94\t|\tloss: 1278.36\n",
      "Training Epoch 43  97.9% | batch:        92 of        94\t|\tloss: 1485.49\n",
      "Training Epoch 43  98.9% | batch:        93 of        94\t|\tloss: 1096.04\n",
      "\n",
      "Training Epoch 44   0.0% | batch:         0 of        94\t|\tloss: 1259.55\n",
      "Training Epoch 44   1.1% | batch:         1 of        94\t|\tloss: 3034.73\n",
      "Training Epoch 44   2.1% | batch:         2 of        94\t|\tloss: 1134.59\n",
      "Training Epoch 44   3.2% | batch:         3 of        94\t|\tloss: 1729.19\n",
      "Training Epoch 44   4.3% | batch:         4 of        94\t|\tloss: 1778.49\n",
      "Training Epoch 44   5.3% | batch:         5 of        94\t|\tloss: 1407.02\n",
      "Training Epoch 44   6.4% | batch:         6 of        94\t|\tloss: 1193.05\n",
      "Training Epoch 44   7.4% | batch:         7 of        94\t|\tloss: 1926.01\n",
      "Training Epoch 44   8.5% | batch:         8 of        94\t|\tloss: 1359.69\n",
      "Training Epoch 44   9.6% | batch:         9 of        94\t|\tloss: 1318.68\n",
      "Training Epoch 44  10.6% | batch:        10 of        94\t|\tloss: 1352.88\n",
      "Training Epoch 44  11.7% | batch:        11 of        94\t|\tloss: 956.798\n",
      "Training Epoch 44  12.8% | batch:        12 of        94\t|\tloss: 1514.93\n",
      "Training Epoch 44  13.8% | batch:        13 of        94\t|\tloss: 990.142\n",
      "Training Epoch 44  14.9% | batch:        14 of        94\t|\tloss: 2273.35\n",
      "Training Epoch 44  16.0% | batch:        15 of        94\t|\tloss: 1562.6\n",
      "Training Epoch 44  17.0% | batch:        16 of        94\t|\tloss: 846.421\n",
      "Training Epoch 44  18.1% | batch:        17 of        94\t|\tloss: 908.444\n",
      "Training Epoch 44  19.1% | batch:        18 of        94\t|\tloss: 1205.57\n",
      "Training Epoch 44  20.2% | batch:        19 of        94\t|\tloss: 1476.47\n",
      "Training Epoch 44  21.3% | batch:        20 of        94\t|\tloss: 1727.68\n",
      "Training Epoch 44  22.3% | batch:        21 of        94\t|\tloss: 1478.41\n",
      "Training Epoch 44  23.4% | batch:        22 of        94\t|\tloss: 709.577\n",
      "Training Epoch 44  24.5% | batch:        23 of        94\t|\tloss: 1056.95\n",
      "Training Epoch 44  25.5% | batch:        24 of        94\t|\tloss: 1177.17\n",
      "Training Epoch 44  26.6% | batch:        25 of        94\t|\tloss: 1955.02\n",
      "Training Epoch 44  27.7% | batch:        26 of        94\t|\tloss: 934.583\n",
      "Training Epoch 44  28.7% | batch:        27 of        94\t|\tloss: 1840.61\n",
      "Training Epoch 44  29.8% | batch:        28 of        94\t|\tloss: 1281.45\n",
      "Training Epoch 44  30.9% | batch:        29 of        94\t|\tloss: 2513.28\n",
      "Training Epoch 44  31.9% | batch:        30 of        94\t|\tloss: 1279.37\n",
      "Training Epoch 44  33.0% | batch:        31 of        94\t|\tloss: 1061.5\n",
      "Training Epoch 44  34.0% | batch:        32 of        94\t|\tloss: 1601.79\n",
      "Training Epoch 44  35.1% | batch:        33 of        94\t|\tloss: 1023.7\n",
      "Training Epoch 44  36.2% | batch:        34 of        94\t|\tloss: 1171.99\n",
      "Training Epoch 44  37.2% | batch:        35 of        94\t|\tloss: 1095.73\n",
      "Training Epoch 44  38.3% | batch:        36 of        94\t|\tloss: 2855.29\n",
      "Training Epoch 44  39.4% | batch:        37 of        94\t|\tloss: 1236.25\n",
      "Training Epoch 44  40.4% | batch:        38 of        94\t|\tloss: 2988.98\n",
      "Training Epoch 44  41.5% | batch:        39 of        94\t|\tloss: 1057.18\n",
      "Training Epoch 44  42.6% | batch:        40 of        94\t|\tloss: 1688.71\n",
      "Training Epoch 44  43.6% | batch:        41 of        94\t|\tloss: 894.521\n",
      "Training Epoch 44  44.7% | batch:        42 of        94\t|\tloss: 1191.18\n",
      "Training Epoch 44  45.7% | batch:        43 of        94\t|\tloss: 761.035\n",
      "Training Epoch 44  46.8% | batch:        44 of        94\t|\tloss: 1955.53\n",
      "Training Epoch 44  47.9% | batch:        45 of        94\t|\tloss: 1215.03\n",
      "Training Epoch 44  48.9% | batch:        46 of        94\t|\tloss: 2308.05\n",
      "Training Epoch 44  50.0% | batch:        47 of        94\t|\tloss: 1587.95\n",
      "Training Epoch 44  51.1% | batch:        48 of        94\t|\tloss: 1174.16\n",
      "Training Epoch 44  52.1% | batch:        49 of        94\t|\tloss: 962.352\n",
      "Training Epoch 44  53.2% | batch:        50 of        94\t|\tloss: 1623.3\n",
      "Training Epoch 44  54.3% | batch:        51 of        94\t|\tloss: 1183.46\n",
      "Training Epoch 44  55.3% | batch:        52 of        94\t|\tloss: 1209.48\n",
      "Training Epoch 44  56.4% | batch:        53 of        94\t|\tloss: 2559.7\n",
      "Training Epoch 44  57.4% | batch:        54 of        94\t|\tloss: 1146.43\n",
      "Training Epoch 44  58.5% | batch:        55 of        94\t|\tloss: 1248.18\n",
      "Training Epoch 44  59.6% | batch:        56 of        94\t|\tloss: 1335.23\n",
      "Training Epoch 44  60.6% | batch:        57 of        94\t|\tloss: 928.322\n",
      "Training Epoch 44  61.7% | batch:        58 of        94\t|\tloss: 1201.75\n",
      "Training Epoch 44  62.8% | batch:        59 of        94\t|\tloss: 1192.32\n",
      "Training Epoch 44  63.8% | batch:        60 of        94\t|\tloss: 1944.89\n",
      "Training Epoch 44  64.9% | batch:        61 of        94\t|\tloss: 1150.42\n",
      "Training Epoch 44  66.0% | batch:        62 of        94\t|\tloss: 1167.01\n",
      "Training Epoch 44  67.0% | batch:        63 of        94\t|\tloss: 988.562\n",
      "Training Epoch 44  68.1% | batch:        64 of        94\t|\tloss: 935.666\n",
      "Training Epoch 44  69.1% | batch:        65 of        94\t|\tloss: 1008.89\n",
      "Training Epoch 44  70.2% | batch:        66 of        94\t|\tloss: 1143.55\n",
      "Training Epoch 44  71.3% | batch:        67 of        94\t|\tloss: 918.695\n",
      "Training Epoch 44  72.3% | batch:        68 of        94\t|\tloss: 922.965\n",
      "Training Epoch 44  73.4% | batch:        69 of        94\t|\tloss: 2242.58\n",
      "Training Epoch 44  74.5% | batch:        70 of        94\t|\tloss: 1034.19\n",
      "Training Epoch 44  75.5% | batch:        71 of        94\t|\tloss: 1108.71\n",
      "Training Epoch 44  76.6% | batch:        72 of        94\t|\tloss: 947.534\n",
      "Training Epoch 44  77.7% | batch:        73 of        94\t|\tloss: 2913.11\n",
      "Training Epoch 44  78.7% | batch:        74 of        94\t|\tloss: 2234.77\n",
      "Training Epoch 44  79.8% | batch:        75 of        94\t|\tloss: 973.114\n",
      "Training Epoch 44  80.9% | batch:        76 of        94\t|\tloss: 1338.83\n",
      "Training Epoch 44  81.9% | batch:        77 of        94\t|\tloss: 1280.89\n",
      "Training Epoch 44  83.0% | batch:        78 of        94\t|\tloss: 1185.89\n",
      "Training Epoch 44  84.0% | batch:        79 of        94\t|\tloss: 1306.18\n",
      "Training Epoch 44  85.1% | batch:        80 of        94\t|\tloss: 2988.89\n",
      "Training Epoch 44  86.2% | batch:        81 of        94\t|\tloss: 1747.24\n",
      "Training Epoch 44  87.2% | batch:        82 of        94\t|\tloss: 1088.77\n",
      "Training Epoch 44  88.3% | batch:        83 of        94\t|\tloss: 1353.42\n",
      "Training Epoch 44  89.4% | batch:        84 of        94\t|\tloss: 1038.25\n",
      "Training Epoch 44  90.4% | batch:        85 of        94\t|\tloss: 1072.39\n",
      "Training Epoch 44  91.5% | batch:        86 of        94\t|\tloss: 1982.55\n",
      "Training Epoch 44  92.6% | batch:        87 of        94\t|\tloss: 1180.24\n",
      "Training Epoch 44  93.6% | batch:        88 of        94\t|\tloss: 1502.07\n",
      "Training Epoch 44  94.7% | batch:        89 of        94\t|\tloss: 832.817\n",
      "Training Epoch 44  95.7% | batch:        90 of        94\t|\tloss: 1421.09\n",
      "Training Epoch 44  96.8% | batch:        91 of        94\t|\tloss: 1738.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:48,955 | INFO : Epoch 44 Training Summary: epoch: 44.000000 | loss: 1433.142117 | \n",
      "2023-05-09 14:21:48,956 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8320178985595703 seconds\n",
      "\n",
      "2023-05-09 14:21:48,956 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8295169310136274 seconds\n",
      "2023-05-09 14:21:48,956 | INFO : Avg batch train. time: 0.019462946074613057 seconds\n",
      "2023-05-09 14:21:48,957 | INFO : Avg sample train. time: 0.00015350872050793989 seconds\n",
      "2023-05-09 14:21:48,958 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 44  97.9% | batch:        92 of        94\t|\tloss: 2026.23\n",
      "Training Epoch 44  98.9% | batch:        93 of        94\t|\tloss: 715.467\n",
      "\n",
      "Evaluating Epoch 44   0.0% | batch:         0 of        40\t|\tloss: 6727.29\n",
      "Evaluating Epoch 44   2.5% | batch:         1 of        40\t|\tloss: 1116.77\n",
      "Evaluating Epoch 44   5.0% | batch:         2 of        40\t|\tloss: 4410.17\n",
      "Evaluating Epoch 44   7.5% | batch:         3 of        40\t|\tloss: 7065.06\n",
      "Evaluating Epoch 44  10.0% | batch:         4 of        40\t|\tloss: 2235.52\n",
      "Evaluating Epoch 44  12.5% | batch:         5 of        40\t|\tloss: 2485.84\n",
      "Evaluating Epoch 44  15.0% | batch:         6 of        40\t|\tloss: 9146.07\n",
      "Evaluating Epoch 44  17.5% | batch:         7 of        40\t|\tloss: 2754.73\n",
      "Evaluating Epoch 44  20.0% | batch:         8 of        40\t|\tloss: 2891.17\n",
      "Evaluating Epoch 44  22.5% | batch:         9 of        40\t|\tloss: 2285.1\n",
      "Evaluating Epoch 44  25.0% | batch:        10 of        40\t|\tloss: 4861.55\n",
      "Evaluating Epoch 44  27.5% | batch:        11 of        40\t|\tloss: 1489.67\n",
      "Evaluating Epoch 44  30.0% | batch:        12 of        40\t|\tloss: 5784.23\n",
      "Evaluating Epoch 44  32.5% | batch:        13 of        40\t|\tloss: 3131.44\n",
      "Evaluating Epoch 44  35.0% | batch:        14 of        40\t|\tloss: 1982.91\n",
      "Evaluating Epoch 44  37.5% | batch:        15 of        40\t|\tloss: 3470.58\n",
      "Evaluating Epoch 44  40.0% | batch:        16 of        40\t|\tloss: 6660.23\n",
      "Evaluating Epoch 44  42.5% | batch:        17 of        40\t|\tloss: 2530.52\n",
      "Evaluating Epoch 44  45.0% | batch:        18 of        40\t|\tloss: 2697.31\n",
      "Evaluating Epoch 44  47.5% | batch:        19 of        40\t|\tloss: 5583.37\n",
      "Evaluating Epoch 44  50.0% | batch:        20 of        40\t|\tloss: 5054.77\n",
      "Evaluating Epoch 44  52.5% | batch:        21 of        40\t|\tloss: 1090.15\n",
      "Evaluating Epoch 44  55.0% | batch:        22 of        40\t|\tloss: 4098.19\n",
      "Evaluating Epoch 44  57.5% | batch:        23 of        40\t|\tloss: 3371.82\n",
      "Evaluating Epoch 44  60.0% | batch:        24 of        40\t|\tloss: 1480.99\n",
      "Evaluating Epoch 44  62.5% | batch:        25 of        40\t|\tloss: 4209.82\n",
      "Evaluating Epoch 44  65.0% | batch:        26 of        40\t|\tloss: 9732.76\n",
      "Evaluating Epoch 44  67.5% | batch:        27 of        40\t|\tloss: 2811.06\n",
      "Evaluating Epoch 44  70.0% | batch:        28 of        40\t|\tloss: 2264.57\n",
      "Evaluating Epoch 44  72.5% | batch:        29 of        40\t|\tloss: 9439.24\n",
      "Evaluating Epoch 44  75.0% | batch:        30 of        40\t|\tloss: 1976.79\n",
      "Evaluating Epoch 44  77.5% | batch:        31 of        40\t|\tloss: 2377.16\n",
      "Evaluating Epoch 44  80.0% | batch:        32 of        40\t|\tloss: 7345.66\n",
      "Evaluating Epoch 44  82.5% | batch:        33 of        40\t|\tloss: 6552.45\n",
      "Evaluating Epoch 44  85.0% | batch:        34 of        40\t|\tloss: 1191.7\n",
      "Evaluating Epoch 44  87.5% | batch:        35 of        40\t|\tloss: 5166.4\n",
      "Evaluating Epoch 44  90.0% | batch:        36 of        40\t|\tloss: 6231.42\n",
      "Evaluating Epoch 44  92.5% | batch:        37 of        40\t|\tloss: 2583.65\n",
      "Evaluating Epoch 44  95.0% | batch:        38 of        40\t|\tloss: 3709.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:49,418 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4601719379425049 seconds\n",
      "\n",
      "2023-05-09 14:21:49,419 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48594018816947937 seconds\n",
      "2023-05-09 14:21:49,419 | INFO : Avg batch val. time: 0.012148504704236984 seconds\n",
      "2023-05-09 14:21:49,420 | INFO : Avg sample val. time: 9.62639041540173e-05 seconds\n",
      "2023-05-09 14:21:49,420 | INFO : Epoch 44 Validation Summary: epoch: 44.000000 | loss: 4182.821300 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 44  97.5% | batch:        39 of        40\t|\tloss: 11341.5\n",
      "\n",
      "Training Epoch 45   0.0% | batch:         0 of        94\t|\tloss: 1073.51\n",
      "Training Epoch 45   1.1% | batch:         1 of        94\t|\tloss: 1498.37\n",
      "Training Epoch 45   2.1% | batch:         2 of        94\t|\tloss: 1726.72\n",
      "Training Epoch 45   3.2% | batch:         3 of        94\t|\tloss: 897.76\n",
      "Training Epoch 45   4.3% | batch:         4 of        94\t|\tloss: 1037.88\n",
      "Training Epoch 45   5.3% | batch:         5 of        94\t|\tloss: 1081.81\n",
      "Training Epoch 45   6.4% | batch:         6 of        94\t|\tloss: 1179.2\n",
      "Training Epoch 45   7.4% | batch:         7 of        94\t|\tloss: 1381.91\n",
      "Training Epoch 45   8.5% | batch:         8 of        94\t|\tloss: 1276.11\n",
      "Training Epoch 45   9.6% | batch:         9 of        94\t|\tloss: 796.538\n",
      "Training Epoch 45  10.6% | batch:        10 of        94\t|\tloss: 2525.94\n",
      "Training Epoch 45  11.7% | batch:        11 of        94\t|\tloss: 1410.12\n",
      "Training Epoch 45  12.8% | batch:        12 of        94\t|\tloss: 992.972\n",
      "Training Epoch 45  13.8% | batch:        13 of        94\t|\tloss: 1549.61\n",
      "Training Epoch 45  14.9% | batch:        14 of        94\t|\tloss: 3592.56\n",
      "Training Epoch 45  16.0% | batch:        15 of        94\t|\tloss: 1022.89\n",
      "Training Epoch 45  17.0% | batch:        16 of        94\t|\tloss: 955.527\n",
      "Training Epoch 45  18.1% | batch:        17 of        94\t|\tloss: 1303.1\n",
      "Training Epoch 45  19.1% | batch:        18 of        94\t|\tloss: 1159.4\n",
      "Training Epoch 45  20.2% | batch:        19 of        94\t|\tloss: 1067.66\n",
      "Training Epoch 45  21.3% | batch:        20 of        94\t|\tloss: 928.803\n",
      "Training Epoch 45  22.3% | batch:        21 of        94\t|\tloss: 1080\n",
      "Training Epoch 45  23.4% | batch:        22 of        94\t|\tloss: 1533.64\n",
      "Training Epoch 45  24.5% | batch:        23 of        94\t|\tloss: 1036.39\n",
      "Training Epoch 45  25.5% | batch:        24 of        94\t|\tloss: 971.889\n",
      "Training Epoch 45  26.6% | batch:        25 of        94\t|\tloss: 1140.78\n",
      "Training Epoch 45  27.7% | batch:        26 of        94\t|\tloss: 1026.23\n",
      "Training Epoch 45  28.7% | batch:        27 of        94\t|\tloss: 1913.99\n",
      "Training Epoch 45  29.8% | batch:        28 of        94\t|\tloss: 2801.82\n",
      "Training Epoch 45  30.9% | batch:        29 of        94\t|\tloss: 852.48\n",
      "Training Epoch 45  31.9% | batch:        30 of        94\t|\tloss: 913.58\n",
      "Training Epoch 45  33.0% | batch:        31 of        94\t|\tloss: 1442.55\n",
      "Training Epoch 45  34.0% | batch:        32 of        94\t|\tloss: 2167.62\n",
      "Training Epoch 45  35.1% | batch:        33 of        94\t|\tloss: 1094.55\n",
      "Training Epoch 45  36.2% | batch:        34 of        94\t|\tloss: 1131.06\n",
      "Training Epoch 45  37.2% | batch:        35 of        94\t|\tloss: 1898.81\n",
      "Training Epoch 45  38.3% | batch:        36 of        94\t|\tloss: 948.285\n",
      "Training Epoch 45  39.4% | batch:        37 of        94\t|\tloss: 1099.07\n",
      "Training Epoch 45  40.4% | batch:        38 of        94\t|\tloss: 694.955\n",
      "Training Epoch 45  41.5% | batch:        39 of        94\t|\tloss: 2870.51\n",
      "Training Epoch 45  42.6% | batch:        40 of        94\t|\tloss: 1127.14\n",
      "Training Epoch 45  43.6% | batch:        41 of        94\t|\tloss: 1120.29\n",
      "Training Epoch 45  44.7% | batch:        42 of        94\t|\tloss: 1740.17\n",
      "Training Epoch 45  45.7% | batch:        43 of        94\t|\tloss: 761.89\n",
      "Training Epoch 45  46.8% | batch:        44 of        94\t|\tloss: 1959.27\n",
      "Training Epoch 45  47.9% | batch:        45 of        94\t|\tloss: 2750.69\n",
      "Training Epoch 45  48.9% | batch:        46 of        94\t|\tloss: 884.14\n",
      "Training Epoch 45  50.0% | batch:        47 of        94\t|\tloss: 869.146\n",
      "Training Epoch 45  51.1% | batch:        48 of        94\t|\tloss: 1180.65\n",
      "Training Epoch 45  52.1% | batch:        49 of        94\t|\tloss: 1430.13\n",
      "Training Epoch 45  53.2% | batch:        50 of        94\t|\tloss: 1921.74\n",
      "Training Epoch 45  54.3% | batch:        51 of        94\t|\tloss: 825.183\n",
      "Training Epoch 45  55.3% | batch:        52 of        94\t|\tloss: 814.328\n",
      "Training Epoch 45  56.4% | batch:        53 of        94\t|\tloss: 1533.67\n",
      "Training Epoch 45  57.4% | batch:        54 of        94\t|\tloss: 1297.83\n",
      "Training Epoch 45  58.5% | batch:        55 of        94\t|\tloss: 1914.35\n",
      "Training Epoch 45  59.6% | batch:        56 of        94\t|\tloss: 1895.61\n",
      "Training Epoch 45  60.6% | batch:        57 of        94\t|\tloss: 1463.41\n",
      "Training Epoch 45  61.7% | batch:        58 of        94\t|\tloss: 1288.32\n",
      "Training Epoch 45  62.8% | batch:        59 of        94\t|\tloss: 2471.23\n",
      "Training Epoch 45  63.8% | batch:        60 of        94\t|\tloss: 1259.37\n",
      "Training Epoch 45  64.9% | batch:        61 of        94\t|\tloss: 2154.79\n",
      "Training Epoch 45  66.0% | batch:        62 of        94\t|\tloss: 1366.22\n",
      "Training Epoch 45  67.0% | batch:        63 of        94\t|\tloss: 1563.84\n",
      "Training Epoch 45  68.1% | batch:        64 of        94\t|\tloss: 1092.18\n",
      "Training Epoch 45  69.1% | batch:        65 of        94\t|\tloss: 1660.23\n",
      "Training Epoch 45  70.2% | batch:        66 of        94\t|\tloss: 1040.56\n",
      "Training Epoch 45  71.3% | batch:        67 of        94\t|\tloss: 2769.48\n",
      "Training Epoch 45  72.3% | batch:        68 of        94\t|\tloss: 2677.81\n",
      "Training Epoch 45  73.4% | batch:        69 of        94\t|\tloss: 1532.03\n",
      "Training Epoch 45  74.5% | batch:        70 of        94\t|\tloss: 1042.22\n",
      "Training Epoch 45  75.5% | batch:        71 of        94\t|\tloss: 949.205\n",
      "Training Epoch 45  76.6% | batch:        72 of        94\t|\tloss: 1463.99\n",
      "Training Epoch 45  77.7% | batch:        73 of        94\t|\tloss: 3339.82\n",
      "Training Epoch 45  78.7% | batch:        74 of        94\t|\tloss: 970.544\n",
      "Training Epoch 45  79.8% | batch:        75 of        94\t|\tloss: 1296.3\n",
      "Training Epoch 45  80.9% | batch:        76 of        94\t|\tloss: 1344\n",
      "Training Epoch 45  81.9% | batch:        77 of        94\t|\tloss: 1014.83\n",
      "Training Epoch 45  83.0% | batch:        78 of        94\t|\tloss: 1022.77\n",
      "Training Epoch 45  84.0% | batch:        79 of        94\t|\tloss: 1160.89\n",
      "Training Epoch 45  85.1% | batch:        80 of        94\t|\tloss: 2468.26\n",
      "Training Epoch 45  86.2% | batch:        81 of        94\t|\tloss: 1173.27\n",
      "Training Epoch 45  87.2% | batch:        82 of        94\t|\tloss: 1440.54\n",
      "Training Epoch 45  88.3% | batch:        83 of        94\t|\tloss: 1466.39\n",
      "Training Epoch 45  89.4% | batch:        84 of        94\t|\tloss: 1060.82\n",
      "Training Epoch 45  90.4% | batch:        85 of        94\t|\tloss: 1693.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:51,256 | INFO : Epoch 45 Training Summary: epoch: 45.000000 | loss: 1483.338146 | \n",
      "2023-05-09 14:21:51,257 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.814399242401123 seconds\n",
      "\n",
      "2023-05-09 14:21:51,258 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.829180982377794 seconds\n",
      "2023-05-09 14:21:51,259 | INFO : Avg batch train. time: 0.019459372152955255 seconds\n",
      "2023-05-09 14:21:51,259 | INFO : Avg sample train. time: 0.0001534805321679639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 45  91.5% | batch:        86 of        94\t|\tloss: 1329.12\n",
      "Training Epoch 45  92.6% | batch:        87 of        94\t|\tloss: 4940.38\n",
      "Training Epoch 45  93.6% | batch:        88 of        94\t|\tloss: 1192.55\n",
      "Training Epoch 45  94.7% | batch:        89 of        94\t|\tloss: 1493.83\n",
      "Training Epoch 45  95.7% | batch:        90 of        94\t|\tloss: 928.53\n",
      "Training Epoch 45  96.8% | batch:        91 of        94\t|\tloss: 1161.36\n",
      "Training Epoch 45  97.9% | batch:        92 of        94\t|\tloss: 1216.63\n",
      "Training Epoch 45  98.9% | batch:        93 of        94\t|\tloss: 13718.1\n",
      "\n",
      "Training Epoch 46   0.0% | batch:         0 of        94\t|\tloss: 1208.89\n",
      "Training Epoch 46   1.1% | batch:         1 of        94\t|\tloss: 1407.18\n",
      "Training Epoch 46   2.1% | batch:         2 of        94\t|\tloss: 1108.84\n",
      "Training Epoch 46   3.2% | batch:         3 of        94\t|\tloss: 995.537\n",
      "Training Epoch 46   4.3% | batch:         4 of        94\t|\tloss: 1472.72\n",
      "Training Epoch 46   5.3% | batch:         5 of        94\t|\tloss: 1529.51\n",
      "Training Epoch 46   6.4% | batch:         6 of        94\t|\tloss: 2973.04\n",
      "Training Epoch 46   7.4% | batch:         7 of        94\t|\tloss: 1443.95\n",
      "Training Epoch 46   8.5% | batch:         8 of        94\t|\tloss: 1358.35\n",
      "Training Epoch 46   9.6% | batch:         9 of        94\t|\tloss: 1626.59\n",
      "Training Epoch 46  10.6% | batch:        10 of        94\t|\tloss: 955.481\n",
      "Training Epoch 46  11.7% | batch:        11 of        94\t|\tloss: 843.241\n",
      "Training Epoch 46  12.8% | batch:        12 of        94\t|\tloss: 1114.43\n",
      "Training Epoch 46  13.8% | batch:        13 of        94\t|\tloss: 1937.83\n",
      "Training Epoch 46  14.9% | batch:        14 of        94\t|\tloss: 945.158\n",
      "Training Epoch 46  16.0% | batch:        15 of        94\t|\tloss: 1980.75\n",
      "Training Epoch 46  17.0% | batch:        16 of        94\t|\tloss: 3358.92\n",
      "Training Epoch 46  18.1% | batch:        17 of        94\t|\tloss: 1921.21\n",
      "Training Epoch 46  19.1% | batch:        18 of        94\t|\tloss: 2247.91\n",
      "Training Epoch 46  20.2% | batch:        19 of        94\t|\tloss: 1182.42\n",
      "Training Epoch 46  21.3% | batch:        20 of        94\t|\tloss: 1642.42\n",
      "Training Epoch 46  22.3% | batch:        21 of        94\t|\tloss: 1178.93\n",
      "Training Epoch 46  23.4% | batch:        22 of        94\t|\tloss: 868.073\n",
      "Training Epoch 46  24.5% | batch:        23 of        94\t|\tloss: 1118\n",
      "Training Epoch 46  25.5% | batch:        24 of        94\t|\tloss: 2174.34\n",
      "Training Epoch 46  26.6% | batch:        25 of        94\t|\tloss: 913.947\n",
      "Training Epoch 46  27.7% | batch:        26 of        94\t|\tloss: 1275.85\n",
      "Training Epoch 46  28.7% | batch:        27 of        94\t|\tloss: 816.328\n",
      "Training Epoch 46  29.8% | batch:        28 of        94\t|\tloss: 1502.2\n",
      "Training Epoch 46  30.9% | batch:        29 of        94\t|\tloss: 987.748\n",
      "Training Epoch 46  31.9% | batch:        30 of        94\t|\tloss: 1168.18\n",
      "Training Epoch 46  33.0% | batch:        31 of        94\t|\tloss: 1337.52\n",
      "Training Epoch 46  34.0% | batch:        32 of        94\t|\tloss: 1306.13\n",
      "Training Epoch 46  35.1% | batch:        33 of        94\t|\tloss: 1235.34\n",
      "Training Epoch 46  36.2% | batch:        34 of        94\t|\tloss: 1291.44\n",
      "Training Epoch 46  37.2% | batch:        35 of        94\t|\tloss: 965.599\n",
      "Training Epoch 46  38.3% | batch:        36 of        94\t|\tloss: 865.641\n",
      "Training Epoch 46  39.4% | batch:        37 of        94\t|\tloss: 683.896\n",
      "Training Epoch 46  40.4% | batch:        38 of        94\t|\tloss: 1013.11\n",
      "Training Epoch 46  41.5% | batch:        39 of        94\t|\tloss: 1372.31\n",
      "Training Epoch 46  42.6% | batch:        40 of        94\t|\tloss: 1348.87\n",
      "Training Epoch 46  43.6% | batch:        41 of        94\t|\tloss: 1083.85\n",
      "Training Epoch 46  44.7% | batch:        42 of        94\t|\tloss: 1461.43\n",
      "Training Epoch 46  45.7% | batch:        43 of        94\t|\tloss: 1142.09\n",
      "Training Epoch 46  46.8% | batch:        44 of        94\t|\tloss: 1262.87\n",
      "Training Epoch 46  47.9% | batch:        45 of        94\t|\tloss: 1342.66\n",
      "Training Epoch 46  48.9% | batch:        46 of        94\t|\tloss: 1068.42\n",
      "Training Epoch 46  50.0% | batch:        47 of        94\t|\tloss: 1025.18\n",
      "Training Epoch 46  51.1% | batch:        48 of        94\t|\tloss: 1077.77\n",
      "Training Epoch 46  52.1% | batch:        49 of        94\t|\tloss: 905.566\n",
      "Training Epoch 46  53.2% | batch:        50 of        94\t|\tloss: 952.398\n",
      "Training Epoch 46  54.3% | batch:        51 of        94\t|\tloss: 1362.7\n",
      "Training Epoch 46  55.3% | batch:        52 of        94\t|\tloss: 2234.12\n",
      "Training Epoch 46  56.4% | batch:        53 of        94\t|\tloss: 2441.33\n",
      "Training Epoch 46  57.4% | batch:        54 of        94\t|\tloss: 1332.74\n",
      "Training Epoch 46  58.5% | batch:        55 of        94\t|\tloss: 1693.93\n",
      "Training Epoch 46  59.6% | batch:        56 of        94\t|\tloss: 1055.56\n",
      "Training Epoch 46  60.6% | batch:        57 of        94\t|\tloss: 1392.76\n",
      "Training Epoch 46  61.7% | batch:        58 of        94\t|\tloss: 1509.06\n",
      "Training Epoch 46  62.8% | batch:        59 of        94\t|\tloss: 1217.75\n",
      "Training Epoch 46  63.8% | batch:        60 of        94\t|\tloss: 1193.35\n",
      "Training Epoch 46  64.9% | batch:        61 of        94\t|\tloss: 1122.91\n",
      "Training Epoch 46  66.0% | batch:        62 of        94\t|\tloss: 1185.83\n",
      "Training Epoch 46  67.0% | batch:        63 of        94\t|\tloss: 906.076\n",
      "Training Epoch 46  68.1% | batch:        64 of        94\t|\tloss: 3251.12\n",
      "Training Epoch 46  69.1% | batch:        65 of        94\t|\tloss: 1381.19\n",
      "Training Epoch 46  70.2% | batch:        66 of        94\t|\tloss: 1174.63\n",
      "Training Epoch 46  71.3% | batch:        67 of        94\t|\tloss: 1355.9\n",
      "Training Epoch 46  72.3% | batch:        68 of        94\t|\tloss: 818.961\n",
      "Training Epoch 46  73.4% | batch:        69 of        94\t|\tloss: 1682.23\n",
      "Training Epoch 46  74.5% | batch:        70 of        94\t|\tloss: 1649.09\n",
      "Training Epoch 46  75.5% | batch:        71 of        94\t|\tloss: 1216.16\n",
      "Training Epoch 46  76.6% | batch:        72 of        94\t|\tloss: 1345.11\n",
      "Training Epoch 46  77.7% | batch:        73 of        94\t|\tloss: 1452.66\n",
      "Training Epoch 46  78.7% | batch:        74 of        94\t|\tloss: 1497.12\n",
      "Training Epoch 46  79.8% | batch:        75 of        94\t|\tloss: 1031.04\n",
      "Training Epoch 46  80.9% | batch:        76 of        94\t|\tloss: 790.534\n",
      "Training Epoch 46  81.9% | batch:        77 of        94\t|\tloss: 978.003\n",
      "Training Epoch 46  83.0% | batch:        78 of        94\t|\tloss: 1128.58\n",
      "Training Epoch 46  84.0% | batch:        79 of        94\t|\tloss: 2753.92\n",
      "Training Epoch 46  85.1% | batch:        80 of        94\t|\tloss: 2538.74\n",
      "Training Epoch 46  86.2% | batch:        81 of        94\t|\tloss: 2191.77\n",
      "Training Epoch 46  87.2% | batch:        82 of        94\t|\tloss: 1368.54\n",
      "Training Epoch 46  88.3% | batch:        83 of        94\t|\tloss: 1050.93\n",
      "Training Epoch 46  89.4% | batch:        84 of        94\t|\tloss: 941.259\n",
      "Training Epoch 46  90.4% | batch:        85 of        94\t|\tloss: 2245.39\n",
      "Training Epoch 46  91.5% | batch:        86 of        94\t|\tloss: 893.562\n",
      "Training Epoch 46  92.6% | batch:        87 of        94\t|\tloss: 945.565\n",
      "Training Epoch 46  93.6% | batch:        88 of        94\t|\tloss: 1944.75\n",
      "Training Epoch 46  94.7% | batch:        89 of        94\t|\tloss: 1412.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:53,105 | INFO : Epoch 46 Training Summary: epoch: 46.000000 | loss: 1396.270505 | \n",
      "2023-05-09 14:21:53,106 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.834348440170288 seconds\n",
      "\n",
      "2023-05-09 14:21:53,107 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8292933184167612 seconds\n",
      "2023-05-09 14:21:53,107 | INFO : Avg batch train. time: 0.019460567217199586 seconds\n",
      "2023-05-09 14:21:53,108 | INFO : Avg sample train. time: 0.0001534899579138078 seconds\n",
      "2023-05-09 14:21:53,108 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 46  95.7% | batch:        90 of        94\t|\tloss: 1053.89\n",
      "Training Epoch 46  96.8% | batch:        91 of        94\t|\tloss: 1726.93\n",
      "Training Epoch 46  97.9% | batch:        92 of        94\t|\tloss: 1355.16\n",
      "Training Epoch 46  98.9% | batch:        93 of        94\t|\tloss: 1663.72\n",
      "\n",
      "Evaluating Epoch 46   0.0% | batch:         0 of        40\t|\tloss: 6741.77\n",
      "Evaluating Epoch 46   2.5% | batch:         1 of        40\t|\tloss: 1160.24\n",
      "Evaluating Epoch 46   5.0% | batch:         2 of        40\t|\tloss: 3792.12\n",
      "Evaluating Epoch 46   7.5% | batch:         3 of        40\t|\tloss: 6369.89\n",
      "Evaluating Epoch 46  10.0% | batch:         4 of        40\t|\tloss: 2160.3\n",
      "Evaluating Epoch 46  12.5% | batch:         5 of        40\t|\tloss: 2071.88\n",
      "Evaluating Epoch 46  15.0% | batch:         6 of        40\t|\tloss: 8065.25\n",
      "Evaluating Epoch 46  17.5% | batch:         7 of        40\t|\tloss: 2949.41\n",
      "Evaluating Epoch 46  20.0% | batch:         8 of        40\t|\tloss: 2940.8\n",
      "Evaluating Epoch 46  22.5% | batch:         9 of        40\t|\tloss: 2133.37\n",
      "Evaluating Epoch 46  25.0% | batch:        10 of        40\t|\tloss: 4861.3\n",
      "Evaluating Epoch 46  27.5% | batch:        11 of        40\t|\tloss: 1456.97\n",
      "Evaluating Epoch 46  30.0% | batch:        12 of        40\t|\tloss: 5260.23\n",
      "Evaluating Epoch 46  32.5% | batch:        13 of        40\t|\tloss: 3043.52\n",
      "Evaluating Epoch 46  35.0% | batch:        14 of        40\t|\tloss: 1881.47\n",
      "Evaluating Epoch 46  37.5% | batch:        15 of        40\t|\tloss: 3770.1\n",
      "Evaluating Epoch 46  40.0% | batch:        16 of        40\t|\tloss: 3230.81\n",
      "Evaluating Epoch 46  42.5% | batch:        17 of        40\t|\tloss: 2630.8\n",
      "Evaluating Epoch 46  45.0% | batch:        18 of        40\t|\tloss: 2732.21\n",
      "Evaluating Epoch 46  47.5% | batch:        19 of        40\t|\tloss: 4335.9\n",
      "Evaluating Epoch 46  50.0% | batch:        20 of        40\t|\tloss: 4891.71\n",
      "Evaluating Epoch 46  52.5% | batch:        21 of        40\t|\tloss: 1066.59\n",
      "Evaluating Epoch 46  55.0% | batch:        22 of        40\t|\tloss: 3599.67\n",
      "Evaluating Epoch 46  57.5% | batch:        23 of        40\t|\tloss: 3136.12\n",
      "Evaluating Epoch 46  60.0% | batch:        24 of        40\t|\tloss: 1529.05\n",
      "Evaluating Epoch 46  62.5% | batch:        25 of        40\t|\tloss: 4160.01\n",
      "Evaluating Epoch 46  65.0% | batch:        26 of        40\t|\tloss: 8907.23\n",
      "Evaluating Epoch 46  67.5% | batch:        27 of        40\t|\tloss: 3100.26\n",
      "Evaluating Epoch 46  70.0% | batch:        28 of        40\t|\tloss: 2172.98\n",
      "Evaluating Epoch 46  72.5% | batch:        29 of        40\t|\tloss: 9125.51\n",
      "Evaluating Epoch 46  75.0% | batch:        30 of        40\t|\tloss: 1903.17\n",
      "Evaluating Epoch 46  77.5% | batch:        31 of        40\t|\tloss: 1927.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:53,566 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4577322006225586 seconds\n",
      "\n",
      "2023-05-09 14:21:53,567 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48481186866760256 seconds\n",
      "2023-05-09 14:21:53,567 | INFO : Avg batch val. time: 0.012120296716690064 seconds\n",
      "2023-05-09 14:21:53,567 | INFO : Avg sample val. time: 9.604038602765503e-05 seconds\n",
      "2023-05-09 14:21:53,568 | INFO : Epoch 46 Validation Summary: epoch: 46.000000 | loss: 3882.814116 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 46  80.0% | batch:        32 of        40\t|\tloss: 7376.03\n",
      "Evaluating Epoch 46  82.5% | batch:        33 of        40\t|\tloss: 6058.44\n",
      "Evaluating Epoch 46  85.0% | batch:        34 of        40\t|\tloss: 1185.99\n",
      "Evaluating Epoch 46  87.5% | batch:        35 of        40\t|\tloss: 4977.62\n",
      "Evaluating Epoch 46  90.0% | batch:        36 of        40\t|\tloss: 5994.4\n",
      "Evaluating Epoch 46  92.5% | batch:        37 of        40\t|\tloss: 2575.43\n",
      "Evaluating Epoch 46  95.0% | batch:        38 of        40\t|\tloss: 3857.55\n",
      "Evaluating Epoch 46  97.5% | batch:        39 of        40\t|\tloss: 9130.99\n",
      "\n",
      "Training Epoch 47   0.0% | batch:         0 of        94\t|\tloss: 809.733\n",
      "Training Epoch 47   1.1% | batch:         1 of        94\t|\tloss: 1702.45\n",
      "Training Epoch 47   2.1% | batch:         2 of        94\t|\tloss: 827.161\n",
      "Training Epoch 47   3.2% | batch:         3 of        94\t|\tloss: 1800.32\n",
      "Training Epoch 47   4.3% | batch:         4 of        94\t|\tloss: 3681.26\n",
      "Training Epoch 47   5.3% | batch:         5 of        94\t|\tloss: 912.652\n",
      "Training Epoch 47   6.4% | batch:         6 of        94\t|\tloss: 780.923\n",
      "Training Epoch 47   7.4% | batch:         7 of        94\t|\tloss: 1028.98\n",
      "Training Epoch 47   8.5% | batch:         8 of        94\t|\tloss: 1883.1\n",
      "Training Epoch 47   9.6% | batch:         9 of        94\t|\tloss: 987.635\n",
      "Training Epoch 47  10.6% | batch:        10 of        94\t|\tloss: 1160.92\n",
      "Training Epoch 47  11.7% | batch:        11 of        94\t|\tloss: 1716.01\n",
      "Training Epoch 47  12.8% | batch:        12 of        94\t|\tloss: 1471.52\n",
      "Training Epoch 47  13.8% | batch:        13 of        94\t|\tloss: 1227.59\n",
      "Training Epoch 47  14.9% | batch:        14 of        94\t|\tloss: 1385.3\n",
      "Training Epoch 47  16.0% | batch:        15 of        94\t|\tloss: 1454.2\n",
      "Training Epoch 47  17.0% | batch:        16 of        94\t|\tloss: 687.313\n",
      "Training Epoch 47  18.1% | batch:        17 of        94\t|\tloss: 1332.16\n",
      "Training Epoch 47  19.1% | batch:        18 of        94\t|\tloss: 1415.06\n",
      "Training Epoch 47  20.2% | batch:        19 of        94\t|\tloss: 2211.83\n",
      "Training Epoch 47  21.3% | batch:        20 of        94\t|\tloss: 898.005\n",
      "Training Epoch 47  22.3% | batch:        21 of        94\t|\tloss: 1826.02\n",
      "Training Epoch 47  23.4% | batch:        22 of        94\t|\tloss: 1044.63\n",
      "Training Epoch 47  24.5% | batch:        23 of        94\t|\tloss: 1509.44\n",
      "Training Epoch 47  25.5% | batch:        24 of        94\t|\tloss: 1042.73\n",
      "Training Epoch 47  26.6% | batch:        25 of        94\t|\tloss: 1314.46\n",
      "Training Epoch 47  27.7% | batch:        26 of        94\t|\tloss: 1183\n",
      "Training Epoch 47  28.7% | batch:        27 of        94\t|\tloss: 1501.23\n",
      "Training Epoch 47  29.8% | batch:        28 of        94\t|\tloss: 1139.86\n",
      "Training Epoch 47  30.9% | batch:        29 of        94\t|\tloss: 1332.28\n",
      "Training Epoch 47  31.9% | batch:        30 of        94\t|\tloss: 1186.88\n",
      "Training Epoch 47  33.0% | batch:        31 of        94\t|\tloss: 1774.35\n",
      "Training Epoch 47  34.0% | batch:        32 of        94\t|\tloss: 1267.02\n",
      "Training Epoch 47  35.1% | batch:        33 of        94\t|\tloss: 1274.09\n",
      "Training Epoch 47  36.2% | batch:        34 of        94\t|\tloss: 1293.22\n",
      "Training Epoch 47  37.2% | batch:        35 of        94\t|\tloss: 900.757\n",
      "Training Epoch 47  38.3% | batch:        36 of        94\t|\tloss: 1972.73\n",
      "Training Epoch 47  39.4% | batch:        37 of        94\t|\tloss: 944.967\n",
      "Training Epoch 47  40.4% | batch:        38 of        94\t|\tloss: 742.987\n",
      "Training Epoch 47  41.5% | batch:        39 of        94\t|\tloss: 657.093\n",
      "Training Epoch 47  42.6% | batch:        40 of        94\t|\tloss: 1770.91\n",
      "Training Epoch 47  43.6% | batch:        41 of        94\t|\tloss: 3301.47\n",
      "Training Epoch 47  44.7% | batch:        42 of        94\t|\tloss: 1370.55\n",
      "Training Epoch 47  45.7% | batch:        43 of        94\t|\tloss: 1104.25\n",
      "Training Epoch 47  46.8% | batch:        44 of        94\t|\tloss: 1033.44\n",
      "Training Epoch 47  47.9% | batch:        45 of        94\t|\tloss: 1349.93\n",
      "Training Epoch 47  48.9% | batch:        46 of        94\t|\tloss: 961.299\n",
      "Training Epoch 47  50.0% | batch:        47 of        94\t|\tloss: 3581.54\n",
      "Training Epoch 47  51.1% | batch:        48 of        94\t|\tloss: 2166.08\n",
      "Training Epoch 47  52.1% | batch:        49 of        94\t|\tloss: 787.68\n",
      "Training Epoch 47  53.2% | batch:        50 of        94\t|\tloss: 1157.84\n",
      "Training Epoch 47  54.3% | batch:        51 of        94\t|\tloss: 1099.12\n",
      "Training Epoch 47  55.3% | batch:        52 of        94\t|\tloss: 952.588\n",
      "Training Epoch 47  56.4% | batch:        53 of        94\t|\tloss: 980.403\n",
      "Training Epoch 47  57.4% | batch:        54 of        94\t|\tloss: 904.438\n",
      "Training Epoch 47  58.5% | batch:        55 of        94\t|\tloss: 2257.59\n",
      "Training Epoch 47  59.6% | batch:        56 of        94\t|\tloss: 1477.91\n",
      "Training Epoch 47  60.6% | batch:        57 of        94\t|\tloss: 718.39\n",
      "Training Epoch 47  61.7% | batch:        58 of        94\t|\tloss: 848.037\n",
      "Training Epoch 47  62.8% | batch:        59 of        94\t|\tloss: 1213.56\n",
      "Training Epoch 47  63.8% | batch:        60 of        94\t|\tloss: 1544.45\n",
      "Training Epoch 47  64.9% | batch:        61 of        94\t|\tloss: 1198.64\n",
      "Training Epoch 47  66.0% | batch:        62 of        94\t|\tloss: 821.027\n",
      "Training Epoch 47  67.0% | batch:        63 of        94\t|\tloss: 707.589\n",
      "Training Epoch 47  68.1% | batch:        64 of        94\t|\tloss: 1669.16\n",
      "Training Epoch 47  69.1% | batch:        65 of        94\t|\tloss: 993.59\n",
      "Training Epoch 47  70.2% | batch:        66 of        94\t|\tloss: 2342.28\n",
      "Training Epoch 47  71.3% | batch:        67 of        94\t|\tloss: 1169.85\n",
      "Training Epoch 47  72.3% | batch:        68 of        94\t|\tloss: 1167.47\n",
      "Training Epoch 47  73.4% | batch:        69 of        94\t|\tloss: 739.446\n",
      "Training Epoch 47  74.5% | batch:        70 of        94\t|\tloss: 693.528\n",
      "Training Epoch 47  75.5% | batch:        71 of        94\t|\tloss: 1554.96\n",
      "Training Epoch 47  76.6% | batch:        72 of        94\t|\tloss: 1053.63\n",
      "Training Epoch 47  77.7% | batch:        73 of        94\t|\tloss: 1449.23\n",
      "Training Epoch 47  78.7% | batch:        74 of        94\t|\tloss: 1044.19\n",
      "Training Epoch 47  79.8% | batch:        75 of        94\t|\tloss: 1006.68\n",
      "Training Epoch 47  80.9% | batch:        76 of        94\t|\tloss: 2000.73\n",
      "Training Epoch 47  81.9% | batch:        77 of        94\t|\tloss: 1670.83\n",
      "Training Epoch 47  83.0% | batch:        78 of        94\t|\tloss: 1362.41\n",
      "Training Epoch 47  84.0% | batch:        79 of        94\t|\tloss: 1754.13\n",
      "Training Epoch 47  85.1% | batch:        80 of        94\t|\tloss: 902.301\n",
      "Training Epoch 47  86.2% | batch:        81 of        94\t|\tloss: 1717.85\n",
      "Training Epoch 47  87.2% | batch:        82 of        94\t|\tloss: 974.227\n",
      "Training Epoch 47  88.3% | batch:        83 of        94\t|\tloss: 959.237\n",
      "Training Epoch 47  89.4% | batch:        84 of        94\t|\tloss: 2310.21\n",
      "Training Epoch 47  90.4% | batch:        85 of        94\t|\tloss: 957.288\n",
      "Training Epoch 47  91.5% | batch:        86 of        94\t|\tloss: 1107.1\n",
      "Training Epoch 47  92.6% | batch:        87 of        94\t|\tloss: 1117.81\n",
      "Training Epoch 47  93.6% | batch:        88 of        94\t|\tloss: 1085.88\n",
      "Training Epoch 47  94.7% | batch:        89 of        94\t|\tloss: 1597.3\n",
      "Training Epoch 47  95.7% | batch:        90 of        94\t|\tloss: 1207.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:55,382 | INFO : Epoch 47 Training Summary: epoch: 47.000000 | loss: 1349.903174 | \n",
      "2023-05-09 14:21:55,383 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7931411266326904 seconds\n",
      "\n",
      "2023-05-09 14:21:55,383 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8285241228468874 seconds\n",
      "2023-05-09 14:21:55,384 | INFO : Avg batch train. time: 0.019452384285605185 seconds\n",
      "2023-05-09 14:21:55,384 | INFO : Avg sample train. time: 0.00015342541725515082 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 47  96.8% | batch:        91 of        94\t|\tloss: 2352.29\n",
      "Training Epoch 47  97.9% | batch:        92 of        94\t|\tloss: 1056.59\n",
      "Training Epoch 47  98.9% | batch:        93 of        94\t|\tloss: 730.615\n",
      "\n",
      "Training Epoch 48   0.0% | batch:         0 of        94\t|\tloss: 1157.28\n",
      "Training Epoch 48   1.1% | batch:         1 of        94\t|\tloss: 1015.37\n",
      "Training Epoch 48   2.1% | batch:         2 of        94\t|\tloss: 1755.76\n",
      "Training Epoch 48   3.2% | batch:         3 of        94\t|\tloss: 850.773\n",
      "Training Epoch 48   4.3% | batch:         4 of        94\t|\tloss: 1227.62\n",
      "Training Epoch 48   5.3% | batch:         5 of        94\t|\tloss: 797.091\n",
      "Training Epoch 48   6.4% | batch:         6 of        94\t|\tloss: 825.498\n",
      "Training Epoch 48   7.4% | batch:         7 of        94\t|\tloss: 2293.3\n",
      "Training Epoch 48   8.5% | batch:         8 of        94\t|\tloss: 1155.96\n",
      "Training Epoch 48   9.6% | batch:         9 of        94\t|\tloss: 1780.23\n",
      "Training Epoch 48  10.6% | batch:        10 of        94\t|\tloss: 874.119\n",
      "Training Epoch 48  11.7% | batch:        11 of        94\t|\tloss: 969.796\n",
      "Training Epoch 48  12.8% | batch:        12 of        94\t|\tloss: 1638.56\n",
      "Training Epoch 48  13.8% | batch:        13 of        94\t|\tloss: 1214.8\n",
      "Training Epoch 48  14.9% | batch:        14 of        94\t|\tloss: 690.724\n",
      "Training Epoch 48  16.0% | batch:        15 of        94\t|\tloss: 1589.1\n",
      "Training Epoch 48  17.0% | batch:        16 of        94\t|\tloss: 1698.17\n",
      "Training Epoch 48  18.1% | batch:        17 of        94\t|\tloss: 1380\n",
      "Training Epoch 48  19.1% | batch:        18 of        94\t|\tloss: 1150.2\n",
      "Training Epoch 48  20.2% | batch:        19 of        94\t|\tloss: 2564.12\n",
      "Training Epoch 48  21.3% | batch:        20 of        94\t|\tloss: 956.808\n",
      "Training Epoch 48  22.3% | batch:        21 of        94\t|\tloss: 880.656\n",
      "Training Epoch 48  23.4% | batch:        22 of        94\t|\tloss: 1760.24\n",
      "Training Epoch 48  24.5% | batch:        23 of        94\t|\tloss: 1021.56\n",
      "Training Epoch 48  25.5% | batch:        24 of        94\t|\tloss: 1229.52\n",
      "Training Epoch 48  26.6% | batch:        25 of        94\t|\tloss: 1071.24\n",
      "Training Epoch 48  27.7% | batch:        26 of        94\t|\tloss: 1195.44\n",
      "Training Epoch 48  28.7% | batch:        27 of        94\t|\tloss: 1425.97\n",
      "Training Epoch 48  29.8% | batch:        28 of        94\t|\tloss: 3341.98\n",
      "Training Epoch 48  30.9% | batch:        29 of        94\t|\tloss: 1268.04\n",
      "Training Epoch 48  31.9% | batch:        30 of        94\t|\tloss: 1106.1\n",
      "Training Epoch 48  33.0% | batch:        31 of        94\t|\tloss: 1238.06\n",
      "Training Epoch 48  34.0% | batch:        32 of        94\t|\tloss: 2736.28\n",
      "Training Epoch 48  35.1% | batch:        33 of        94\t|\tloss: 1418.63\n",
      "Training Epoch 48  36.2% | batch:        34 of        94\t|\tloss: 1438.35\n",
      "Training Epoch 48  37.2% | batch:        35 of        94\t|\tloss: 2224.11\n",
      "Training Epoch 48  38.3% | batch:        36 of        94\t|\tloss: 1207.56\n",
      "Training Epoch 48  39.4% | batch:        37 of        94\t|\tloss: 1260.08\n",
      "Training Epoch 48  40.4% | batch:        38 of        94\t|\tloss: 1232.17\n",
      "Training Epoch 48  41.5% | batch:        39 of        94\t|\tloss: 896.482\n",
      "Training Epoch 48  42.6% | batch:        40 of        94\t|\tloss: 2415.15\n",
      "Training Epoch 48  43.6% | batch:        41 of        94\t|\tloss: 1588.24\n",
      "Training Epoch 48  44.7% | batch:        42 of        94\t|\tloss: 1408.45\n",
      "Training Epoch 48  45.7% | batch:        43 of        94\t|\tloss: 1157.97\n",
      "Training Epoch 48  46.8% | batch:        44 of        94\t|\tloss: 1384.58\n",
      "Training Epoch 48  47.9% | batch:        45 of        94\t|\tloss: 1193.06\n",
      "Training Epoch 48  48.9% | batch:        46 of        94\t|\tloss: 880.901\n",
      "Training Epoch 48  50.0% | batch:        47 of        94\t|\tloss: 1653.78\n",
      "Training Epoch 48  51.1% | batch:        48 of        94\t|\tloss: 926.051\n",
      "Training Epoch 48  52.1% | batch:        49 of        94\t|\tloss: 1673.82\n",
      "Training Epoch 48  53.2% | batch:        50 of        94\t|\tloss: 1336.33\n",
      "Training Epoch 48  54.3% | batch:        51 of        94\t|\tloss: 1117.05\n",
      "Training Epoch 48  55.3% | batch:        52 of        94\t|\tloss: 969.692\n",
      "Training Epoch 48  56.4% | batch:        53 of        94\t|\tloss: 2779.73\n",
      "Training Epoch 48  57.4% | batch:        54 of        94\t|\tloss: 2331.92\n",
      "Training Epoch 48  58.5% | batch:        55 of        94\t|\tloss: 1142.12\n",
      "Training Epoch 48  59.6% | batch:        56 of        94\t|\tloss: 841.306\n",
      "Training Epoch 48  60.6% | batch:        57 of        94\t|\tloss: 1023.61\n",
      "Training Epoch 48  61.7% | batch:        58 of        94\t|\tloss: 1129.43\n",
      "Training Epoch 48  62.8% | batch:        59 of        94\t|\tloss: 1019.03\n",
      "Training Epoch 48  63.8% | batch:        60 of        94\t|\tloss: 1229.38\n",
      "Training Epoch 48  64.9% | batch:        61 of        94\t|\tloss: 1020.92\n",
      "Training Epoch 48  66.0% | batch:        62 of        94\t|\tloss: 1612.69\n",
      "Training Epoch 48  67.0% | batch:        63 of        94\t|\tloss: 1238.59\n",
      "Training Epoch 48  68.1% | batch:        64 of        94\t|\tloss: 1265.17\n",
      "Training Epoch 48  69.1% | batch:        65 of        94\t|\tloss: 937.705\n",
      "Training Epoch 48  70.2% | batch:        66 of        94\t|\tloss: 973.16\n",
      "Training Epoch 48  71.3% | batch:        67 of        94\t|\tloss: 1167.17\n",
      "Training Epoch 48  72.3% | batch:        68 of        94\t|\tloss: 1399.6\n",
      "Training Epoch 48  73.4% | batch:        69 of        94\t|\tloss: 1245.25\n",
      "Training Epoch 48  74.5% | batch:        70 of        94\t|\tloss: 1364.45\n",
      "Training Epoch 48  75.5% | batch:        71 of        94\t|\tloss: 1004.27\n",
      "Training Epoch 48  76.6% | batch:        72 of        94\t|\tloss: 931.742\n",
      "Training Epoch 48  77.7% | batch:        73 of        94\t|\tloss: 1441.68\n",
      "Training Epoch 48  78.7% | batch:        74 of        94\t|\tloss: 1284.88\n",
      "Training Epoch 48  79.8% | batch:        75 of        94\t|\tloss: 1070.6\n",
      "Training Epoch 48  80.9% | batch:        76 of        94\t|\tloss: 1255.07\n",
      "Training Epoch 48  81.9% | batch:        77 of        94\t|\tloss: 1493.62\n",
      "Training Epoch 48  83.0% | batch:        78 of        94\t|\tloss: 2026.47\n",
      "Training Epoch 48  84.0% | batch:        79 of        94\t|\tloss: 1082.37\n",
      "Training Epoch 48  85.1% | batch:        80 of        94\t|\tloss: 923.797\n",
      "Training Epoch 48  86.2% | batch:        81 of        94\t|\tloss: 785.57\n",
      "Training Epoch 48  87.2% | batch:        82 of        94\t|\tloss: 2358.11\n",
      "Training Epoch 48  88.3% | batch:        83 of        94\t|\tloss: 2633.73\n",
      "Training Epoch 48  89.4% | batch:        84 of        94\t|\tloss: 868.907\n",
      "Training Epoch 48  90.4% | batch:        85 of        94\t|\tloss: 1003.7\n",
      "Training Epoch 48  91.5% | batch:        86 of        94\t|\tloss: 1088.75\n",
      "Training Epoch 48  92.6% | batch:        87 of        94\t|\tloss: 1807.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:57,223 | INFO : Epoch 48 Training Summary: epoch: 48.000000 | loss: 1352.416839 | \n",
      "2023-05-09 14:21:57,224 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8183047771453857 seconds\n",
      "\n",
      "2023-05-09 14:21:57,224 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8283112198114395 seconds\n",
      "2023-05-09 14:21:57,225 | INFO : Avg batch train. time: 0.019450119359696164 seconds\n",
      "2023-05-09 14:21:57,225 | INFO : Avg sample train. time: 0.0001534075532649303 seconds\n",
      "2023-05-09 14:21:57,225 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 48  93.6% | batch:        88 of        94\t|\tloss: 1632.89\n",
      "Training Epoch 48  94.7% | batch:        89 of        94\t|\tloss: 1051.5\n",
      "Training Epoch 48  95.7% | batch:        90 of        94\t|\tloss: 965.717\n",
      "Training Epoch 48  96.8% | batch:        91 of        94\t|\tloss: 1269.6\n",
      "Training Epoch 48  97.9% | batch:        92 of        94\t|\tloss: 869.43\n",
      "Training Epoch 48  98.9% | batch:        93 of        94\t|\tloss: 997.646\n",
      "\n",
      "Evaluating Epoch 48   0.0% | batch:         0 of        40\t|\tloss: 6627.88\n",
      "Evaluating Epoch 48   2.5% | batch:         1 of        40\t|\tloss: 1141.17\n",
      "Evaluating Epoch 48   5.0% | batch:         2 of        40\t|\tloss: 4298.82\n",
      "Evaluating Epoch 48   7.5% | batch:         3 of        40\t|\tloss: 6876.75\n",
      "Evaluating Epoch 48  10.0% | batch:         4 of        40\t|\tloss: 2694.33\n",
      "Evaluating Epoch 48  12.5% | batch:         5 of        40\t|\tloss: 2611.7\n",
      "Evaluating Epoch 48  15.0% | batch:         6 of        40\t|\tloss: 8589.56\n",
      "Evaluating Epoch 48  17.5% | batch:         7 of        40\t|\tloss: 3290.94\n",
      "Evaluating Epoch 48  20.0% | batch:         8 of        40\t|\tloss: 2859.86\n",
      "Evaluating Epoch 48  22.5% | batch:         9 of        40\t|\tloss: 2401.67\n",
      "Evaluating Epoch 48  25.0% | batch:        10 of        40\t|\tloss: 5327.96\n",
      "Evaluating Epoch 48  27.5% | batch:        11 of        40\t|\tloss: 1302.46\n",
      "Evaluating Epoch 48  30.0% | batch:        12 of        40\t|\tloss: 5944.09\n",
      "Evaluating Epoch 48  32.5% | batch:        13 of        40\t|\tloss: 3625.95\n",
      "Evaluating Epoch 48  35.0% | batch:        14 of        40\t|\tloss: 2009.36\n",
      "Evaluating Epoch 48  37.5% | batch:        15 of        40\t|\tloss: 3242.53\n",
      "Evaluating Epoch 48  40.0% | batch:        16 of        40\t|\tloss: 4074.23\n",
      "Evaluating Epoch 48  42.5% | batch:        17 of        40\t|\tloss: 3202.11\n",
      "Evaluating Epoch 48  45.0% | batch:        18 of        40\t|\tloss: 2229.13\n",
      "Evaluating Epoch 48  47.5% | batch:        19 of        40\t|\tloss: 5722.81\n",
      "Evaluating Epoch 48  50.0% | batch:        20 of        40\t|\tloss: 5350.55\n",
      "Evaluating Epoch 48  52.5% | batch:        21 of        40\t|\tloss: 1061.38\n",
      "Evaluating Epoch 48  55.0% | batch:        22 of        40\t|\tloss: 5053.01\n",
      "Evaluating Epoch 48  57.5% | batch:        23 of        40\t|\tloss: 3737.49\n",
      "Evaluating Epoch 48  60.0% | batch:        24 of        40\t|\tloss: 1588\n",
      "Evaluating Epoch 48  62.5% | batch:        25 of        40\t|\tloss: 3645.94\n",
      "Evaluating Epoch 48  65.0% | batch:        26 of        40\t|\tloss: 9063.55\n",
      "Evaluating Epoch 48  67.5% | batch:        27 of        40\t|\tloss: 2859.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:57,684 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4585402011871338 seconds\n",
      "\n",
      "2023-05-09 14:21:57,685 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48380141991835374 seconds\n",
      "2023-05-09 14:21:57,685 | INFO : Avg batch val. time: 0.012095035497958843 seconds\n",
      "2023-05-09 14:21:57,686 | INFO : Avg sample val. time: 9.584021789190843e-05 seconds\n",
      "2023-05-09 14:21:57,686 | INFO : Epoch 48 Validation Summary: epoch: 48.000000 | loss: 4172.548639 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 48  70.0% | batch:        28 of        40\t|\tloss: 1997.47\n",
      "Evaluating Epoch 48  72.5% | batch:        29 of        40\t|\tloss: 9647.58\n",
      "Evaluating Epoch 48  75.0% | batch:        30 of        40\t|\tloss: 2076.62\n",
      "Evaluating Epoch 48  77.5% | batch:        31 of        40\t|\tloss: 2004.52\n",
      "Evaluating Epoch 48  80.0% | batch:        32 of        40\t|\tloss: 7697.48\n",
      "Evaluating Epoch 48  82.5% | batch:        33 of        40\t|\tloss: 6247.35\n",
      "Evaluating Epoch 48  85.0% | batch:        34 of        40\t|\tloss: 954.919\n",
      "Evaluating Epoch 48  87.5% | batch:        35 of        40\t|\tloss: 5531.43\n",
      "Evaluating Epoch 48  90.0% | batch:        36 of        40\t|\tloss: 5601.68\n",
      "Evaluating Epoch 48  92.5% | batch:        37 of        40\t|\tloss: 2652.14\n",
      "Evaluating Epoch 48  95.0% | batch:        38 of        40\t|\tloss: 3621.59\n",
      "Evaluating Epoch 48  97.5% | batch:        39 of        40\t|\tloss: 13917.6\n",
      "\n",
      "Training Epoch 49   0.0% | batch:         0 of        94\t|\tloss: 919.138\n",
      "Training Epoch 49   1.1% | batch:         1 of        94\t|\tloss: 642.406\n",
      "Training Epoch 49   2.1% | batch:         2 of        94\t|\tloss: 1414.3\n",
      "Training Epoch 49   3.2% | batch:         3 of        94\t|\tloss: 1390.4\n",
      "Training Epoch 49   4.3% | batch:         4 of        94\t|\tloss: 1179.69\n",
      "Training Epoch 49   5.3% | batch:         5 of        94\t|\tloss: 1646.87\n",
      "Training Epoch 49   6.4% | batch:         6 of        94\t|\tloss: 898.491\n",
      "Training Epoch 49   7.4% | batch:         7 of        94\t|\tloss: 1394.69\n",
      "Training Epoch 49   8.5% | batch:         8 of        94\t|\tloss: 1258.85\n",
      "Training Epoch 49   9.6% | batch:         9 of        94\t|\tloss: 1079.99\n",
      "Training Epoch 49  10.6% | batch:        10 of        94\t|\tloss: 1037.53\n",
      "Training Epoch 49  11.7% | batch:        11 of        94\t|\tloss: 1123.25\n",
      "Training Epoch 49  12.8% | batch:        12 of        94\t|\tloss: 881.584\n",
      "Training Epoch 49  13.8% | batch:        13 of        94\t|\tloss: 992.367\n",
      "Training Epoch 49  14.9% | batch:        14 of        94\t|\tloss: 1118.75\n",
      "Training Epoch 49  16.0% | batch:        15 of        94\t|\tloss: 874.658\n",
      "Training Epoch 49  17.0% | batch:        16 of        94\t|\tloss: 985.959\n",
      "Training Epoch 49  18.1% | batch:        17 of        94\t|\tloss: 1112.72\n",
      "Training Epoch 49  19.1% | batch:        18 of        94\t|\tloss: 1024.42\n",
      "Training Epoch 49  20.2% | batch:        19 of        94\t|\tloss: 999.975\n",
      "Training Epoch 49  21.3% | batch:        20 of        94\t|\tloss: 1140.61\n",
      "Training Epoch 49  22.3% | batch:        21 of        94\t|\tloss: 2583.41\n",
      "Training Epoch 49  23.4% | batch:        22 of        94\t|\tloss: 1030.75\n",
      "Training Epoch 49  24.5% | batch:        23 of        94\t|\tloss: 1511.2\n",
      "Training Epoch 49  25.5% | batch:        24 of        94\t|\tloss: 999.599\n",
      "Training Epoch 49  26.6% | batch:        25 of        94\t|\tloss: 1317.06\n",
      "Training Epoch 49  27.7% | batch:        26 of        94\t|\tloss: 1179.07\n",
      "Training Epoch 49  28.7% | batch:        27 of        94\t|\tloss: 1684.66\n",
      "Training Epoch 49  29.8% | batch:        28 of        94\t|\tloss: 1030.63\n",
      "Training Epoch 49  30.9% | batch:        29 of        94\t|\tloss: 991.542\n",
      "Training Epoch 49  31.9% | batch:        30 of        94\t|\tloss: 1654.43\n",
      "Training Epoch 49  33.0% | batch:        31 of        94\t|\tloss: 1735.27\n",
      "Training Epoch 49  34.0% | batch:        32 of        94\t|\tloss: 1229.95\n",
      "Training Epoch 49  35.1% | batch:        33 of        94\t|\tloss: 2369.85\n",
      "Training Epoch 49  36.2% | batch:        34 of        94\t|\tloss: 1091.26\n",
      "Training Epoch 49  37.2% | batch:        35 of        94\t|\tloss: 1482.85\n",
      "Training Epoch 49  38.3% | batch:        36 of        94\t|\tloss: 1515.71\n",
      "Training Epoch 49  39.4% | batch:        37 of        94\t|\tloss: 2003.6\n",
      "Training Epoch 49  40.4% | batch:        38 of        94\t|\tloss: 1732.02\n",
      "Training Epoch 49  41.5% | batch:        39 of        94\t|\tloss: 1254.26\n",
      "Training Epoch 49  42.6% | batch:        40 of        94\t|\tloss: 854.113\n",
      "Training Epoch 49  43.6% | batch:        41 of        94\t|\tloss: 919.088\n",
      "Training Epoch 49  44.7% | batch:        42 of        94\t|\tloss: 1520.18\n",
      "Training Epoch 49  45.7% | batch:        43 of        94\t|\tloss: 1122.83\n",
      "Training Epoch 49  46.8% | batch:        44 of        94\t|\tloss: 1380.52\n",
      "Training Epoch 49  47.9% | batch:        45 of        94\t|\tloss: 1284.02\n",
      "Training Epoch 49  48.9% | batch:        46 of        94\t|\tloss: 654.174\n",
      "Training Epoch 49  50.0% | batch:        47 of        94\t|\tloss: 1061.25\n",
      "Training Epoch 49  51.1% | batch:        48 of        94\t|\tloss: 2303.71\n",
      "Training Epoch 49  52.1% | batch:        49 of        94\t|\tloss: 821.316\n",
      "Training Epoch 49  53.2% | batch:        50 of        94\t|\tloss: 1241.79\n",
      "Training Epoch 49  54.3% | batch:        51 of        94\t|\tloss: 1949.85\n",
      "Training Epoch 49  55.3% | batch:        52 of        94\t|\tloss: 1079.95\n",
      "Training Epoch 49  56.4% | batch:        53 of        94\t|\tloss: 1704.66\n",
      "Training Epoch 49  57.4% | batch:        54 of        94\t|\tloss: 993.097\n",
      "Training Epoch 49  58.5% | batch:        55 of        94\t|\tloss: 1414.03\n",
      "Training Epoch 49  59.6% | batch:        56 of        94\t|\tloss: 1123.59\n",
      "Training Epoch 49  60.6% | batch:        57 of        94\t|\tloss: 1768.19\n",
      "Training Epoch 49  61.7% | batch:        58 of        94\t|\tloss: 1032.44\n",
      "Training Epoch 49  62.8% | batch:        59 of        94\t|\tloss: 994.599\n",
      "Training Epoch 49  63.8% | batch:        60 of        94\t|\tloss: 1277.37\n",
      "Training Epoch 49  64.9% | batch:        61 of        94\t|\tloss: 830.927\n",
      "Training Epoch 49  66.0% | batch:        62 of        94\t|\tloss: 1834.72\n",
      "Training Epoch 49  67.0% | batch:        63 of        94\t|\tloss: 2458.62\n",
      "Training Epoch 49  68.1% | batch:        64 of        94\t|\tloss: 4030.53\n",
      "Training Epoch 49  69.1% | batch:        65 of        94\t|\tloss: 1189.24\n",
      "Training Epoch 49  70.2% | batch:        66 of        94\t|\tloss: 1356.01\n",
      "Training Epoch 49  71.3% | batch:        67 of        94\t|\tloss: 925.98\n",
      "Training Epoch 49  72.3% | batch:        68 of        94\t|\tloss: 2011.94\n",
      "Training Epoch 49  73.4% | batch:        69 of        94\t|\tloss: 1376.84\n",
      "Training Epoch 49  74.5% | batch:        70 of        94\t|\tloss: 1932.7\n",
      "Training Epoch 49  75.5% | batch:        71 of        94\t|\tloss: 3232.69\n",
      "Training Epoch 49  76.6% | batch:        72 of        94\t|\tloss: 2065.28\n",
      "Training Epoch 49  77.7% | batch:        73 of        94\t|\tloss: 1102.11\n",
      "Training Epoch 49  78.7% | batch:        74 of        94\t|\tloss: 1028.08\n",
      "Training Epoch 49  79.8% | batch:        75 of        94\t|\tloss: 795.092\n",
      "Training Epoch 49  80.9% | batch:        76 of        94\t|\tloss: 968.582\n",
      "Training Epoch 49  81.9% | batch:        77 of        94\t|\tloss: 952.393\n",
      "Training Epoch 49  83.0% | batch:        78 of        94\t|\tloss: 973.203\n",
      "Training Epoch 49  84.0% | batch:        79 of        94\t|\tloss: 1301.92\n",
      "Training Epoch 49  85.1% | batch:        80 of        94\t|\tloss: 1558\n",
      "Training Epoch 49  86.2% | batch:        81 of        94\t|\tloss: 1428.55\n",
      "Training Epoch 49  87.2% | batch:        82 of        94\t|\tloss: 863.983\n",
      "Training Epoch 49  88.3% | batch:        83 of        94\t|\tloss: 2774.77\n",
      "Training Epoch 49  89.4% | batch:        84 of        94\t|\tloss: 1013.52\n",
      "Training Epoch 49  90.4% | batch:        85 of        94\t|\tloss: 1063.23\n",
      "Training Epoch 49  91.5% | batch:        86 of        94\t|\tloss: 904.665\n",
      "Training Epoch 49  92.6% | batch:        87 of        94\t|\tloss: 1624.12\n",
      "Training Epoch 49  93.6% | batch:        88 of        94\t|\tloss: 1320.85\n",
      "Training Epoch 49  94.7% | batch:        89 of        94\t|\tloss: 1998.05\n",
      "Training Epoch 49  95.7% | batch:        90 of        94\t|\tloss: 1896.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:21:59,544 | INFO : Epoch 49 Training Summary: epoch: 49.000000 | loss: 1370.657696 | \n",
      "2023-05-09 14:21:59,544 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8360559940338135 seconds\n",
      "\n",
      "2023-05-09 14:21:59,545 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8284692764282227 seconds\n",
      "2023-05-09 14:21:59,545 | INFO : Avg batch train. time: 0.0194518008130662 seconds\n",
      "2023-05-09 14:21:59,546 | INFO : Avg sample train. time: 0.0001534208152733867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 49  96.8% | batch:        91 of        94\t|\tloss: 982.382\n",
      "Training Epoch 49  97.9% | batch:        92 of        94\t|\tloss: 1699.69\n",
      "Training Epoch 49  98.9% | batch:        93 of        94\t|\tloss: 1016.73\n",
      "\n",
      "Training Epoch 50   0.0% | batch:         0 of        94\t|\tloss: 986.47\n",
      "Training Epoch 50   1.1% | batch:         1 of        94\t|\tloss: 826.615\n",
      "Training Epoch 50   2.1% | batch:         2 of        94\t|\tloss: 921.874\n",
      "Training Epoch 50   3.2% | batch:         3 of        94\t|\tloss: 2885.74\n",
      "Training Epoch 50   4.3% | batch:         4 of        94\t|\tloss: 745.439\n",
      "Training Epoch 50   5.3% | batch:         5 of        94\t|\tloss: 1643.28\n",
      "Training Epoch 50   6.4% | batch:         6 of        94\t|\tloss: 1762.96\n",
      "Training Epoch 50   7.4% | batch:         7 of        94\t|\tloss: 1535.76\n",
      "Training Epoch 50   8.5% | batch:         8 of        94\t|\tloss: 1193.47\n",
      "Training Epoch 50   9.6% | batch:         9 of        94\t|\tloss: 823.392\n",
      "Training Epoch 50  10.6% | batch:        10 of        94\t|\tloss: 1509.05\n",
      "Training Epoch 50  11.7% | batch:        11 of        94\t|\tloss: 1050.06\n",
      "Training Epoch 50  12.8% | batch:        12 of        94\t|\tloss: 951.421\n",
      "Training Epoch 50  13.8% | batch:        13 of        94\t|\tloss: 1263.13\n",
      "Training Epoch 50  14.9% | batch:        14 of        94\t|\tloss: 1114.08\n",
      "Training Epoch 50  16.0% | batch:        15 of        94\t|\tloss: 2522.94\n",
      "Training Epoch 50  17.0% | batch:        16 of        94\t|\tloss: 1006.34\n",
      "Training Epoch 50  18.1% | batch:        17 of        94\t|\tloss: 844.105\n",
      "Training Epoch 50  19.1% | batch:        18 of        94\t|\tloss: 1154.95\n",
      "Training Epoch 50  20.2% | batch:        19 of        94\t|\tloss: 1266.66\n",
      "Training Epoch 50  21.3% | batch:        20 of        94\t|\tloss: 1790.75\n",
      "Training Epoch 50  22.3% | batch:        21 of        94\t|\tloss: 701.475\n",
      "Training Epoch 50  23.4% | batch:        22 of        94\t|\tloss: 682.81\n",
      "Training Epoch 50  24.5% | batch:        23 of        94\t|\tloss: 831.834\n",
      "Training Epoch 50  25.5% | batch:        24 of        94\t|\tloss: 1472.82\n",
      "Training Epoch 50  26.6% | batch:        25 of        94\t|\tloss: 1324.89\n",
      "Training Epoch 50  27.7% | batch:        26 of        94\t|\tloss: 889.224\n",
      "Training Epoch 50  28.7% | batch:        27 of        94\t|\tloss: 1639.09\n",
      "Training Epoch 50  29.8% | batch:        28 of        94\t|\tloss: 2334.6\n",
      "Training Epoch 50  30.9% | batch:        29 of        94\t|\tloss: 1156.55\n",
      "Training Epoch 50  31.9% | batch:        30 of        94\t|\tloss: 1783.54\n",
      "Training Epoch 50  33.0% | batch:        31 of        94\t|\tloss: 1427.4\n",
      "Training Epoch 50  34.0% | batch:        32 of        94\t|\tloss: 1027.07\n",
      "Training Epoch 50  35.1% | batch:        33 of        94\t|\tloss: 1223.54\n",
      "Training Epoch 50  36.2% | batch:        34 of        94\t|\tloss: 1384\n",
      "Training Epoch 50  37.2% | batch:        35 of        94\t|\tloss: 1123.72\n",
      "Training Epoch 50  38.3% | batch:        36 of        94\t|\tloss: 1502.53\n",
      "Training Epoch 50  39.4% | batch:        37 of        94\t|\tloss: 1700.62\n",
      "Training Epoch 50  40.4% | batch:        38 of        94\t|\tloss: 785.71\n",
      "Training Epoch 50  41.5% | batch:        39 of        94\t|\tloss: 1120.52\n",
      "Training Epoch 50  42.6% | batch:        40 of        94\t|\tloss: 869.733\n",
      "Training Epoch 50  43.6% | batch:        41 of        94\t|\tloss: 1024.78\n",
      "Training Epoch 50  44.7% | batch:        42 of        94\t|\tloss: 986.175\n",
      "Training Epoch 50  45.7% | batch:        43 of        94\t|\tloss: 1021.07\n",
      "Training Epoch 50  46.8% | batch:        44 of        94\t|\tloss: 2269.94\n",
      "Training Epoch 50  47.9% | batch:        45 of        94\t|\tloss: 695.574\n",
      "Training Epoch 50  48.9% | batch:        46 of        94\t|\tloss: 789.871\n",
      "Training Epoch 50  50.0% | batch:        47 of        94\t|\tloss: 1634.04\n",
      "Training Epoch 50  51.1% | batch:        48 of        94\t|\tloss: 1201.82\n",
      "Training Epoch 50  52.1% | batch:        49 of        94\t|\tloss: 881.862\n",
      "Training Epoch 50  53.2% | batch:        50 of        94\t|\tloss: 993.529\n",
      "Training Epoch 50  54.3% | batch:        51 of        94\t|\tloss: 1786.41\n",
      "Training Epoch 50  55.3% | batch:        52 of        94\t|\tloss: 1084.24\n",
      "Training Epoch 50  56.4% | batch:        53 of        94\t|\tloss: 1400.65\n",
      "Training Epoch 50  57.4% | batch:        54 of        94\t|\tloss: 2289.26\n",
      "Training Epoch 50  58.5% | batch:        55 of        94\t|\tloss: 1050.99\n",
      "Training Epoch 50  59.6% | batch:        56 of        94\t|\tloss: 1780.97\n",
      "Training Epoch 50  60.6% | batch:        57 of        94\t|\tloss: 1413.36\n",
      "Training Epoch 50  61.7% | batch:        58 of        94\t|\tloss: 1435.45\n",
      "Training Epoch 50  62.8% | batch:        59 of        94\t|\tloss: 1319.68\n",
      "Training Epoch 50  63.8% | batch:        60 of        94\t|\tloss: 1265.6\n",
      "Training Epoch 50  64.9% | batch:        61 of        94\t|\tloss: 1230.75\n",
      "Training Epoch 50  66.0% | batch:        62 of        94\t|\tloss: 1142.67\n",
      "Training Epoch 50  67.0% | batch:        63 of        94\t|\tloss: 988.434\n",
      "Training Epoch 50  68.1% | batch:        64 of        94\t|\tloss: 2916.05\n",
      "Training Epoch 50  69.1% | batch:        65 of        94\t|\tloss: 1179.72\n",
      "Training Epoch 50  70.2% | batch:        66 of        94\t|\tloss: 1258.57\n",
      "Training Epoch 50  71.3% | batch:        67 of        94\t|\tloss: 846.651\n",
      "Training Epoch 50  72.3% | batch:        68 of        94\t|\tloss: 1212.71\n",
      "Training Epoch 50  73.4% | batch:        69 of        94\t|\tloss: 1173.99\n",
      "Training Epoch 50  74.5% | batch:        70 of        94\t|\tloss: 1094.31\n",
      "Training Epoch 50  75.5% | batch:        71 of        94\t|\tloss: 2701.31\n",
      "Training Epoch 50  76.6% | batch:        72 of        94\t|\tloss: 1395.69\n",
      "Training Epoch 50  77.7% | batch:        73 of        94\t|\tloss: 1296.33\n",
      "Training Epoch 50  78.7% | batch:        74 of        94\t|\tloss: 1566.73\n",
      "Training Epoch 50  79.8% | batch:        75 of        94\t|\tloss: 1168.7\n",
      "Training Epoch 50  80.9% | batch:        76 of        94\t|\tloss: 969.33\n",
      "Training Epoch 50  81.9% | batch:        77 of        94\t|\tloss: 881.644\n",
      "Training Epoch 50  83.0% | batch:        78 of        94\t|\tloss: 1045.62\n",
      "Training Epoch 50  84.0% | batch:        79 of        94\t|\tloss: 1679.9\n",
      "Training Epoch 50  85.1% | batch:        80 of        94\t|\tloss: 1285.97\n",
      "Training Epoch 50  86.2% | batch:        81 of        94\t|\tloss: 908.651\n",
      "Training Epoch 50  87.2% | batch:        82 of        94\t|\tloss: 1003.22\n",
      "Training Epoch 50  88.3% | batch:        83 of        94\t|\tloss: 1027.99\n",
      "Training Epoch 50  89.4% | batch:        84 of        94\t|\tloss: 835.941\n",
      "Training Epoch 50  90.4% | batch:        85 of        94\t|\tloss: 1215.29\n",
      "Training Epoch 50  91.5% | batch:        86 of        94\t|\tloss: 1780.38\n",
      "Training Epoch 50  92.6% | batch:        87 of        94\t|\tloss: 1180.09\n",
      "Training Epoch 50  93.6% | batch:        88 of        94\t|\tloss: 926.817\n",
      "Training Epoch 50  94.7% | batch:        89 of        94\t|\tloss: 963.483\n",
      "Training Epoch 50  95.7% | batch:        90 of        94\t|\tloss: 897.436\n",
      "Training Epoch 50  96.8% | batch:        91 of        94\t|\tloss: 806.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:01,404 | INFO : Epoch 50 Training Summary: epoch: 50.000000 | loss: 1297.613478 | \n",
      "2023-05-09 14:22:01,405 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8378775119781494 seconds\n",
      "\n",
      "2023-05-09 14:22:01,406 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8286574411392211 seconds\n",
      "2023-05-09 14:22:01,406 | INFO : Avg batch train. time: 0.019453802565310863 seconds\n",
      "2023-05-09 14:22:01,407 | INFO : Avg sample train. time: 0.00015343660355254414 seconds\n",
      "2023-05-09 14:22:01,407 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 50  97.9% | batch:        92 of        94\t|\tloss: 2620.56\n",
      "Training Epoch 50  98.9% | batch:        93 of        94\t|\tloss: 4693.38\n",
      "\n",
      "Evaluating Epoch 50   0.0% | batch:         0 of        40\t|\tloss: 6954.26\n",
      "Evaluating Epoch 50   2.5% | batch:         1 of        40\t|\tloss: 1250.78\n",
      "Evaluating Epoch 50   5.0% | batch:         2 of        40\t|\tloss: 3902.81\n",
      "Evaluating Epoch 50   7.5% | batch:         3 of        40\t|\tloss: 7030.29\n",
      "Evaluating Epoch 50  10.0% | batch:         4 of        40\t|\tloss: 3167.94\n",
      "Evaluating Epoch 50  12.5% | batch:         5 of        40\t|\tloss: 2666\n",
      "Evaluating Epoch 50  15.0% | batch:         6 of        40\t|\tloss: 8959.52\n",
      "Evaluating Epoch 50  17.5% | batch:         7 of        40\t|\tloss: 3138\n",
      "Evaluating Epoch 50  20.0% | batch:         8 of        40\t|\tloss: 3144.84\n",
      "Evaluating Epoch 50  22.5% | batch:         9 of        40\t|\tloss: 2357.75\n",
      "Evaluating Epoch 50  25.0% | batch:        10 of        40\t|\tloss: 5238.46\n",
      "Evaluating Epoch 50  27.5% | batch:        11 of        40\t|\tloss: 1373.96\n",
      "Evaluating Epoch 50  30.0% | batch:        12 of        40\t|\tloss: 6391.46\n",
      "Evaluating Epoch 50  32.5% | batch:        13 of        40\t|\tloss: 3488.28\n",
      "Evaluating Epoch 50  35.0% | batch:        14 of        40\t|\tloss: 2218.99\n",
      "Evaluating Epoch 50  37.5% | batch:        15 of        40\t|\tloss: 3193.64\n",
      "Evaluating Epoch 50  40.0% | batch:        16 of        40\t|\tloss: 4131.26\n",
      "Evaluating Epoch 50  42.5% | batch:        17 of        40\t|\tloss: 2803.6\n",
      "Evaluating Epoch 50  45.0% | batch:        18 of        40\t|\tloss: 2281.39\n",
      "Evaluating Epoch 50  47.5% | batch:        19 of        40\t|\tloss: 5356.09\n",
      "Evaluating Epoch 50  50.0% | batch:        20 of        40\t|\tloss: 5225.33\n",
      "Evaluating Epoch 50  52.5% | batch:        21 of        40\t|\tloss: 1227.86\n",
      "Evaluating Epoch 50  55.0% | batch:        22 of        40\t|\tloss: 4625.16\n",
      "Evaluating Epoch 50  57.5% | batch:        23 of        40\t|\tloss: 3710.6\n",
      "Evaluating Epoch 50  60.0% | batch:        24 of        40\t|\tloss: 1691.5\n",
      "Evaluating Epoch 50  62.5% | batch:        25 of        40\t|\tloss: 3394.92\n",
      "Evaluating Epoch 50  65.0% | batch:        26 of        40\t|\tloss: 10252\n",
      "Evaluating Epoch 50  67.5% | batch:        27 of        40\t|\tloss: 2888.05\n",
      "Evaluating Epoch 50  70.0% | batch:        28 of        40\t|\tloss: 2236.91\n",
      "Evaluating Epoch 50  72.5% | batch:        29 of        40\t|\tloss: 9432.38\n",
      "Evaluating Epoch 50  75.0% | batch:        30 of        40\t|\tloss: 2059.11\n",
      "Evaluating Epoch 50  77.5% | batch:        31 of        40\t|\tloss: 1813.58\n",
      "Evaluating Epoch 50  80.0% | batch:        32 of        40\t|\tloss: 7191.06\n",
      "Evaluating Epoch 50  82.5% | batch:        33 of        40\t|\tloss: 6679.91\n",
      "Evaluating Epoch 50  85.0% | batch:        34 of        40\t|\tloss: 921.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:01,865 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4573228359222412 seconds\n",
      "\n",
      "2023-05-09 14:22:01,866 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4828207316222014 seconds\n",
      "2023-05-09 14:22:01,866 | INFO : Avg batch val. time: 0.012070518290555035 seconds\n",
      "2023-05-09 14:22:01,866 | INFO : Avg sample val. time: 9.56459452500399e-05 seconds\n",
      "2023-05-09 14:22:01,867 | INFO : Epoch 50 Validation Summary: epoch: 50.000000 | loss: 4198.296665 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 50  87.5% | batch:        35 of        40\t|\tloss: 5428.27\n",
      "Evaluating Epoch 50  90.0% | batch:        36 of        40\t|\tloss: 5615.77\n",
      "Evaluating Epoch 50  92.5% | batch:        37 of        40\t|\tloss: 2865.15\n",
      "Evaluating Epoch 50  95.0% | batch:        38 of        40\t|\tloss: 2920.04\n",
      "Evaluating Epoch 50  97.5% | batch:        39 of        40\t|\tloss: 14496.4\n",
      "\n",
      "Training Epoch 51   0.0% | batch:         0 of        94\t|\tloss: 840.347\n",
      "Training Epoch 51   1.1% | batch:         1 of        94\t|\tloss: 1218.58\n",
      "Training Epoch 51   2.1% | batch:         2 of        94\t|\tloss: 993.188\n",
      "Training Epoch 51   3.2% | batch:         3 of        94\t|\tloss: 994.998\n",
      "Training Epoch 51   4.3% | batch:         4 of        94\t|\tloss: 1560.8\n",
      "Training Epoch 51   5.3% | batch:         5 of        94\t|\tloss: 1328.87\n",
      "Training Epoch 51   6.4% | batch:         6 of        94\t|\tloss: 2981.78\n",
      "Training Epoch 51   7.4% | batch:         7 of        94\t|\tloss: 1170.94\n",
      "Training Epoch 51   8.5% | batch:         8 of        94\t|\tloss: 1202.14\n",
      "Training Epoch 51   9.6% | batch:         9 of        94\t|\tloss: 1145.18\n",
      "Training Epoch 51  10.6% | batch:        10 of        94\t|\tloss: 944.618\n",
      "Training Epoch 51  11.7% | batch:        11 of        94\t|\tloss: 2546.04\n",
      "Training Epoch 51  12.8% | batch:        12 of        94\t|\tloss: 854.523\n",
      "Training Epoch 51  13.8% | batch:        13 of        94\t|\tloss: 1432.6\n",
      "Training Epoch 51  14.9% | batch:        14 of        94\t|\tloss: 892.239\n",
      "Training Epoch 51  16.0% | batch:        15 of        94\t|\tloss: 1284.04\n",
      "Training Epoch 51  17.0% | batch:        16 of        94\t|\tloss: 1303.51\n",
      "Training Epoch 51  18.1% | batch:        17 of        94\t|\tloss: 1169.9\n",
      "Training Epoch 51  19.1% | batch:        18 of        94\t|\tloss: 959.221\n",
      "Training Epoch 51  20.2% | batch:        19 of        94\t|\tloss: 1369.76\n",
      "Training Epoch 51  21.3% | batch:        20 of        94\t|\tloss: 1358.52\n",
      "Training Epoch 51  22.3% | batch:        21 of        94\t|\tloss: 1081.58\n",
      "Training Epoch 51  23.4% | batch:        22 of        94\t|\tloss: 886.41\n",
      "Training Epoch 51  24.5% | batch:        23 of        94\t|\tloss: 1045.26\n",
      "Training Epoch 51  25.5% | batch:        24 of        94\t|\tloss: 1891.95\n",
      "Training Epoch 51  26.6% | batch:        25 of        94\t|\tloss: 927.456\n",
      "Training Epoch 51  27.7% | batch:        26 of        94\t|\tloss: 1087.19\n",
      "Training Epoch 51  28.7% | batch:        27 of        94\t|\tloss: 871.322\n",
      "Training Epoch 51  29.8% | batch:        28 of        94\t|\tloss: 870.306\n",
      "Training Epoch 51  30.9% | batch:        29 of        94\t|\tloss: 2573.44\n",
      "Training Epoch 51  31.9% | batch:        30 of        94\t|\tloss: 1175.5\n",
      "Training Epoch 51  33.0% | batch:        31 of        94\t|\tloss: 1125.97\n",
      "Training Epoch 51  34.0% | batch:        32 of        94\t|\tloss: 3783.03\n",
      "Training Epoch 51  35.1% | batch:        33 of        94\t|\tloss: 1216.59\n",
      "Training Epoch 51  36.2% | batch:        34 of        94\t|\tloss: 856.704\n",
      "Training Epoch 51  37.2% | batch:        35 of        94\t|\tloss: 923.621\n",
      "Training Epoch 51  38.3% | batch:        36 of        94\t|\tloss: 896.291\n",
      "Training Epoch 51  39.4% | batch:        37 of        94\t|\tloss: 1078\n",
      "Training Epoch 51  40.4% | batch:        38 of        94\t|\tloss: 2789.67\n",
      "Training Epoch 51  41.5% | batch:        39 of        94\t|\tloss: 3130.29\n",
      "Training Epoch 51  42.6% | batch:        40 of        94\t|\tloss: 784.878\n",
      "Training Epoch 51  43.6% | batch:        41 of        94\t|\tloss: 1160.46\n",
      "Training Epoch 51  44.7% | batch:        42 of        94\t|\tloss: 1074.87\n",
      "Training Epoch 51  45.7% | batch:        43 of        94\t|\tloss: 854.802\n",
      "Training Epoch 51  46.8% | batch:        44 of        94\t|\tloss: 771.89\n",
      "Training Epoch 51  47.9% | batch:        45 of        94\t|\tloss: 1048.37\n",
      "Training Epoch 51  48.9% | batch:        46 of        94\t|\tloss: 1473.57\n",
      "Training Epoch 51  50.0% | batch:        47 of        94\t|\tloss: 820.289\n",
      "Training Epoch 51  51.1% | batch:        48 of        94\t|\tloss: 1277.53\n",
      "Training Epoch 51  52.1% | batch:        49 of        94\t|\tloss: 1628.47\n",
      "Training Epoch 51  53.2% | batch:        50 of        94\t|\tloss: 1802.57\n",
      "Training Epoch 51  54.3% | batch:        51 of        94\t|\tloss: 965.764\n",
      "Training Epoch 51  55.3% | batch:        52 of        94\t|\tloss: 1973.87\n",
      "Training Epoch 51  56.4% | batch:        53 of        94\t|\tloss: 1666.25\n",
      "Training Epoch 51  57.4% | batch:        54 of        94\t|\tloss: 1353.4\n",
      "Training Epoch 51  58.5% | batch:        55 of        94\t|\tloss: 946.019\n",
      "Training Epoch 51  59.6% | batch:        56 of        94\t|\tloss: 1866.84\n",
      "Training Epoch 51  60.6% | batch:        57 of        94\t|\tloss: 1409.62\n",
      "Training Epoch 51  61.7% | batch:        58 of        94\t|\tloss: 1191.24\n",
      "Training Epoch 51  62.8% | batch:        59 of        94\t|\tloss: 1044.84\n",
      "Training Epoch 51  63.8% | batch:        60 of        94\t|\tloss: 1435.63\n",
      "Training Epoch 51  64.9% | batch:        61 of        94\t|\tloss: 1702.71\n",
      "Training Epoch 51  66.0% | batch:        62 of        94\t|\tloss: 985.201\n",
      "Training Epoch 51  67.0% | batch:        63 of        94\t|\tloss: 1532.08\n",
      "Training Epoch 51  68.1% | batch:        64 of        94\t|\tloss: 1234.11\n",
      "Training Epoch 51  69.1% | batch:        65 of        94\t|\tloss: 968.731\n",
      "Training Epoch 51  70.2% | batch:        66 of        94\t|\tloss: 1697.27\n",
      "Training Epoch 51  71.3% | batch:        67 of        94\t|\tloss: 1537.91\n",
      "Training Epoch 51  72.3% | batch:        68 of        94\t|\tloss: 2604.75\n",
      "Training Epoch 51  73.4% | batch:        69 of        94\t|\tloss: 845.734\n",
      "Training Epoch 51  74.5% | batch:        70 of        94\t|\tloss: 857.189\n",
      "Training Epoch 51  75.5% | batch:        71 of        94\t|\tloss: 1549.91\n",
      "Training Epoch 51  76.6% | batch:        72 of        94\t|\tloss: 1087.62\n",
      "Training Epoch 51  77.7% | batch:        73 of        94\t|\tloss: 1628.69\n",
      "Training Epoch 51  78.7% | batch:        74 of        94\t|\tloss: 991.374\n",
      "Training Epoch 51  79.8% | batch:        75 of        94\t|\tloss: 1124.24\n",
      "Training Epoch 51  80.9% | batch:        76 of        94\t|\tloss: 1260.45\n",
      "Training Epoch 51  81.9% | batch:        77 of        94\t|\tloss: 999.927\n",
      "Training Epoch 51  83.0% | batch:        78 of        94\t|\tloss: 854.033\n",
      "Training Epoch 51  84.0% | batch:        79 of        94\t|\tloss: 1230.08\n",
      "Training Epoch 51  85.1% | batch:        80 of        94\t|\tloss: 947.812\n",
      "Training Epoch 51  86.2% | batch:        81 of        94\t|\tloss: 1676.63\n",
      "Training Epoch 51  87.2% | batch:        82 of        94\t|\tloss: 1079.75\n",
      "Training Epoch 51  88.3% | batch:        83 of        94\t|\tloss: 2002.4\n",
      "Training Epoch 51  89.4% | batch:        84 of        94\t|\tloss: 888.136\n",
      "Training Epoch 51  90.4% | batch:        85 of        94\t|\tloss: 1450.63\n",
      "Training Epoch 51  91.5% | batch:        86 of        94\t|\tloss: 1069.22\n",
      "Training Epoch 51  92.6% | batch:        87 of        94\t|\tloss: 994.979\n",
      "Training Epoch 51  93.6% | batch:        88 of        94\t|\tloss: 1711.26\n",
      "Training Epoch 51  94.7% | batch:        89 of        94\t|\tloss: 2174.02\n",
      "Training Epoch 51  95.7% | batch:        90 of        94\t|\tloss: 1760.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:03,664 | INFO : Epoch 51 Training Summary: epoch: 51.000000 | loss: 1343.202534 | \n",
      "2023-05-09 14:22:03,665 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7756648063659668 seconds\n",
      "\n",
      "2023-05-09 14:22:03,665 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8276183698691575 seconds\n",
      "2023-05-09 14:22:03,666 | INFO : Avg batch train. time: 0.019442748615629335 seconds\n",
      "2023-05-09 14:22:03,667 | INFO : Avg sample train. time: 0.00015334941851561986 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 51  96.8% | batch:        91 of        94\t|\tloss: 1239.99\n",
      "Training Epoch 51  97.9% | batch:        92 of        94\t|\tloss: 876.631\n",
      "Training Epoch 51  98.9% | batch:        93 of        94\t|\tloss: 1713.92\n",
      "\n",
      "Training Epoch 52   0.0% | batch:         0 of        94\t|\tloss: 1541.81\n",
      "Training Epoch 52   1.1% | batch:         1 of        94\t|\tloss: 1339.62\n",
      "Training Epoch 52   2.1% | batch:         2 of        94\t|\tloss: 1292.11\n",
      "Training Epoch 52   3.2% | batch:         3 of        94\t|\tloss: 875.368\n",
      "Training Epoch 52   4.3% | batch:         4 of        94\t|\tloss: 2198.16\n",
      "Training Epoch 52   5.3% | batch:         5 of        94\t|\tloss: 951.936\n",
      "Training Epoch 52   6.4% | batch:         6 of        94\t|\tloss: 1055.91\n",
      "Training Epoch 52   7.4% | batch:         7 of        94\t|\tloss: 1136.24\n",
      "Training Epoch 52   8.5% | batch:         8 of        94\t|\tloss: 1496.61\n",
      "Training Epoch 52   9.6% | batch:         9 of        94\t|\tloss: 1968.5\n",
      "Training Epoch 52  10.6% | batch:        10 of        94\t|\tloss: 1175.9\n",
      "Training Epoch 52  11.7% | batch:        11 of        94\t|\tloss: 917.649\n",
      "Training Epoch 52  12.8% | batch:        12 of        94\t|\tloss: 1595.89\n",
      "Training Epoch 52  13.8% | batch:        13 of        94\t|\tloss: 812.186\n",
      "Training Epoch 52  14.9% | batch:        14 of        94\t|\tloss: 3255.14\n",
      "Training Epoch 52  16.0% | batch:        15 of        94\t|\tloss: 1696.55\n",
      "Training Epoch 52  17.0% | batch:        16 of        94\t|\tloss: 2075.7\n",
      "Training Epoch 52  18.1% | batch:        17 of        94\t|\tloss: 1012.54\n",
      "Training Epoch 52  19.1% | batch:        18 of        94\t|\tloss: 992.412\n",
      "Training Epoch 52  20.2% | batch:        19 of        94\t|\tloss: 1148.31\n",
      "Training Epoch 52  21.3% | batch:        20 of        94\t|\tloss: 889.638\n",
      "Training Epoch 52  22.3% | batch:        21 of        94\t|\tloss: 1334.34\n",
      "Training Epoch 52  23.4% | batch:        22 of        94\t|\tloss: 1291.27\n",
      "Training Epoch 52  24.5% | batch:        23 of        94\t|\tloss: 867.674\n",
      "Training Epoch 52  25.5% | batch:        24 of        94\t|\tloss: 1371.27\n",
      "Training Epoch 52  26.6% | batch:        25 of        94\t|\tloss: 2457.12\n",
      "Training Epoch 52  27.7% | batch:        26 of        94\t|\tloss: 1830.15\n",
      "Training Epoch 52  28.7% | batch:        27 of        94\t|\tloss: 1326.05\n",
      "Training Epoch 52  29.8% | batch:        28 of        94\t|\tloss: 1131.03\n",
      "Training Epoch 52  30.9% | batch:        29 of        94\t|\tloss: 1201.59\n",
      "Training Epoch 52  31.9% | batch:        30 of        94\t|\tloss: 1124.05\n",
      "Training Epoch 52  33.0% | batch:        31 of        94\t|\tloss: 625.407\n",
      "Training Epoch 52  34.0% | batch:        32 of        94\t|\tloss: 1985.86\n",
      "Training Epoch 52  35.1% | batch:        33 of        94\t|\tloss: 1208.24\n",
      "Training Epoch 52  36.2% | batch:        34 of        94\t|\tloss: 1556.34\n",
      "Training Epoch 52  37.2% | batch:        35 of        94\t|\tloss: 1202.07\n",
      "Training Epoch 52  38.3% | batch:        36 of        94\t|\tloss: 1535.53\n",
      "Training Epoch 52  39.4% | batch:        37 of        94\t|\tloss: 1005.15\n",
      "Training Epoch 52  40.4% | batch:        38 of        94\t|\tloss: 861.505\n",
      "Training Epoch 52  41.5% | batch:        39 of        94\t|\tloss: 1180.99\n",
      "Training Epoch 52  42.6% | batch:        40 of        94\t|\tloss: 664.256\n",
      "Training Epoch 52  43.6% | batch:        41 of        94\t|\tloss: 1152.41\n",
      "Training Epoch 52  44.7% | batch:        42 of        94\t|\tloss: 856.995\n",
      "Training Epoch 52  45.7% | batch:        43 of        94\t|\tloss: 828.065\n",
      "Training Epoch 52  46.8% | batch:        44 of        94\t|\tloss: 1105.22\n",
      "Training Epoch 52  47.9% | batch:        45 of        94\t|\tloss: 1555.21\n",
      "Training Epoch 52  48.9% | batch:        46 of        94\t|\tloss: 1397.95\n",
      "Training Epoch 52  50.0% | batch:        47 of        94\t|\tloss: 1086.23\n",
      "Training Epoch 52  51.1% | batch:        48 of        94\t|\tloss: 1282.79\n",
      "Training Epoch 52  52.1% | batch:        49 of        94\t|\tloss: 1431.48\n",
      "Training Epoch 52  53.2% | batch:        50 of        94\t|\tloss: 1773.61\n",
      "Training Epoch 52  54.3% | batch:        51 of        94\t|\tloss: 755.716\n",
      "Training Epoch 52  55.3% | batch:        52 of        94\t|\tloss: 1430.53\n",
      "Training Epoch 52  56.4% | batch:        53 of        94\t|\tloss: 831.53\n",
      "Training Epoch 52  57.4% | batch:        54 of        94\t|\tloss: 922.396\n",
      "Training Epoch 52  58.5% | batch:        55 of        94\t|\tloss: 1453.74\n",
      "Training Epoch 52  59.6% | batch:        56 of        94\t|\tloss: 1586.72\n",
      "Training Epoch 52  60.6% | batch:        57 of        94\t|\tloss: 1708.61\n",
      "Training Epoch 52  61.7% | batch:        58 of        94\t|\tloss: 1558.04\n",
      "Training Epoch 52  62.8% | batch:        59 of        94\t|\tloss: 2958.16\n",
      "Training Epoch 52  63.8% | batch:        60 of        94\t|\tloss: 944.63\n",
      "Training Epoch 52  64.9% | batch:        61 of        94\t|\tloss: 924.275\n",
      "Training Epoch 52  66.0% | batch:        62 of        94\t|\tloss: 955.864\n",
      "Training Epoch 52  67.0% | batch:        63 of        94\t|\tloss: 687.42\n",
      "Training Epoch 52  68.1% | batch:        64 of        94\t|\tloss: 1153.24\n",
      "Training Epoch 52  69.1% | batch:        65 of        94\t|\tloss: 895.37\n",
      "Training Epoch 52  70.2% | batch:        66 of        94\t|\tloss: 1205.64\n",
      "Training Epoch 52  71.3% | batch:        67 of        94\t|\tloss: 2048.41\n",
      "Training Epoch 52  72.3% | batch:        68 of        94\t|\tloss: 1019.83\n",
      "Training Epoch 52  73.4% | batch:        69 of        94\t|\tloss: 1202.95\n",
      "Training Epoch 52  74.5% | batch:        70 of        94\t|\tloss: 916.568\n",
      "Training Epoch 52  75.5% | batch:        71 of        94\t|\tloss: 1293.21\n",
      "Training Epoch 52  76.6% | batch:        72 of        94\t|\tloss: 1327.46\n",
      "Training Epoch 52  77.7% | batch:        73 of        94\t|\tloss: 992.847\n",
      "Training Epoch 52  78.7% | batch:        74 of        94\t|\tloss: 1015.28\n",
      "Training Epoch 52  79.8% | batch:        75 of        94\t|\tloss: 1408.59\n",
      "Training Epoch 52  80.9% | batch:        76 of        94\t|\tloss: 1054.02\n",
      "Training Epoch 52  81.9% | batch:        77 of        94\t|\tloss: 897.566\n",
      "Training Epoch 52  83.0% | batch:        78 of        94\t|\tloss: 1094.03\n",
      "Training Epoch 52  84.0% | batch:        79 of        94\t|\tloss: 3081.1\n",
      "Training Epoch 52  85.1% | batch:        80 of        94\t|\tloss: 1828.58\n",
      "Training Epoch 52  86.2% | batch:        81 of        94\t|\tloss: 969.217\n",
      "Training Epoch 52  87.2% | batch:        82 of        94\t|\tloss: 1233.92\n",
      "Training Epoch 52  88.3% | batch:        83 of        94\t|\tloss: 1298.69\n",
      "Training Epoch 52  89.4% | batch:        84 of        94\t|\tloss: 1851.11\n",
      "Training Epoch 52  90.4% | batch:        85 of        94\t|\tloss: 1833.61\n",
      "Training Epoch 52  91.5% | batch:        86 of        94\t|\tloss: 912.195\n",
      "Training Epoch 52  92.6% | batch:        87 of        94\t|\tloss: 2900.67\n",
      "Training Epoch 52  93.6% | batch:        88 of        94\t|\tloss: 1416.07\n",
      "Training Epoch 52  94.7% | batch:        89 of        94\t|\tloss: 1012.56\n",
      "Training Epoch 52  95.7% | batch:        90 of        94\t|\tloss: 1058.36\n",
      "Training Epoch 52  96.8% | batch:        91 of        94\t|\tloss: 983.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:05,386 | INFO : Epoch 52 Training Summary: epoch: 52.000000 | loss: 1324.922927 | \n",
      "2023-05-09 14:22:05,386 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6988787651062012 seconds\n",
      "\n",
      "2023-05-09 14:22:05,387 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8251426082391005 seconds\n",
      "2023-05-09 14:22:05,387 | INFO : Avg batch train. time: 0.019416410725947877 seconds\n",
      "2023-05-09 14:22:05,388 | INFO : Avg sample train. time: 0.00015314168553776645 seconds\n",
      "2023-05-09 14:22:05,389 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 52  97.9% | batch:        92 of        94\t|\tloss: 846.165\n",
      "Training Epoch 52  98.9% | batch:        93 of        94\t|\tloss: 2164.1\n",
      "\n",
      "Evaluating Epoch 52   0.0% | batch:         0 of        40\t|\tloss: 6267.32\n",
      "Evaluating Epoch 52   2.5% | batch:         1 of        40\t|\tloss: 1102.95\n",
      "Evaluating Epoch 52   5.0% | batch:         2 of        40\t|\tloss: 3092.74\n",
      "Evaluating Epoch 52   7.5% | batch:         3 of        40\t|\tloss: 6710.49\n",
      "Evaluating Epoch 52  10.0% | batch:         4 of        40\t|\tloss: 2446.43\n",
      "Evaluating Epoch 52  12.5% | batch:         5 of        40\t|\tloss: 2036.67\n",
      "Evaluating Epoch 52  15.0% | batch:         6 of        40\t|\tloss: 9012.83\n",
      "Evaluating Epoch 52  17.5% | batch:         7 of        40\t|\tloss: 2987.26\n",
      "Evaluating Epoch 52  20.0% | batch:         8 of        40\t|\tloss: 2767.38\n",
      "Evaluating Epoch 52  22.5% | batch:         9 of        40\t|\tloss: 1824.92\n",
      "Evaluating Epoch 52  25.0% | batch:        10 of        40\t|\tloss: 4680.2\n",
      "Evaluating Epoch 52  27.5% | batch:        11 of        40\t|\tloss: 1315.5\n",
      "Evaluating Epoch 52  30.0% | batch:        12 of        40\t|\tloss: 6088.71\n",
      "Evaluating Epoch 52  32.5% | batch:        13 of        40\t|\tloss: 3208.38\n",
      "Evaluating Epoch 52  35.0% | batch:        14 of        40\t|\tloss: 1978.51\n",
      "Evaluating Epoch 52  37.5% | batch:        15 of        40\t|\tloss: 2941.51\n",
      "Evaluating Epoch 52  40.0% | batch:        16 of        40\t|\tloss: 4067.43\n",
      "Evaluating Epoch 52  42.5% | batch:        17 of        40\t|\tloss: 2736.49\n",
      "Evaluating Epoch 52  45.0% | batch:        18 of        40\t|\tloss: 2595.06\n",
      "Evaluating Epoch 52  47.5% | batch:        19 of        40\t|\tloss: 5582.02\n",
      "Evaluating Epoch 52  50.0% | batch:        20 of        40\t|\tloss: 5845.43\n",
      "Evaluating Epoch 52  52.5% | batch:        21 of        40\t|\tloss: 1227.51\n",
      "Evaluating Epoch 52  55.0% | batch:        22 of        40\t|\tloss: 4036.44\n",
      "Evaluating Epoch 52  57.5% | batch:        23 of        40\t|\tloss: 3212.58\n",
      "Evaluating Epoch 52  60.0% | batch:        24 of        40\t|\tloss: 1549.83\n",
      "Evaluating Epoch 52  62.5% | batch:        25 of        40\t|\tloss: 3322.91\n",
      "Evaluating Epoch 52  65.0% | batch:        26 of        40\t|\tloss: 10074.2\n",
      "Evaluating Epoch 52  67.5% | batch:        27 of        40\t|\tloss: 2884.43\n",
      "Evaluating Epoch 52  70.0% | batch:        28 of        40\t|\tloss: 1760.86\n",
      "Evaluating Epoch 52  72.5% | batch:        29 of        40\t|\tloss: 9660.15\n",
      "Evaluating Epoch 52  75.0% | batch:        30 of        40\t|\tloss: 1632.33\n",
      "Evaluating Epoch 52  77.5% | batch:        31 of        40\t|\tloss: 1716.16\n",
      "Evaluating Epoch 52  80.0% | batch:        32 of        40\t|\tloss: 7216.34\n",
      "Evaluating Epoch 52  82.5% | batch:        33 of        40\t|\tloss: 6230.86\n",
      "Evaluating Epoch 52  85.0% | batch:        34 of        40\t|\tloss: 966.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:05,848 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45926594734191895 seconds\n",
      "\n",
      "2023-05-09 14:22:05,849 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48197948932647705 seconds\n",
      "2023-05-09 14:22:05,849 | INFO : Avg batch val. time: 0.012049487233161927 seconds\n",
      "2023-05-09 14:22:05,850 | INFO : Avg sample val. time: 9.547929661776487e-05 seconds\n",
      "2023-05-09 14:22:05,850 | INFO : Epoch 52 Validation Summary: epoch: 52.000000 | loss: 3978.371026 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 52  87.5% | batch:        35 of        40\t|\tloss: 5180.16\n",
      "Evaluating Epoch 52  90.0% | batch:        36 of        40\t|\tloss: 5467.86\n",
      "Evaluating Epoch 52  92.5% | batch:        37 of        40\t|\tloss: 2478.63\n",
      "Evaluating Epoch 52  95.0% | batch:        38 of        40\t|\tloss: 3085.92\n",
      "Evaluating Epoch 52  97.5% | batch:        39 of        40\t|\tloss: 13496.3\n",
      "\n",
      "Training Epoch 53   0.0% | batch:         0 of        94\t|\tloss: 943.654\n",
      "Training Epoch 53   1.1% | batch:         1 of        94\t|\tloss: 1456.81\n",
      "Training Epoch 53   2.1% | batch:         2 of        94\t|\tloss: 2063.99\n",
      "Training Epoch 53   3.2% | batch:         3 of        94\t|\tloss: 803.125\n",
      "Training Epoch 53   4.3% | batch:         4 of        94\t|\tloss: 1498.2\n",
      "Training Epoch 53   5.3% | batch:         5 of        94\t|\tloss: 1954.92\n",
      "Training Epoch 53   6.4% | batch:         6 of        94\t|\tloss: 748.251\n",
      "Training Epoch 53   7.4% | batch:         7 of        94\t|\tloss: 723.939\n",
      "Training Epoch 53   8.5% | batch:         8 of        94\t|\tloss: 1498.9\n",
      "Training Epoch 53   9.6% | batch:         9 of        94\t|\tloss: 955.87\n",
      "Training Epoch 53  10.6% | batch:        10 of        94\t|\tloss: 982.897\n",
      "Training Epoch 53  11.7% | batch:        11 of        94\t|\tloss: 1639.87\n",
      "Training Epoch 53  12.8% | batch:        12 of        94\t|\tloss: 1043.02\n",
      "Training Epoch 53  13.8% | batch:        13 of        94\t|\tloss: 1220.05\n",
      "Training Epoch 53  14.9% | batch:        14 of        94\t|\tloss: 1115.26\n",
      "Training Epoch 53  16.0% | batch:        15 of        94\t|\tloss: 2417.82\n",
      "Training Epoch 53  17.0% | batch:        16 of        94\t|\tloss: 2759.59\n",
      "Training Epoch 53  18.1% | batch:        17 of        94\t|\tloss: 1372.39\n",
      "Training Epoch 53  19.1% | batch:        18 of        94\t|\tloss: 1141.42\n",
      "Training Epoch 53  20.2% | batch:        19 of        94\t|\tloss: 1146.35\n",
      "Training Epoch 53  21.3% | batch:        20 of        94\t|\tloss: 1165.37\n",
      "Training Epoch 53  22.3% | batch:        21 of        94\t|\tloss: 1436.23\n",
      "Training Epoch 53  23.4% | batch:        22 of        94\t|\tloss: 1205.65\n",
      "Training Epoch 53  24.5% | batch:        23 of        94\t|\tloss: 1194.11\n",
      "Training Epoch 53  25.5% | batch:        24 of        94\t|\tloss: 775.368\n",
      "Training Epoch 53  26.6% | batch:        25 of        94\t|\tloss: 1127.67\n",
      "Training Epoch 53  27.7% | batch:        26 of        94\t|\tloss: 1092.77\n",
      "Training Epoch 53  28.7% | batch:        27 of        94\t|\tloss: 766.312\n",
      "Training Epoch 53  29.8% | batch:        28 of        94\t|\tloss: 1042.92\n",
      "Training Epoch 53  30.9% | batch:        29 of        94\t|\tloss: 850.096\n",
      "Training Epoch 53  31.9% | batch:        30 of        94\t|\tloss: 1061.49\n",
      "Training Epoch 53  33.0% | batch:        31 of        94\t|\tloss: 964.71\n",
      "Training Epoch 53  34.0% | batch:        32 of        94\t|\tloss: 981.338\n",
      "Training Epoch 53  35.1% | batch:        33 of        94\t|\tloss: 2322.02\n",
      "Training Epoch 53  36.2% | batch:        34 of        94\t|\tloss: 1193.47\n",
      "Training Epoch 53  37.2% | batch:        35 of        94\t|\tloss: 1045.1\n",
      "Training Epoch 53  38.3% | batch:        36 of        94\t|\tloss: 855.11\n",
      "Training Epoch 53  39.4% | batch:        37 of        94\t|\tloss: 1219.5\n",
      "Training Epoch 53  40.4% | batch:        38 of        94\t|\tloss: 1853.15\n",
      "Training Epoch 53  41.5% | batch:        39 of        94\t|\tloss: 1165.99\n",
      "Training Epoch 53  42.6% | batch:        40 of        94\t|\tloss: 871.713\n",
      "Training Epoch 53  43.6% | batch:        41 of        94\t|\tloss: 851.812\n",
      "Training Epoch 53  44.7% | batch:        42 of        94\t|\tloss: 2312.43\n",
      "Training Epoch 53  45.7% | batch:        43 of        94\t|\tloss: 802.26\n",
      "Training Epoch 53  46.8% | batch:        44 of        94\t|\tloss: 892.261\n",
      "Training Epoch 53  47.9% | batch:        45 of        94\t|\tloss: 962.863\n",
      "Training Epoch 53  48.9% | batch:        46 of        94\t|\tloss: 673.301\n",
      "Training Epoch 53  50.0% | batch:        47 of        94\t|\tloss: 1780.72\n",
      "Training Epoch 53  51.1% | batch:        48 of        94\t|\tloss: 855.843\n",
      "Training Epoch 53  52.1% | batch:        49 of        94\t|\tloss: 1063.88\n",
      "Training Epoch 53  53.2% | batch:        50 of        94\t|\tloss: 755.655\n",
      "Training Epoch 53  54.3% | batch:        51 of        94\t|\tloss: 1136.72\n",
      "Training Epoch 53  55.3% | batch:        52 of        94\t|\tloss: 1472.93\n",
      "Training Epoch 53  56.4% | batch:        53 of        94\t|\tloss: 1019.59\n",
      "Training Epoch 53  57.4% | batch:        54 of        94\t|\tloss: 743.934\n",
      "Training Epoch 53  58.5% | batch:        55 of        94\t|\tloss: 1334.41\n",
      "Training Epoch 53  59.6% | batch:        56 of        94\t|\tloss: 808.148\n",
      "Training Epoch 53  60.6% | batch:        57 of        94\t|\tloss: 941.161\n",
      "Training Epoch 53  61.7% | batch:        58 of        94\t|\tloss: 805.708\n",
      "Training Epoch 53  62.8% | batch:        59 of        94\t|\tloss: 3571.47\n",
      "Training Epoch 53  63.8% | batch:        60 of        94\t|\tloss: 1368.45\n",
      "Training Epoch 53  64.9% | batch:        61 of        94\t|\tloss: 1181.78\n",
      "Training Epoch 53  66.0% | batch:        62 of        94\t|\tloss: 2150.4\n",
      "Training Epoch 53  67.0% | batch:        63 of        94\t|\tloss: 1134.72\n",
      "Training Epoch 53  68.1% | batch:        64 of        94\t|\tloss: 1004.72\n",
      "Training Epoch 53  69.1% | batch:        65 of        94\t|\tloss: 881.692\n",
      "Training Epoch 53  70.2% | batch:        66 of        94\t|\tloss: 790.602\n",
      "Training Epoch 53  71.3% | batch:        67 of        94\t|\tloss: 1048.17\n",
      "Training Epoch 53  72.3% | batch:        68 of        94\t|\tloss: 861.995\n",
      "Training Epoch 53  73.4% | batch:        69 of        94\t|\tloss: 894.002\n",
      "Training Epoch 53  74.5% | batch:        70 of        94\t|\tloss: 1024.43\n",
      "Training Epoch 53  75.5% | batch:        71 of        94\t|\tloss: 1995.2\n",
      "Training Epoch 53  76.6% | batch:        72 of        94\t|\tloss: 1141.13\n",
      "Training Epoch 53  77.7% | batch:        73 of        94\t|\tloss: 1079.51\n",
      "Training Epoch 53  78.7% | batch:        74 of        94\t|\tloss: 1872.44\n",
      "Training Epoch 53  79.8% | batch:        75 of        94\t|\tloss: 1880.45\n",
      "Training Epoch 53  80.9% | batch:        76 of        94\t|\tloss: 984.315\n",
      "Training Epoch 53  81.9% | batch:        77 of        94\t|\tloss: 1203.59\n",
      "Training Epoch 53  83.0% | batch:        78 of        94\t|\tloss: 1155.68\n",
      "Training Epoch 53  84.0% | batch:        79 of        94\t|\tloss: 1743.44\n",
      "Training Epoch 53  85.1% | batch:        80 of        94\t|\tloss: 1187.64\n",
      "Training Epoch 53  86.2% | batch:        81 of        94\t|\tloss: 1074.91\n",
      "Training Epoch 53  87.2% | batch:        82 of        94\t|\tloss: 772.54\n",
      "Training Epoch 53  88.3% | batch:        83 of        94\t|\tloss: 1396.28\n",
      "Training Epoch 53  89.4% | batch:        84 of        94\t|\tloss: 1289.79\n",
      "Training Epoch 53  90.4% | batch:        85 of        94\t|\tloss: 2056.62\n",
      "Training Epoch 53  91.5% | batch:        86 of        94\t|\tloss: 1120.08\n",
      "Training Epoch 53  92.6% | batch:        87 of        94\t|\tloss: 937.478\n",
      "Training Epoch 53  93.6% | batch:        88 of        94\t|\tloss: 1052.58\n",
      "Training Epoch 53  94.7% | batch:        89 of        94\t|\tloss: 1225.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:07,695 | INFO : Epoch 53 Training Summary: epoch: 53.000000 | loss: 1259.374316 | \n",
      "2023-05-09 14:22:07,696 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8240399360656738 seconds\n",
      "\n",
      "2023-05-09 14:22:07,696 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8251218031037528 seconds\n",
      "2023-05-09 14:22:07,697 | INFO : Avg batch train. time: 0.019416189394720774 seconds\n",
      "2023-05-09 14:22:07,697 | INFO : Avg sample train. time: 0.0001531399398476047 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 53  95.7% | batch:        90 of        94\t|\tloss: 2849.97\n",
      "Training Epoch 53  96.8% | batch:        91 of        94\t|\tloss: 1075.86\n",
      "Training Epoch 53  97.9% | batch:        92 of        94\t|\tloss: 1212.91\n",
      "Training Epoch 53  98.9% | batch:        93 of        94\t|\tloss: 1368.14\n",
      "\n",
      "Training Epoch 54   0.0% | batch:         0 of        94\t|\tloss: 852.7\n",
      "Training Epoch 54   1.1% | batch:         1 of        94\t|\tloss: 1431.74\n",
      "Training Epoch 54   2.1% | batch:         2 of        94\t|\tloss: 878.082\n",
      "Training Epoch 54   3.2% | batch:         3 of        94\t|\tloss: 1819.16\n",
      "Training Epoch 54   4.3% | batch:         4 of        94\t|\tloss: 2678.37\n",
      "Training Epoch 54   5.3% | batch:         5 of        94\t|\tloss: 901.709\n",
      "Training Epoch 54   6.4% | batch:         6 of        94\t|\tloss: 1244.84\n",
      "Training Epoch 54   7.4% | batch:         7 of        94\t|\tloss: 1377.25\n",
      "Training Epoch 54   8.5% | batch:         8 of        94\t|\tloss: 1221.31\n",
      "Training Epoch 54   9.6% | batch:         9 of        94\t|\tloss: 2590.57\n",
      "Training Epoch 54  10.6% | batch:        10 of        94\t|\tloss: 1327.88\n",
      "Training Epoch 54  11.7% | batch:        11 of        94\t|\tloss: 1486.5\n",
      "Training Epoch 54  12.8% | batch:        12 of        94\t|\tloss: 1744.49\n",
      "Training Epoch 54  13.8% | batch:        13 of        94\t|\tloss: 1266.1\n",
      "Training Epoch 54  14.9% | batch:        14 of        94\t|\tloss: 1045.55\n",
      "Training Epoch 54  16.0% | batch:        15 of        94\t|\tloss: 1515.9\n",
      "Training Epoch 54  17.0% | batch:        16 of        94\t|\tloss: 838.51\n",
      "Training Epoch 54  18.1% | batch:        17 of        94\t|\tloss: 1185.41\n",
      "Training Epoch 54  19.1% | batch:        18 of        94\t|\tloss: 1653.34\n",
      "Training Epoch 54  20.2% | batch:        19 of        94\t|\tloss: 644.574\n",
      "Training Epoch 54  21.3% | batch:        20 of        94\t|\tloss: 822.303\n",
      "Training Epoch 54  22.3% | batch:        21 of        94\t|\tloss: 789.26\n",
      "Training Epoch 54  23.4% | batch:        22 of        94\t|\tloss: 1075.56\n",
      "Training Epoch 54  24.5% | batch:        23 of        94\t|\tloss: 782.809\n",
      "Training Epoch 54  25.5% | batch:        24 of        94\t|\tloss: 1429.98\n",
      "Training Epoch 54  26.6% | batch:        25 of        94\t|\tloss: 1079.99\n",
      "Training Epoch 54  27.7% | batch:        26 of        94\t|\tloss: 884.304\n",
      "Training Epoch 54  28.7% | batch:        27 of        94\t|\tloss: 772.376\n",
      "Training Epoch 54  29.8% | batch:        28 of        94\t|\tloss: 700.114\n",
      "Training Epoch 54  30.9% | batch:        29 of        94\t|\tloss: 1310.79\n",
      "Training Epoch 54  31.9% | batch:        30 of        94\t|\tloss: 852.607\n",
      "Training Epoch 54  33.0% | batch:        31 of        94\t|\tloss: 788.737\n",
      "Training Epoch 54  34.0% | batch:        32 of        94\t|\tloss: 1787.22\n",
      "Training Epoch 54  35.1% | batch:        33 of        94\t|\tloss: 1488.06\n",
      "Training Epoch 54  36.2% | batch:        34 of        94\t|\tloss: 1107.46\n",
      "Training Epoch 54  37.2% | batch:        35 of        94\t|\tloss: 1143.91\n",
      "Training Epoch 54  38.3% | batch:        36 of        94\t|\tloss: 1252.03\n",
      "Training Epoch 54  39.4% | batch:        37 of        94\t|\tloss: 1069.67\n",
      "Training Epoch 54  40.4% | batch:        38 of        94\t|\tloss: 850.629\n",
      "Training Epoch 54  41.5% | batch:        39 of        94\t|\tloss: 1021.74\n",
      "Training Epoch 54  42.6% | batch:        40 of        94\t|\tloss: 843.769\n",
      "Training Epoch 54  43.6% | batch:        41 of        94\t|\tloss: 805.615\n",
      "Training Epoch 54  44.7% | batch:        42 of        94\t|\tloss: 839.063\n",
      "Training Epoch 54  45.7% | batch:        43 of        94\t|\tloss: 1208.6\n",
      "Training Epoch 54  46.8% | batch:        44 of        94\t|\tloss: 893.935\n",
      "Training Epoch 54  47.9% | batch:        45 of        94\t|\tloss: 1369.89\n",
      "Training Epoch 54  48.9% | batch:        46 of        94\t|\tloss: 920.912\n",
      "Training Epoch 54  50.0% | batch:        47 of        94\t|\tloss: 1872.61\n",
      "Training Epoch 54  51.1% | batch:        48 of        94\t|\tloss: 1142.28\n",
      "Training Epoch 54  52.1% | batch:        49 of        94\t|\tloss: 794.317\n",
      "Training Epoch 54  53.2% | batch:        50 of        94\t|\tloss: 3429.07\n",
      "Training Epoch 54  54.3% | batch:        51 of        94\t|\tloss: 1198.04\n",
      "Training Epoch 54  55.3% | batch:        52 of        94\t|\tloss: 1665.98\n",
      "Training Epoch 54  56.4% | batch:        53 of        94\t|\tloss: 1219.96\n",
      "Training Epoch 54  57.4% | batch:        54 of        94\t|\tloss: 2798.48\n",
      "Training Epoch 54  58.5% | batch:        55 of        94\t|\tloss: 1307.21\n",
      "Training Epoch 54  59.6% | batch:        56 of        94\t|\tloss: 1365.62\n",
      "Training Epoch 54  60.6% | batch:        57 of        94\t|\tloss: 1077.02\n",
      "Training Epoch 54  61.7% | batch:        58 of        94\t|\tloss: 1019.89\n",
      "Training Epoch 54  62.8% | batch:        59 of        94\t|\tloss: 763.986\n",
      "Training Epoch 54  63.8% | batch:        60 of        94\t|\tloss: 1507.52\n",
      "Training Epoch 54  64.9% | batch:        61 of        94\t|\tloss: 2579.78\n",
      "Training Epoch 54  66.0% | batch:        62 of        94\t|\tloss: 838.12\n",
      "Training Epoch 54  67.0% | batch:        63 of        94\t|\tloss: 1120.24\n",
      "Training Epoch 54  68.1% | batch:        64 of        94\t|\tloss: 947.742\n",
      "Training Epoch 54  69.1% | batch:        65 of        94\t|\tloss: 1046.84\n",
      "Training Epoch 54  70.2% | batch:        66 of        94\t|\tloss: 1993.48\n",
      "Training Epoch 54  71.3% | batch:        67 of        94\t|\tloss: 769.35\n",
      "Training Epoch 54  72.3% | batch:        68 of        94\t|\tloss: 1117.48\n",
      "Training Epoch 54  73.4% | batch:        69 of        94\t|\tloss: 1335.17\n",
      "Training Epoch 54  74.5% | batch:        70 of        94\t|\tloss: 996.697\n",
      "Training Epoch 54  75.5% | batch:        71 of        94\t|\tloss: 2111.86\n",
      "Training Epoch 54  76.6% | batch:        72 of        94\t|\tloss: 942.115\n",
      "Training Epoch 54  77.7% | batch:        73 of        94\t|\tloss: 908.901\n",
      "Training Epoch 54  78.7% | batch:        74 of        94\t|\tloss: 1112.55\n",
      "Training Epoch 54  79.8% | batch:        75 of        94\t|\tloss: 944.493\n",
      "Training Epoch 54  80.9% | batch:        76 of        94\t|\tloss: 1007.44\n",
      "Training Epoch 54  81.9% | batch:        77 of        94\t|\tloss: 998.69\n",
      "Training Epoch 54  83.0% | batch:        78 of        94\t|\tloss: 1175.68\n",
      "Training Epoch 54  84.0% | batch:        79 of        94\t|\tloss: 886.156\n",
      "Training Epoch 54  85.1% | batch:        80 of        94\t|\tloss: 966.101\n",
      "Training Epoch 54  86.2% | batch:        81 of        94\t|\tloss: 987.084\n",
      "Training Epoch 54  87.2% | batch:        82 of        94\t|\tloss: 1540.92\n",
      "Training Epoch 54  88.3% | batch:        83 of        94\t|\tloss: 957.894\n",
      "Training Epoch 54  89.4% | batch:        84 of        94\t|\tloss: 930.365\n",
      "Training Epoch 54  90.4% | batch:        85 of        94\t|\tloss: 1710.05\n",
      "Training Epoch 54  91.5% | batch:        86 of        94\t|\tloss: 1455.17\n",
      "Training Epoch 54  92.6% | batch:        87 of        94\t|\tloss: 1455.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:09,553 | INFO : Epoch 54 Training Summary: epoch: 54.000000 | loss: 1244.465169 | \n",
      "2023-05-09 14:22:09,554 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8348524570465088 seconds\n",
      "\n",
      "2023-05-09 14:22:09,554 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.825302000398989 seconds\n",
      "2023-05-09 14:22:09,555 | INFO : Avg batch train. time: 0.01941810638722329 seconds\n",
      "2023-05-09 14:22:09,556 | INFO : Avg sample train. time: 0.00015315505960723184 seconds\n",
      "2023-05-09 14:22:09,556 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 54  93.6% | batch:        88 of        94\t|\tloss: 1115.98\n",
      "Training Epoch 54  94.7% | batch:        89 of        94\t|\tloss: 962.053\n",
      "Training Epoch 54  95.7% | batch:        90 of        94\t|\tloss: 1295.29\n",
      "Training Epoch 54  96.8% | batch:        91 of        94\t|\tloss: 1288.32\n",
      "Training Epoch 54  97.9% | batch:        92 of        94\t|\tloss: 1445.74\n",
      "Training Epoch 54  98.9% | batch:        93 of        94\t|\tloss: 1562.88\n",
      "\n",
      "Evaluating Epoch 54   0.0% | batch:         0 of        40\t|\tloss: 7308.87\n",
      "Evaluating Epoch 54   2.5% | batch:         1 of        40\t|\tloss: 1167.44\n",
      "Evaluating Epoch 54   5.0% | batch:         2 of        40\t|\tloss: 3533.9\n",
      "Evaluating Epoch 54   7.5% | batch:         3 of        40\t|\tloss: 7276.84\n",
      "Evaluating Epoch 54  10.0% | batch:         4 of        40\t|\tloss: 3315.82\n",
      "Evaluating Epoch 54  12.5% | batch:         5 of        40\t|\tloss: 3009.65\n",
      "Evaluating Epoch 54  15.0% | batch:         6 of        40\t|\tloss: 8851.62\n",
      "Evaluating Epoch 54  17.5% | batch:         7 of        40\t|\tloss: 3106.65\n",
      "Evaluating Epoch 54  20.0% | batch:         8 of        40\t|\tloss: 2682.33\n",
      "Evaluating Epoch 54  22.5% | batch:         9 of        40\t|\tloss: 2103.16\n",
      "Evaluating Epoch 54  25.0% | batch:        10 of        40\t|\tloss: 5327.61\n",
      "Evaluating Epoch 54  27.5% | batch:        11 of        40\t|\tloss: 1375.3\n",
      "Evaluating Epoch 54  30.0% | batch:        12 of        40\t|\tloss: 6398.35\n",
      "Evaluating Epoch 54  32.5% | batch:        13 of        40\t|\tloss: 3566.76\n",
      "Evaluating Epoch 54  35.0% | batch:        14 of        40\t|\tloss: 1909.54\n",
      "Evaluating Epoch 54  37.5% | batch:        15 of        40\t|\tloss: 3122.36\n",
      "Evaluating Epoch 54  40.0% | batch:        16 of        40\t|\tloss: 5254.51\n",
      "Evaluating Epoch 54  42.5% | batch:        17 of        40\t|\tloss: 2459.51\n",
      "Evaluating Epoch 54  45.0% | batch:        18 of        40\t|\tloss: 2156.99\n",
      "Evaluating Epoch 54  47.5% | batch:        19 of        40\t|\tloss: 5331.75\n",
      "Evaluating Epoch 54  50.0% | batch:        20 of        40\t|\tloss: 5703.14\n",
      "Evaluating Epoch 54  52.5% | batch:        21 of        40\t|\tloss: 1137.26\n",
      "Evaluating Epoch 54  55.0% | batch:        22 of        40\t|\tloss: 3241.45\n",
      "Evaluating Epoch 54  57.5% | batch:        23 of        40\t|\tloss: 3213.59\n",
      "Evaluating Epoch 54  60.0% | batch:        24 of        40\t|\tloss: 1674.02\n",
      "Evaluating Epoch 54  62.5% | batch:        25 of        40\t|\tloss: 3372.07\n",
      "Evaluating Epoch 54  65.0% | batch:        26 of        40\t|\tloss: 9843.27\n",
      "Evaluating Epoch 54  67.5% | batch:        27 of        40\t|\tloss: 3275.7\n",
      "Evaluating Epoch 54  70.0% | batch:        28 of        40\t|\tloss: 2021.66\n",
      "Evaluating Epoch 54  72.5% | batch:        29 of        40\t|\tloss: 9355.29\n",
      "Evaluating Epoch 54  75.0% | batch:        30 of        40\t|\tloss: 2033.86\n",
      "Evaluating Epoch 54  77.5% | batch:        31 of        40\t|\tloss: 1988.89\n",
      "Evaluating Epoch 54  80.0% | batch:        32 of        40\t|\tloss: 7221.55\n",
      "Evaluating Epoch 54  82.5% | batch:        33 of        40\t|\tloss: 6720.87\n",
      "Evaluating Epoch 54  85.0% | batch:        34 of        40\t|\tloss: 936.76\n",
      "Evaluating Epoch 54  87.5% | batch:        35 of        40\t|\tloss: 5669.9\n",
      "Evaluating Epoch 54  90.0% | batch:        36 of        40\t|\tloss: 7387.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:10,015 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4584643840789795 seconds\n",
      "\n",
      "2023-05-09 14:22:10,016 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4811686236282875 seconds\n",
      "2023-05-09 14:22:10,016 | INFO : Avg batch val. time: 0.012029215590707187 seconds\n",
      "2023-05-09 14:22:10,016 | INFO : Avg sample val. time: 9.531866553650703e-05 seconds\n",
      "2023-05-09 14:22:10,017 | INFO : Epoch 54 Validation Summary: epoch: 54.000000 | loss: 4208.595517 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 54  92.5% | batch:        37 of        40\t|\tloss: 2701.35\n",
      "Evaluating Epoch 54  95.0% | batch:        38 of        40\t|\tloss: 3713.82\n",
      "Evaluating Epoch 54  97.5% | batch:        39 of        40\t|\tloss: 12583.4\n",
      "\n",
      "Training Epoch 55   0.0% | batch:         0 of        94\t|\tloss: 1111.97\n",
      "Training Epoch 55   1.1% | batch:         1 of        94\t|\tloss: 1167.79\n",
      "Training Epoch 55   2.1% | batch:         2 of        94\t|\tloss: 877.045\n",
      "Training Epoch 55   3.2% | batch:         3 of        94\t|\tloss: 1037.79\n",
      "Training Epoch 55   4.3% | batch:         4 of        94\t|\tloss: 1066.54\n",
      "Training Epoch 55   5.3% | batch:         5 of        94\t|\tloss: 1539.23\n",
      "Training Epoch 55   6.4% | batch:         6 of        94\t|\tloss: 1316.58\n",
      "Training Epoch 55   7.4% | batch:         7 of        94\t|\tloss: 1497.44\n",
      "Training Epoch 55   8.5% | batch:         8 of        94\t|\tloss: 963.927\n",
      "Training Epoch 55   9.6% | batch:         9 of        94\t|\tloss: 1042.24\n",
      "Training Epoch 55  10.6% | batch:        10 of        94\t|\tloss: 765.41\n",
      "Training Epoch 55  11.7% | batch:        11 of        94\t|\tloss: 913.931\n",
      "Training Epoch 55  12.8% | batch:        12 of        94\t|\tloss: 928.788\n",
      "Training Epoch 55  13.8% | batch:        13 of        94\t|\tloss: 1069.05\n",
      "Training Epoch 55  14.9% | batch:        14 of        94\t|\tloss: 924.964\n",
      "Training Epoch 55  16.0% | batch:        15 of        94\t|\tloss: 951.287\n",
      "Training Epoch 55  17.0% | batch:        16 of        94\t|\tloss: 1021.91\n",
      "Training Epoch 55  18.1% | batch:        17 of        94\t|\tloss: 1135.11\n",
      "Training Epoch 55  19.1% | batch:        18 of        94\t|\tloss: 825.951\n",
      "Training Epoch 55  20.2% | batch:        19 of        94\t|\tloss: 583.832\n",
      "Training Epoch 55  21.3% | batch:        20 of        94\t|\tloss: 664.211\n",
      "Training Epoch 55  22.3% | batch:        21 of        94\t|\tloss: 1773.24\n",
      "Training Epoch 55  23.4% | batch:        22 of        94\t|\tloss: 1306.95\n",
      "Training Epoch 55  24.5% | batch:        23 of        94\t|\tloss: 1040.06\n",
      "Training Epoch 55  25.5% | batch:        24 of        94\t|\tloss: 878.29\n",
      "Training Epoch 55  26.6% | batch:        25 of        94\t|\tloss: 837.701\n",
      "Training Epoch 55  27.7% | batch:        26 of        94\t|\tloss: 1665.29\n",
      "Training Epoch 55  28.7% | batch:        27 of        94\t|\tloss: 811.273\n",
      "Training Epoch 55  29.8% | batch:        28 of        94\t|\tloss: 1104.13\n",
      "Training Epoch 55  30.9% | batch:        29 of        94\t|\tloss: 1194.53\n",
      "Training Epoch 55  31.9% | batch:        30 of        94\t|\tloss: 2371.81\n",
      "Training Epoch 55  33.0% | batch:        31 of        94\t|\tloss: 1280.14\n",
      "Training Epoch 55  34.0% | batch:        32 of        94\t|\tloss: 979.519\n",
      "Training Epoch 55  35.1% | batch:        33 of        94\t|\tloss: 864.651\n",
      "Training Epoch 55  36.2% | batch:        34 of        94\t|\tloss: 1008.2\n",
      "Training Epoch 55  37.2% | batch:        35 of        94\t|\tloss: 922.681\n",
      "Training Epoch 55  38.3% | batch:        36 of        94\t|\tloss: 788.87\n",
      "Training Epoch 55  39.4% | batch:        37 of        94\t|\tloss: 843.468\n",
      "Training Epoch 55  40.4% | batch:        38 of        94\t|\tloss: 784.115\n",
      "Training Epoch 55  41.5% | batch:        39 of        94\t|\tloss: 1613.2\n",
      "Training Epoch 55  42.6% | batch:        40 of        94\t|\tloss: 1870.08\n",
      "Training Epoch 55  43.6% | batch:        41 of        94\t|\tloss: 1188.2\n",
      "Training Epoch 55  44.7% | batch:        42 of        94\t|\tloss: 759.382\n",
      "Training Epoch 55  45.7% | batch:        43 of        94\t|\tloss: 1151.64\n",
      "Training Epoch 55  46.8% | batch:        44 of        94\t|\tloss: 882.741\n",
      "Training Epoch 55  47.9% | batch:        45 of        94\t|\tloss: 1197.06\n",
      "Training Epoch 55  48.9% | batch:        46 of        94\t|\tloss: 1244.67\n",
      "Training Epoch 55  50.0% | batch:        47 of        94\t|\tloss: 1548.36\n",
      "Training Epoch 55  51.1% | batch:        48 of        94\t|\tloss: 1379.1\n",
      "Training Epoch 55  52.1% | batch:        49 of        94\t|\tloss: 710.138\n",
      "Training Epoch 55  53.2% | batch:        50 of        94\t|\tloss: 1086.2\n",
      "Training Epoch 55  54.3% | batch:        51 of        94\t|\tloss: 965.194\n",
      "Training Epoch 55  55.3% | batch:        52 of        94\t|\tloss: 1404.21\n",
      "Training Epoch 55  56.4% | batch:        53 of        94\t|\tloss: 1884.38\n",
      "Training Epoch 55  57.4% | batch:        54 of        94\t|\tloss: 1643.44\n",
      "Training Epoch 55  58.5% | batch:        55 of        94\t|\tloss: 856.252\n",
      "Training Epoch 55  59.6% | batch:        56 of        94\t|\tloss: 915.795\n",
      "Training Epoch 55  60.6% | batch:        57 of        94\t|\tloss: 962.583\n",
      "Training Epoch 55  61.7% | batch:        58 of        94\t|\tloss: 676.955\n",
      "Training Epoch 55  62.8% | batch:        59 of        94\t|\tloss: 1524.06\n",
      "Training Epoch 55  63.8% | batch:        60 of        94\t|\tloss: 2994.07\n",
      "Training Epoch 55  64.9% | batch:        61 of        94\t|\tloss: 961.5\n",
      "Training Epoch 55  66.0% | batch:        62 of        94\t|\tloss: 1509.48\n",
      "Training Epoch 55  67.0% | batch:        63 of        94\t|\tloss: 802.73\n",
      "Training Epoch 55  68.1% | batch:        64 of        94\t|\tloss: 1212.45\n",
      "Training Epoch 55  69.1% | batch:        65 of        94\t|\tloss: 796.935\n",
      "Training Epoch 55  70.2% | batch:        66 of        94\t|\tloss: 994.653\n",
      "Training Epoch 55  71.3% | batch:        67 of        94\t|\tloss: 1887.75\n",
      "Training Epoch 55  72.3% | batch:        68 of        94\t|\tloss: 1922.7\n",
      "Training Epoch 55  73.4% | batch:        69 of        94\t|\tloss: 3316.79\n",
      "Training Epoch 55  74.5% | batch:        70 of        94\t|\tloss: 715.887\n",
      "Training Epoch 55  75.5% | batch:        71 of        94\t|\tloss: 946.427\n",
      "Training Epoch 55  76.6% | batch:        72 of        94\t|\tloss: 1376.64\n",
      "Training Epoch 55  77.7% | batch:        73 of        94\t|\tloss: 1263.56\n",
      "Training Epoch 55  78.7% | batch:        74 of        94\t|\tloss: 789.764\n",
      "Training Epoch 55  79.8% | batch:        75 of        94\t|\tloss: 1286.45\n",
      "Training Epoch 55  80.9% | batch:        76 of        94\t|\tloss: 1076.49\n",
      "Training Epoch 55  81.9% | batch:        77 of        94\t|\tloss: 1119.05\n",
      "Training Epoch 55  83.0% | batch:        78 of        94\t|\tloss: 1021.9\n",
      "Training Epoch 55  84.0% | batch:        79 of        94\t|\tloss: 1101.85\n",
      "Training Epoch 55  85.1% | batch:        80 of        94\t|\tloss: 2741.75\n",
      "Training Epoch 55  86.2% | batch:        81 of        94\t|\tloss: 1945.29\n",
      "Training Epoch 55  87.2% | batch:        82 of        94\t|\tloss: 1655.76\n",
      "Training Epoch 55  88.3% | batch:        83 of        94\t|\tloss: 1299.8\n",
      "Training Epoch 55  89.4% | batch:        84 of        94\t|\tloss: 1050.58\n",
      "Training Epoch 55  90.4% | batch:        85 of        94\t|\tloss: 845.643\n",
      "Training Epoch 55  91.5% | batch:        86 of        94\t|\tloss: 1304.27\n",
      "Training Epoch 55  92.6% | batch:        87 of        94\t|\tloss: 1272.01\n",
      "Training Epoch 55  93.6% | batch:        88 of        94\t|\tloss: 2255.64\n",
      "Training Epoch 55  94.7% | batch:        89 of        94\t|\tloss: 1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:11,884 | INFO : Epoch 55 Training Summary: epoch: 55.000000 | loss: 1233.563029 | \n",
      "2023-05-09 14:22:11,885 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.846224069595337 seconds\n",
      "\n",
      "2023-05-09 14:22:11,885 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8256824016571045 seconds\n",
      "2023-05-09 14:22:11,886 | INFO : Avg batch train. time: 0.019422153209118134 seconds\n",
      "2023-05-09 14:22:11,887 | INFO : Avg sample train. time: 0.00015318697781986109 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 55  95.7% | batch:        90 of        94\t|\tloss: 923.97\n",
      "Training Epoch 55  96.8% | batch:        91 of        94\t|\tloss: 1031.45\n",
      "Training Epoch 55  97.9% | batch:        92 of        94\t|\tloss: 2921.21\n",
      "Training Epoch 55  98.9% | batch:        93 of        94\t|\tloss: 1364.85\n",
      "\n",
      "Training Epoch 56   0.0% | batch:         0 of        94\t|\tloss: 1063.42\n",
      "Training Epoch 56   1.1% | batch:         1 of        94\t|\tloss: 1833.77\n",
      "Training Epoch 56   2.1% | batch:         2 of        94\t|\tloss: 1163.91\n",
      "Training Epoch 56   3.2% | batch:         3 of        94\t|\tloss: 991.074\n",
      "Training Epoch 56   4.3% | batch:         4 of        94\t|\tloss: 1112.11\n",
      "Training Epoch 56   5.3% | batch:         5 of        94\t|\tloss: 962.684\n",
      "Training Epoch 56   6.4% | batch:         6 of        94\t|\tloss: 1249.98\n",
      "Training Epoch 56   7.4% | batch:         7 of        94\t|\tloss: 874.427\n",
      "Training Epoch 56   8.5% | batch:         8 of        94\t|\tloss: 1077.08\n",
      "Training Epoch 56   9.6% | batch:         9 of        94\t|\tloss: 1060\n",
      "Training Epoch 56  10.6% | batch:        10 of        94\t|\tloss: 1519.92\n",
      "Training Epoch 56  11.7% | batch:        11 of        94\t|\tloss: 1058\n",
      "Training Epoch 56  12.8% | batch:        12 of        94\t|\tloss: 1621.99\n",
      "Training Epoch 56  13.8% | batch:        13 of        94\t|\tloss: 816.071\n",
      "Training Epoch 56  14.9% | batch:        14 of        94\t|\tloss: 941.701\n",
      "Training Epoch 56  16.0% | batch:        15 of        94\t|\tloss: 793.342\n",
      "Training Epoch 56  17.0% | batch:        16 of        94\t|\tloss: 1711.6\n",
      "Training Epoch 56  18.1% | batch:        17 of        94\t|\tloss: 1150.2\n",
      "Training Epoch 56  19.1% | batch:        18 of        94\t|\tloss: 710.068\n",
      "Training Epoch 56  20.2% | batch:        19 of        94\t|\tloss: 2387.38\n",
      "Training Epoch 56  21.3% | batch:        20 of        94\t|\tloss: 925.891\n",
      "Training Epoch 56  22.3% | batch:        21 of        94\t|\tloss: 814.204\n",
      "Training Epoch 56  23.4% | batch:        22 of        94\t|\tloss: 1728.44\n",
      "Training Epoch 56  24.5% | batch:        23 of        94\t|\tloss: 1120.51\n",
      "Training Epoch 56  25.5% | batch:        24 of        94\t|\tloss: 801.61\n",
      "Training Epoch 56  26.6% | batch:        25 of        94\t|\tloss: 1258.83\n",
      "Training Epoch 56  27.7% | batch:        26 of        94\t|\tloss: 922.915\n",
      "Training Epoch 56  28.7% | batch:        27 of        94\t|\tloss: 1636.17\n",
      "Training Epoch 56  29.8% | batch:        28 of        94\t|\tloss: 886.783\n",
      "Training Epoch 56  30.9% | batch:        29 of        94\t|\tloss: 967.193\n",
      "Training Epoch 56  31.9% | batch:        30 of        94\t|\tloss: 1919.49\n",
      "Training Epoch 56  33.0% | batch:        31 of        94\t|\tloss: 1461.62\n",
      "Training Epoch 56  34.0% | batch:        32 of        94\t|\tloss: 1502.46\n",
      "Training Epoch 56  35.1% | batch:        33 of        94\t|\tloss: 991.32\n",
      "Training Epoch 56  36.2% | batch:        34 of        94\t|\tloss: 858.49\n",
      "Training Epoch 56  37.2% | batch:        35 of        94\t|\tloss: 1414.83\n",
      "Training Epoch 56  38.3% | batch:        36 of        94\t|\tloss: 1949.04\n",
      "Training Epoch 56  39.4% | batch:        37 of        94\t|\tloss: 1127.7\n",
      "Training Epoch 56  40.4% | batch:        38 of        94\t|\tloss: 878.087\n",
      "Training Epoch 56  41.5% | batch:        39 of        94\t|\tloss: 1338.28\n",
      "Training Epoch 56  42.6% | batch:        40 of        94\t|\tloss: 799.398\n",
      "Training Epoch 56  43.6% | batch:        41 of        94\t|\tloss: 1225.22\n",
      "Training Epoch 56  44.7% | batch:        42 of        94\t|\tloss: 1451.7\n",
      "Training Epoch 56  45.7% | batch:        43 of        94\t|\tloss: 727.275\n",
      "Training Epoch 56  46.8% | batch:        44 of        94\t|\tloss: 1087.84\n",
      "Training Epoch 56  47.9% | batch:        45 of        94\t|\tloss: 844.448\n",
      "Training Epoch 56  48.9% | batch:        46 of        94\t|\tloss: 1662.41\n",
      "Training Epoch 56  50.0% | batch:        47 of        94\t|\tloss: 951.239\n",
      "Training Epoch 56  51.1% | batch:        48 of        94\t|\tloss: 1230.04\n",
      "Training Epoch 56  52.1% | batch:        49 of        94\t|\tloss: 898.254\n",
      "Training Epoch 56  53.2% | batch:        50 of        94\t|\tloss: 1193.94\n",
      "Training Epoch 56  54.3% | batch:        51 of        94\t|\tloss: 1033.21\n",
      "Training Epoch 56  55.3% | batch:        52 of        94\t|\tloss: 740.114\n",
      "Training Epoch 56  56.4% | batch:        53 of        94\t|\tloss: 1182.89\n",
      "Training Epoch 56  57.4% | batch:        54 of        94\t|\tloss: 1173.1\n",
      "Training Epoch 56  58.5% | batch:        55 of        94\t|\tloss: 1270.44\n",
      "Training Epoch 56  59.6% | batch:        56 of        94\t|\tloss: 1267.62\n",
      "Training Epoch 56  60.6% | batch:        57 of        94\t|\tloss: 1542.01\n",
      "Training Epoch 56  61.7% | batch:        58 of        94\t|\tloss: 1656.42\n",
      "Training Epoch 56  62.8% | batch:        59 of        94\t|\tloss: 933.928\n",
      "Training Epoch 56  63.8% | batch:        60 of        94\t|\tloss: 2468.35\n",
      "Training Epoch 56  64.9% | batch:        61 of        94\t|\tloss: 1906\n",
      "Training Epoch 56  66.0% | batch:        62 of        94\t|\tloss: 2008.26\n",
      "Training Epoch 56  67.0% | batch:        63 of        94\t|\tloss: 1955.05\n",
      "Training Epoch 56  68.1% | batch:        64 of        94\t|\tloss: 885.959\n",
      "Training Epoch 56  69.1% | batch:        65 of        94\t|\tloss: 913.081\n",
      "Training Epoch 56  70.2% | batch:        66 of        94\t|\tloss: 1365.36\n",
      "Training Epoch 56  71.3% | batch:        67 of        94\t|\tloss: 1176.86\n",
      "Training Epoch 56  72.3% | batch:        68 of        94\t|\tloss: 1144.38\n",
      "Training Epoch 56  73.4% | batch:        69 of        94\t|\tloss: 1116.34\n",
      "Training Epoch 56  74.5% | batch:        70 of        94\t|\tloss: 1344.83\n",
      "Training Epoch 56  75.5% | batch:        71 of        94\t|\tloss: 1496.88\n",
      "Training Epoch 56  76.6% | batch:        72 of        94\t|\tloss: 846.095\n",
      "Training Epoch 56  77.7% | batch:        73 of        94\t|\tloss: 1229.34\n",
      "Training Epoch 56  78.7% | batch:        74 of        94\t|\tloss: 1240.85\n",
      "Training Epoch 56  79.8% | batch:        75 of        94\t|\tloss: 873.141\n",
      "Training Epoch 56  80.9% | batch:        76 of        94\t|\tloss: 1139.35\n",
      "Training Epoch 56  81.9% | batch:        77 of        94\t|\tloss: 1375.07\n",
      "Training Epoch 56  83.0% | batch:        78 of        94\t|\tloss: 1216.68\n",
      "Training Epoch 56  84.0% | batch:        79 of        94\t|\tloss: 1097.18\n",
      "Training Epoch 56  85.1% | batch:        80 of        94\t|\tloss: 1060.85\n",
      "Training Epoch 56  86.2% | batch:        81 of        94\t|\tloss: 1155.94\n",
      "Training Epoch 56  87.2% | batch:        82 of        94\t|\tloss: 2502.27\n",
      "Training Epoch 56  88.3% | batch:        83 of        94\t|\tloss: 1351.95\n",
      "Training Epoch 56  89.4% | batch:        84 of        94\t|\tloss: 972.205\n",
      "Training Epoch 56  90.4% | batch:        85 of        94\t|\tloss: 1532.43\n",
      "Training Epoch 56  91.5% | batch:        86 of        94\t|\tloss: 1610.23\n",
      "Training Epoch 56  92.6% | batch:        87 of        94\t|\tloss: 1190.15\n",
      "Training Epoch 56  93.6% | batch:        88 of        94\t|\tloss: 1377.49\n",
      "Training Epoch 56  94.7% | batch:        89 of        94\t|\tloss: 913.692\n",
      "Training Epoch 56  95.7% | batch:        90 of        94\t|\tloss: 1163.92\n",
      "Training Epoch 56  96.8% | batch:        91 of        94\t|\tloss: 913.533\n",
      "Training Epoch 56  97.9% | batch:        92 of        94\t|\tloss: 909.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:13,786 | INFO : Epoch 56 Training Summary: epoch: 56.000000 | loss: 1235.900303 | \n",
      "2023-05-09 14:22:13,787 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8795583248138428 seconds\n",
      "\n",
      "2023-05-09 14:22:13,787 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8266444717134749 seconds\n",
      "2023-05-09 14:22:13,788 | INFO : Avg batch train. time: 0.01943238799695186 seconds\n",
      "2023-05-09 14:22:13,789 | INFO : Avg sample train. time: 0.0001532677019393753 seconds\n",
      "2023-05-09 14:22:13,789 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 56  98.9% | batch:        93 of        94\t|\tloss: 1337.45\n",
      "\n",
      "Evaluating Epoch 56   0.0% | batch:         0 of        40\t|\tloss: 6653.05\n",
      "Evaluating Epoch 56   2.5% | batch:         1 of        40\t|\tloss: 1200.49\n",
      "Evaluating Epoch 56   5.0% | batch:         2 of        40\t|\tloss: 4841.31\n",
      "Evaluating Epoch 56   7.5% | batch:         3 of        40\t|\tloss: 8064.1\n",
      "Evaluating Epoch 56  10.0% | batch:         4 of        40\t|\tloss: 2506.13\n",
      "Evaluating Epoch 56  12.5% | batch:         5 of        40\t|\tloss: 2566.88\n",
      "Evaluating Epoch 56  15.0% | batch:         6 of        40\t|\tloss: 8929.85\n",
      "Evaluating Epoch 56  17.5% | batch:         7 of        40\t|\tloss: 2950.18\n",
      "Evaluating Epoch 56  20.0% | batch:         8 of        40\t|\tloss: 2863.29\n",
      "Evaluating Epoch 56  22.5% | batch:         9 of        40\t|\tloss: 2288.96\n",
      "Evaluating Epoch 56  25.0% | batch:        10 of        40\t|\tloss: 5014.99\n",
      "Evaluating Epoch 56  27.5% | batch:        11 of        40\t|\tloss: 1509.01\n",
      "Evaluating Epoch 56  30.0% | batch:        12 of        40\t|\tloss: 6041.5\n",
      "Evaluating Epoch 56  32.5% | batch:        13 of        40\t|\tloss: 3384.46\n",
      "Evaluating Epoch 56  35.0% | batch:        14 of        40\t|\tloss: 2151.77\n",
      "Evaluating Epoch 56  37.5% | batch:        15 of        40\t|\tloss: 2988.61\n",
      "Evaluating Epoch 56  40.0% | batch:        16 of        40\t|\tloss: 4567.98\n",
      "Evaluating Epoch 56  42.5% | batch:        17 of        40\t|\tloss: 2642.94\n",
      "Evaluating Epoch 56  45.0% | batch:        18 of        40\t|\tloss: 2379.97\n",
      "Evaluating Epoch 56  47.5% | batch:        19 of        40\t|\tloss: 5546.39\n",
      "Evaluating Epoch 56  50.0% | batch:        20 of        40\t|\tloss: 5117.28\n",
      "Evaluating Epoch 56  52.5% | batch:        21 of        40\t|\tloss: 1033.7\n",
      "Evaluating Epoch 56  55.0% | batch:        22 of        40\t|\tloss: 4290.16\n",
      "Evaluating Epoch 56  57.5% | batch:        23 of        40\t|\tloss: 3149.39\n",
      "Evaluating Epoch 56  60.0% | batch:        24 of        40\t|\tloss: 1702.89\n",
      "Evaluating Epoch 56  62.5% | batch:        25 of        40\t|\tloss: 3333.47\n",
      "Evaluating Epoch 56  65.0% | batch:        26 of        40\t|\tloss: 9625.92\n",
      "Evaluating Epoch 56  67.5% | batch:        27 of        40\t|\tloss: 3178.91\n",
      "Evaluating Epoch 56  70.0% | batch:        28 of        40\t|\tloss: 2162.34\n",
      "Evaluating Epoch 56  72.5% | batch:        29 of        40\t|\tloss: 9683.97\n",
      "Evaluating Epoch 56  75.0% | batch:        30 of        40\t|\tloss: 1851.51\n",
      "Evaluating Epoch 56  77.5% | batch:        31 of        40\t|\tloss: 2123.99\n",
      "Evaluating Epoch 56  80.0% | batch:        32 of        40\t|\tloss: 7953.1\n",
      "Evaluating Epoch 56  82.5% | batch:        33 of        40\t|\tloss: 6897.12\n",
      "Evaluating Epoch 56  85.0% | batch:        34 of        40\t|\tloss: 1019.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:14,248 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4580397605895996 seconds\n",
      "\n",
      "2023-05-09 14:22:14,248 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.48039766152699787 seconds\n",
      "2023-05-09 14:22:14,249 | INFO : Avg batch val. time: 0.012009941538174947 seconds\n",
      "2023-05-09 14:22:14,249 | INFO : Avg sample val. time: 9.516593928823254e-05 seconds\n",
      "2023-05-09 14:22:14,251 | INFO : Epoch 56 Validation Summary: epoch: 56.000000 | loss: 4253.559525 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 56  87.5% | batch:        35 of        40\t|\tloss: 6702.31\n",
      "Evaluating Epoch 56  90.0% | batch:        36 of        40\t|\tloss: 7283.19\n",
      "Evaluating Epoch 56  92.5% | batch:        37 of        40\t|\tloss: 2641.88\n",
      "Evaluating Epoch 56  95.0% | batch:        38 of        40\t|\tloss: 3761.35\n",
      "Evaluating Epoch 56  97.5% | batch:        39 of        40\t|\tloss: 11761.6\n",
      "\n",
      "Training Epoch 57   0.0% | batch:         0 of        94\t|\tloss: 895.648\n",
      "Training Epoch 57   1.1% | batch:         1 of        94\t|\tloss: 1419.85\n",
      "Training Epoch 57   2.1% | batch:         2 of        94\t|\tloss: 1536.44\n",
      "Training Epoch 57   3.2% | batch:         3 of        94\t|\tloss: 1012.09\n",
      "Training Epoch 57   4.3% | batch:         4 of        94\t|\tloss: 978.009\n",
      "Training Epoch 57   5.3% | batch:         5 of        94\t|\tloss: 568.551\n",
      "Training Epoch 57   6.4% | batch:         6 of        94\t|\tloss: 969.967\n",
      "Training Epoch 57   7.4% | batch:         7 of        94\t|\tloss: 1250.95\n",
      "Training Epoch 57   8.5% | batch:         8 of        94\t|\tloss: 887.883\n",
      "Training Epoch 57   9.6% | batch:         9 of        94\t|\tloss: 1200.84\n",
      "Training Epoch 57  10.6% | batch:        10 of        94\t|\tloss: 2201.73\n",
      "Training Epoch 57  11.7% | batch:        11 of        94\t|\tloss: 692.899\n",
      "Training Epoch 57  12.8% | batch:        12 of        94\t|\tloss: 1246.3\n",
      "Training Epoch 57  13.8% | batch:        13 of        94\t|\tloss: 920.967\n",
      "Training Epoch 57  14.9% | batch:        14 of        94\t|\tloss: 778.03\n",
      "Training Epoch 57  16.0% | batch:        15 of        94\t|\tloss: 837.015\n",
      "Training Epoch 57  17.0% | batch:        16 of        94\t|\tloss: 1986.63\n",
      "Training Epoch 57  18.1% | batch:        17 of        94\t|\tloss: 937.064\n",
      "Training Epoch 57  19.1% | batch:        18 of        94\t|\tloss: 1104.57\n",
      "Training Epoch 57  20.2% | batch:        19 of        94\t|\tloss: 940.343\n",
      "Training Epoch 57  21.3% | batch:        20 of        94\t|\tloss: 964.469\n",
      "Training Epoch 57  22.3% | batch:        21 of        94\t|\tloss: 3117.25\n",
      "Training Epoch 57  23.4% | batch:        22 of        94\t|\tloss: 1180.18\n",
      "Training Epoch 57  24.5% | batch:        23 of        94\t|\tloss: 1063.69\n",
      "Training Epoch 57  25.5% | batch:        24 of        94\t|\tloss: 1083.39\n",
      "Training Epoch 57  26.6% | batch:        25 of        94\t|\tloss: 1270.19\n",
      "Training Epoch 57  27.7% | batch:        26 of        94\t|\tloss: 1404.25\n",
      "Training Epoch 57  28.7% | batch:        27 of        94\t|\tloss: 981.129\n",
      "Training Epoch 57  29.8% | batch:        28 of        94\t|\tloss: 1070.49\n",
      "Training Epoch 57  30.9% | batch:        29 of        94\t|\tloss: 961.234\n",
      "Training Epoch 57  31.9% | batch:        30 of        94\t|\tloss: 1267.44\n",
      "Training Epoch 57  33.0% | batch:        31 of        94\t|\tloss: 1154.7\n",
      "Training Epoch 57  34.0% | batch:        32 of        94\t|\tloss: 777.903\n",
      "Training Epoch 57  35.1% | batch:        33 of        94\t|\tloss: 912.694\n",
      "Training Epoch 57  36.2% | batch:        34 of        94\t|\tloss: 942.787\n",
      "Training Epoch 57  37.2% | batch:        35 of        94\t|\tloss: 1557.79\n",
      "Training Epoch 57  38.3% | batch:        36 of        94\t|\tloss: 1136.49\n",
      "Training Epoch 57  39.4% | batch:        37 of        94\t|\tloss: 877.075\n",
      "Training Epoch 57  40.4% | batch:        38 of        94\t|\tloss: 936.532\n",
      "Training Epoch 57  41.5% | batch:        39 of        94\t|\tloss: 892.073\n",
      "Training Epoch 57  42.6% | batch:        40 of        94\t|\tloss: 1697.57\n",
      "Training Epoch 57  43.6% | batch:        41 of        94\t|\tloss: 1086.32\n",
      "Training Epoch 57  44.7% | batch:        42 of        94\t|\tloss: 1293.8\n",
      "Training Epoch 57  45.7% | batch:        43 of        94\t|\tloss: 1593.76\n",
      "Training Epoch 57  46.8% | batch:        44 of        94\t|\tloss: 1299.45\n",
      "Training Epoch 57  47.9% | batch:        45 of        94\t|\tloss: 1448.34\n",
      "Training Epoch 57  48.9% | batch:        46 of        94\t|\tloss: 1481.23\n",
      "Training Epoch 57  50.0% | batch:        47 of        94\t|\tloss: 1033.11\n",
      "Training Epoch 57  51.1% | batch:        48 of        94\t|\tloss: 747.332\n",
      "Training Epoch 57  52.1% | batch:        49 of        94\t|\tloss: 1178.09\n",
      "Training Epoch 57  53.2% | batch:        50 of        94\t|\tloss: 1230.51\n",
      "Training Epoch 57  54.3% | batch:        51 of        94\t|\tloss: 774.837\n",
      "Training Epoch 57  55.3% | batch:        52 of        94\t|\tloss: 983.78\n",
      "Training Epoch 57  56.4% | batch:        53 of        94\t|\tloss: 831.034\n",
      "Training Epoch 57  57.4% | batch:        54 of        94\t|\tloss: 4070.76\n",
      "Training Epoch 57  58.5% | batch:        55 of        94\t|\tloss: 1276.7\n",
      "Training Epoch 57  59.6% | batch:        56 of        94\t|\tloss: 2362.71\n",
      "Training Epoch 57  60.6% | batch:        57 of        94\t|\tloss: 1094.6\n",
      "Training Epoch 57  61.7% | batch:        58 of        94\t|\tloss: 845.836\n",
      "Training Epoch 57  62.8% | batch:        59 of        94\t|\tloss: 1118.76\n",
      "Training Epoch 57  63.8% | batch:        60 of        94\t|\tloss: 1174.61\n",
      "Training Epoch 57  64.9% | batch:        61 of        94\t|\tloss: 793.212\n",
      "Training Epoch 57  66.0% | batch:        62 of        94\t|\tloss: 1171.16\n",
      "Training Epoch 57  67.0% | batch:        63 of        94\t|\tloss: 2494.01\n",
      "Training Epoch 57  68.1% | batch:        64 of        94\t|\tloss: 862.305\n",
      "Training Epoch 57  69.1% | batch:        65 of        94\t|\tloss: 857.573\n",
      "Training Epoch 57  70.2% | batch:        66 of        94\t|\tloss: 1036.65\n",
      "Training Epoch 57  71.3% | batch:        67 of        94\t|\tloss: 2024.61\n",
      "Training Epoch 57  72.3% | batch:        68 of        94\t|\tloss: 1965.56\n",
      "Training Epoch 57  73.4% | batch:        69 of        94\t|\tloss: 692.16\n",
      "Training Epoch 57  74.5% | batch:        70 of        94\t|\tloss: 871.089\n",
      "Training Epoch 57  75.5% | batch:        71 of        94\t|\tloss: 1182.63\n",
      "Training Epoch 57  76.6% | batch:        72 of        94\t|\tloss: 1277.18\n",
      "Training Epoch 57  77.7% | batch:        73 of        94\t|\tloss: 1018.89\n",
      "Training Epoch 57  78.7% | batch:        74 of        94\t|\tloss: 1167.61\n",
      "Training Epoch 57  79.8% | batch:        75 of        94\t|\tloss: 1521.73\n",
      "Training Epoch 57  80.9% | batch:        76 of        94\t|\tloss: 889.115\n",
      "Training Epoch 57  81.9% | batch:        77 of        94\t|\tloss: 897.47\n",
      "Training Epoch 57  83.0% | batch:        78 of        94\t|\tloss: 1678.49\n",
      "Training Epoch 57  84.0% | batch:        79 of        94\t|\tloss: 2851.69\n",
      "Training Epoch 57  85.1% | batch:        80 of        94\t|\tloss: 3528.19\n",
      "Training Epoch 57  86.2% | batch:        81 of        94\t|\tloss: 1204.75\n",
      "Training Epoch 57  87.2% | batch:        82 of        94\t|\tloss: 905.356\n",
      "Training Epoch 57  88.3% | batch:        83 of        94\t|\tloss: 1408.81\n",
      "Training Epoch 57  89.4% | batch:        84 of        94\t|\tloss: 1720.54\n",
      "Training Epoch 57  90.4% | batch:        85 of        94\t|\tloss: 1124.68\n",
      "Training Epoch 57  91.5% | batch:        86 of        94\t|\tloss: 1159.71\n",
      "Training Epoch 57  92.6% | batch:        87 of        94\t|\tloss: 1070.15\n",
      "Training Epoch 57  93.6% | batch:        88 of        94\t|\tloss: 1136.23\n",
      "Training Epoch 57  94.7% | batch:        89 of        94\t|\tloss: 1934.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:16,122 | INFO : Epoch 57 Training Summary: epoch: 57.000000 | loss: 1286.135400 | \n",
      "2023-05-09 14:22:16,123 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8503057956695557 seconds\n",
      "\n",
      "2023-05-09 14:22:16,123 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8270595826600726 seconds\n",
      "2023-05-09 14:22:16,124 | INFO : Avg batch train. time: 0.019436804070851837 seconds\n",
      "2023-05-09 14:22:16,124 | INFO : Avg sample train. time: 0.00015330253252727577 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 57  95.7% | batch:        90 of        94\t|\tloss: 1130.26\n",
      "Training Epoch 57  96.8% | batch:        91 of        94\t|\tloss: 1265.84\n",
      "Training Epoch 57  97.9% | batch:        92 of        94\t|\tloss: 1477.97\n",
      "Training Epoch 57  98.9% | batch:        93 of        94\t|\tloss: 8137.6\n",
      "\n",
      "Training Epoch 58   0.0% | batch:         0 of        94\t|\tloss: 1070.41\n",
      "Training Epoch 58   1.1% | batch:         1 of        94\t|\tloss: 1054.89\n",
      "Training Epoch 58   2.1% | batch:         2 of        94\t|\tloss: 1469.73\n",
      "Training Epoch 58   3.2% | batch:         3 of        94\t|\tloss: 1767.2\n",
      "Training Epoch 58   4.3% | batch:         4 of        94\t|\tloss: 584.179\n",
      "Training Epoch 58   5.3% | batch:         5 of        94\t|\tloss: 1161.13\n",
      "Training Epoch 58   6.4% | batch:         6 of        94\t|\tloss: 2847\n",
      "Training Epoch 58   7.4% | batch:         7 of        94\t|\tloss: 721.858\n",
      "Training Epoch 58   8.5% | batch:         8 of        94\t|\tloss: 942.509\n",
      "Training Epoch 58   9.6% | batch:         9 of        94\t|\tloss: 886.156\n",
      "Training Epoch 58  10.6% | batch:        10 of        94\t|\tloss: 735.59\n",
      "Training Epoch 58  11.7% | batch:        11 of        94\t|\tloss: 1114.46\n",
      "Training Epoch 58  12.8% | batch:        12 of        94\t|\tloss: 1114.58\n",
      "Training Epoch 58  13.8% | batch:        13 of        94\t|\tloss: 1367.95\n",
      "Training Epoch 58  14.9% | batch:        14 of        94\t|\tloss: 1568.68\n",
      "Training Epoch 58  16.0% | batch:        15 of        94\t|\tloss: 2531.72\n",
      "Training Epoch 58  17.0% | batch:        16 of        94\t|\tloss: 1737.71\n",
      "Training Epoch 58  18.1% | batch:        17 of        94\t|\tloss: 856.826\n",
      "Training Epoch 58  19.1% | batch:        18 of        94\t|\tloss: 1129.37\n",
      "Training Epoch 58  20.2% | batch:        19 of        94\t|\tloss: 1601.67\n",
      "Training Epoch 58  21.3% | batch:        20 of        94\t|\tloss: 877.087\n",
      "Training Epoch 58  22.3% | batch:        21 of        94\t|\tloss: 916.333\n",
      "Training Epoch 58  23.4% | batch:        22 of        94\t|\tloss: 1144.36\n",
      "Training Epoch 58  24.5% | batch:        23 of        94\t|\tloss: 968.827\n",
      "Training Epoch 58  25.5% | batch:        24 of        94\t|\tloss: 817.203\n",
      "Training Epoch 58  26.6% | batch:        25 of        94\t|\tloss: 1058.09\n",
      "Training Epoch 58  27.7% | batch:        26 of        94\t|\tloss: 1291.65\n",
      "Training Epoch 58  28.7% | batch:        27 of        94\t|\tloss: 1137.59\n",
      "Training Epoch 58  29.8% | batch:        28 of        94\t|\tloss: 936.978\n",
      "Training Epoch 58  30.9% | batch:        29 of        94\t|\tloss: 958.452\n",
      "Training Epoch 58  31.9% | batch:        30 of        94\t|\tloss: 1337.83\n",
      "Training Epoch 58  33.0% | batch:        31 of        94\t|\tloss: 739.25\n",
      "Training Epoch 58  34.0% | batch:        32 of        94\t|\tloss: 1372.46\n",
      "Training Epoch 58  35.1% | batch:        33 of        94\t|\tloss: 2696.79\n",
      "Training Epoch 58  36.2% | batch:        34 of        94\t|\tloss: 2658.4\n",
      "Training Epoch 58  37.2% | batch:        35 of        94\t|\tloss: 2422.48\n",
      "Training Epoch 58  38.3% | batch:        36 of        94\t|\tloss: 874.505\n",
      "Training Epoch 58  39.4% | batch:        37 of        94\t|\tloss: 1034.18\n",
      "Training Epoch 58  40.4% | batch:        38 of        94\t|\tloss: 2217.5\n",
      "Training Epoch 58  41.5% | batch:        39 of        94\t|\tloss: 1391.5\n",
      "Training Epoch 58  42.6% | batch:        40 of        94\t|\tloss: 971.217\n",
      "Training Epoch 58  43.6% | batch:        41 of        94\t|\tloss: 1098.43\n",
      "Training Epoch 58  44.7% | batch:        42 of        94\t|\tloss: 664.241\n",
      "Training Epoch 58  45.7% | batch:        43 of        94\t|\tloss: 892.15\n",
      "Training Epoch 58  46.8% | batch:        44 of        94\t|\tloss: 1191.28\n",
      "Training Epoch 58  47.9% | batch:        45 of        94\t|\tloss: 871.897\n",
      "Training Epoch 58  48.9% | batch:        46 of        94\t|\tloss: 1550.54\n",
      "Training Epoch 58  50.0% | batch:        47 of        94\t|\tloss: 1463.37\n",
      "Training Epoch 58  51.1% | batch:        48 of        94\t|\tloss: 870.686\n",
      "Training Epoch 58  52.1% | batch:        49 of        94\t|\tloss: 1075.43\n",
      "Training Epoch 58  53.2% | batch:        50 of        94\t|\tloss: 932.963\n",
      "Training Epoch 58  54.3% | batch:        51 of        94\t|\tloss: 836.984\n",
      "Training Epoch 58  55.3% | batch:        52 of        94\t|\tloss: 1239.78\n",
      "Training Epoch 58  56.4% | batch:        53 of        94\t|\tloss: 1608.22\n",
      "Training Epoch 58  57.4% | batch:        54 of        94\t|\tloss: 1083.5\n",
      "Training Epoch 58  58.5% | batch:        55 of        94\t|\tloss: 1691.57\n",
      "Training Epoch 58  59.6% | batch:        56 of        94\t|\tloss: 939.791\n",
      "Training Epoch 58  60.6% | batch:        57 of        94\t|\tloss: 1295.44\n",
      "Training Epoch 58  61.7% | batch:        58 of        94\t|\tloss: 1746.81\n",
      "Training Epoch 58  62.8% | batch:        59 of        94\t|\tloss: 1867.42\n",
      "Training Epoch 58  63.8% | batch:        60 of        94\t|\tloss: 1154.92\n",
      "Training Epoch 58  64.9% | batch:        61 of        94\t|\tloss: 1100.37\n",
      "Training Epoch 58  66.0% | batch:        62 of        94\t|\tloss: 1288.17\n",
      "Training Epoch 58  67.0% | batch:        63 of        94\t|\tloss: 1449.38\n",
      "Training Epoch 58  68.1% | batch:        64 of        94\t|\tloss: 807.246\n",
      "Training Epoch 58  69.1% | batch:        65 of        94\t|\tloss: 1120.39\n",
      "Training Epoch 58  70.2% | batch:        66 of        94\t|\tloss: 840.179\n",
      "Training Epoch 58  71.3% | batch:        67 of        94\t|\tloss: 841.309\n",
      "Training Epoch 58  72.3% | batch:        68 of        94\t|\tloss: 1579.03\n",
      "Training Epoch 58  73.4% | batch:        69 of        94\t|\tloss: 1145.46\n",
      "Training Epoch 58  74.5% | batch:        70 of        94\t|\tloss: 1597.79\n",
      "Training Epoch 58  75.5% | batch:        71 of        94\t|\tloss: 931.94\n",
      "Training Epoch 58  76.6% | batch:        72 of        94\t|\tloss: 1149.4\n",
      "Training Epoch 58  77.7% | batch:        73 of        94\t|\tloss: 1039.59\n",
      "Training Epoch 58  78.7% | batch:        74 of        94\t|\tloss: 1738.96\n",
      "Training Epoch 58  79.8% | batch:        75 of        94\t|\tloss: 842.852\n",
      "Training Epoch 58  80.9% | batch:        76 of        94\t|\tloss: 932.718\n",
      "Training Epoch 58  81.9% | batch:        77 of        94\t|\tloss: 1187.44\n",
      "Training Epoch 58  83.0% | batch:        78 of        94\t|\tloss: 754.397\n",
      "Training Epoch 58  84.0% | batch:        79 of        94\t|\tloss: 1207.46\n",
      "Training Epoch 58  85.1% | batch:        80 of        94\t|\tloss: 1069.17\n",
      "Training Epoch 58  86.2% | batch:        81 of        94\t|\tloss: 1616.69\n",
      "Training Epoch 58  87.2% | batch:        82 of        94\t|\tloss: 1808.98\n",
      "Training Epoch 58  88.3% | batch:        83 of        94\t|\tloss: 1192.05\n",
      "Training Epoch 58  89.4% | batch:        84 of        94\t|\tloss: 1012.16\n",
      "Training Epoch 58  90.4% | batch:        85 of        94\t|\tloss: 1132.92\n",
      "Training Epoch 58  91.5% | batch:        86 of        94\t|\tloss: 1574.71\n",
      "Training Epoch 58  92.6% | batch:        87 of        94\t|\tloss: 950.974\n",
      "Training Epoch 58  93.6% | batch:        88 of        94\t|\tloss: 2375.79\n",
      "Training Epoch 58  94.7% | batch:        89 of        94\t|\tloss: 843.971\n",
      "Training Epoch 58  95.7% | batch:        90 of        94\t|\tloss: 1252.54\n",
      "Training Epoch 58  96.8% | batch:        91 of        94\t|\tloss: 1081.26\n",
      "Training Epoch 58  97.9% | batch:        92 of        94\t|\tloss: 833.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:18,001 | INFO : Epoch 58 Training Summary: epoch: 58.000000 | loss: 1252.002998 | \n",
      "2023-05-09 14:22:18,001 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.85577392578125 seconds\n",
      "\n",
      "2023-05-09 14:22:18,002 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8275546575414723 seconds\n",
      "2023-05-09 14:22:18,002 | INFO : Avg batch train. time: 0.01944207082490928 seconds\n",
      "2023-05-09 14:22:18,003 | INFO : Avg sample train. time: 0.00015334407262472497 seconds\n",
      "2023-05-09 14:22:18,003 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 58  98.9% | batch:        93 of        94\t|\tloss: 1032.43\n",
      "\n",
      "Evaluating Epoch 58   0.0% | batch:         0 of        40\t|\tloss: 7317.13\n",
      "Evaluating Epoch 58   2.5% | batch:         1 of        40\t|\tloss: 1205.79\n",
      "Evaluating Epoch 58   5.0% | batch:         2 of        40\t|\tloss: 3989.29\n",
      "Evaluating Epoch 58   7.5% | batch:         3 of        40\t|\tloss: 7386.02\n",
      "Evaluating Epoch 58  10.0% | batch:         4 of        40\t|\tloss: 3260.86\n",
      "Evaluating Epoch 58  12.5% | batch:         5 of        40\t|\tloss: 2927.95\n",
      "Evaluating Epoch 58  15.0% | batch:         6 of        40\t|\tloss: 8643.67\n",
      "Evaluating Epoch 58  17.5% | batch:         7 of        40\t|\tloss: 3343.26\n",
      "Evaluating Epoch 58  20.0% | batch:         8 of        40\t|\tloss: 2734.73\n",
      "Evaluating Epoch 58  22.5% | batch:         9 of        40\t|\tloss: 2080.04\n",
      "Evaluating Epoch 58  25.0% | batch:        10 of        40\t|\tloss: 5285.38\n",
      "Evaluating Epoch 58  27.5% | batch:        11 of        40\t|\tloss: 1396.68\n",
      "Evaluating Epoch 58  30.0% | batch:        12 of        40\t|\tloss: 5854.83\n",
      "Evaluating Epoch 58  32.5% | batch:        13 of        40\t|\tloss: 3604.54\n",
      "Evaluating Epoch 58  35.0% | batch:        14 of        40\t|\tloss: 2137\n",
      "Evaluating Epoch 58  37.5% | batch:        15 of        40\t|\tloss: 3065.33\n",
      "Evaluating Epoch 58  40.0% | batch:        16 of        40\t|\tloss: 4454.74\n",
      "Evaluating Epoch 58  42.5% | batch:        17 of        40\t|\tloss: 2642.8\n",
      "Evaluating Epoch 58  45.0% | batch:        18 of        40\t|\tloss: 2657.16\n",
      "Evaluating Epoch 58  47.5% | batch:        19 of        40\t|\tloss: 5465.49\n",
      "Evaluating Epoch 58  50.0% | batch:        20 of        40\t|\tloss: 5676.56\n",
      "Evaluating Epoch 58  52.5% | batch:        21 of        40\t|\tloss: 1308.52\n",
      "Evaluating Epoch 58  55.0% | batch:        22 of        40\t|\tloss: 4073.89\n",
      "Evaluating Epoch 58  57.5% | batch:        23 of        40\t|\tloss: 3719.37\n",
      "Evaluating Epoch 58  60.0% | batch:        24 of        40\t|\tloss: 1758.18\n",
      "Evaluating Epoch 58  62.5% | batch:        25 of        40\t|\tloss: 2709.36\n",
      "Evaluating Epoch 58  65.0% | batch:        26 of        40\t|\tloss: 9291.28\n",
      "Evaluating Epoch 58  67.5% | batch:        27 of        40\t|\tloss: 2623.89\n",
      "Evaluating Epoch 58  70.0% | batch:        28 of        40\t|\tloss: 2030.83\n",
      "Evaluating Epoch 58  72.5% | batch:        29 of        40\t|\tloss: 9683.47\n",
      "Evaluating Epoch 58  75.0% | batch:        30 of        40\t|\tloss: 1918.55\n",
      "Evaluating Epoch 58  77.5% | batch:        31 of        40\t|\tloss: 1881.37\n",
      "Evaluating Epoch 58  80.0% | batch:        32 of        40\t|\tloss: 7263.23\n",
      "Evaluating Epoch 58  82.5% | batch:        33 of        40\t|\tloss: 7179.56\n",
      "Evaluating Epoch 58  85.0% | batch:        34 of        40\t|\tloss: 894.474\n",
      "Evaluating Epoch 58  87.5% | batch:        35 of        40\t|\tloss: 5374.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:18,462 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.457568883895874 seconds\n",
      "\n",
      "2023-05-09 14:22:18,462 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4796612493453487 seconds\n",
      "2023-05-09 14:22:18,463 | INFO : Avg batch val. time: 0.011991531233633718 seconds\n",
      "2023-05-09 14:22:18,463 | INFO : Avg sample val. time: 9.502005731880917e-05 seconds\n",
      "2023-05-09 14:22:18,463 | INFO : Epoch 58 Validation Summary: epoch: 58.000000 | loss: 4163.674966 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 58  90.0% | batch:        36 of        40\t|\tloss: 7179.05\n",
      "Evaluating Epoch 58  92.5% | batch:        37 of        40\t|\tloss: 2759.06\n",
      "Evaluating Epoch 58  95.0% | batch:        38 of        40\t|\tloss: 2985.9\n",
      "Evaluating Epoch 58  97.5% | batch:        39 of        40\t|\tloss: 10151\n",
      "\n",
      "Training Epoch 59   0.0% | batch:         0 of        94\t|\tloss: 867.521\n",
      "Training Epoch 59   1.1% | batch:         1 of        94\t|\tloss: 1138.11\n",
      "Training Epoch 59   2.1% | batch:         2 of        94\t|\tloss: 1722.13\n",
      "Training Epoch 59   3.2% | batch:         3 of        94\t|\tloss: 884.988\n",
      "Training Epoch 59   4.3% | batch:         4 of        94\t|\tloss: 1120.9\n",
      "Training Epoch 59   5.3% | batch:         5 of        94\t|\tloss: 1117.84\n",
      "Training Epoch 59   6.4% | batch:         6 of        94\t|\tloss: 1055.17\n",
      "Training Epoch 59   7.4% | batch:         7 of        94\t|\tloss: 672.245\n",
      "Training Epoch 59   8.5% | batch:         8 of        94\t|\tloss: 1195.57\n",
      "Training Epoch 59   9.6% | batch:         9 of        94\t|\tloss: 954.431\n",
      "Training Epoch 59  10.6% | batch:        10 of        94\t|\tloss: 927.634\n",
      "Training Epoch 59  11.7% | batch:        11 of        94\t|\tloss: 815.034\n",
      "Training Epoch 59  12.8% | batch:        12 of        94\t|\tloss: 882.445\n",
      "Training Epoch 59  13.8% | batch:        13 of        94\t|\tloss: 1159.58\n",
      "Training Epoch 59  14.9% | batch:        14 of        94\t|\tloss: 1098.62\n",
      "Training Epoch 59  16.0% | batch:        15 of        94\t|\tloss: 1021.21\n",
      "Training Epoch 59  17.0% | batch:        16 of        94\t|\tloss: 1356.3\n",
      "Training Epoch 59  18.1% | batch:        17 of        94\t|\tloss: 1287.88\n",
      "Training Epoch 59  19.1% | batch:        18 of        94\t|\tloss: 1015.46\n",
      "Training Epoch 59  20.2% | batch:        19 of        94\t|\tloss: 823.48\n",
      "Training Epoch 59  21.3% | batch:        20 of        94\t|\tloss: 1678.72\n",
      "Training Epoch 59  22.3% | batch:        21 of        94\t|\tloss: 966.529\n",
      "Training Epoch 59  23.4% | batch:        22 of        94\t|\tloss: 1184.84\n",
      "Training Epoch 59  24.5% | batch:        23 of        94\t|\tloss: 1075.76\n",
      "Training Epoch 59  25.5% | batch:        24 of        94\t|\tloss: 1256.42\n",
      "Training Epoch 59  26.6% | batch:        25 of        94\t|\tloss: 1139.41\n",
      "Training Epoch 59  27.7% | batch:        26 of        94\t|\tloss: 1296.59\n",
      "Training Epoch 59  28.7% | batch:        27 of        94\t|\tloss: 1840.75\n",
      "Training Epoch 59  29.8% | batch:        28 of        94\t|\tloss: 912.676\n",
      "Training Epoch 59  30.9% | batch:        29 of        94\t|\tloss: 1008.03\n",
      "Training Epoch 59  31.9% | batch:        30 of        94\t|\tloss: 1448.46\n",
      "Training Epoch 59  33.0% | batch:        31 of        94\t|\tloss: 1191.45\n",
      "Training Epoch 59  34.0% | batch:        32 of        94\t|\tloss: 1031.46\n",
      "Training Epoch 59  35.1% | batch:        33 of        94\t|\tloss: 2349.09\n",
      "Training Epoch 59  36.2% | batch:        34 of        94\t|\tloss: 1110.27\n",
      "Training Epoch 59  37.2% | batch:        35 of        94\t|\tloss: 1018.96\n",
      "Training Epoch 59  38.3% | batch:        36 of        94\t|\tloss: 931.138\n",
      "Training Epoch 59  39.4% | batch:        37 of        94\t|\tloss: 1195.98\n",
      "Training Epoch 59  40.4% | batch:        38 of        94\t|\tloss: 1797.68\n",
      "Training Epoch 59  41.5% | batch:        39 of        94\t|\tloss: 772.887\n",
      "Training Epoch 59  42.6% | batch:        40 of        94\t|\tloss: 801.704\n",
      "Training Epoch 59  43.6% | batch:        41 of        94\t|\tloss: 691.913\n",
      "Training Epoch 59  44.7% | batch:        42 of        94\t|\tloss: 842.346\n",
      "Training Epoch 59  45.7% | batch:        43 of        94\t|\tloss: 1010.75\n",
      "Training Epoch 59  46.8% | batch:        44 of        94\t|\tloss: 1589.63\n",
      "Training Epoch 59  47.9% | batch:        45 of        94\t|\tloss: 912.75\n",
      "Training Epoch 59  48.9% | batch:        46 of        94\t|\tloss: 737.782\n",
      "Training Epoch 59  50.0% | batch:        47 of        94\t|\tloss: 1907.92\n",
      "Training Epoch 59  51.1% | batch:        48 of        94\t|\tloss: 1381.17\n",
      "Training Epoch 59  52.1% | batch:        49 of        94\t|\tloss: 1115.98\n",
      "Training Epoch 59  53.2% | batch:        50 of        94\t|\tloss: 1240.51\n",
      "Training Epoch 59  54.3% | batch:        51 of        94\t|\tloss: 1604.65\n",
      "Training Epoch 59  55.3% | batch:        52 of        94\t|\tloss: 1516.73\n",
      "Training Epoch 59  56.4% | batch:        53 of        94\t|\tloss: 1754.19\n",
      "Training Epoch 59  57.4% | batch:        54 of        94\t|\tloss: 1326.32\n",
      "Training Epoch 59  58.5% | batch:        55 of        94\t|\tloss: 1503.1\n",
      "Training Epoch 59  59.6% | batch:        56 of        94\t|\tloss: 1340.22\n",
      "Training Epoch 59  60.6% | batch:        57 of        94\t|\tloss: 1544.36\n",
      "Training Epoch 59  61.7% | batch:        58 of        94\t|\tloss: 2958.14\n",
      "Training Epoch 59  62.8% | batch:        59 of        94\t|\tloss: 1336.17\n",
      "Training Epoch 59  63.8% | batch:        60 of        94\t|\tloss: 1058.65\n",
      "Training Epoch 59  64.9% | batch:        61 of        94\t|\tloss: 1064.27\n",
      "Training Epoch 59  66.0% | batch:        62 of        94\t|\tloss: 1178.3\n",
      "Training Epoch 59  67.0% | batch:        63 of        94\t|\tloss: 1269.95\n",
      "Training Epoch 59  68.1% | batch:        64 of        94\t|\tloss: 1063.33\n",
      "Training Epoch 59  69.1% | batch:        65 of        94\t|\tloss: 851.546\n",
      "Training Epoch 59  70.2% | batch:        66 of        94\t|\tloss: 1106.62\n",
      "Training Epoch 59  71.3% | batch:        67 of        94\t|\tloss: 2500.86\n",
      "Training Epoch 59  72.3% | batch:        68 of        94\t|\tloss: 1378.31\n",
      "Training Epoch 59  73.4% | batch:        69 of        94\t|\tloss: 1299.59\n",
      "Training Epoch 59  74.5% | batch:        70 of        94\t|\tloss: 1585.44\n",
      "Training Epoch 59  75.5% | batch:        71 of        94\t|\tloss: 934.306\n",
      "Training Epoch 59  76.6% | batch:        72 of        94\t|\tloss: 985.27\n",
      "Training Epoch 59  77.7% | batch:        73 of        94\t|\tloss: 2049.46\n",
      "Training Epoch 59  78.7% | batch:        74 of        94\t|\tloss: 909.137\n",
      "Training Epoch 59  79.8% | batch:        75 of        94\t|\tloss: 929.139\n",
      "Training Epoch 59  80.9% | batch:        76 of        94\t|\tloss: 842.225\n",
      "Training Epoch 59  81.9% | batch:        77 of        94\t|\tloss: 1301.46\n",
      "Training Epoch 59  83.0% | batch:        78 of        94\t|\tloss: 1428.36\n",
      "Training Epoch 59  84.0% | batch:        79 of        94\t|\tloss: 1135.43\n",
      "Training Epoch 59  85.1% | batch:        80 of        94\t|\tloss: 971.096\n",
      "Training Epoch 59  86.2% | batch:        81 of        94\t|\tloss: 761.441\n",
      "Training Epoch 59  87.2% | batch:        82 of        94\t|\tloss: 1530.2\n",
      "Training Epoch 59  88.3% | batch:        83 of        94\t|\tloss: 844.315\n",
      "Training Epoch 59  89.4% | batch:        84 of        94\t|\tloss: 1321.23\n",
      "Training Epoch 59  90.4% | batch:        85 of        94\t|\tloss: 1758.97\n",
      "Training Epoch 59  91.5% | batch:        86 of        94\t|\tloss: 1322.77\n",
      "Training Epoch 59  92.6% | batch:        87 of        94\t|\tloss: 3112.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:20,339 | INFO : Epoch 59 Training Summary: epoch: 59.000000 | loss: 1241.874494 | \n",
      "2023-05-09 14:22:20,340 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8542735576629639 seconds\n",
      "\n",
      "2023-05-09 14:22:20,341 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8280075202553958 seconds\n",
      "2023-05-09 14:22:20,341 | INFO : Avg batch train. time: 0.019446888513355274 seconds\n",
      "2023-05-09 14:22:20,342 | INFO : Avg sample train. time: 0.00015338207083868063 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 59  93.6% | batch:        88 of        94\t|\tloss: 1243.47\n",
      "Training Epoch 59  94.7% | batch:        89 of        94\t|\tloss: 1019.52\n",
      "Training Epoch 59  95.7% | batch:        90 of        94\t|\tloss: 890.219\n",
      "Training Epoch 59  96.8% | batch:        91 of        94\t|\tloss: 1066.48\n",
      "Training Epoch 59  97.9% | batch:        92 of        94\t|\tloss: 1243.1\n",
      "Training Epoch 59  98.9% | batch:        93 of        94\t|\tloss: 2134.08\n",
      "\n",
      "Training Epoch 60   0.0% | batch:         0 of        94\t|\tloss: 794.706\n",
      "Training Epoch 60   1.1% | batch:         1 of        94\t|\tloss: 926.116\n",
      "Training Epoch 60   2.1% | batch:         2 of        94\t|\tloss: 854.735\n",
      "Training Epoch 60   3.2% | batch:         3 of        94\t|\tloss: 1030.38\n",
      "Training Epoch 60   4.3% | batch:         4 of        94\t|\tloss: 1726.77\n",
      "Training Epoch 60   5.3% | batch:         5 of        94\t|\tloss: 1798.18\n",
      "Training Epoch 60   6.4% | batch:         6 of        94\t|\tloss: 2385.71\n",
      "Training Epoch 60   7.4% | batch:         7 of        94\t|\tloss: 784.182\n",
      "Training Epoch 60   8.5% | batch:         8 of        94\t|\tloss: 962.955\n",
      "Training Epoch 60   9.6% | batch:         9 of        94\t|\tloss: 2297.25\n",
      "Training Epoch 60  10.6% | batch:        10 of        94\t|\tloss: 771.384\n",
      "Training Epoch 60  11.7% | batch:        11 of        94\t|\tloss: 1668.81\n",
      "Training Epoch 60  12.8% | batch:        12 of        94\t|\tloss: 1054.31\n",
      "Training Epoch 60  13.8% | batch:        13 of        94\t|\tloss: 775.913\n",
      "Training Epoch 60  14.9% | batch:        14 of        94\t|\tloss: 2325.01\n",
      "Training Epoch 60  16.0% | batch:        15 of        94\t|\tloss: 623.216\n",
      "Training Epoch 60  17.0% | batch:        16 of        94\t|\tloss: 985.621\n",
      "Training Epoch 60  18.1% | batch:        17 of        94\t|\tloss: 970.121\n",
      "Training Epoch 60  19.1% | batch:        18 of        94\t|\tloss: 1403.86\n",
      "Training Epoch 60  20.2% | batch:        19 of        94\t|\tloss: 903.76\n",
      "Training Epoch 60  21.3% | batch:        20 of        94\t|\tloss: 863.194\n",
      "Training Epoch 60  22.3% | batch:        21 of        94\t|\tloss: 1054.6\n",
      "Training Epoch 60  23.4% | batch:        22 of        94\t|\tloss: 1370.31\n",
      "Training Epoch 60  24.5% | batch:        23 of        94\t|\tloss: 1364.3\n",
      "Training Epoch 60  25.5% | batch:        24 of        94\t|\tloss: 1029.34\n",
      "Training Epoch 60  26.6% | batch:        25 of        94\t|\tloss: 830.906\n",
      "Training Epoch 60  27.7% | batch:        26 of        94\t|\tloss: 771.767\n",
      "Training Epoch 60  28.7% | batch:        27 of        94\t|\tloss: 1475.71\n",
      "Training Epoch 60  29.8% | batch:        28 of        94\t|\tloss: 831.606\n",
      "Training Epoch 60  30.9% | batch:        29 of        94\t|\tloss: 1558.38\n",
      "Training Epoch 60  31.9% | batch:        30 of        94\t|\tloss: 989.486\n",
      "Training Epoch 60  33.0% | batch:        31 of        94\t|\tloss: 3450.55\n",
      "Training Epoch 60  34.0% | batch:        32 of        94\t|\tloss: 1553.35\n",
      "Training Epoch 60  35.1% | batch:        33 of        94\t|\tloss: 969.414\n",
      "Training Epoch 60  36.2% | batch:        34 of        94\t|\tloss: 1744.34\n",
      "Training Epoch 60  37.2% | batch:        35 of        94\t|\tloss: 1345.89\n",
      "Training Epoch 60  38.3% | batch:        36 of        94\t|\tloss: 884.412\n",
      "Training Epoch 60  39.4% | batch:        37 of        94\t|\tloss: 1000.36\n",
      "Training Epoch 60  40.4% | batch:        38 of        94\t|\tloss: 836.209\n",
      "Training Epoch 60  41.5% | batch:        39 of        94\t|\tloss: 1186.53\n",
      "Training Epoch 60  42.6% | batch:        40 of        94\t|\tloss: 824.87\n",
      "Training Epoch 60  43.6% | batch:        41 of        94\t|\tloss: 841.549\n",
      "Training Epoch 60  44.7% | batch:        42 of        94\t|\tloss: 931.996\n",
      "Training Epoch 60  45.7% | batch:        43 of        94\t|\tloss: 973.856\n",
      "Training Epoch 60  46.8% | batch:        44 of        94\t|\tloss: 1044.75\n",
      "Training Epoch 60  47.9% | batch:        45 of        94\t|\tloss: 1078.48\n",
      "Training Epoch 60  48.9% | batch:        46 of        94\t|\tloss: 1352.7\n",
      "Training Epoch 60  50.0% | batch:        47 of        94\t|\tloss: 1116.53\n",
      "Training Epoch 60  51.1% | batch:        48 of        94\t|\tloss: 1255.56\n",
      "Training Epoch 60  52.1% | batch:        49 of        94\t|\tloss: 865.371\n",
      "Training Epoch 60  53.2% | batch:        50 of        94\t|\tloss: 1034.46\n",
      "Training Epoch 60  54.3% | batch:        51 of        94\t|\tloss: 1229\n",
      "Training Epoch 60  55.3% | batch:        52 of        94\t|\tloss: 821.64\n",
      "Training Epoch 60  56.4% | batch:        53 of        94\t|\tloss: 926.997\n",
      "Training Epoch 60  57.4% | batch:        54 of        94\t|\tloss: 1053.62\n",
      "Training Epoch 60  58.5% | batch:        55 of        94\t|\tloss: 1454.26\n",
      "Training Epoch 60  59.6% | batch:        56 of        94\t|\tloss: 850.24\n",
      "Training Epoch 60  60.6% | batch:        57 of        94\t|\tloss: 834.116\n",
      "Training Epoch 60  61.7% | batch:        58 of        94\t|\tloss: 1082.27\n",
      "Training Epoch 60  62.8% | batch:        59 of        94\t|\tloss: 957.879\n",
      "Training Epoch 60  63.8% | batch:        60 of        94\t|\tloss: 1789.11\n",
      "Training Epoch 60  64.9% | batch:        61 of        94\t|\tloss: 819.056\n",
      "Training Epoch 60  66.0% | batch:        62 of        94\t|\tloss: 1127.09\n",
      "Training Epoch 60  67.0% | batch:        63 of        94\t|\tloss: 848.802\n",
      "Training Epoch 60  68.1% | batch:        64 of        94\t|\tloss: 1132.63\n",
      "Training Epoch 60  69.1% | batch:        65 of        94\t|\tloss: 986.334\n",
      "Training Epoch 60  70.2% | batch:        66 of        94\t|\tloss: 1615.81\n",
      "Training Epoch 60  71.3% | batch:        67 of        94\t|\tloss: 1360.82\n",
      "Training Epoch 60  72.3% | batch:        68 of        94\t|\tloss: 669.971\n",
      "Training Epoch 60  73.4% | batch:        69 of        94\t|\tloss: 806.229\n",
      "Training Epoch 60  74.5% | batch:        70 of        94\t|\tloss: 1259.94\n",
      "Training Epoch 60  75.5% | batch:        71 of        94\t|\tloss: 1744.78\n",
      "Training Epoch 60  76.6% | batch:        72 of        94\t|\tloss: 1096.98\n",
      "Training Epoch 60  77.7% | batch:        73 of        94\t|\tloss: 1184.39\n",
      "Training Epoch 60  78.7% | batch:        74 of        94\t|\tloss: 1500.09\n",
      "Training Epoch 60  79.8% | batch:        75 of        94\t|\tloss: 1551.42\n",
      "Training Epoch 60  80.9% | batch:        76 of        94\t|\tloss: 2077.34\n",
      "Training Epoch 60  81.9% | batch:        77 of        94\t|\tloss: 1235.88\n",
      "Training Epoch 60  83.0% | batch:        78 of        94\t|\tloss: 748.136\n",
      "Training Epoch 60  84.0% | batch:        79 of        94\t|\tloss: 1649.37\n",
      "Training Epoch 60  85.1% | batch:        80 of        94\t|\tloss: 2089.18\n",
      "Training Epoch 60  86.2% | batch:        81 of        94\t|\tloss: 901.145\n",
      "Training Epoch 60  87.2% | batch:        82 of        94\t|\tloss: 1216.15\n",
      "Training Epoch 60  88.3% | batch:        83 of        94\t|\tloss: 1228.72\n",
      "Training Epoch 60  89.4% | batch:        84 of        94\t|\tloss: 738.637\n",
      "Training Epoch 60  90.4% | batch:        85 of        94\t|\tloss: 861.356\n",
      "Training Epoch 60  91.5% | batch:        86 of        94\t|\tloss: 1019.64\n",
      "Training Epoch 60  92.6% | batch:        87 of        94\t|\tloss: 903.318\n",
      "Training Epoch 60  93.6% | batch:        88 of        94\t|\tloss: 922.81\n",
      "Training Epoch 60  94.7% | batch:        89 of        94\t|\tloss: 1368.25\n",
      "Training Epoch 60  95.7% | batch:        90 of        94\t|\tloss: 778.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:22,207 | INFO : Epoch 60 Training Summary: epoch: 60.000000 | loss: 1195.641462 | \n",
      "2023-05-09 14:22:22,208 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8442566394805908 seconds\n",
      "\n",
      "2023-05-09 14:22:22,209 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8282783389091493 seconds\n",
      "2023-05-09 14:22:22,209 | INFO : Avg batch train. time: 0.01944976956286329 seconds\n",
      "2023-05-09 14:22:22,210 | INFO : Avg sample train. time: 0.0001534047943370657 seconds\n",
      "2023-05-09 14:22:22,210 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 60  96.8% | batch:        91 of        94\t|\tloss: 1345.4\n",
      "Training Epoch 60  97.9% | batch:        92 of        94\t|\tloss: 1932.67\n",
      "Training Epoch 60  98.9% | batch:        93 of        94\t|\tloss: 1204.03\n",
      "\n",
      "Evaluating Epoch 60   0.0% | batch:         0 of        40\t|\tloss: 7057.52\n",
      "Evaluating Epoch 60   2.5% | batch:         1 of        40\t|\tloss: 1281.24\n",
      "Evaluating Epoch 60   5.0% | batch:         2 of        40\t|\tloss: 3997.95\n",
      "Evaluating Epoch 60   7.5% | batch:         3 of        40\t|\tloss: 7205.87\n",
      "Evaluating Epoch 60  10.0% | batch:         4 of        40\t|\tloss: 2348.87\n",
      "Evaluating Epoch 60  12.5% | batch:         5 of        40\t|\tloss: 2152.56\n",
      "Evaluating Epoch 60  15.0% | batch:         6 of        40\t|\tloss: 8919.43\n",
      "Evaluating Epoch 60  17.5% | batch:         7 of        40\t|\tloss: 3193.28\n",
      "Evaluating Epoch 60  20.0% | batch:         8 of        40\t|\tloss: 2692.53\n",
      "Evaluating Epoch 60  22.5% | batch:         9 of        40\t|\tloss: 1950.67\n",
      "Evaluating Epoch 60  25.0% | batch:        10 of        40\t|\tloss: 5371.76\n",
      "Evaluating Epoch 60  27.5% | batch:        11 of        40\t|\tloss: 1743.92\n",
      "Evaluating Epoch 60  30.0% | batch:        12 of        40\t|\tloss: 6695.42\n",
      "Evaluating Epoch 60  32.5% | batch:        13 of        40\t|\tloss: 3600.23\n",
      "Evaluating Epoch 60  35.0% | batch:        14 of        40\t|\tloss: 2161.67\n",
      "Evaluating Epoch 60  37.5% | batch:        15 of        40\t|\tloss: 3584.31\n",
      "Evaluating Epoch 60  40.0% | batch:        16 of        40\t|\tloss: 4345.87\n",
      "Evaluating Epoch 60  42.5% | batch:        17 of        40\t|\tloss: 2868.17\n",
      "Evaluating Epoch 60  45.0% | batch:        18 of        40\t|\tloss: 2618.43\n",
      "Evaluating Epoch 60  47.5% | batch:        19 of        40\t|\tloss: 6389.88\n",
      "Evaluating Epoch 60  50.0% | batch:        20 of        40\t|\tloss: 5506.86\n",
      "Evaluating Epoch 60  52.5% | batch:        21 of        40\t|\tloss: 1196.59\n",
      "Evaluating Epoch 60  55.0% | batch:        22 of        40\t|\tloss: 3963.17\n",
      "Evaluating Epoch 60  57.5% | batch:        23 of        40\t|\tloss: 3583.04\n",
      "Evaluating Epoch 60  60.0% | batch:        24 of        40\t|\tloss: 1653.88\n",
      "Evaluating Epoch 60  62.5% | batch:        25 of        40\t|\tloss: 3630.08\n",
      "Evaluating Epoch 60  65.0% | batch:        26 of        40\t|\tloss: 10944.4\n",
      "Evaluating Epoch 60  67.5% | batch:        27 of        40\t|\tloss: 3020.52\n",
      "Evaluating Epoch 60  70.0% | batch:        28 of        40\t|\tloss: 1970.36\n",
      "Evaluating Epoch 60  72.5% | batch:        29 of        40\t|\tloss: 9689.5\n",
      "Evaluating Epoch 60  75.0% | batch:        30 of        40\t|\tloss: 2320.5\n",
      "Evaluating Epoch 60  77.5% | batch:        31 of        40\t|\tloss: 2198.43\n",
      "Evaluating Epoch 60  80.0% | batch:        32 of        40\t|\tloss: 7848.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:22,668 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4575200080871582 seconds\n",
      "\n",
      "2023-05-09 14:22:22,668 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4789693355560303 seconds\n",
      "2023-05-09 14:22:22,669 | INFO : Avg batch val. time: 0.011974233388900756 seconds\n",
      "2023-05-09 14:22:22,669 | INFO : Avg sample val. time: 9.488299040333404e-05 seconds\n",
      "2023-05-09 14:22:22,670 | INFO : Epoch 60 Validation Summary: epoch: 60.000000 | loss: 4297.180765 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 60  82.5% | batch:        33 of        40\t|\tloss: 6803.81\n",
      "Evaluating Epoch 60  85.0% | batch:        34 of        40\t|\tloss: 1385.96\n",
      "Evaluating Epoch 60  87.5% | batch:        35 of        40\t|\tloss: 5179.39\n",
      "Evaluating Epoch 60  90.0% | batch:        36 of        40\t|\tloss: 6503.17\n",
      "Evaluating Epoch 60  92.5% | batch:        37 of        40\t|\tloss: 2780.03\n",
      "Evaluating Epoch 60  95.0% | batch:        38 of        40\t|\tloss: 3852.94\n",
      "Evaluating Epoch 60  97.5% | batch:        39 of        40\t|\tloss: 12020.9\n",
      "\n",
      "Training Epoch 61   0.0% | batch:         0 of        94\t|\tloss: 1061.51\n",
      "Training Epoch 61   1.1% | batch:         1 of        94\t|\tloss: 1059.98\n",
      "Training Epoch 61   2.1% | batch:         2 of        94\t|\tloss: 1298.53\n",
      "Training Epoch 61   3.2% | batch:         3 of        94\t|\tloss: 944.275\n",
      "Training Epoch 61   4.3% | batch:         4 of        94\t|\tloss: 796.446\n",
      "Training Epoch 61   5.3% | batch:         5 of        94\t|\tloss: 3559.55\n",
      "Training Epoch 61   6.4% | batch:         6 of        94\t|\tloss: 832.428\n",
      "Training Epoch 61   7.4% | batch:         7 of        94\t|\tloss: 840.423\n",
      "Training Epoch 61   8.5% | batch:         8 of        94\t|\tloss: 976.014\n",
      "Training Epoch 61   9.6% | batch:         9 of        94\t|\tloss: 804.805\n",
      "Training Epoch 61  10.6% | batch:        10 of        94\t|\tloss: 2721.41\n",
      "Training Epoch 61  11.7% | batch:        11 of        94\t|\tloss: 818.428\n",
      "Training Epoch 61  12.8% | batch:        12 of        94\t|\tloss: 1659.01\n",
      "Training Epoch 61  13.8% | batch:        13 of        94\t|\tloss: 1242.58\n",
      "Training Epoch 61  14.9% | batch:        14 of        94\t|\tloss: 910.782\n",
      "Training Epoch 61  16.0% | batch:        15 of        94\t|\tloss: 1328.28\n",
      "Training Epoch 61  17.0% | batch:        16 of        94\t|\tloss: 1018.65\n",
      "Training Epoch 61  18.1% | batch:        17 of        94\t|\tloss: 1016.42\n",
      "Training Epoch 61  19.1% | batch:        18 of        94\t|\tloss: 969.586\n",
      "Training Epoch 61  20.2% | batch:        19 of        94\t|\tloss: 1051.98\n",
      "Training Epoch 61  21.3% | batch:        20 of        94\t|\tloss: 642.406\n",
      "Training Epoch 61  22.3% | batch:        21 of        94\t|\tloss: 1188.34\n",
      "Training Epoch 61  23.4% | batch:        22 of        94\t|\tloss: 681.97\n",
      "Training Epoch 61  24.5% | batch:        23 of        94\t|\tloss: 1340.83\n",
      "Training Epoch 61  25.5% | batch:        24 of        94\t|\tloss: 1347.96\n",
      "Training Epoch 61  26.6% | batch:        25 of        94\t|\tloss: 1910.97\n",
      "Training Epoch 61  27.7% | batch:        26 of        94\t|\tloss: 1139.39\n",
      "Training Epoch 61  28.7% | batch:        27 of        94\t|\tloss: 804.156\n",
      "Training Epoch 61  29.8% | batch:        28 of        94\t|\tloss: 1975.75\n",
      "Training Epoch 61  30.9% | batch:        29 of        94\t|\tloss: 823.555\n",
      "Training Epoch 61  31.9% | batch:        30 of        94\t|\tloss: 783.357\n",
      "Training Epoch 61  33.0% | batch:        31 of        94\t|\tloss: 923.15\n",
      "Training Epoch 61  34.0% | batch:        32 of        94\t|\tloss: 1131.19\n",
      "Training Epoch 61  35.1% | batch:        33 of        94\t|\tloss: 937.344\n",
      "Training Epoch 61  36.2% | batch:        34 of        94\t|\tloss: 998.681\n",
      "Training Epoch 61  37.2% | batch:        35 of        94\t|\tloss: 863.947\n",
      "Training Epoch 61  38.3% | batch:        36 of        94\t|\tloss: 1478.61\n",
      "Training Epoch 61  39.4% | batch:        37 of        94\t|\tloss: 927.404\n",
      "Training Epoch 61  40.4% | batch:        38 of        94\t|\tloss: 1452.17\n",
      "Training Epoch 61  41.5% | batch:        39 of        94\t|\tloss: 869.482\n",
      "Training Epoch 61  42.6% | batch:        40 of        94\t|\tloss: 1372.69\n",
      "Training Epoch 61  43.6% | batch:        41 of        94\t|\tloss: 904.4\n",
      "Training Epoch 61  44.7% | batch:        42 of        94\t|\tloss: 1393.03\n",
      "Training Epoch 61  45.7% | batch:        43 of        94\t|\tloss: 1329.92\n",
      "Training Epoch 61  46.8% | batch:        44 of        94\t|\tloss: 991.788\n",
      "Training Epoch 61  47.9% | batch:        45 of        94\t|\tloss: 2201.14\n",
      "Training Epoch 61  48.9% | batch:        46 of        94\t|\tloss: 614.761\n",
      "Training Epoch 61  50.0% | batch:        47 of        94\t|\tloss: 1178.85\n",
      "Training Epoch 61  51.1% | batch:        48 of        94\t|\tloss: 1206.49\n",
      "Training Epoch 61  52.1% | batch:        49 of        94\t|\tloss: 2319.75\n",
      "Training Epoch 61  53.2% | batch:        50 of        94\t|\tloss: 1044.11\n",
      "Training Epoch 61  54.3% | batch:        51 of        94\t|\tloss: 1489.86\n",
      "Training Epoch 61  55.3% | batch:        52 of        94\t|\tloss: 1093.99\n",
      "Training Epoch 61  56.4% | batch:        53 of        94\t|\tloss: 1973.87\n",
      "Training Epoch 61  57.4% | batch:        54 of        94\t|\tloss: 950.716\n",
      "Training Epoch 61  58.5% | batch:        55 of        94\t|\tloss: 953.118\n",
      "Training Epoch 61  59.6% | batch:        56 of        94\t|\tloss: 903.433\n",
      "Training Epoch 61  60.6% | batch:        57 of        94\t|\tloss: 1476.28\n",
      "Training Epoch 61  61.7% | batch:        58 of        94\t|\tloss: 891.265\n",
      "Training Epoch 61  62.8% | batch:        59 of        94\t|\tloss: 749.751\n",
      "Training Epoch 61  63.8% | batch:        60 of        94\t|\tloss: 1158.55\n",
      "Training Epoch 61  64.9% | batch:        61 of        94\t|\tloss: 708.265\n",
      "Training Epoch 61  66.0% | batch:        62 of        94\t|\tloss: 1573.27\n",
      "Training Epoch 61  67.0% | batch:        63 of        94\t|\tloss: 1855.75\n",
      "Training Epoch 61  68.1% | batch:        64 of        94\t|\tloss: 793.792\n",
      "Training Epoch 61  69.1% | batch:        65 of        94\t|\tloss: 2680.05\n",
      "Training Epoch 61  70.2% | batch:        66 of        94\t|\tloss: 736.377\n",
      "Training Epoch 61  71.3% | batch:        67 of        94\t|\tloss: 936.489\n",
      "Training Epoch 61  72.3% | batch:        68 of        94\t|\tloss: 1268.73\n",
      "Training Epoch 61  73.4% | batch:        69 of        94\t|\tloss: 1896.75\n",
      "Training Epoch 61  74.5% | batch:        70 of        94\t|\tloss: 724.428\n",
      "Training Epoch 61  75.5% | batch:        71 of        94\t|\tloss: 611.705\n",
      "Training Epoch 61  76.6% | batch:        72 of        94\t|\tloss: 1071.47\n",
      "Training Epoch 61  77.7% | batch:        73 of        94\t|\tloss: 844.385\n",
      "Training Epoch 61  78.7% | batch:        74 of        94\t|\tloss: 1160.68\n",
      "Training Epoch 61  79.8% | batch:        75 of        94\t|\tloss: 1198.1\n",
      "Training Epoch 61  80.9% | batch:        76 of        94\t|\tloss: 711.792\n",
      "Training Epoch 61  81.9% | batch:        77 of        94\t|\tloss: 2372.55\n",
      "Training Epoch 61  83.0% | batch:        78 of        94\t|\tloss: 2133.94\n",
      "Training Epoch 61  84.0% | batch:        79 of        94\t|\tloss: 973.034\n",
      "Training Epoch 61  85.1% | batch:        80 of        94\t|\tloss: 914.903\n",
      "Training Epoch 61  86.2% | batch:        81 of        94\t|\tloss: 969.622\n",
      "Training Epoch 61  87.2% | batch:        82 of        94\t|\tloss: 995.385\n",
      "Training Epoch 61  88.3% | batch:        83 of        94\t|\tloss: 944.355\n",
      "Training Epoch 61  89.4% | batch:        84 of        94\t|\tloss: 1023.16\n",
      "Training Epoch 61  90.4% | batch:        85 of        94\t|\tloss: 1153.05\n",
      "Training Epoch 61  91.5% | batch:        86 of        94\t|\tloss: 878.24\n",
      "Training Epoch 61  92.6% | batch:        87 of        94\t|\tloss: 1365.78\n",
      "Training Epoch 61  93.6% | batch:        88 of        94\t|\tloss: 750.028\n",
      "Training Epoch 61  94.7% | batch:        89 of        94\t|\tloss: 996.581\n",
      "Training Epoch 61  95.7% | batch:        90 of        94\t|\tloss: 1230.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:24,505 | INFO : Epoch 61 Training Summary: epoch: 61.000000 | loss: 1191.065664 | \n",
      "2023-05-09 14:22:24,506 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8141839504241943 seconds\n",
      "\n",
      "2023-05-09 14:22:24,506 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8280472833602155 seconds\n",
      "2023-05-09 14:22:24,507 | INFO : Avg batch train. time: 0.019447311525108677 seconds\n",
      "2023-05-09 14:22:24,508 | INFO : Avg sample train. time: 0.000153385407229419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 61  96.8% | batch:        91 of        94\t|\tloss: 984.77\n",
      "Training Epoch 61  97.9% | batch:        92 of        94\t|\tloss: 979.764\n",
      "Training Epoch 61  98.9% | batch:        93 of        94\t|\tloss: 1211\n",
      "\n",
      "Training Epoch 62   0.0% | batch:         0 of        94\t|\tloss: 1038.53\n",
      "Training Epoch 62   1.1% | batch:         1 of        94\t|\tloss: 1031.16\n",
      "Training Epoch 62   2.1% | batch:         2 of        94\t|\tloss: 1671.93\n",
      "Training Epoch 62   3.2% | batch:         3 of        94\t|\tloss: 1072.97\n",
      "Training Epoch 62   4.3% | batch:         4 of        94\t|\tloss: 771.506\n",
      "Training Epoch 62   5.3% | batch:         5 of        94\t|\tloss: 977.843\n",
      "Training Epoch 62   6.4% | batch:         6 of        94\t|\tloss: 816.364\n",
      "Training Epoch 62   7.4% | batch:         7 of        94\t|\tloss: 977.326\n",
      "Training Epoch 62   8.5% | batch:         8 of        94\t|\tloss: 1128.63\n",
      "Training Epoch 62   9.6% | batch:         9 of        94\t|\tloss: 969.102\n",
      "Training Epoch 62  10.6% | batch:        10 of        94\t|\tloss: 1458.45\n",
      "Training Epoch 62  11.7% | batch:        11 of        94\t|\tloss: 1340.58\n",
      "Training Epoch 62  12.8% | batch:        12 of        94\t|\tloss: 1144.2\n",
      "Training Epoch 62  13.8% | batch:        13 of        94\t|\tloss: 809.563\n",
      "Training Epoch 62  14.9% | batch:        14 of        94\t|\tloss: 1351.62\n",
      "Training Epoch 62  16.0% | batch:        15 of        94\t|\tloss: 1417.74\n",
      "Training Epoch 62  17.0% | batch:        16 of        94\t|\tloss: 969.748\n",
      "Training Epoch 62  18.1% | batch:        17 of        94\t|\tloss: 1292.26\n",
      "Training Epoch 62  19.1% | batch:        18 of        94\t|\tloss: 835.026\n",
      "Training Epoch 62  20.2% | batch:        19 of        94\t|\tloss: 2695.97\n",
      "Training Epoch 62  21.3% | batch:        20 of        94\t|\tloss: 844.774\n",
      "Training Epoch 62  22.3% | batch:        21 of        94\t|\tloss: 942.642\n",
      "Training Epoch 62  23.4% | batch:        22 of        94\t|\tloss: 1450.6\n",
      "Training Epoch 62  24.5% | batch:        23 of        94\t|\tloss: 1262.84\n",
      "Training Epoch 62  25.5% | batch:        24 of        94\t|\tloss: 696.92\n",
      "Training Epoch 62  26.6% | batch:        25 of        94\t|\tloss: 759.396\n",
      "Training Epoch 62  27.7% | batch:        26 of        94\t|\tloss: 731.827\n",
      "Training Epoch 62  28.7% | batch:        27 of        94\t|\tloss: 882.893\n",
      "Training Epoch 62  29.8% | batch:        28 of        94\t|\tloss: 1275.54\n",
      "Training Epoch 62  30.9% | batch:        29 of        94\t|\tloss: 952.309\n",
      "Training Epoch 62  31.9% | batch:        30 of        94\t|\tloss: 1717.41\n",
      "Training Epoch 62  33.0% | batch:        31 of        94\t|\tloss: 801.963\n",
      "Training Epoch 62  34.0% | batch:        32 of        94\t|\tloss: 721.928\n",
      "Training Epoch 62  35.1% | batch:        33 of        94\t|\tloss: 1166.26\n",
      "Training Epoch 62  36.2% | batch:        34 of        94\t|\tloss: 666.843\n",
      "Training Epoch 62  37.2% | batch:        35 of        94\t|\tloss: 2192.97\n",
      "Training Epoch 62  38.3% | batch:        36 of        94\t|\tloss: 1938\n",
      "Training Epoch 62  39.4% | batch:        37 of        94\t|\tloss: 1225.72\n",
      "Training Epoch 62  40.4% | batch:        38 of        94\t|\tloss: 1123.42\n",
      "Training Epoch 62  41.5% | batch:        39 of        94\t|\tloss: 947.52\n",
      "Training Epoch 62  42.6% | batch:        40 of        94\t|\tloss: 3183.41\n",
      "Training Epoch 62  43.6% | batch:        41 of        94\t|\tloss: 1265.54\n",
      "Training Epoch 62  44.7% | batch:        42 of        94\t|\tloss: 1100.47\n",
      "Training Epoch 62  45.7% | batch:        43 of        94\t|\tloss: 1918.02\n",
      "Training Epoch 62  46.8% | batch:        44 of        94\t|\tloss: 862.735\n",
      "Training Epoch 62  47.9% | batch:        45 of        94\t|\tloss: 859.956\n",
      "Training Epoch 62  48.9% | batch:        46 of        94\t|\tloss: 1347.33\n",
      "Training Epoch 62  50.0% | batch:        47 of        94\t|\tloss: 795.396\n",
      "Training Epoch 62  51.1% | batch:        48 of        94\t|\tloss: 1002.71\n",
      "Training Epoch 62  52.1% | batch:        49 of        94\t|\tloss: 1158.87\n",
      "Training Epoch 62  53.2% | batch:        50 of        94\t|\tloss: 1628.24\n",
      "Training Epoch 62  54.3% | batch:        51 of        94\t|\tloss: 1218.92\n",
      "Training Epoch 62  55.3% | batch:        52 of        94\t|\tloss: 1458.91\n",
      "Training Epoch 62  56.4% | batch:        53 of        94\t|\tloss: 932.35\n",
      "Training Epoch 62  57.4% | batch:        54 of        94\t|\tloss: 2571.42\n",
      "Training Epoch 62  58.5% | batch:        55 of        94\t|\tloss: 1704.64\n",
      "Training Epoch 62  59.6% | batch:        56 of        94\t|\tloss: 1058.2\n",
      "Training Epoch 62  60.6% | batch:        57 of        94\t|\tloss: 947.2\n",
      "Training Epoch 62  61.7% | batch:        58 of        94\t|\tloss: 1211.42\n",
      "Training Epoch 62  62.8% | batch:        59 of        94\t|\tloss: 1145.98\n",
      "Training Epoch 62  63.8% | batch:        60 of        94\t|\tloss: 1025.64\n",
      "Training Epoch 62  64.9% | batch:        61 of        94\t|\tloss: 876.61\n",
      "Training Epoch 62  66.0% | batch:        62 of        94\t|\tloss: 1171.62\n",
      "Training Epoch 62  67.0% | batch:        63 of        94\t|\tloss: 924.966\n",
      "Training Epoch 62  68.1% | batch:        64 of        94\t|\tloss: 1281.16\n",
      "Training Epoch 62  69.1% | batch:        65 of        94\t|\tloss: 1735.11\n",
      "Training Epoch 62  70.2% | batch:        66 of        94\t|\tloss: 933.527\n",
      "Training Epoch 62  71.3% | batch:        67 of        94\t|\tloss: 1459.19\n",
      "Training Epoch 62  72.3% | batch:        68 of        94\t|\tloss: 973.375\n",
      "Training Epoch 62  73.4% | batch:        69 of        94\t|\tloss: 727.445\n",
      "Training Epoch 62  74.5% | batch:        70 of        94\t|\tloss: 854.875\n",
      "Training Epoch 62  75.5% | batch:        71 of        94\t|\tloss: 1203.6\n",
      "Training Epoch 62  76.6% | batch:        72 of        94\t|\tloss: 1040.32\n",
      "Training Epoch 62  77.7% | batch:        73 of        94\t|\tloss: 958.353\n",
      "Training Epoch 62  78.7% | batch:        74 of        94\t|\tloss: 2691.62\n",
      "Training Epoch 62  79.8% | batch:        75 of        94\t|\tloss: 746.964\n",
      "Training Epoch 62  80.9% | batch:        76 of        94\t|\tloss: 1175.44\n",
      "Training Epoch 62  81.9% | batch:        77 of        94\t|\tloss: 1002.71\n",
      "Training Epoch 62  83.0% | batch:        78 of        94\t|\tloss: 827.908\n",
      "Training Epoch 62  84.0% | batch:        79 of        94\t|\tloss: 868.883\n",
      "Training Epoch 62  85.1% | batch:        80 of        94\t|\tloss: 749.801\n",
      "Training Epoch 62  86.2% | batch:        81 of        94\t|\tloss: 1073.27\n",
      "Training Epoch 62  87.2% | batch:        82 of        94\t|\tloss: 747.283\n",
      "Training Epoch 62  88.3% | batch:        83 of        94\t|\tloss: 1752.65\n",
      "Training Epoch 62  89.4% | batch:        84 of        94\t|\tloss: 878.698\n",
      "Training Epoch 62  90.4% | batch:        85 of        94\t|\tloss: 936.064\n",
      "Training Epoch 62  91.5% | batch:        86 of        94\t|\tloss: 826.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:26,366 | INFO : Epoch 62 Training Summary: epoch: 62.000000 | loss: 1180.652632 | \n",
      "2023-05-09 14:22:26,367 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8383090496063232 seconds\n",
      "\n",
      "2023-05-09 14:22:26,368 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8282127957190237 seconds\n",
      "2023-05-09 14:22:26,368 | INFO : Avg batch train. time: 0.01944907229488323 seconds\n",
      "2023-05-09 14:22:26,369 | INFO : Avg sample train. time: 0.0001533992948245531 seconds\n",
      "2023-05-09 14:22:26,369 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 62  92.6% | batch:        87 of        94\t|\tloss: 1521.95\n",
      "Training Epoch 62  93.6% | batch:        88 of        94\t|\tloss: 1235.91\n",
      "Training Epoch 62  94.7% | batch:        89 of        94\t|\tloss: 819.662\n",
      "Training Epoch 62  95.7% | batch:        90 of        94\t|\tloss: 1056.03\n",
      "Training Epoch 62  96.8% | batch:        91 of        94\t|\tloss: 923.133\n",
      "Training Epoch 62  97.9% | batch:        92 of        94\t|\tloss: 1047.65\n",
      "Training Epoch 62  98.9% | batch:        93 of        94\t|\tloss: 4000.85\n",
      "\n",
      "Evaluating Epoch 62   0.0% | batch:         0 of        40\t|\tloss: 7369.95\n",
      "Evaluating Epoch 62   2.5% | batch:         1 of        40\t|\tloss: 1266.12\n",
      "Evaluating Epoch 62   5.0% | batch:         2 of        40\t|\tloss: 6526.41\n",
      "Evaluating Epoch 62   7.5% | batch:         3 of        40\t|\tloss: 7433\n",
      "Evaluating Epoch 62  10.0% | batch:         4 of        40\t|\tloss: 3124.86\n",
      "Evaluating Epoch 62  12.5% | batch:         5 of        40\t|\tloss: 4099.82\n",
      "Evaluating Epoch 62  15.0% | batch:         6 of        40\t|\tloss: 10466.3\n",
      "Evaluating Epoch 62  17.5% | batch:         7 of        40\t|\tloss: 3177.58\n",
      "Evaluating Epoch 62  20.0% | batch:         8 of        40\t|\tloss: 2638.43\n",
      "Evaluating Epoch 62  22.5% | batch:         9 of        40\t|\tloss: 3118.25\n",
      "Evaluating Epoch 62  25.0% | batch:        10 of        40\t|\tloss: 5251.57\n",
      "Evaluating Epoch 62  27.5% | batch:        11 of        40\t|\tloss: 1596.54\n",
      "Evaluating Epoch 62  30.0% | batch:        12 of        40\t|\tloss: 6335.36\n",
      "Evaluating Epoch 62  32.5% | batch:        13 of        40\t|\tloss: 3577.64\n",
      "Evaluating Epoch 62  35.0% | batch:        14 of        40\t|\tloss: 2485.15\n",
      "Evaluating Epoch 62  37.5% | batch:        15 of        40\t|\tloss: 3456.69\n",
      "Evaluating Epoch 62  40.0% | batch:        16 of        40\t|\tloss: 3916.97\n",
      "Evaluating Epoch 62  42.5% | batch:        17 of        40\t|\tloss: 2747.98\n",
      "Evaluating Epoch 62  45.0% | batch:        18 of        40\t|\tloss: 2314.62\n",
      "Evaluating Epoch 62  47.5% | batch:        19 of        40\t|\tloss: 6572.43\n",
      "Evaluating Epoch 62  50.0% | batch:        20 of        40\t|\tloss: 5353.68\n",
      "Evaluating Epoch 62  52.5% | batch:        21 of        40\t|\tloss: 1272.04\n",
      "Evaluating Epoch 62  55.0% | batch:        22 of        40\t|\tloss: 5275.08\n",
      "Evaluating Epoch 62  57.5% | batch:        23 of        40\t|\tloss: 3976.79\n",
      "Evaluating Epoch 62  60.0% | batch:        24 of        40\t|\tloss: 2091.99\n",
      "Evaluating Epoch 62  62.5% | batch:        25 of        40\t|\tloss: 4409.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:26,831 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4611508846282959 seconds\n",
      "\n",
      "2023-05-09 14:22:26,831 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4784293824976141 seconds\n",
      "2023-05-09 14:22:26,832 | INFO : Avg batch val. time: 0.011960734562440352 seconds\n",
      "2023-05-09 14:22:26,832 | INFO : Avg sample val. time: 9.477602664374288e-05 seconds\n",
      "2023-05-09 14:22:26,833 | INFO : Epoch 62 Validation Summary: epoch: 62.000000 | loss: 4621.388342 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 62  65.0% | batch:        26 of        40\t|\tloss: 9730.63\n",
      "Evaluating Epoch 62  67.5% | batch:        27 of        40\t|\tloss: 2968.09\n",
      "Evaluating Epoch 62  70.0% | batch:        28 of        40\t|\tloss: 2943.18\n",
      "Evaluating Epoch 62  72.5% | batch:        29 of        40\t|\tloss: 9675.33\n",
      "Evaluating Epoch 62  75.0% | batch:        30 of        40\t|\tloss: 2387.23\n",
      "Evaluating Epoch 62  77.5% | batch:        31 of        40\t|\tloss: 2594.62\n",
      "Evaluating Epoch 62  80.0% | batch:        32 of        40\t|\tloss: 10351\n",
      "Evaluating Epoch 62  82.5% | batch:        33 of        40\t|\tloss: 6354.65\n",
      "Evaluating Epoch 62  85.0% | batch:        34 of        40\t|\tloss: 912.573\n",
      "Evaluating Epoch 62  87.5% | batch:        35 of        40\t|\tloss: 7100.72\n",
      "Evaluating Epoch 62  90.0% | batch:        36 of        40\t|\tloss: 5564.89\n",
      "Evaluating Epoch 62  92.5% | batch:        37 of        40\t|\tloss: 3064.65\n",
      "Evaluating Epoch 62  95.0% | batch:        38 of        40\t|\tloss: 3900.32\n",
      "Evaluating Epoch 62  97.5% | batch:        39 of        40\t|\tloss: 11093.9\n",
      "\n",
      "Training Epoch 63   0.0% | batch:         0 of        94\t|\tloss: 1008.87\n",
      "Training Epoch 63   1.1% | batch:         1 of        94\t|\tloss: 2179.66\n",
      "Training Epoch 63   2.1% | batch:         2 of        94\t|\tloss: 1661.06\n",
      "Training Epoch 63   3.2% | batch:         3 of        94\t|\tloss: 716.265\n",
      "Training Epoch 63   4.3% | batch:         4 of        94\t|\tloss: 1316.15\n",
      "Training Epoch 63   5.3% | batch:         5 of        94\t|\tloss: 818.905\n",
      "Training Epoch 63   6.4% | batch:         6 of        94\t|\tloss: 735.496\n",
      "Training Epoch 63   7.4% | batch:         7 of        94\t|\tloss: 1485.45\n",
      "Training Epoch 63   8.5% | batch:         8 of        94\t|\tloss: 574.376\n",
      "Training Epoch 63   9.6% | batch:         9 of        94\t|\tloss: 1958.77\n",
      "Training Epoch 63  10.6% | batch:        10 of        94\t|\tloss: 955.893\n",
      "Training Epoch 63  11.7% | batch:        11 of        94\t|\tloss: 1508.08\n",
      "Training Epoch 63  12.8% | batch:        12 of        94\t|\tloss: 708.301\n",
      "Training Epoch 63  13.8% | batch:        13 of        94\t|\tloss: 1105.49\n",
      "Training Epoch 63  14.9% | batch:        14 of        94\t|\tloss: 1072.13\n",
      "Training Epoch 63  16.0% | batch:        15 of        94\t|\tloss: 1238.88\n",
      "Training Epoch 63  17.0% | batch:        16 of        94\t|\tloss: 902.452\n",
      "Training Epoch 63  18.1% | batch:        17 of        94\t|\tloss: 898.202\n",
      "Training Epoch 63  19.1% | batch:        18 of        94\t|\tloss: 717.064\n",
      "Training Epoch 63  20.2% | batch:        19 of        94\t|\tloss: 824.413\n",
      "Training Epoch 63  21.3% | batch:        20 of        94\t|\tloss: 932.814\n",
      "Training Epoch 63  22.3% | batch:        21 of        94\t|\tloss: 1231.54\n",
      "Training Epoch 63  23.4% | batch:        22 of        94\t|\tloss: 863.459\n",
      "Training Epoch 63  24.5% | batch:        23 of        94\t|\tloss: 1033.68\n",
      "Training Epoch 63  25.5% | batch:        24 of        94\t|\tloss: 740.115\n",
      "Training Epoch 63  26.6% | batch:        25 of        94\t|\tloss: 1625.19\n",
      "Training Epoch 63  27.7% | batch:        26 of        94\t|\tloss: 658.083\n",
      "Training Epoch 63  28.7% | batch:        27 of        94\t|\tloss: 852.376\n",
      "Training Epoch 63  29.8% | batch:        28 of        94\t|\tloss: 1234.36\n",
      "Training Epoch 63  30.9% | batch:        29 of        94\t|\tloss: 873.5\n",
      "Training Epoch 63  31.9% | batch:        30 of        94\t|\tloss: 1771.86\n",
      "Training Epoch 63  33.0% | batch:        31 of        94\t|\tloss: 1329.87\n",
      "Training Epoch 63  34.0% | batch:        32 of        94\t|\tloss: 879.697\n",
      "Training Epoch 63  35.1% | batch:        33 of        94\t|\tloss: 1193.04\n",
      "Training Epoch 63  36.2% | batch:        34 of        94\t|\tloss: 1230.91\n",
      "Training Epoch 63  37.2% | batch:        35 of        94\t|\tloss: 1095.4\n",
      "Training Epoch 63  38.3% | batch:        36 of        94\t|\tloss: 2762.42\n",
      "Training Epoch 63  39.4% | batch:        37 of        94\t|\tloss: 712.744\n",
      "Training Epoch 63  40.4% | batch:        38 of        94\t|\tloss: 740.435\n",
      "Training Epoch 63  41.5% | batch:        39 of        94\t|\tloss: 696.389\n",
      "Training Epoch 63  42.6% | batch:        40 of        94\t|\tloss: 985.737\n",
      "Training Epoch 63  43.6% | batch:        41 of        94\t|\tloss: 851.671\n",
      "Training Epoch 63  44.7% | batch:        42 of        94\t|\tloss: 1481.42\n",
      "Training Epoch 63  45.7% | batch:        43 of        94\t|\tloss: 867.79\n",
      "Training Epoch 63  46.8% | batch:        44 of        94\t|\tloss: 820.467\n",
      "Training Epoch 63  47.9% | batch:        45 of        94\t|\tloss: 713.883\n",
      "Training Epoch 63  48.9% | batch:        46 of        94\t|\tloss: 860.636\n",
      "Training Epoch 63  50.0% | batch:        47 of        94\t|\tloss: 1382.95\n",
      "Training Epoch 63  51.1% | batch:        48 of        94\t|\tloss: 1003.29\n",
      "Training Epoch 63  52.1% | batch:        49 of        94\t|\tloss: 1231.09\n",
      "Training Epoch 63  53.2% | batch:        50 of        94\t|\tloss: 1075.66\n",
      "Training Epoch 63  54.3% | batch:        51 of        94\t|\tloss: 1221.38\n",
      "Training Epoch 63  55.3% | batch:        52 of        94\t|\tloss: 957.556\n",
      "Training Epoch 63  56.4% | batch:        53 of        94\t|\tloss: 1070.57\n",
      "Training Epoch 63  57.4% | batch:        54 of        94\t|\tloss: 761.226\n",
      "Training Epoch 63  58.5% | batch:        55 of        94\t|\tloss: 845.152\n",
      "Training Epoch 63  59.6% | batch:        56 of        94\t|\tloss: 2914.37\n",
      "Training Epoch 63  60.6% | batch:        57 of        94\t|\tloss: 956.43\n",
      "Training Epoch 63  61.7% | batch:        58 of        94\t|\tloss: 842.072\n",
      "Training Epoch 63  62.8% | batch:        59 of        94\t|\tloss: 880.217\n",
      "Training Epoch 63  63.8% | batch:        60 of        94\t|\tloss: 1510.08\n",
      "Training Epoch 63  64.9% | batch:        61 of        94\t|\tloss: 1981.12\n",
      "Training Epoch 63  66.0% | batch:        62 of        94\t|\tloss: 651.115\n",
      "Training Epoch 63  67.0% | batch:        63 of        94\t|\tloss: 1142.16\n",
      "Training Epoch 63  68.1% | batch:        64 of        94\t|\tloss: 1082.38\n",
      "Training Epoch 63  69.1% | batch:        65 of        94\t|\tloss: 1175.81\n",
      "Training Epoch 63  70.2% | batch:        66 of        94\t|\tloss: 2707.44\n",
      "Training Epoch 63  71.3% | batch:        67 of        94\t|\tloss: 1408.6\n",
      "Training Epoch 63  72.3% | batch:        68 of        94\t|\tloss: 862.495\n",
      "Training Epoch 63  73.4% | batch:        69 of        94\t|\tloss: 1422.51\n",
      "Training Epoch 63  74.5% | batch:        70 of        94\t|\tloss: 1086.36\n",
      "Training Epoch 63  75.5% | batch:        71 of        94\t|\tloss: 1102.24\n",
      "Training Epoch 63  76.6% | batch:        72 of        94\t|\tloss: 1608.83\n",
      "Training Epoch 63  77.7% | batch:        73 of        94\t|\tloss: 726.828\n",
      "Training Epoch 63  78.7% | batch:        74 of        94\t|\tloss: 1553.27\n",
      "Training Epoch 63  79.8% | batch:        75 of        94\t|\tloss: 785.463\n",
      "Training Epoch 63  80.9% | batch:        76 of        94\t|\tloss: 2210.23\n",
      "Training Epoch 63  81.9% | batch:        77 of        94\t|\tloss: 1824.09\n",
      "Training Epoch 63  83.0% | batch:        78 of        94\t|\tloss: 844.434\n",
      "Training Epoch 63  84.0% | batch:        79 of        94\t|\tloss: 765.206\n",
      "Training Epoch 63  85.1% | batch:        80 of        94\t|\tloss: 935.724\n",
      "Training Epoch 63  86.2% | batch:        81 of        94\t|\tloss: 1650.34\n",
      "Training Epoch 63  87.2% | batch:        82 of        94\t|\tloss: 1549.15\n",
      "Training Epoch 63  88.3% | batch:        83 of        94\t|\tloss: 853.757\n",
      "Training Epoch 63  89.4% | batch:        84 of        94\t|\tloss: 967.754\n",
      "Training Epoch 63  90.4% | batch:        85 of        94\t|\tloss: 1150.78\n",
      "Training Epoch 63  91.5% | batch:        86 of        94\t|\tloss: 1581.04\n",
      "Training Epoch 63  92.6% | batch:        87 of        94\t|\tloss: 1593.82\n",
      "Training Epoch 63  93.6% | batch:        88 of        94\t|\tloss: 778.404\n",
      "Training Epoch 63  94.7% | batch:        89 of        94\t|\tloss: 791.295\n",
      "Training Epoch 63  95.7% | batch:        90 of        94\t|\tloss: 962.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:28,665 | INFO : Epoch 63 Training Summary: epoch: 63.000000 | loss: 1168.602811 | \n",
      "2023-05-09 14:22:28,666 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8101413249969482 seconds\n",
      "\n",
      "2023-05-09 14:22:28,666 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8279259469774034 seconds\n",
      "2023-05-09 14:22:28,667 | INFO : Avg batch train. time: 0.019446020712525568 seconds\n",
      "2023-05-09 14:22:28,667 | INFO : Avg sample train. time: 0.00015337522629446245 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 63  96.8% | batch:        91 of        94\t|\tloss: 1084.74\n",
      "Training Epoch 63  97.9% | batch:        92 of        94\t|\tloss: 1746.05\n",
      "Training Epoch 63  98.9% | batch:        93 of        94\t|\tloss: 1317\n",
      "\n",
      "Training Epoch 64   0.0% | batch:         0 of        94\t|\tloss: 816.848\n",
      "Training Epoch 64   1.1% | batch:         1 of        94\t|\tloss: 1451.19\n",
      "Training Epoch 64   2.1% | batch:         2 of        94\t|\tloss: 1079.37\n",
      "Training Epoch 64   3.2% | batch:         3 of        94\t|\tloss: 1165.68\n",
      "Training Epoch 64   4.3% | batch:         4 of        94\t|\tloss: 959.995\n",
      "Training Epoch 64   5.3% | batch:         5 of        94\t|\tloss: 976.587\n",
      "Training Epoch 64   6.4% | batch:         6 of        94\t|\tloss: 1029.31\n",
      "Training Epoch 64   7.4% | batch:         7 of        94\t|\tloss: 1265.5\n",
      "Training Epoch 64   8.5% | batch:         8 of        94\t|\tloss: 937.325\n",
      "Training Epoch 64   9.6% | batch:         9 of        94\t|\tloss: 849.673\n",
      "Training Epoch 64  10.6% | batch:        10 of        94\t|\tloss: 800.189\n",
      "Training Epoch 64  11.7% | batch:        11 of        94\t|\tloss: 1105.61\n",
      "Training Epoch 64  12.8% | batch:        12 of        94\t|\tloss: 2201.65\n",
      "Training Epoch 64  13.8% | batch:        13 of        94\t|\tloss: 836.861\n",
      "Training Epoch 64  14.9% | batch:        14 of        94\t|\tloss: 673.543\n",
      "Training Epoch 64  16.0% | batch:        15 of        94\t|\tloss: 720.025\n",
      "Training Epoch 64  17.0% | batch:        16 of        94\t|\tloss: 1013.69\n",
      "Training Epoch 64  18.1% | batch:        17 of        94\t|\tloss: 956.043\n",
      "Training Epoch 64  19.1% | batch:        18 of        94\t|\tloss: 865.758\n",
      "Training Epoch 64  20.2% | batch:        19 of        94\t|\tloss: 1626.96\n",
      "Training Epoch 64  21.3% | batch:        20 of        94\t|\tloss: 1059.47\n",
      "Training Epoch 64  22.3% | batch:        21 of        94\t|\tloss: 735.257\n",
      "Training Epoch 64  23.4% | batch:        22 of        94\t|\tloss: 1236.67\n",
      "Training Epoch 64  24.5% | batch:        23 of        94\t|\tloss: 909.731\n",
      "Training Epoch 64  25.5% | batch:        24 of        94\t|\tloss: 1389.8\n",
      "Training Epoch 64  26.6% | batch:        25 of        94\t|\tloss: 903.45\n",
      "Training Epoch 64  27.7% | batch:        26 of        94\t|\tloss: 1229.13\n",
      "Training Epoch 64  28.7% | batch:        27 of        94\t|\tloss: 507.518\n",
      "Training Epoch 64  29.8% | batch:        28 of        94\t|\tloss: 742.725\n",
      "Training Epoch 64  30.9% | batch:        29 of        94\t|\tloss: 1098.24\n",
      "Training Epoch 64  31.9% | batch:        30 of        94\t|\tloss: 800.387\n",
      "Training Epoch 64  33.0% | batch:        31 of        94\t|\tloss: 752.782\n",
      "Training Epoch 64  34.0% | batch:        32 of        94\t|\tloss: 2661.86\n",
      "Training Epoch 64  35.1% | batch:        33 of        94\t|\tloss: 1170.43\n",
      "Training Epoch 64  36.2% | batch:        34 of        94\t|\tloss: 1986.87\n",
      "Training Epoch 64  37.2% | batch:        35 of        94\t|\tloss: 1698.45\n",
      "Training Epoch 64  38.3% | batch:        36 of        94\t|\tloss: 1467.05\n",
      "Training Epoch 64  39.4% | batch:        37 of        94\t|\tloss: 733\n",
      "Training Epoch 64  40.4% | batch:        38 of        94\t|\tloss: 986.056\n",
      "Training Epoch 64  41.5% | batch:        39 of        94\t|\tloss: 1014.95\n",
      "Training Epoch 64  42.6% | batch:        40 of        94\t|\tloss: 1041.72\n",
      "Training Epoch 64  43.6% | batch:        41 of        94\t|\tloss: 2509.57\n",
      "Training Epoch 64  44.7% | batch:        42 of        94\t|\tloss: 1022.69\n",
      "Training Epoch 64  45.7% | batch:        43 of        94\t|\tloss: 1066.5\n",
      "Training Epoch 64  46.8% | batch:        44 of        94\t|\tloss: 730.498\n",
      "Training Epoch 64  47.9% | batch:        45 of        94\t|\tloss: 1166.48\n",
      "Training Epoch 64  48.9% | batch:        46 of        94\t|\tloss: 1335.77\n",
      "Training Epoch 64  50.0% | batch:        47 of        94\t|\tloss: 1122.59\n",
      "Training Epoch 64  51.1% | batch:        48 of        94\t|\tloss: 871.876\n",
      "Training Epoch 64  52.1% | batch:        49 of        94\t|\tloss: 1060.31\n",
      "Training Epoch 64  53.2% | batch:        50 of        94\t|\tloss: 687.058\n",
      "Training Epoch 64  54.3% | batch:        51 of        94\t|\tloss: 1073.6\n",
      "Training Epoch 64  55.3% | batch:        52 of        94\t|\tloss: 832.428\n",
      "Training Epoch 64  56.4% | batch:        53 of        94\t|\tloss: 2029.44\n",
      "Training Epoch 64  57.4% | batch:        54 of        94\t|\tloss: 1273.76\n",
      "Training Epoch 64  58.5% | batch:        55 of        94\t|\tloss: 1025.22\n",
      "Training Epoch 64  59.6% | batch:        56 of        94\t|\tloss: 2614.61\n",
      "Training Epoch 64  60.6% | batch:        57 of        94\t|\tloss: 956.994\n",
      "Training Epoch 64  61.7% | batch:        58 of        94\t|\tloss: 997.404\n",
      "Training Epoch 64  62.8% | batch:        59 of        94\t|\tloss: 872.173\n",
      "Training Epoch 64  63.8% | batch:        60 of        94\t|\tloss: 1152.6\n",
      "Training Epoch 64  64.9% | batch:        61 of        94\t|\tloss: 909.371\n",
      "Training Epoch 64  66.0% | batch:        62 of        94\t|\tloss: 833.588\n",
      "Training Epoch 64  67.0% | batch:        63 of        94\t|\tloss: 1137.26\n",
      "Training Epoch 64  68.1% | batch:        64 of        94\t|\tloss: 1245.36\n",
      "Training Epoch 64  69.1% | batch:        65 of        94\t|\tloss: 963.332\n",
      "Training Epoch 64  70.2% | batch:        66 of        94\t|\tloss: 889.14\n",
      "Training Epoch 64  71.3% | batch:        67 of        94\t|\tloss: 2423.11\n",
      "Training Epoch 64  72.3% | batch:        68 of        94\t|\tloss: 825.285\n",
      "Training Epoch 64  73.4% | batch:        69 of        94\t|\tloss: 907.853\n",
      "Training Epoch 64  74.5% | batch:        70 of        94\t|\tloss: 930.779\n",
      "Training Epoch 64  75.5% | batch:        71 of        94\t|\tloss: 870.353\n",
      "Training Epoch 64  76.6% | batch:        72 of        94\t|\tloss: 1442.75\n",
      "Training Epoch 64  77.7% | batch:        73 of        94\t|\tloss: 1039.04\n",
      "Training Epoch 64  78.7% | batch:        74 of        94\t|\tloss: 2546.02\n",
      "Training Epoch 64  79.8% | batch:        75 of        94\t|\tloss: 1002.64\n",
      "Training Epoch 64  80.9% | batch:        76 of        94\t|\tloss: 1244.65\n",
      "Training Epoch 64  81.9% | batch:        77 of        94\t|\tloss: 875.369\n",
      "Training Epoch 64  83.0% | batch:        78 of        94\t|\tloss: 898.011\n",
      "Training Epoch 64  84.0% | batch:        79 of        94\t|\tloss: 1141.67\n",
      "Training Epoch 64  85.1% | batch:        80 of        94\t|\tloss: 1809.01\n",
      "Training Epoch 64  86.2% | batch:        81 of        94\t|\tloss: 986.668\n",
      "Training Epoch 64  87.2% | batch:        82 of        94\t|\tloss: 1790.94\n",
      "Training Epoch 64  88.3% | batch:        83 of        94\t|\tloss: 1067.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:30,517 | INFO : Epoch 64 Training Summary: epoch: 64.000000 | loss: 1163.237037 | \n",
      "2023-05-09 14:22:30,518 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.829458236694336 seconds\n",
      "\n",
      "2023-05-09 14:22:30,518 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8279498890042305 seconds\n",
      "2023-05-09 14:22:30,519 | INFO : Avg batch train. time: 0.01944627541493862 seconds\n",
      "2023-05-09 14:22:30,519 | INFO : Avg sample train. time: 0.00015337723519082318 seconds\n",
      "2023-05-09 14:22:30,519 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 64  89.4% | batch:        84 of        94\t|\tloss: 1028.02\n",
      "Training Epoch 64  90.4% | batch:        85 of        94\t|\tloss: 1746.46\n",
      "Training Epoch 64  91.5% | batch:        86 of        94\t|\tloss: 1191.28\n",
      "Training Epoch 64  92.6% | batch:        87 of        94\t|\tloss: 982.332\n",
      "Training Epoch 64  93.6% | batch:        88 of        94\t|\tloss: 1322.52\n",
      "Training Epoch 64  94.7% | batch:        89 of        94\t|\tloss: 926.268\n",
      "Training Epoch 64  95.7% | batch:        90 of        94\t|\tloss: 1075.78\n",
      "Training Epoch 64  96.8% | batch:        91 of        94\t|\tloss: 1232.2\n",
      "Training Epoch 64  97.9% | batch:        92 of        94\t|\tloss: 1055.28\n",
      "Training Epoch 64  98.9% | batch:        93 of        94\t|\tloss: 1003.29\n",
      "\n",
      "Evaluating Epoch 64   0.0% | batch:         0 of        40\t|\tloss: 7578.72\n",
      "Evaluating Epoch 64   2.5% | batch:         1 of        40\t|\tloss: 1088.19\n",
      "Evaluating Epoch 64   5.0% | batch:         2 of        40\t|\tloss: 3235.15\n",
      "Evaluating Epoch 64   7.5% | batch:         3 of        40\t|\tloss: 6893.89\n",
      "Evaluating Epoch 64  10.0% | batch:         4 of        40\t|\tloss: 2675.61\n",
      "Evaluating Epoch 64  12.5% | batch:         5 of        40\t|\tloss: 2235.35\n",
      "Evaluating Epoch 64  15.0% | batch:         6 of        40\t|\tloss: 8435.72\n",
      "Evaluating Epoch 64  17.5% | batch:         7 of        40\t|\tloss: 3119.85\n",
      "Evaluating Epoch 64  20.0% | batch:         8 of        40\t|\tloss: 2555.7\n",
      "Evaluating Epoch 64  22.5% | batch:         9 of        40\t|\tloss: 2012.46\n",
      "Evaluating Epoch 64  25.0% | batch:        10 of        40\t|\tloss: 5831.1\n",
      "Evaluating Epoch 64  27.5% | batch:        11 of        40\t|\tloss: 1478.69\n",
      "Evaluating Epoch 64  30.0% | batch:        12 of        40\t|\tloss: 6004.85\n",
      "Evaluating Epoch 64  32.5% | batch:        13 of        40\t|\tloss: 4122.35\n",
      "Evaluating Epoch 64  35.0% | batch:        14 of        40\t|\tloss: 2181.24\n",
      "Evaluating Epoch 64  37.5% | batch:        15 of        40\t|\tloss: 3069.08\n",
      "Evaluating Epoch 64  40.0% | batch:        16 of        40\t|\tloss: 4558.49\n",
      "Evaluating Epoch 64  42.5% | batch:        17 of        40\t|\tloss: 2777.12\n",
      "Evaluating Epoch 64  45.0% | batch:        18 of        40\t|\tloss: 2244.19\n",
      "Evaluating Epoch 64  47.5% | batch:        19 of        40\t|\tloss: 4938.87\n",
      "Evaluating Epoch 64  50.0% | batch:        20 of        40\t|\tloss: 5396.11\n",
      "Evaluating Epoch 64  52.5% | batch:        21 of        40\t|\tloss: 1145.78\n",
      "Evaluating Epoch 64  55.0% | batch:        22 of        40\t|\tloss: 3171.1\n",
      "Evaluating Epoch 64  57.5% | batch:        23 of        40\t|\tloss: 3870.55\n",
      "Evaluating Epoch 64  60.0% | batch:        24 of        40\t|\tloss: 1691.26\n",
      "Evaluating Epoch 64  62.5% | batch:        25 of        40\t|\tloss: 3041.9\n",
      "Evaluating Epoch 64  65.0% | batch:        26 of        40\t|\tloss: 10947.8\n",
      "Evaluating Epoch 64  67.5% | batch:        27 of        40\t|\tloss: 2839.73\n",
      "Evaluating Epoch 64  70.0% | batch:        28 of        40\t|\tloss: 2024.6\n",
      "Evaluating Epoch 64  72.5% | batch:        29 of        40\t|\tloss: 9845.12\n",
      "Evaluating Epoch 64  75.0% | batch:        30 of        40\t|\tloss: 2176.32\n",
      "Evaluating Epoch 64  77.5% | batch:        31 of        40\t|\tloss: 1889.58\n",
      "Evaluating Epoch 64  80.0% | batch:        32 of        40\t|\tloss: 7245.63\n",
      "Evaluating Epoch 64  82.5% | batch:        33 of        40\t|\tloss: 6719.94\n",
      "Evaluating Epoch 64  85.0% | batch:        34 of        40\t|\tloss: 1090.19\n",
      "Evaluating Epoch 64  87.5% | batch:        35 of        40\t|\tloss: 4676.97\n",
      "Evaluating Epoch 64  90.0% | batch:        36 of        40\t|\tloss: 7463.86\n",
      "Evaluating Epoch 64  92.5% | batch:        37 of        40\t|\tloss: 2701.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:30,978 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4577963352203369 seconds\n",
      "\n",
      "2023-05-09 14:22:30,978 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47782252816592946 seconds\n",
      "2023-05-09 14:22:30,979 | INFO : Avg batch val. time: 0.011945563204148236 seconds\n",
      "2023-05-09 14:22:30,980 | INFO : Avg sample val. time: 9.465580985854387e-05 seconds\n",
      "2023-05-09 14:22:30,980 | INFO : Epoch 64 Validation Summary: epoch: 64.000000 | loss: 4135.749266 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 64  95.0% | batch:        38 of        40\t|\tloss: 3068.33\n",
      "Evaluating Epoch 64  97.5% | batch:        39 of        40\t|\tloss: 11568.5\n",
      "\n",
      "Training Epoch 65   0.0% | batch:         0 of        94\t|\tloss: 1063.68\n",
      "Training Epoch 65   1.1% | batch:         1 of        94\t|\tloss: 966.522\n",
      "Training Epoch 65   2.1% | batch:         2 of        94\t|\tloss: 1233.39\n",
      "Training Epoch 65   3.2% | batch:         3 of        94\t|\tloss: 2023.82\n",
      "Training Epoch 65   4.3% | batch:         4 of        94\t|\tloss: 1129.78\n",
      "Training Epoch 65   5.3% | batch:         5 of        94\t|\tloss: 2940.18\n",
      "Training Epoch 65   6.4% | batch:         6 of        94\t|\tloss: 1466.34\n",
      "Training Epoch 65   7.4% | batch:         7 of        94\t|\tloss: 1123.27\n",
      "Training Epoch 65   8.5% | batch:         8 of        94\t|\tloss: 944.249\n",
      "Training Epoch 65   9.6% | batch:         9 of        94\t|\tloss: 1090.01\n",
      "Training Epoch 65  10.6% | batch:        10 of        94\t|\tloss: 1054.87\n",
      "Training Epoch 65  11.7% | batch:        11 of        94\t|\tloss: 1190.64\n",
      "Training Epoch 65  12.8% | batch:        12 of        94\t|\tloss: 1134.17\n",
      "Training Epoch 65  13.8% | batch:        13 of        94\t|\tloss: 617.657\n",
      "Training Epoch 65  14.9% | batch:        14 of        94\t|\tloss: 823.404\n",
      "Training Epoch 65  16.0% | batch:        15 of        94\t|\tloss: 1019.46\n",
      "Training Epoch 65  17.0% | batch:        16 of        94\t|\tloss: 2283.68\n",
      "Training Epoch 65  18.1% | batch:        17 of        94\t|\tloss: 1506.09\n",
      "Training Epoch 65  19.1% | batch:        18 of        94\t|\tloss: 1291.32\n",
      "Training Epoch 65  20.2% | batch:        19 of        94\t|\tloss: 882.597\n",
      "Training Epoch 65  21.3% | batch:        20 of        94\t|\tloss: 1018.55\n",
      "Training Epoch 65  22.3% | batch:        21 of        94\t|\tloss: 1116.75\n",
      "Training Epoch 65  23.4% | batch:        22 of        94\t|\tloss: 910.734\n",
      "Training Epoch 65  24.5% | batch:        23 of        94\t|\tloss: 835.103\n",
      "Training Epoch 65  25.5% | batch:        24 of        94\t|\tloss: 894.445\n",
      "Training Epoch 65  26.6% | batch:        25 of        94\t|\tloss: 992.943\n",
      "Training Epoch 65  27.7% | batch:        26 of        94\t|\tloss: 845.263\n",
      "Training Epoch 65  28.7% | batch:        27 of        94\t|\tloss: 1161.98\n",
      "Training Epoch 65  29.8% | batch:        28 of        94\t|\tloss: 776.993\n",
      "Training Epoch 65  30.9% | batch:        29 of        94\t|\tloss: 1513.06\n",
      "Training Epoch 65  31.9% | batch:        30 of        94\t|\tloss: 1098.49\n",
      "Training Epoch 65  33.0% | batch:        31 of        94\t|\tloss: 1050.03\n",
      "Training Epoch 65  34.0% | batch:        32 of        94\t|\tloss: 1141.86\n",
      "Training Epoch 65  35.1% | batch:        33 of        94\t|\tloss: 793.742\n",
      "Training Epoch 65  36.2% | batch:        34 of        94\t|\tloss: 806.738\n",
      "Training Epoch 65  37.2% | batch:        35 of        94\t|\tloss: 1483.41\n",
      "Training Epoch 65  38.3% | batch:        36 of        94\t|\tloss: 834.541\n",
      "Training Epoch 65  39.4% | batch:        37 of        94\t|\tloss: 1196.25\n",
      "Training Epoch 65  40.4% | batch:        38 of        94\t|\tloss: 794.994\n",
      "Training Epoch 65  41.5% | batch:        39 of        94\t|\tloss: 915.542\n",
      "Training Epoch 65  42.6% | batch:        40 of        94\t|\tloss: 1047.18\n",
      "Training Epoch 65  43.6% | batch:        41 of        94\t|\tloss: 1164.5\n",
      "Training Epoch 65  44.7% | batch:        42 of        94\t|\tloss: 883.097\n",
      "Training Epoch 65  45.7% | batch:        43 of        94\t|\tloss: 1107.24\n",
      "Training Epoch 65  46.8% | batch:        44 of        94\t|\tloss: 871.657\n",
      "Training Epoch 65  47.9% | batch:        45 of        94\t|\tloss: 1006.72\n",
      "Training Epoch 65  48.9% | batch:        46 of        94\t|\tloss: 1065.67\n",
      "Training Epoch 65  50.0% | batch:        47 of        94\t|\tloss: 1292.53\n",
      "Training Epoch 65  51.1% | batch:        48 of        94\t|\tloss: 842.49\n",
      "Training Epoch 65  52.1% | batch:        49 of        94\t|\tloss: 1555.99\n",
      "Training Epoch 65  53.2% | batch:        50 of        94\t|\tloss: 1423.62\n",
      "Training Epoch 65  54.3% | batch:        51 of        94\t|\tloss: 1382.94\n",
      "Training Epoch 65  55.3% | batch:        52 of        94\t|\tloss: 1678.06\n",
      "Training Epoch 65  56.4% | batch:        53 of        94\t|\tloss: 1326.36\n",
      "Training Epoch 65  57.4% | batch:        54 of        94\t|\tloss: 1217.83\n",
      "Training Epoch 65  58.5% | batch:        55 of        94\t|\tloss: 1396.35\n",
      "Training Epoch 65  59.6% | batch:        56 of        94\t|\tloss: 1525.54\n",
      "Training Epoch 65  60.6% | batch:        57 of        94\t|\tloss: 1338.58\n",
      "Training Epoch 65  61.7% | batch:        58 of        94\t|\tloss: 1090.66\n",
      "Training Epoch 65  62.8% | batch:        59 of        94\t|\tloss: 748.306\n",
      "Training Epoch 65  63.8% | batch:        60 of        94\t|\tloss: 1043.34\n",
      "Training Epoch 65  64.9% | batch:        61 of        94\t|\tloss: 1040.41\n",
      "Training Epoch 65  66.0% | batch:        62 of        94\t|\tloss: 685.086\n",
      "Training Epoch 65  67.0% | batch:        63 of        94\t|\tloss: 635.893\n",
      "Training Epoch 65  68.1% | batch:        64 of        94\t|\tloss: 2190.37\n",
      "Training Epoch 65  69.1% | batch:        65 of        94\t|\tloss: 951.845\n",
      "Training Epoch 65  70.2% | batch:        66 of        94\t|\tloss: 905.644\n",
      "Training Epoch 65  71.3% | batch:        67 of        94\t|\tloss: 1021.21\n",
      "Training Epoch 65  72.3% | batch:        68 of        94\t|\tloss: 1086.57\n",
      "Training Epoch 65  73.4% | batch:        69 of        94\t|\tloss: 1118.23\n",
      "Training Epoch 65  74.5% | batch:        70 of        94\t|\tloss: 1151.61\n",
      "Training Epoch 65  75.5% | batch:        71 of        94\t|\tloss: 1196.04\n",
      "Training Epoch 65  76.6% | batch:        72 of        94\t|\tloss: 1171.94\n",
      "Training Epoch 65  77.7% | batch:        73 of        94\t|\tloss: 1161.9\n",
      "Training Epoch 65  78.7% | batch:        74 of        94\t|\tloss: 1057.2\n",
      "Training Epoch 65  79.8% | batch:        75 of        94\t|\tloss: 746.609\n",
      "Training Epoch 65  80.9% | batch:        76 of        94\t|\tloss: 1113.51\n",
      "Training Epoch 65  81.9% | batch:        77 of        94\t|\tloss: 1421.31\n",
      "Training Epoch 65  83.0% | batch:        78 of        94\t|\tloss: 675.79\n",
      "Training Epoch 65  84.0% | batch:        79 of        94\t|\tloss: 777.941\n",
      "Training Epoch 65  85.1% | batch:        80 of        94\t|\tloss: 1253.51\n",
      "Training Epoch 65  86.2% | batch:        81 of        94\t|\tloss: 781.548\n",
      "Training Epoch 65  87.2% | batch:        82 of        94\t|\tloss: 1095.1\n",
      "Training Epoch 65  88.3% | batch:        83 of        94\t|\tloss: 968.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:32,841 | INFO : Epoch 65 Training Summary: epoch: 65.000000 | loss: 1150.605447 | \n",
      "2023-05-09 14:22:32,842 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.838698148727417 seconds\n",
      "\n",
      "2023-05-09 14:22:32,842 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8281152468461257 seconds\n",
      "2023-05-09 14:22:32,843 | INFO : Avg batch train. time: 0.01944803454091623 seconds\n",
      "2023-05-09 14:22:32,843 | INFO : Avg sample train. time: 0.00015339110982095366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 65  89.4% | batch:        84 of        94\t|\tloss: 999.275\n",
      "Training Epoch 65  90.4% | batch:        85 of        94\t|\tloss: 3645.7\n",
      "Training Epoch 65  91.5% | batch:        86 of        94\t|\tloss: 839.322\n",
      "Training Epoch 65  92.6% | batch:        87 of        94\t|\tloss: 1145.18\n",
      "Training Epoch 65  93.6% | batch:        88 of        94\t|\tloss: 1179.18\n",
      "Training Epoch 65  94.7% | batch:        89 of        94\t|\tloss: 833.355\n",
      "Training Epoch 65  95.7% | batch:        90 of        94\t|\tloss: 898.204\n",
      "Training Epoch 65  96.8% | batch:        91 of        94\t|\tloss: 1209.81\n",
      "Training Epoch 65  97.9% | batch:        92 of        94\t|\tloss: 763.403\n",
      "Training Epoch 65  98.9% | batch:        93 of        94\t|\tloss: 3983.52\n",
      "\n",
      "Training Epoch 66   0.0% | batch:         0 of        94\t|\tloss: 828.067\n",
      "Training Epoch 66   1.1% | batch:         1 of        94\t|\tloss: 1154.47\n",
      "Training Epoch 66   2.1% | batch:         2 of        94\t|\tloss: 883.187\n",
      "Training Epoch 66   3.2% | batch:         3 of        94\t|\tloss: 1915.98\n",
      "Training Epoch 66   4.3% | batch:         4 of        94\t|\tloss: 932.186\n",
      "Training Epoch 66   5.3% | batch:         5 of        94\t|\tloss: 952.459\n",
      "Training Epoch 66   6.4% | batch:         6 of        94\t|\tloss: 884.491\n",
      "Training Epoch 66   7.4% | batch:         7 of        94\t|\tloss: 1291.19\n",
      "Training Epoch 66   8.5% | batch:         8 of        94\t|\tloss: 1082.82\n",
      "Training Epoch 66   9.6% | batch:         9 of        94\t|\tloss: 1454.59\n",
      "Training Epoch 66  10.6% | batch:        10 of        94\t|\tloss: 1195.68\n",
      "Training Epoch 66  11.7% | batch:        11 of        94\t|\tloss: 1001.38\n",
      "Training Epoch 66  12.8% | batch:        12 of        94\t|\tloss: 2228.79\n",
      "Training Epoch 66  13.8% | batch:        13 of        94\t|\tloss: 1304.4\n",
      "Training Epoch 66  14.9% | batch:        14 of        94\t|\tloss: 1123.34\n",
      "Training Epoch 66  16.0% | batch:        15 of        94\t|\tloss: 1011.36\n",
      "Training Epoch 66  17.0% | batch:        16 of        94\t|\tloss: 648.34\n",
      "Training Epoch 66  18.1% | batch:        17 of        94\t|\tloss: 809.306\n",
      "Training Epoch 66  19.1% | batch:        18 of        94\t|\tloss: 1371.76\n",
      "Training Epoch 66  20.2% | batch:        19 of        94\t|\tloss: 930.85\n",
      "Training Epoch 66  21.3% | batch:        20 of        94\t|\tloss: 1426.26\n",
      "Training Epoch 66  22.3% | batch:        21 of        94\t|\tloss: 1223.11\n",
      "Training Epoch 66  23.4% | batch:        22 of        94\t|\tloss: 872.004\n",
      "Training Epoch 66  24.5% | batch:        23 of        94\t|\tloss: 1188.01\n",
      "Training Epoch 66  25.5% | batch:        24 of        94\t|\tloss: 926.875\n",
      "Training Epoch 66  26.6% | batch:        25 of        94\t|\tloss: 740.663\n",
      "Training Epoch 66  27.7% | batch:        26 of        94\t|\tloss: 747.019\n",
      "Training Epoch 66  28.7% | batch:        27 of        94\t|\tloss: 771.976\n",
      "Training Epoch 66  29.8% | batch:        28 of        94\t|\tloss: 768.201\n",
      "Training Epoch 66  30.9% | batch:        29 of        94\t|\tloss: 1096.64\n",
      "Training Epoch 66  31.9% | batch:        30 of        94\t|\tloss: 894.744\n",
      "Training Epoch 66  33.0% | batch:        31 of        94\t|\tloss: 1123.11\n",
      "Training Epoch 66  34.0% | batch:        32 of        94\t|\tloss: 816.479\n",
      "Training Epoch 66  35.1% | batch:        33 of        94\t|\tloss: 883.874\n",
      "Training Epoch 66  36.2% | batch:        34 of        94\t|\tloss: 969.298\n",
      "Training Epoch 66  37.2% | batch:        35 of        94\t|\tloss: 869.92\n",
      "Training Epoch 66  38.3% | batch:        36 of        94\t|\tloss: 932.551\n",
      "Training Epoch 66  39.4% | batch:        37 of        94\t|\tloss: 1843.4\n",
      "Training Epoch 66  40.4% | batch:        38 of        94\t|\tloss: 798.203\n",
      "Training Epoch 66  41.5% | batch:        39 of        94\t|\tloss: 786.852\n",
      "Training Epoch 66  42.6% | batch:        40 of        94\t|\tloss: 764.569\n",
      "Training Epoch 66  43.6% | batch:        41 of        94\t|\tloss: 1136.39\n",
      "Training Epoch 66  44.7% | batch:        42 of        94\t|\tloss: 1216.57\n",
      "Training Epoch 66  45.7% | batch:        43 of        94\t|\tloss: 827.855\n",
      "Training Epoch 66  46.8% | batch:        44 of        94\t|\tloss: 1010.68\n",
      "Training Epoch 66  47.9% | batch:        45 of        94\t|\tloss: 728.533\n",
      "Training Epoch 66  48.9% | batch:        46 of        94\t|\tloss: 901.263\n",
      "Training Epoch 66  50.0% | batch:        47 of        94\t|\tloss: 1141.05\n",
      "Training Epoch 66  51.1% | batch:        48 of        94\t|\tloss: 1539.7\n",
      "Training Epoch 66  52.1% | batch:        49 of        94\t|\tloss: 2128.46\n",
      "Training Epoch 66  53.2% | batch:        50 of        94\t|\tloss: 952.706\n",
      "Training Epoch 66  54.3% | batch:        51 of        94\t|\tloss: 991.989\n",
      "Training Epoch 66  55.3% | batch:        52 of        94\t|\tloss: 1142.93\n",
      "Training Epoch 66  56.4% | batch:        53 of        94\t|\tloss: 914.366\n",
      "Training Epoch 66  57.4% | batch:        54 of        94\t|\tloss: 1010.17\n",
      "Training Epoch 66  58.5% | batch:        55 of        94\t|\tloss: 836.524\n",
      "Training Epoch 66  59.6% | batch:        56 of        94\t|\tloss: 1149.96\n",
      "Training Epoch 66  60.6% | batch:        57 of        94\t|\tloss: 3026.92\n",
      "Training Epoch 66  61.7% | batch:        58 of        94\t|\tloss: 1231.62\n",
      "Training Epoch 66  62.8% | batch:        59 of        94\t|\tloss: 1166.96\n",
      "Training Epoch 66  63.8% | batch:        60 of        94\t|\tloss: 1521.44\n",
      "Training Epoch 66  64.9% | batch:        61 of        94\t|\tloss: 910.008\n",
      "Training Epoch 66  66.0% | batch:        62 of        94\t|\tloss: 785.032\n",
      "Training Epoch 66  67.0% | batch:        63 of        94\t|\tloss: 761.685\n",
      "Training Epoch 66  68.1% | batch:        64 of        94\t|\tloss: 890.206\n",
      "Training Epoch 66  69.1% | batch:        65 of        94\t|\tloss: 959.234\n",
      "Training Epoch 66  70.2% | batch:        66 of        94\t|\tloss: 2067.54\n",
      "Training Epoch 66  71.3% | batch:        67 of        94\t|\tloss: 1006.19\n",
      "Training Epoch 66  72.3% | batch:        68 of        94\t|\tloss: 812.919\n",
      "Training Epoch 66  73.4% | batch:        69 of        94\t|\tloss: 1093.05\n",
      "Training Epoch 66  74.5% | batch:        70 of        94\t|\tloss: 1529.29\n",
      "Training Epoch 66  75.5% | batch:        71 of        94\t|\tloss: 1036.65\n",
      "Training Epoch 66  76.6% | batch:        72 of        94\t|\tloss: 3141.44\n",
      "Training Epoch 66  77.7% | batch:        73 of        94\t|\tloss: 2880.18\n",
      "Training Epoch 66  78.7% | batch:        74 of        94\t|\tloss: 948.77\n",
      "Training Epoch 66  79.8% | batch:        75 of        94\t|\tloss: 1317.17\n",
      "Training Epoch 66  80.9% | batch:        76 of        94\t|\tloss: 1609.14\n",
      "Training Epoch 66  81.9% | batch:        77 of        94\t|\tloss: 1041.57\n",
      "Training Epoch 66  83.0% | batch:        78 of        94\t|\tloss: 1213.71\n",
      "Training Epoch 66  84.0% | batch:        79 of        94\t|\tloss: 1059.94\n",
      "Training Epoch 66  85.1% | batch:        80 of        94\t|\tloss: 922.503\n",
      "Training Epoch 66  86.2% | batch:        81 of        94\t|\tloss: 1255.34\n",
      "Training Epoch 66  87.2% | batch:        82 of        94\t|\tloss: 1012.73\n",
      "Training Epoch 66  88.3% | batch:        83 of        94\t|\tloss: 1086.02\n",
      "Training Epoch 66  89.4% | batch:        84 of        94\t|\tloss: 992.182\n",
      "Training Epoch 66  90.4% | batch:        85 of        94\t|\tloss: 880.985\n",
      "Training Epoch 66  91.5% | batch:        86 of        94\t|\tloss: 1620.48\n",
      "Training Epoch 66  92.6% | batch:        87 of        94\t|\tloss: 1003.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:34,699 | INFO : Epoch 66 Training Summary: epoch: 66.000000 | loss: 1161.514329 | \n",
      "2023-05-09 14:22:34,700 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8348891735076904 seconds\n",
      "\n",
      "2023-05-09 14:22:34,700 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8282178820985737 seconds\n",
      "2023-05-09 14:22:34,701 | INFO : Avg batch train. time: 0.019449126405303975 seconds\n",
      "2023-05-09 14:22:34,701 | INFO : Avg sample train. time: 0.00015339972160585447 seconds\n",
      "2023-05-09 14:22:34,702 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 66  93.6% | batch:        88 of        94\t|\tloss: 1228.35\n",
      "Training Epoch 66  94.7% | batch:        89 of        94\t|\tloss: 789.483\n",
      "Training Epoch 66  95.7% | batch:        90 of        94\t|\tloss: 1629.42\n",
      "Training Epoch 66  96.8% | batch:        91 of        94\t|\tloss: 664.141\n",
      "Training Epoch 66  97.9% | batch:        92 of        94\t|\tloss: 1608.15\n",
      "Training Epoch 66  98.9% | batch:        93 of        94\t|\tloss: 3345.7\n",
      "\n",
      "Evaluating Epoch 66   0.0% | batch:         0 of        40\t|\tloss: 7546.58\n",
      "Evaluating Epoch 66   2.5% | batch:         1 of        40\t|\tloss: 1086.74\n",
      "Evaluating Epoch 66   5.0% | batch:         2 of        40\t|\tloss: 3337.23\n",
      "Evaluating Epoch 66   7.5% | batch:         3 of        40\t|\tloss: 6808.99\n",
      "Evaluating Epoch 66  10.0% | batch:         4 of        40\t|\tloss: 2596.71\n",
      "Evaluating Epoch 66  12.5% | batch:         5 of        40\t|\tloss: 2740.15\n",
      "Evaluating Epoch 66  15.0% | batch:         6 of        40\t|\tloss: 9060.99\n",
      "Evaluating Epoch 66  17.5% | batch:         7 of        40\t|\tloss: 3377.92\n",
      "Evaluating Epoch 66  20.0% | batch:         8 of        40\t|\tloss: 2699.03\n",
      "Evaluating Epoch 66  22.5% | batch:         9 of        40\t|\tloss: 1807.75\n",
      "Evaluating Epoch 66  25.0% | batch:        10 of        40\t|\tloss: 5747.78\n",
      "Evaluating Epoch 66  27.5% | batch:        11 of        40\t|\tloss: 1625.85\n",
      "Evaluating Epoch 66  30.0% | batch:        12 of        40\t|\tloss: 6495.46\n",
      "Evaluating Epoch 66  32.5% | batch:        13 of        40\t|\tloss: 3661.07\n",
      "Evaluating Epoch 66  35.0% | batch:        14 of        40\t|\tloss: 2116.1\n",
      "Evaluating Epoch 66  37.5% | batch:        15 of        40\t|\tloss: 3248.05\n",
      "Evaluating Epoch 66  40.0% | batch:        16 of        40\t|\tloss: 4784.19\n",
      "Evaluating Epoch 66  42.5% | batch:        17 of        40\t|\tloss: 2996.02\n",
      "Evaluating Epoch 66  45.0% | batch:        18 of        40\t|\tloss: 2548.01\n",
      "Evaluating Epoch 66  47.5% | batch:        19 of        40\t|\tloss: 6093.04\n",
      "Evaluating Epoch 66  50.0% | batch:        20 of        40\t|\tloss: 5986.06\n",
      "Evaluating Epoch 66  52.5% | batch:        21 of        40\t|\tloss: 1215.76\n",
      "Evaluating Epoch 66  55.0% | batch:        22 of        40\t|\tloss: 3400.39\n",
      "Evaluating Epoch 66  57.5% | batch:        23 of        40\t|\tloss: 3880.53\n",
      "Evaluating Epoch 66  60.0% | batch:        24 of        40\t|\tloss: 1641.98\n",
      "Evaluating Epoch 66  62.5% | batch:        25 of        40\t|\tloss: 3256.2\n",
      "Evaluating Epoch 66  65.0% | batch:        26 of        40\t|\tloss: 10699\n",
      "Evaluating Epoch 66  67.5% | batch:        27 of        40\t|\tloss: 3026.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:35,156 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4542207717895508 seconds\n",
      "\n",
      "2023-05-09 14:22:35,157 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4771481922694615 seconds\n",
      "2023-05-09 14:22:35,157 | INFO : Avg batch val. time: 0.011928704806736537 seconds\n",
      "2023-05-09 14:22:35,158 | INFO : Avg sample val. time: 9.45222250929995e-05 seconds\n",
      "2023-05-09 14:22:35,158 | INFO : Epoch 66 Validation Summary: epoch: 66.000000 | loss: 4273.216744 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 66  70.0% | batch:        28 of        40\t|\tloss: 2357.94\n",
      "Evaluating Epoch 66  72.5% | batch:        29 of        40\t|\tloss: 9952.55\n",
      "Evaluating Epoch 66  75.0% | batch:        30 of        40\t|\tloss: 2002.8\n",
      "Evaluating Epoch 66  77.5% | batch:        31 of        40\t|\tloss: 1857.7\n",
      "Evaluating Epoch 66  80.0% | batch:        32 of        40\t|\tloss: 7941\n",
      "Evaluating Epoch 66  82.5% | batch:        33 of        40\t|\tloss: 6778.51\n",
      "Evaluating Epoch 66  85.0% | batch:        34 of        40\t|\tloss: 1123.59\n",
      "Evaluating Epoch 66  87.5% | batch:        35 of        40\t|\tloss: 5415.54\n",
      "Evaluating Epoch 66  90.0% | batch:        36 of        40\t|\tloss: 6368.73\n",
      "Evaluating Epoch 66  92.5% | batch:        37 of        40\t|\tloss: 2708.16\n",
      "Evaluating Epoch 66  95.0% | batch:        38 of        40\t|\tloss: 3351.73\n",
      "Evaluating Epoch 66  97.5% | batch:        39 of        40\t|\tloss: 11846\n",
      "\n",
      "Training Epoch 67   0.0% | batch:         0 of        94\t|\tloss: 715.282\n",
      "Training Epoch 67   1.1% | batch:         1 of        94\t|\tloss: 723.737\n",
      "Training Epoch 67   2.1% | batch:         2 of        94\t|\tloss: 1505.5\n",
      "Training Epoch 67   3.2% | batch:         3 of        94\t|\tloss: 1800.8\n",
      "Training Epoch 67   4.3% | batch:         4 of        94\t|\tloss: 1035.14\n",
      "Training Epoch 67   5.3% | batch:         5 of        94\t|\tloss: 961.881\n",
      "Training Epoch 67   6.4% | batch:         6 of        94\t|\tloss: 827.534\n",
      "Training Epoch 67   7.4% | batch:         7 of        94\t|\tloss: 1707.05\n",
      "Training Epoch 67   8.5% | batch:         8 of        94\t|\tloss: 1273.53\n",
      "Training Epoch 67   9.6% | batch:         9 of        94\t|\tloss: 997.369\n",
      "Training Epoch 67  10.6% | batch:        10 of        94\t|\tloss: 658.574\n",
      "Training Epoch 67  11.7% | batch:        11 of        94\t|\tloss: 1016.16\n",
      "Training Epoch 67  12.8% | batch:        12 of        94\t|\tloss: 607.841\n",
      "Training Epoch 67  13.8% | batch:        13 of        94\t|\tloss: 595.108\n",
      "Training Epoch 67  14.9% | batch:        14 of        94\t|\tloss: 860.677\n",
      "Training Epoch 67  16.0% | batch:        15 of        94\t|\tloss: 923.659\n",
      "Training Epoch 67  17.0% | batch:        16 of        94\t|\tloss: 1746.95\n",
      "Training Epoch 67  18.1% | batch:        17 of        94\t|\tloss: 1103.12\n",
      "Training Epoch 67  19.1% | batch:        18 of        94\t|\tloss: 1969.07\n",
      "Training Epoch 67  20.2% | batch:        19 of        94\t|\tloss: 804.286\n",
      "Training Epoch 67  21.3% | batch:        20 of        94\t|\tloss: 3658.59\n",
      "Training Epoch 67  22.3% | batch:        21 of        94\t|\tloss: 804.726\n",
      "Training Epoch 67  23.4% | batch:        22 of        94\t|\tloss: 1071.63\n",
      "Training Epoch 67  24.5% | batch:        23 of        94\t|\tloss: 1250.32\n",
      "Training Epoch 67  25.5% | batch:        24 of        94\t|\tloss: 1425.15\n",
      "Training Epoch 67  26.6% | batch:        25 of        94\t|\tloss: 1020.43\n",
      "Training Epoch 67  27.7% | batch:        26 of        94\t|\tloss: 1387.18\n",
      "Training Epoch 67  28.7% | batch:        27 of        94\t|\tloss: 790.116\n",
      "Training Epoch 67  29.8% | batch:        28 of        94\t|\tloss: 1654\n",
      "Training Epoch 67  30.9% | batch:        29 of        94\t|\tloss: 1272.57\n",
      "Training Epoch 67  31.9% | batch:        30 of        94\t|\tloss: 1243.49\n",
      "Training Epoch 67  33.0% | batch:        31 of        94\t|\tloss: 1177.6\n",
      "Training Epoch 67  34.0% | batch:        32 of        94\t|\tloss: 767.969\n",
      "Training Epoch 67  35.1% | batch:        33 of        94\t|\tloss: 1083.23\n",
      "Training Epoch 67  36.2% | batch:        34 of        94\t|\tloss: 992.727\n",
      "Training Epoch 67  37.2% | batch:        35 of        94\t|\tloss: 912.586\n",
      "Training Epoch 67  38.3% | batch:        36 of        94\t|\tloss: 2197.76\n",
      "Training Epoch 67  39.4% | batch:        37 of        94\t|\tloss: 1189.77\n",
      "Training Epoch 67  40.4% | batch:        38 of        94\t|\tloss: 1301.01\n",
      "Training Epoch 67  41.5% | batch:        39 of        94\t|\tloss: 1111.56\n",
      "Training Epoch 67  42.6% | batch:        40 of        94\t|\tloss: 983.934\n",
      "Training Epoch 67  43.6% | batch:        41 of        94\t|\tloss: 1016.16\n",
      "Training Epoch 67  44.7% | batch:        42 of        94\t|\tloss: 1431.9\n",
      "Training Epoch 67  45.7% | batch:        43 of        94\t|\tloss: 668.918\n",
      "Training Epoch 67  46.8% | batch:        44 of        94\t|\tloss: 1148.48\n",
      "Training Epoch 67  47.9% | batch:        45 of        94\t|\tloss: 1046.25\n",
      "Training Epoch 67  48.9% | batch:        46 of        94\t|\tloss: 782.318\n",
      "Training Epoch 67  50.0% | batch:        47 of        94\t|\tloss: 1063.72\n",
      "Training Epoch 67  51.1% | batch:        48 of        94\t|\tloss: 1010.4\n",
      "Training Epoch 67  52.1% | batch:        49 of        94\t|\tloss: 648.264\n",
      "Training Epoch 67  53.2% | batch:        50 of        94\t|\tloss: 1330.19\n",
      "Training Epoch 67  54.3% | batch:        51 of        94\t|\tloss: 687.557\n",
      "Training Epoch 67  55.3% | batch:        52 of        94\t|\tloss: 1293.61\n",
      "Training Epoch 67  56.4% | batch:        53 of        94\t|\tloss: 983.132\n",
      "Training Epoch 67  57.4% | batch:        54 of        94\t|\tloss: 987.713\n",
      "Training Epoch 67  58.5% | batch:        55 of        94\t|\tloss: 855.178\n",
      "Training Epoch 67  59.6% | batch:        56 of        94\t|\tloss: 1004.34\n",
      "Training Epoch 67  60.6% | batch:        57 of        94\t|\tloss: 1891.53\n",
      "Training Epoch 67  61.7% | batch:        58 of        94\t|\tloss: 1983.75\n",
      "Training Epoch 67  62.8% | batch:        59 of        94\t|\tloss: 753.241\n",
      "Training Epoch 67  63.8% | batch:        60 of        94\t|\tloss: 946.586\n",
      "Training Epoch 67  64.9% | batch:        61 of        94\t|\tloss: 1300.63\n",
      "Training Epoch 67  66.0% | batch:        62 of        94\t|\tloss: 881.897\n",
      "Training Epoch 67  67.0% | batch:        63 of        94\t|\tloss: 840.5\n",
      "Training Epoch 67  68.1% | batch:        64 of        94\t|\tloss: 2740.11\n",
      "Training Epoch 67  69.1% | batch:        65 of        94\t|\tloss: 1174.73\n",
      "Training Epoch 67  70.2% | batch:        66 of        94\t|\tloss: 850.056\n",
      "Training Epoch 67  71.3% | batch:        67 of        94\t|\tloss: 947.428\n",
      "Training Epoch 67  72.3% | batch:        68 of        94\t|\tloss: 1177.39\n",
      "Training Epoch 67  73.4% | batch:        69 of        94\t|\tloss: 1398.73\n",
      "Training Epoch 67  74.5% | batch:        70 of        94\t|\tloss: 803.782\n",
      "Training Epoch 67  75.5% | batch:        71 of        94\t|\tloss: 846.092\n",
      "Training Epoch 67  76.6% | batch:        72 of        94\t|\tloss: 1313.06\n",
      "Training Epoch 67  77.7% | batch:        73 of        94\t|\tloss: 1424.24\n",
      "Training Epoch 67  78.7% | batch:        74 of        94\t|\tloss: 743.044\n",
      "Training Epoch 67  79.8% | batch:        75 of        94\t|\tloss: 837.887\n",
      "Training Epoch 67  80.9% | batch:        76 of        94\t|\tloss: 975.552\n",
      "Training Epoch 67  81.9% | batch:        77 of        94\t|\tloss: 821.991\n",
      "Training Epoch 67  83.0% | batch:        78 of        94\t|\tloss: 1004.73\n",
      "Training Epoch 67  84.0% | batch:        79 of        94\t|\tloss: 1155.19\n",
      "Training Epoch 67  85.1% | batch:        80 of        94\t|\tloss: 1069.41\n",
      "Training Epoch 67  86.2% | batch:        81 of        94\t|\tloss: 899.892\n",
      "Training Epoch 67  87.2% | batch:        82 of        94\t|\tloss: 751.385\n",
      "Training Epoch 67  88.3% | batch:        83 of        94\t|\tloss: 939.679\n",
      "Training Epoch 67  89.4% | batch:        84 of        94\t|\tloss: 2042.98\n",
      "Training Epoch 67  90.4% | batch:        85 of        94\t|\tloss: 681.973\n",
      "Training Epoch 67  91.5% | batch:        86 of        94\t|\tloss: 1215.65\n",
      "Training Epoch 67  92.6% | batch:        87 of        94\t|\tloss: 1034.53\n",
      "Training Epoch 67  93.6% | batch:        88 of        94\t|\tloss: 996.919\n",
      "Training Epoch 67  94.7% | batch:        89 of        94\t|\tloss: 1015.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:37,014 | INFO : Epoch 67 Training Summary: epoch: 67.000000 | loss: 1137.136986 | \n",
      "2023-05-09 14:22:37,014 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8341615200042725 seconds\n",
      "\n",
      "2023-05-09 14:22:37,015 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8283065931120914 seconds\n",
      "2023-05-09 14:22:37,015 | INFO : Avg batch train. time: 0.019450070139490336 seconds\n",
      "2023-05-09 14:22:37,016 | INFO : Avg sample train. time: 0.00015340716505387578 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 67  95.7% | batch:        90 of        94\t|\tloss: 1101.89\n",
      "Training Epoch 67  96.8% | batch:        91 of        94\t|\tloss: 870.772\n",
      "Training Epoch 67  97.9% | batch:        92 of        94\t|\tloss: 1295.7\n",
      "Training Epoch 67  98.9% | batch:        93 of        94\t|\tloss: 564.949\n",
      "\n",
      "Training Epoch 68   0.0% | batch:         0 of        94\t|\tloss: 836.997\n",
      "Training Epoch 68   1.1% | batch:         1 of        94\t|\tloss: 988.601\n",
      "Training Epoch 68   2.1% | batch:         2 of        94\t|\tloss: 1026.96\n",
      "Training Epoch 68   3.2% | batch:         3 of        94\t|\tloss: 727.826\n",
      "Training Epoch 68   4.3% | batch:         4 of        94\t|\tloss: 1029.19\n",
      "Training Epoch 68   5.3% | batch:         5 of        94\t|\tloss: 1348.11\n",
      "Training Epoch 68   6.4% | batch:         6 of        94\t|\tloss: 707.664\n",
      "Training Epoch 68   7.4% | batch:         7 of        94\t|\tloss: 1385.12\n",
      "Training Epoch 68   8.5% | batch:         8 of        94\t|\tloss: 828.206\n",
      "Training Epoch 68   9.6% | batch:         9 of        94\t|\tloss: 847.296\n",
      "Training Epoch 68  10.6% | batch:        10 of        94\t|\tloss: 689.208\n",
      "Training Epoch 68  11.7% | batch:        11 of        94\t|\tloss: 732.012\n",
      "Training Epoch 68  12.8% | batch:        12 of        94\t|\tloss: 2424.43\n",
      "Training Epoch 68  13.8% | batch:        13 of        94\t|\tloss: 1234.86\n",
      "Training Epoch 68  14.9% | batch:        14 of        94\t|\tloss: 1027.3\n",
      "Training Epoch 68  16.0% | batch:        15 of        94\t|\tloss: 970.83\n",
      "Training Epoch 68  17.0% | batch:        16 of        94\t|\tloss: 927.756\n",
      "Training Epoch 68  18.1% | batch:        17 of        94\t|\tloss: 1349.24\n",
      "Training Epoch 68  19.1% | batch:        18 of        94\t|\tloss: 931.042\n",
      "Training Epoch 68  20.2% | batch:        19 of        94\t|\tloss: 745.453\n",
      "Training Epoch 68  21.3% | batch:        20 of        94\t|\tloss: 939.239\n",
      "Training Epoch 68  22.3% | batch:        21 of        94\t|\tloss: 907.349\n",
      "Training Epoch 68  23.4% | batch:        22 of        94\t|\tloss: 975.025\n",
      "Training Epoch 68  24.5% | batch:        23 of        94\t|\tloss: 1408.52\n",
      "Training Epoch 68  25.5% | batch:        24 of        94\t|\tloss: 1036.91\n",
      "Training Epoch 68  26.6% | batch:        25 of        94\t|\tloss: 681.609\n",
      "Training Epoch 68  27.7% | batch:        26 of        94\t|\tloss: 752.658\n",
      "Training Epoch 68  28.7% | batch:        27 of        94\t|\tloss: 907.721\n",
      "Training Epoch 68  29.8% | batch:        28 of        94\t|\tloss: 1030.6\n",
      "Training Epoch 68  30.9% | batch:        29 of        94\t|\tloss: 710.041\n",
      "Training Epoch 68  31.9% | batch:        30 of        94\t|\tloss: 731.38\n",
      "Training Epoch 68  33.0% | batch:        31 of        94\t|\tloss: 1656.39\n",
      "Training Epoch 68  34.0% | batch:        32 of        94\t|\tloss: 948.031\n",
      "Training Epoch 68  35.1% | batch:        33 of        94\t|\tloss: 1547.51\n",
      "Training Epoch 68  36.2% | batch:        34 of        94\t|\tloss: 1492.81\n",
      "Training Epoch 68  37.2% | batch:        35 of        94\t|\tloss: 734.115\n",
      "Training Epoch 68  38.3% | batch:        36 of        94\t|\tloss: 789.149\n",
      "Training Epoch 68  39.4% | batch:        37 of        94\t|\tloss: 910.377\n",
      "Training Epoch 68  40.4% | batch:        38 of        94\t|\tloss: 1586.03\n",
      "Training Epoch 68  41.5% | batch:        39 of        94\t|\tloss: 862.773\n",
      "Training Epoch 68  42.6% | batch:        40 of        94\t|\tloss: 1357.5\n",
      "Training Epoch 68  43.6% | batch:        41 of        94\t|\tloss: 1081.35\n",
      "Training Epoch 68  44.7% | batch:        42 of        94\t|\tloss: 951.672\n",
      "Training Epoch 68  45.7% | batch:        43 of        94\t|\tloss: 607.089\n",
      "Training Epoch 68  46.8% | batch:        44 of        94\t|\tloss: 813.465\n",
      "Training Epoch 68  47.9% | batch:        45 of        94\t|\tloss: 1481.28\n",
      "Training Epoch 68  48.9% | batch:        46 of        94\t|\tloss: 813.239\n",
      "Training Epoch 68  50.0% | batch:        47 of        94\t|\tloss: 1767.38\n",
      "Training Epoch 68  51.1% | batch:        48 of        94\t|\tloss: 816.057\n",
      "Training Epoch 68  52.1% | batch:        49 of        94\t|\tloss: 1039.86\n",
      "Training Epoch 68  53.2% | batch:        50 of        94\t|\tloss: 1187.22\n",
      "Training Epoch 68  54.3% | batch:        51 of        94\t|\tloss: 1367.74\n",
      "Training Epoch 68  55.3% | batch:        52 of        94\t|\tloss: 1089\n",
      "Training Epoch 68  56.4% | batch:        53 of        94\t|\tloss: 1166.37\n",
      "Training Epoch 68  57.4% | batch:        54 of        94\t|\tloss: 887.896\n",
      "Training Epoch 68  58.5% | batch:        55 of        94\t|\tloss: 963.993\n",
      "Training Epoch 68  59.6% | batch:        56 of        94\t|\tloss: 1081.51\n",
      "Training Epoch 68  60.6% | batch:        57 of        94\t|\tloss: 827.927\n",
      "Training Epoch 68  61.7% | batch:        58 of        94\t|\tloss: 2345.9\n",
      "Training Epoch 68  62.8% | batch:        59 of        94\t|\tloss: 2992.66\n",
      "Training Epoch 68  63.8% | batch:        60 of        94\t|\tloss: 697.857\n",
      "Training Epoch 68  64.9% | batch:        61 of        94\t|\tloss: 1134.65\n",
      "Training Epoch 68  66.0% | batch:        62 of        94\t|\tloss: 988.441\n",
      "Training Epoch 68  67.0% | batch:        63 of        94\t|\tloss: 793.515\n",
      "Training Epoch 68  68.1% | batch:        64 of        94\t|\tloss: 818.842\n",
      "Training Epoch 68  69.1% | batch:        65 of        94\t|\tloss: 1181.72\n",
      "Training Epoch 68  70.2% | batch:        66 of        94\t|\tloss: 806.388\n",
      "Training Epoch 68  71.3% | batch:        67 of        94\t|\tloss: 787.24\n",
      "Training Epoch 68  72.3% | batch:        68 of        94\t|\tloss: 1164.34\n",
      "Training Epoch 68  73.4% | batch:        69 of        94\t|\tloss: 950.286\n",
      "Training Epoch 68  74.5% | batch:        70 of        94\t|\tloss: 1518.69\n",
      "Training Epoch 68  75.5% | batch:        71 of        94\t|\tloss: 1068.74\n",
      "Training Epoch 68  76.6% | batch:        72 of        94\t|\tloss: 1896.37\n",
      "Training Epoch 68  77.7% | batch:        73 of        94\t|\tloss: 1062.27\n",
      "Training Epoch 68  78.7% | batch:        74 of        94\t|\tloss: 1094.44\n",
      "Training Epoch 68  79.8% | batch:        75 of        94\t|\tloss: 1734.45\n",
      "Training Epoch 68  80.9% | batch:        76 of        94\t|\tloss: 1656.22\n",
      "Training Epoch 68  81.9% | batch:        77 of        94\t|\tloss: 716.492\n",
      "Training Epoch 68  83.0% | batch:        78 of        94\t|\tloss: 866.79\n",
      "Training Epoch 68  84.0% | batch:        79 of        94\t|\tloss: 1050.32\n",
      "Training Epoch 68  85.1% | batch:        80 of        94\t|\tloss: 1155.67\n",
      "Training Epoch 68  86.2% | batch:        81 of        94\t|\tloss: 913.885\n",
      "Training Epoch 68  87.2% | batch:        82 of        94\t|\tloss: 870.037\n",
      "Training Epoch 68  88.3% | batch:        83 of        94\t|\tloss: 727.764\n",
      "Training Epoch 68  89.4% | batch:        84 of        94\t|\tloss: 1253\n",
      "Training Epoch 68  90.4% | batch:        85 of        94\t|\tloss: 1878.51\n",
      "Training Epoch 68  91.5% | batch:        86 of        94\t|\tloss: 1023.78\n",
      "Training Epoch 68  92.6% | batch:        87 of        94\t|\tloss: 1563.83\n",
      "Training Epoch 68  93.6% | batch:        88 of        94\t|\tloss: 1579.8\n",
      "Training Epoch 68  94.7% | batch:        89 of        94\t|\tloss: 1042.44\n",
      "Training Epoch 68  95.7% | batch:        90 of        94\t|\tloss: 940.799\n",
      "Training Epoch 68  96.8% | batch:        91 of        94\t|\tloss: 1012.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:38,880 | INFO : Epoch 68 Training Summary: epoch: 68.000000 | loss: 1105.373883 | \n",
      "2023-05-09 14:22:38,881 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8517897129058838 seconds\n",
      "\n",
      "2023-05-09 14:22:38,882 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8286519331090592 seconds\n",
      "2023-05-09 14:22:38,882 | INFO : Avg batch train. time: 0.01945374396924531 seconds\n",
      "2023-05-09 14:22:38,882 | INFO : Avg sample train. time: 0.00015343614139193314 seconds\n",
      "2023-05-09 14:22:38,883 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 68  97.9% | batch:        92 of        94\t|\tloss: 870.016\n",
      "Training Epoch 68  98.9% | batch:        93 of        94\t|\tloss: 867.693\n",
      "\n",
      "Evaluating Epoch 68   0.0% | batch:         0 of        40\t|\tloss: 7668.09\n",
      "Evaluating Epoch 68   2.5% | batch:         1 of        40\t|\tloss: 1273.58\n",
      "Evaluating Epoch 68   5.0% | batch:         2 of        40\t|\tloss: 3522.19\n",
      "Evaluating Epoch 68   7.5% | batch:         3 of        40\t|\tloss: 6615.27\n",
      "Evaluating Epoch 68  10.0% | batch:         4 of        40\t|\tloss: 2499.89\n",
      "Evaluating Epoch 68  12.5% | batch:         5 of        40\t|\tloss: 1926.59\n",
      "Evaluating Epoch 68  15.0% | batch:         6 of        40\t|\tloss: 8272.77\n",
      "Evaluating Epoch 68  17.5% | batch:         7 of        40\t|\tloss: 3562.95\n",
      "Evaluating Epoch 68  20.0% | batch:         8 of        40\t|\tloss: 2941.13\n",
      "Evaluating Epoch 68  22.5% | batch:         9 of        40\t|\tloss: 1857.38\n",
      "Evaluating Epoch 68  25.0% | batch:        10 of        40\t|\tloss: 5629.45\n",
      "Evaluating Epoch 68  27.5% | batch:        11 of        40\t|\tloss: 1760.14\n",
      "Evaluating Epoch 68  30.0% | batch:        12 of        40\t|\tloss: 6547.87\n",
      "Evaluating Epoch 68  32.5% | batch:        13 of        40\t|\tloss: 4071.24\n",
      "Evaluating Epoch 68  35.0% | batch:        14 of        40\t|\tloss: 2363.64\n",
      "Evaluating Epoch 68  37.5% | batch:        15 of        40\t|\tloss: 3718.05\n",
      "Evaluating Epoch 68  40.0% | batch:        16 of        40\t|\tloss: 4365.14\n",
      "Evaluating Epoch 68  42.5% | batch:        17 of        40\t|\tloss: 3095.85\n",
      "Evaluating Epoch 68  45.0% | batch:        18 of        40\t|\tloss: 2769.37\n",
      "Evaluating Epoch 68  47.5% | batch:        19 of        40\t|\tloss: 6552.4\n",
      "Evaluating Epoch 68  50.0% | batch:        20 of        40\t|\tloss: 5807.29\n",
      "Evaluating Epoch 68  52.5% | batch:        21 of        40\t|\tloss: 1538.66\n",
      "Evaluating Epoch 68  55.0% | batch:        22 of        40\t|\tloss: 3462.37\n",
      "Evaluating Epoch 68  57.5% | batch:        23 of        40\t|\tloss: 3864.2\n",
      "Evaluating Epoch 68  60.0% | batch:        24 of        40\t|\tloss: 1669.14\n",
      "Evaluating Epoch 68  62.5% | batch:        25 of        40\t|\tloss: 3864.21\n",
      "Evaluating Epoch 68  65.0% | batch:        26 of        40\t|\tloss: 11142.9\n",
      "Evaluating Epoch 68  67.5% | batch:        27 of        40\t|\tloss: 3489.54\n",
      "Evaluating Epoch 68  70.0% | batch:        28 of        40\t|\tloss: 2087\n",
      "Evaluating Epoch 68  72.5% | batch:        29 of        40\t|\tloss: 9666.8\n",
      "Evaluating Epoch 68  75.0% | batch:        30 of        40\t|\tloss: 2204.16\n",
      "Evaluating Epoch 68  77.5% | batch:        31 of        40\t|\tloss: 1876.56\n",
      "Evaluating Epoch 68  80.0% | batch:        32 of        40\t|\tloss: 6894.03\n",
      "Evaluating Epoch 68  82.5% | batch:        33 of        40\t|\tloss: 6939.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:39,338 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.454697847366333 seconds\n",
      "\n",
      "2023-05-09 14:22:39,338 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47652457157770794 seconds\n",
      "2023-05-09 14:22:39,339 | INFO : Avg batch val. time: 0.011913114289442698 seconds\n",
      "2023-05-09 14:22:39,339 | INFO : Avg sample val. time: 9.439868692109904e-05 seconds\n",
      "2023-05-09 14:22:39,340 | INFO : Epoch 68 Validation Summary: epoch: 68.000000 | loss: 4351.721684 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 68  85.0% | batch:        34 of        40\t|\tloss: 1246.45\n",
      "Evaluating Epoch 68  87.5% | batch:        35 of        40\t|\tloss: 5527.91\n",
      "Evaluating Epoch 68  90.0% | batch:        36 of        40\t|\tloss: 7145.29\n",
      "Evaluating Epoch 68  92.5% | batch:        37 of        40\t|\tloss: 2914.59\n",
      "Evaluating Epoch 68  95.0% | batch:        38 of        40\t|\tloss: 3961.2\n",
      "Evaluating Epoch 68  97.5% | batch:        39 of        40\t|\tloss: 12129.1\n",
      "\n",
      "Training Epoch 69   0.0% | batch:         0 of        94\t|\tloss: 1161.75\n",
      "Training Epoch 69   1.1% | batch:         1 of        94\t|\tloss: 3691.59\n",
      "Training Epoch 69   2.1% | batch:         2 of        94\t|\tloss: 1154.19\n",
      "Training Epoch 69   3.2% | batch:         3 of        94\t|\tloss: 1396.8\n",
      "Training Epoch 69   4.3% | batch:         4 of        94\t|\tloss: 791.635\n",
      "Training Epoch 69   5.3% | batch:         5 of        94\t|\tloss: 938.32\n",
      "Training Epoch 69   6.4% | batch:         6 of        94\t|\tloss: 867.238\n",
      "Training Epoch 69   7.4% | batch:         7 of        94\t|\tloss: 1144.06\n",
      "Training Epoch 69   8.5% | batch:         8 of        94\t|\tloss: 2342.86\n",
      "Training Epoch 69   9.6% | batch:         9 of        94\t|\tloss: 1411.45\n",
      "Training Epoch 69  10.6% | batch:        10 of        94\t|\tloss: 1088.01\n",
      "Training Epoch 69  11.7% | batch:        11 of        94\t|\tloss: 708.713\n",
      "Training Epoch 69  12.8% | batch:        12 of        94\t|\tloss: 876.064\n",
      "Training Epoch 69  13.8% | batch:        13 of        94\t|\tloss: 947.785\n",
      "Training Epoch 69  14.9% | batch:        14 of        94\t|\tloss: 539.2\n",
      "Training Epoch 69  16.0% | batch:        15 of        94\t|\tloss: 1120.52\n",
      "Training Epoch 69  17.0% | batch:        16 of        94\t|\tloss: 676.141\n",
      "Training Epoch 69  18.1% | batch:        17 of        94\t|\tloss: 2112.41\n",
      "Training Epoch 69  19.1% | batch:        18 of        94\t|\tloss: 1068.46\n",
      "Training Epoch 69  20.2% | batch:        19 of        94\t|\tloss: 727.347\n",
      "Training Epoch 69  21.3% | batch:        20 of        94\t|\tloss: 834.212\n",
      "Training Epoch 69  22.3% | batch:        21 of        94\t|\tloss: 890.17\n",
      "Training Epoch 69  23.4% | batch:        22 of        94\t|\tloss: 729.187\n",
      "Training Epoch 69  24.5% | batch:        23 of        94\t|\tloss: 581.101\n",
      "Training Epoch 69  25.5% | batch:        24 of        94\t|\tloss: 802.063\n",
      "Training Epoch 69  26.6% | batch:        25 of        94\t|\tloss: 949.203\n",
      "Training Epoch 69  27.7% | batch:        26 of        94\t|\tloss: 1778.41\n",
      "Training Epoch 69  28.7% | batch:        27 of        94\t|\tloss: 1296.15\n",
      "Training Epoch 69  29.8% | batch:        28 of        94\t|\tloss: 826.829\n",
      "Training Epoch 69  30.9% | batch:        29 of        94\t|\tloss: 1045.93\n",
      "Training Epoch 69  31.9% | batch:        30 of        94\t|\tloss: 1439.39\n",
      "Training Epoch 69  33.0% | batch:        31 of        94\t|\tloss: 805.137\n",
      "Training Epoch 69  34.0% | batch:        32 of        94\t|\tloss: 931.621\n",
      "Training Epoch 69  35.1% | batch:        33 of        94\t|\tloss: 851.044\n",
      "Training Epoch 69  36.2% | batch:        34 of        94\t|\tloss: 907.517\n",
      "Training Epoch 69  37.2% | batch:        35 of        94\t|\tloss: 990.526\n",
      "Training Epoch 69  38.3% | batch:        36 of        94\t|\tloss: 2235.25\n",
      "Training Epoch 69  39.4% | batch:        37 of        94\t|\tloss: 686.079\n",
      "Training Epoch 69  40.4% | batch:        38 of        94\t|\tloss: 928.282\n",
      "Training Epoch 69  41.5% | batch:        39 of        94\t|\tloss: 1336.8\n",
      "Training Epoch 69  42.6% | batch:        40 of        94\t|\tloss: 675.169\n",
      "Training Epoch 69  43.6% | batch:        41 of        94\t|\tloss: 793.05\n",
      "Training Epoch 69  44.7% | batch:        42 of        94\t|\tloss: 906.956\n",
      "Training Epoch 69  45.7% | batch:        43 of        94\t|\tloss: 773.941\n",
      "Training Epoch 69  46.8% | batch:        44 of        94\t|\tloss: 701.975\n",
      "Training Epoch 69  47.9% | batch:        45 of        94\t|\tloss: 643.484\n",
      "Training Epoch 69  48.9% | batch:        46 of        94\t|\tloss: 1851.31\n",
      "Training Epoch 69  50.0% | batch:        47 of        94\t|\tloss: 951.516\n",
      "Training Epoch 69  51.1% | batch:        48 of        94\t|\tloss: 1297.93\n",
      "Training Epoch 69  52.1% | batch:        49 of        94\t|\tloss: 1724.34\n",
      "Training Epoch 69  53.2% | batch:        50 of        94\t|\tloss: 827.547\n",
      "Training Epoch 69  54.3% | batch:        51 of        94\t|\tloss: 962.993\n",
      "Training Epoch 69  55.3% | batch:        52 of        94\t|\tloss: 1246.39\n",
      "Training Epoch 69  56.4% | batch:        53 of        94\t|\tloss: 1196.21\n",
      "Training Epoch 69  57.4% | batch:        54 of        94\t|\tloss: 1269.99\n",
      "Training Epoch 69  58.5% | batch:        55 of        94\t|\tloss: 1113.71\n",
      "Training Epoch 69  59.6% | batch:        56 of        94\t|\tloss: 1413.76\n",
      "Training Epoch 69  60.6% | batch:        57 of        94\t|\tloss: 889.133\n",
      "Training Epoch 69  61.7% | batch:        58 of        94\t|\tloss: 2369.83\n",
      "Training Epoch 69  62.8% | batch:        59 of        94\t|\tloss: 1100.73\n",
      "Training Epoch 69  63.8% | batch:        60 of        94\t|\tloss: 664.339\n",
      "Training Epoch 69  64.9% | batch:        61 of        94\t|\tloss: 718.761\n",
      "Training Epoch 69  66.0% | batch:        62 of        94\t|\tloss: 1555.64\n",
      "Training Epoch 69  67.0% | batch:        63 of        94\t|\tloss: 1106.53\n",
      "Training Epoch 69  68.1% | batch:        64 of        94\t|\tloss: 1331.23\n",
      "Training Epoch 69  69.1% | batch:        65 of        94\t|\tloss: 1431.57\n",
      "Training Epoch 69  70.2% | batch:        66 of        94\t|\tloss: 895.992\n",
      "Training Epoch 69  71.3% | batch:        67 of        94\t|\tloss: 813.791\n",
      "Training Epoch 69  72.3% | batch:        68 of        94\t|\tloss: 852.836\n",
      "Training Epoch 69  73.4% | batch:        69 of        94\t|\tloss: 1150.91\n",
      "Training Epoch 69  74.5% | batch:        70 of        94\t|\tloss: 781.265\n",
      "Training Epoch 69  75.5% | batch:        71 of        94\t|\tloss: 1062.03\n",
      "Training Epoch 69  76.6% | batch:        72 of        94\t|\tloss: 964.209\n",
      "Training Epoch 69  77.7% | batch:        73 of        94\t|\tloss: 911.884\n",
      "Training Epoch 69  78.7% | batch:        74 of        94\t|\tloss: 884.591\n",
      "Training Epoch 69  79.8% | batch:        75 of        94\t|\tloss: 1241.31\n",
      "Training Epoch 69  80.9% | batch:        76 of        94\t|\tloss: 785.674\n",
      "Training Epoch 69  81.9% | batch:        77 of        94\t|\tloss: 1047.48\n",
      "Training Epoch 69  83.0% | batch:        78 of        94\t|\tloss: 1144.18\n",
      "Training Epoch 69  84.0% | batch:        79 of        94\t|\tloss: 876.545\n",
      "Training Epoch 69  85.1% | batch:        80 of        94\t|\tloss: 1744.34\n",
      "Training Epoch 69  86.2% | batch:        81 of        94\t|\tloss: 980.98\n",
      "Training Epoch 69  87.2% | batch:        82 of        94\t|\tloss: 1514.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:41,210 | INFO : Epoch 69 Training Summary: epoch: 69.000000 | loss: 1115.852939 | \n",
      "2023-05-09 14:22:41,210 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8484933376312256 seconds\n",
      "\n",
      "2023-05-09 14:22:41,211 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.828939489696337 seconds\n",
      "2023-05-09 14:22:41,212 | INFO : Avg batch train. time: 0.019456803081875924 seconds\n",
      "2023-05-09 14:22:41,212 | INFO : Avg sample train. time: 0.000153460269315014 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 69  88.3% | batch:        83 of        94\t|\tloss: 746.99\n",
      "Training Epoch 69  89.4% | batch:        84 of        94\t|\tloss: 1008.01\n",
      "Training Epoch 69  90.4% | batch:        85 of        94\t|\tloss: 1139.9\n",
      "Training Epoch 69  91.5% | batch:        86 of        94\t|\tloss: 1162.22\n",
      "Training Epoch 69  92.6% | batch:        87 of        94\t|\tloss: 1417.73\n",
      "Training Epoch 69  93.6% | batch:        88 of        94\t|\tloss: 865.115\n",
      "Training Epoch 69  94.7% | batch:        89 of        94\t|\tloss: 1622.03\n",
      "Training Epoch 69  95.7% | batch:        90 of        94\t|\tloss: 855.848\n",
      "Training Epoch 69  96.8% | batch:        91 of        94\t|\tloss: 1216.48\n",
      "Training Epoch 69  97.9% | batch:        92 of        94\t|\tloss: 818.901\n",
      "Training Epoch 69  98.9% | batch:        93 of        94\t|\tloss: 2409.86\n",
      "\n",
      "Training Epoch 70   0.0% | batch:         0 of        94\t|\tloss: 991.511\n",
      "Training Epoch 70   1.1% | batch:         1 of        94\t|\tloss: 701.326\n",
      "Training Epoch 70   2.1% | batch:         2 of        94\t|\tloss: 879.904\n",
      "Training Epoch 70   3.2% | batch:         3 of        94\t|\tloss: 2182.49\n",
      "Training Epoch 70   4.3% | batch:         4 of        94\t|\tloss: 655.626\n",
      "Training Epoch 70   5.3% | batch:         5 of        94\t|\tloss: 1254.56\n",
      "Training Epoch 70   6.4% | batch:         6 of        94\t|\tloss: 1370.61\n",
      "Training Epoch 70   7.4% | batch:         7 of        94\t|\tloss: 781.666\n",
      "Training Epoch 70   8.5% | batch:         8 of        94\t|\tloss: 1389.89\n",
      "Training Epoch 70   9.6% | batch:         9 of        94\t|\tloss: 707.603\n",
      "Training Epoch 70  10.6% | batch:        10 of        94\t|\tloss: 1221.99\n",
      "Training Epoch 70  11.7% | batch:        11 of        94\t|\tloss: 841.102\n",
      "Training Epoch 70  12.8% | batch:        12 of        94\t|\tloss: 1596.65\n",
      "Training Epoch 70  13.8% | batch:        13 of        94\t|\tloss: 1198.81\n",
      "Training Epoch 70  14.9% | batch:        14 of        94\t|\tloss: 1663.41\n",
      "Training Epoch 70  16.0% | batch:        15 of        94\t|\tloss: 795.949\n",
      "Training Epoch 70  17.0% | batch:        16 of        94\t|\tloss: 1243.29\n",
      "Training Epoch 70  18.1% | batch:        17 of        94\t|\tloss: 1113.6\n",
      "Training Epoch 70  19.1% | batch:        18 of        94\t|\tloss: 787.617\n",
      "Training Epoch 70  20.2% | batch:        19 of        94\t|\tloss: 945.664\n",
      "Training Epoch 70  21.3% | batch:        20 of        94\t|\tloss: 846.469\n",
      "Training Epoch 70  22.3% | batch:        21 of        94\t|\tloss: 849.897\n",
      "Training Epoch 70  23.4% | batch:        22 of        94\t|\tloss: 1454.64\n",
      "Training Epoch 70  24.5% | batch:        23 of        94\t|\tloss: 800.135\n",
      "Training Epoch 70  25.5% | batch:        24 of        94\t|\tloss: 1355.14\n",
      "Training Epoch 70  26.6% | batch:        25 of        94\t|\tloss: 1275.38\n",
      "Training Epoch 70  27.7% | batch:        26 of        94\t|\tloss: 1104.3\n",
      "Training Epoch 70  28.7% | batch:        27 of        94\t|\tloss: 1040.55\n",
      "Training Epoch 70  29.8% | batch:        28 of        94\t|\tloss: 745.251\n",
      "Training Epoch 70  30.9% | batch:        29 of        94\t|\tloss: 2237.63\n",
      "Training Epoch 70  31.9% | batch:        30 of        94\t|\tloss: 797.261\n",
      "Training Epoch 70  33.0% | batch:        31 of        94\t|\tloss: 918.997\n",
      "Training Epoch 70  34.0% | batch:        32 of        94\t|\tloss: 688.305\n",
      "Training Epoch 70  35.1% | batch:        33 of        94\t|\tloss: 910.232\n",
      "Training Epoch 70  36.2% | batch:        34 of        94\t|\tloss: 1554.78\n",
      "Training Epoch 70  37.2% | batch:        35 of        94\t|\tloss: 1037.12\n",
      "Training Epoch 70  38.3% | batch:        36 of        94\t|\tloss: 694.622\n",
      "Training Epoch 70  39.4% | batch:        37 of        94\t|\tloss: 664.568\n",
      "Training Epoch 70  40.4% | batch:        38 of        94\t|\tloss: 1045.67\n",
      "Training Epoch 70  41.5% | batch:        39 of        94\t|\tloss: 923.671\n",
      "Training Epoch 70  42.6% | batch:        40 of        94\t|\tloss: 716.814\n",
      "Training Epoch 70  43.6% | batch:        41 of        94\t|\tloss: 808.497\n",
      "Training Epoch 70  44.7% | batch:        42 of        94\t|\tloss: 904.734\n",
      "Training Epoch 70  45.7% | batch:        43 of        94\t|\tloss: 1353.3\n",
      "Training Epoch 70  46.8% | batch:        44 of        94\t|\tloss: 615.441\n",
      "Training Epoch 70  47.9% | batch:        45 of        94\t|\tloss: 709.298\n",
      "Training Epoch 70  48.9% | batch:        46 of        94\t|\tloss: 1699.58\n",
      "Training Epoch 70  50.0% | batch:        47 of        94\t|\tloss: 1704.07\n",
      "Training Epoch 70  51.1% | batch:        48 of        94\t|\tloss: 706.35\n",
      "Training Epoch 70  52.1% | batch:        49 of        94\t|\tloss: 1161.51\n",
      "Training Epoch 70  53.2% | batch:        50 of        94\t|\tloss: 974.54\n",
      "Training Epoch 70  54.3% | batch:        51 of        94\t|\tloss: 1027.87\n",
      "Training Epoch 70  55.3% | batch:        52 of        94\t|\tloss: 2827.54\n",
      "Training Epoch 70  56.4% | batch:        53 of        94\t|\tloss: 1361.61\n",
      "Training Epoch 70  57.4% | batch:        54 of        94\t|\tloss: 1835.08\n",
      "Training Epoch 70  58.5% | batch:        55 of        94\t|\tloss: 1199.14\n",
      "Training Epoch 70  59.6% | batch:        56 of        94\t|\tloss: 1598.46\n",
      "Training Epoch 70  60.6% | batch:        57 of        94\t|\tloss: 1174.55\n",
      "Training Epoch 70  61.7% | batch:        58 of        94\t|\tloss: 1896.44\n",
      "Training Epoch 70  62.8% | batch:        59 of        94\t|\tloss: 1208.74\n",
      "Training Epoch 70  63.8% | batch:        60 of        94\t|\tloss: 1416.29\n",
      "Training Epoch 70  64.9% | batch:        61 of        94\t|\tloss: 1339.92\n",
      "Training Epoch 70  66.0% | batch:        62 of        94\t|\tloss: 1072.37\n",
      "Training Epoch 70  67.0% | batch:        63 of        94\t|\tloss: 918.83\n",
      "Training Epoch 70  68.1% | batch:        64 of        94\t|\tloss: 1126.21\n",
      "Training Epoch 70  69.1% | batch:        65 of        94\t|\tloss: 3633.06\n",
      "Training Epoch 70  70.2% | batch:        66 of        94\t|\tloss: 1040.61\n",
      "Training Epoch 70  71.3% | batch:        67 of        94\t|\tloss: 915.65\n",
      "Training Epoch 70  72.3% | batch:        68 of        94\t|\tloss: 1397.19\n",
      "Training Epoch 70  73.4% | batch:        69 of        94\t|\tloss: 796.173\n",
      "Training Epoch 70  74.5% | batch:        70 of        94\t|\tloss: 1173.94\n",
      "Training Epoch 70  75.5% | batch:        71 of        94\t|\tloss: 780.423\n",
      "Training Epoch 70  76.6% | batch:        72 of        94\t|\tloss: 749.992\n",
      "Training Epoch 70  77.7% | batch:        73 of        94\t|\tloss: 913.21\n",
      "Training Epoch 70  78.7% | batch:        74 of        94\t|\tloss: 765.287\n",
      "Training Epoch 70  79.8% | batch:        75 of        94\t|\tloss: 877.305\n",
      "Training Epoch 70  80.9% | batch:        76 of        94\t|\tloss: 843.526\n",
      "Training Epoch 70  81.9% | batch:        77 of        94\t|\tloss: 979.098\n",
      "Training Epoch 70  83.0% | batch:        78 of        94\t|\tloss: 744.63\n",
      "Training Epoch 70  84.0% | batch:        79 of        94\t|\tloss: 571.012\n",
      "Training Epoch 70  85.1% | batch:        80 of        94\t|\tloss: 1292.88\n",
      "Training Epoch 70  86.2% | batch:        81 of        94\t|\tloss: 1282.18\n",
      "Training Epoch 70  87.2% | batch:        82 of        94\t|\tloss: 1219.62\n",
      "Training Epoch 70  88.3% | batch:        83 of        94\t|\tloss: 1146.79\n",
      "Training Epoch 70  89.4% | batch:        84 of        94\t|\tloss: 972.254\n",
      "Training Epoch 70  90.4% | batch:        85 of        94\t|\tloss: 1269.29\n",
      "Training Epoch 70  91.5% | batch:        86 of        94\t|\tloss: 791.86\n",
      "Training Epoch 70  92.6% | batch:        87 of        94\t|\tloss: 1141.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:43,064 | INFO : Epoch 70 Training Summary: epoch: 70.000000 | loss: 1134.821553 | \n",
      "2023-05-09 14:22:43,065 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8308453559875488 seconds\n",
      "\n",
      "2023-05-09 14:22:43,066 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.82896671635764 seconds\n",
      "2023-05-09 14:22:43,066 | INFO : Avg batch train. time: 0.019457092727208934 seconds\n",
      "2023-05-09 14:22:43,067 | INFO : Avg sample train. time: 0.00015346255381420038 seconds\n",
      "2023-05-09 14:22:43,067 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 70  93.6% | batch:        88 of        94\t|\tloss: 1285.56\n",
      "Training Epoch 70  94.7% | batch:        89 of        94\t|\tloss: 997.493\n",
      "Training Epoch 70  95.7% | batch:        90 of        94\t|\tloss: 1419.02\n",
      "Training Epoch 70  96.8% | batch:        91 of        94\t|\tloss: 1011.06\n",
      "Training Epoch 70  97.9% | batch:        92 of        94\t|\tloss: 812.091\n",
      "Training Epoch 70  98.9% | batch:        93 of        94\t|\tloss: 1959.81\n",
      "\n",
      "Evaluating Epoch 70   0.0% | batch:         0 of        40\t|\tloss: 7246.77\n",
      "Evaluating Epoch 70   2.5% | batch:         1 of        40\t|\tloss: 1095.92\n",
      "Evaluating Epoch 70   5.0% | batch:         2 of        40\t|\tloss: 6053.44\n",
      "Evaluating Epoch 70   7.5% | batch:         3 of        40\t|\tloss: 6911.36\n",
      "Evaluating Epoch 70  10.0% | batch:         4 of        40\t|\tloss: 3188.46\n",
      "Evaluating Epoch 70  12.5% | batch:         5 of        40\t|\tloss: 3700.16\n",
      "Evaluating Epoch 70  15.0% | batch:         6 of        40\t|\tloss: 10052.5\n",
      "Evaluating Epoch 70  17.5% | batch:         7 of        40\t|\tloss: 3043.42\n",
      "Evaluating Epoch 70  20.0% | batch:         8 of        40\t|\tloss: 2564.44\n",
      "Evaluating Epoch 70  22.5% | batch:         9 of        40\t|\tloss: 2558.67\n",
      "Evaluating Epoch 70  25.0% | batch:        10 of        40\t|\tloss: 5015.98\n",
      "Evaluating Epoch 70  27.5% | batch:        11 of        40\t|\tloss: 1333.03\n",
      "Evaluating Epoch 70  30.0% | batch:        12 of        40\t|\tloss: 5763.8\n",
      "Evaluating Epoch 70  32.5% | batch:        13 of        40\t|\tloss: 3338.55\n",
      "Evaluating Epoch 70  35.0% | batch:        14 of        40\t|\tloss: 1940.14\n",
      "Evaluating Epoch 70  37.5% | batch:        15 of        40\t|\tloss: 3683.35\n",
      "Evaluating Epoch 70  40.0% | batch:        16 of        40\t|\tloss: 3825.65\n",
      "Evaluating Epoch 70  42.5% | batch:        17 of        40\t|\tloss: 2764.25\n",
      "Evaluating Epoch 70  45.0% | batch:        18 of        40\t|\tloss: 2210.25\n",
      "Evaluating Epoch 70  47.5% | batch:        19 of        40\t|\tloss: 7137.72\n",
      "Evaluating Epoch 70  50.0% | batch:        20 of        40\t|\tloss: 5621.12\n",
      "Evaluating Epoch 70  52.5% | batch:        21 of        40\t|\tloss: 1243.23\n",
      "Evaluating Epoch 70  55.0% | batch:        22 of        40\t|\tloss: 4676.36\n",
      "Evaluating Epoch 70  57.5% | batch:        23 of        40\t|\tloss: 3496.61\n",
      "Evaluating Epoch 70  60.0% | batch:        24 of        40\t|\tloss: 1593.27\n",
      "Evaluating Epoch 70  62.5% | batch:        25 of        40\t|\tloss: 4141.29\n",
      "Evaluating Epoch 70  65.0% | batch:        26 of        40\t|\tloss: 9245.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:43,526 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4579956531524658 seconds\n",
      "\n",
      "2023-05-09 14:22:43,527 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4760237899986473 seconds\n",
      "2023-05-09 14:22:43,527 | INFO : Avg batch val. time: 0.011900594749966183 seconds\n",
      "2023-05-09 14:22:43,528 | INFO : Avg sample val. time: 9.429948296328196e-05 seconds\n",
      "2023-05-09 14:22:43,528 | INFO : Epoch 70 Validation Summary: epoch: 70.000000 | loss: 4404.611017 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 70  67.5% | batch:        27 of        40\t|\tloss: 3182.59\n",
      "Evaluating Epoch 70  70.0% | batch:        28 of        40\t|\tloss: 2321.62\n",
      "Evaluating Epoch 70  72.5% | batch:        29 of        40\t|\tloss: 9184.38\n",
      "Evaluating Epoch 70  75.0% | batch:        30 of        40\t|\tloss: 2326.61\n",
      "Evaluating Epoch 70  77.5% | batch:        31 of        40\t|\tloss: 2111.95\n",
      "Evaluating Epoch 70  80.0% | batch:        32 of        40\t|\tloss: 8878.22\n",
      "Evaluating Epoch 70  82.5% | batch:        33 of        40\t|\tloss: 6812.87\n",
      "Evaluating Epoch 70  85.0% | batch:        34 of        40\t|\tloss: 944.301\n",
      "Evaluating Epoch 70  87.5% | batch:        35 of        40\t|\tloss: 7146.33\n",
      "Evaluating Epoch 70  90.0% | batch:        36 of        40\t|\tloss: 6722.4\n",
      "Evaluating Epoch 70  92.5% | batch:        37 of        40\t|\tloss: 2741.39\n",
      "Evaluating Epoch 70  95.0% | batch:        38 of        40\t|\tloss: 3134.06\n",
      "Evaluating Epoch 70  97.5% | batch:        39 of        40\t|\tloss: 10867.4\n",
      "\n",
      "Training Epoch 71   0.0% | batch:         0 of        94\t|\tloss: 902.402\n",
      "Training Epoch 71   1.1% | batch:         1 of        94\t|\tloss: 1043.63\n",
      "Training Epoch 71   2.1% | batch:         2 of        94\t|\tloss: 1013.75\n",
      "Training Epoch 71   3.2% | batch:         3 of        94\t|\tloss: 747.047\n",
      "Training Epoch 71   4.3% | batch:         4 of        94\t|\tloss: 1225.67\n",
      "Training Epoch 71   5.3% | batch:         5 of        94\t|\tloss: 1096.35\n",
      "Training Epoch 71   6.4% | batch:         6 of        94\t|\tloss: 1727.93\n",
      "Training Epoch 71   7.4% | batch:         7 of        94\t|\tloss: 978.991\n",
      "Training Epoch 71   8.5% | batch:         8 of        94\t|\tloss: 2465.41\n",
      "Training Epoch 71   9.6% | batch:         9 of        94\t|\tloss: 2094.68\n",
      "Training Epoch 71  10.6% | batch:        10 of        94\t|\tloss: 806.322\n",
      "Training Epoch 71  11.7% | batch:        11 of        94\t|\tloss: 1990.06\n",
      "Training Epoch 71  12.8% | batch:        12 of        94\t|\tloss: 715.092\n",
      "Training Epoch 71  13.8% | batch:        13 of        94\t|\tloss: 788.238\n",
      "Training Epoch 71  14.9% | batch:        14 of        94\t|\tloss: 653.27\n",
      "Training Epoch 71  16.0% | batch:        15 of        94\t|\tloss: 1135.83\n",
      "Training Epoch 71  17.0% | batch:        16 of        94\t|\tloss: 693.41\n",
      "Training Epoch 71  18.1% | batch:        17 of        94\t|\tloss: 945.433\n",
      "Training Epoch 71  19.1% | batch:        18 of        94\t|\tloss: 1071.06\n",
      "Training Epoch 71  20.2% | batch:        19 of        94\t|\tloss: 867.469\n",
      "Training Epoch 71  21.3% | batch:        20 of        94\t|\tloss: 834.474\n",
      "Training Epoch 71  22.3% | batch:        21 of        94\t|\tloss: 840.122\n",
      "Training Epoch 71  23.4% | batch:        22 of        94\t|\tloss: 772.594\n",
      "Training Epoch 71  24.5% | batch:        23 of        94\t|\tloss: 930.97\n",
      "Training Epoch 71  25.5% | batch:        24 of        94\t|\tloss: 769.245\n",
      "Training Epoch 71  26.6% | batch:        25 of        94\t|\tloss: 1216.88\n",
      "Training Epoch 71  27.7% | batch:        26 of        94\t|\tloss: 825.653\n",
      "Training Epoch 71  28.7% | batch:        27 of        94\t|\tloss: 1104.89\n",
      "Training Epoch 71  29.8% | batch:        28 of        94\t|\tloss: 697.161\n",
      "Training Epoch 71  30.9% | batch:        29 of        94\t|\tloss: 885.041\n",
      "Training Epoch 71  31.9% | batch:        30 of        94\t|\tloss: 797.305\n",
      "Training Epoch 71  33.0% | batch:        31 of        94\t|\tloss: 1337.73\n",
      "Training Epoch 71  34.0% | batch:        32 of        94\t|\tloss: 1179.74\n",
      "Training Epoch 71  35.1% | batch:        33 of        94\t|\tloss: 2673.33\n",
      "Training Epoch 71  36.2% | batch:        34 of        94\t|\tloss: 1420.51\n",
      "Training Epoch 71  37.2% | batch:        35 of        94\t|\tloss: 1618.39\n",
      "Training Epoch 71  38.3% | batch:        36 of        94\t|\tloss: 1206.01\n",
      "Training Epoch 71  39.4% | batch:        37 of        94\t|\tloss: 1539.18\n",
      "Training Epoch 71  40.4% | batch:        38 of        94\t|\tloss: 1003.95\n",
      "Training Epoch 71  41.5% | batch:        39 of        94\t|\tloss: 2425.01\n",
      "Training Epoch 71  42.6% | batch:        40 of        94\t|\tloss: 1066.29\n",
      "Training Epoch 71  43.6% | batch:        41 of        94\t|\tloss: 669.294\n",
      "Training Epoch 71  44.7% | batch:        42 of        94\t|\tloss: 1057.17\n",
      "Training Epoch 71  45.7% | batch:        43 of        94\t|\tloss: 1105.45\n",
      "Training Epoch 71  46.8% | batch:        44 of        94\t|\tloss: 836.92\n",
      "Training Epoch 71  47.9% | batch:        45 of        94\t|\tloss: 1398.54\n",
      "Training Epoch 71  48.9% | batch:        46 of        94\t|\tloss: 702.265\n",
      "Training Epoch 71  50.0% | batch:        47 of        94\t|\tloss: 966.836\n",
      "Training Epoch 71  51.1% | batch:        48 of        94\t|\tloss: 999.236\n",
      "Training Epoch 71  52.1% | batch:        49 of        94\t|\tloss: 1221.81\n",
      "Training Epoch 71  53.2% | batch:        50 of        94\t|\tloss: 780.773\n",
      "Training Epoch 71  54.3% | batch:        51 of        94\t|\tloss: 1483.08\n",
      "Training Epoch 71  55.3% | batch:        52 of        94\t|\tloss: 755.636\n",
      "Training Epoch 71  56.4% | batch:        53 of        94\t|\tloss: 853.337\n",
      "Training Epoch 71  57.4% | batch:        54 of        94\t|\tloss: 1649.92\n",
      "Training Epoch 71  58.5% | batch:        55 of        94\t|\tloss: 799.618\n",
      "Training Epoch 71  59.6% | batch:        56 of        94\t|\tloss: 765.875\n",
      "Training Epoch 71  60.6% | batch:        57 of        94\t|\tloss: 1049.69\n",
      "Training Epoch 71  61.7% | batch:        58 of        94\t|\tloss: 1299.06\n",
      "Training Epoch 71  62.8% | batch:        59 of        94\t|\tloss: 1069.96\n",
      "Training Epoch 71  63.8% | batch:        60 of        94\t|\tloss: 695.886\n",
      "Training Epoch 71  64.9% | batch:        61 of        94\t|\tloss: 1735.16\n",
      "Training Epoch 71  66.0% | batch:        62 of        94\t|\tloss: 957.108\n",
      "Training Epoch 71  67.0% | batch:        63 of        94\t|\tloss: 1035.16\n",
      "Training Epoch 71  68.1% | batch:        64 of        94\t|\tloss: 746.428\n",
      "Training Epoch 71  69.1% | batch:        65 of        94\t|\tloss: 831.827\n",
      "Training Epoch 71  70.2% | batch:        66 of        94\t|\tloss: 815.168\n",
      "Training Epoch 71  71.3% | batch:        67 of        94\t|\tloss: 1026.22\n",
      "Training Epoch 71  72.3% | batch:        68 of        94\t|\tloss: 1630.46\n",
      "Training Epoch 71  73.4% | batch:        69 of        94\t|\tloss: 842.379\n",
      "Training Epoch 71  74.5% | batch:        70 of        94\t|\tloss: 1491.69\n",
      "Training Epoch 71  75.5% | batch:        71 of        94\t|\tloss: 1429.3\n",
      "Training Epoch 71  76.6% | batch:        72 of        94\t|\tloss: 1130.92\n",
      "Training Epoch 71  77.7% | batch:        73 of        94\t|\tloss: 964.771\n",
      "Training Epoch 71  78.7% | batch:        74 of        94\t|\tloss: 775.005\n",
      "Training Epoch 71  79.8% | batch:        75 of        94\t|\tloss: 806.47\n",
      "Training Epoch 71  80.9% | batch:        76 of        94\t|\tloss: 862.154\n",
      "Training Epoch 71  81.9% | batch:        77 of        94\t|\tloss: 1071.14\n",
      "Training Epoch 71  83.0% | batch:        78 of        94\t|\tloss: 1001.33\n",
      "Training Epoch 71  84.0% | batch:        79 of        94\t|\tloss: 894.338\n",
      "Training Epoch 71  85.1% | batch:        80 of        94\t|\tloss: 808.563\n",
      "Training Epoch 71  86.2% | batch:        81 of        94\t|\tloss: 918.047\n",
      "Training Epoch 71  87.2% | batch:        82 of        94\t|\tloss: 736.563\n",
      "Training Epoch 71  88.3% | batch:        83 of        94\t|\tloss: 927.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:45,266 | INFO : Epoch 71 Training Summary: epoch: 71.000000 | loss: 1092.958721 | \n",
      "2023-05-09 14:22:45,267 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7166638374328613 seconds\n",
      "\n",
      "2023-05-09 14:22:45,268 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8273849856685584 seconds\n",
      "2023-05-09 14:22:45,268 | INFO : Avg batch train. time: 0.019440265804984664 seconds\n",
      "2023-05-09 14:22:45,269 | INFO : Avg sample train. time: 0.00015332983601850633 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 71  89.4% | batch:        84 of        94\t|\tloss: 988.223\n",
      "Training Epoch 71  90.4% | batch:        85 of        94\t|\tloss: 1728.45\n",
      "Training Epoch 71  91.5% | batch:        86 of        94\t|\tloss: 1301.37\n",
      "Training Epoch 71  92.6% | batch:        87 of        94\t|\tloss: 641.622\n",
      "Training Epoch 71  93.6% | batch:        88 of        94\t|\tloss: 1169.88\n",
      "Training Epoch 71  94.7% | batch:        89 of        94\t|\tloss: 679.08\n",
      "Training Epoch 71  95.7% | batch:        90 of        94\t|\tloss: 945.205\n",
      "Training Epoch 71  96.8% | batch:        91 of        94\t|\tloss: 1082.69\n",
      "Training Epoch 71  97.9% | batch:        92 of        94\t|\tloss: 1128.37\n",
      "Training Epoch 71  98.9% | batch:        93 of        94\t|\tloss: 3615.83\n",
      "\n",
      "Training Epoch 72   0.0% | batch:         0 of        94\t|\tloss: 1054.44\n",
      "Training Epoch 72   1.1% | batch:         1 of        94\t|\tloss: 873.349\n",
      "Training Epoch 72   2.1% | batch:         2 of        94\t|\tloss: 1086.11\n",
      "Training Epoch 72   3.2% | batch:         3 of        94\t|\tloss: 838.564\n",
      "Training Epoch 72   4.3% | batch:         4 of        94\t|\tloss: 650.999\n",
      "Training Epoch 72   5.3% | batch:         5 of        94\t|\tloss: 1001.9\n",
      "Training Epoch 72   6.4% | batch:         6 of        94\t|\tloss: 882.565\n",
      "Training Epoch 72   7.4% | batch:         7 of        94\t|\tloss: 874.54\n",
      "Training Epoch 72   8.5% | batch:         8 of        94\t|\tloss: 1006.46\n",
      "Training Epoch 72   9.6% | batch:         9 of        94\t|\tloss: 1368.5\n",
      "Training Epoch 72  10.6% | batch:        10 of        94\t|\tloss: 2927.6\n",
      "Training Epoch 72  11.7% | batch:        11 of        94\t|\tloss: 1658.19\n",
      "Training Epoch 72  12.8% | batch:        12 of        94\t|\tloss: 1046.08\n",
      "Training Epoch 72  13.8% | batch:        13 of        94\t|\tloss: 950.816\n",
      "Training Epoch 72  14.9% | batch:        14 of        94\t|\tloss: 1197.72\n",
      "Training Epoch 72  16.0% | batch:        15 of        94\t|\tloss: 940.127\n",
      "Training Epoch 72  17.0% | batch:        16 of        94\t|\tloss: 686.044\n",
      "Training Epoch 72  18.1% | batch:        17 of        94\t|\tloss: 814.083\n",
      "Training Epoch 72  19.1% | batch:        18 of        94\t|\tloss: 2554.99\n",
      "Training Epoch 72  20.2% | batch:        19 of        94\t|\tloss: 1747.03\n",
      "Training Epoch 72  21.3% | batch:        20 of        94\t|\tloss: 1246.39\n",
      "Training Epoch 72  22.3% | batch:        21 of        94\t|\tloss: 703.133\n",
      "Training Epoch 72  23.4% | batch:        22 of        94\t|\tloss: 1027.88\n",
      "Training Epoch 72  24.5% | batch:        23 of        94\t|\tloss: 1207.52\n",
      "Training Epoch 72  25.5% | batch:        24 of        94\t|\tloss: 992.042\n",
      "Training Epoch 72  26.6% | batch:        25 of        94\t|\tloss: 1119.98\n",
      "Training Epoch 72  27.7% | batch:        26 of        94\t|\tloss: 2066.03\n",
      "Training Epoch 72  28.7% | batch:        27 of        94\t|\tloss: 861.848\n",
      "Training Epoch 72  29.8% | batch:        28 of        94\t|\tloss: 1885.08\n",
      "Training Epoch 72  30.9% | batch:        29 of        94\t|\tloss: 1403.91\n",
      "Training Epoch 72  31.9% | batch:        30 of        94\t|\tloss: 1605.34\n",
      "Training Epoch 72  33.0% | batch:        31 of        94\t|\tloss: 998.376\n",
      "Training Epoch 72  34.0% | batch:        32 of        94\t|\tloss: 1148.12\n",
      "Training Epoch 72  35.1% | batch:        33 of        94\t|\tloss: 1058.38\n",
      "Training Epoch 72  36.2% | batch:        34 of        94\t|\tloss: 1439.52\n",
      "Training Epoch 72  37.2% | batch:        35 of        94\t|\tloss: 2181.86\n",
      "Training Epoch 72  38.3% | batch:        36 of        94\t|\tloss: 880.744\n",
      "Training Epoch 72  39.4% | batch:        37 of        94\t|\tloss: 978.234\n",
      "Training Epoch 72  40.4% | batch:        38 of        94\t|\tloss: 891.313\n",
      "Training Epoch 72  41.5% | batch:        39 of        94\t|\tloss: 913.288\n",
      "Training Epoch 72  42.6% | batch:        40 of        94\t|\tloss: 746.564\n",
      "Training Epoch 72  43.6% | batch:        41 of        94\t|\tloss: 1303.76\n",
      "Training Epoch 72  44.7% | batch:        42 of        94\t|\tloss: 891.331\n",
      "Training Epoch 72  45.7% | batch:        43 of        94\t|\tloss: 877.887\n",
      "Training Epoch 72  46.8% | batch:        44 of        94\t|\tloss: 755.803\n",
      "Training Epoch 72  47.9% | batch:        45 of        94\t|\tloss: 818.43\n",
      "Training Epoch 72  48.9% | batch:        46 of        94\t|\tloss: 1282.32\n",
      "Training Epoch 72  50.0% | batch:        47 of        94\t|\tloss: 759.475\n",
      "Training Epoch 72  51.1% | batch:        48 of        94\t|\tloss: 1704.28\n",
      "Training Epoch 72  52.1% | batch:        49 of        94\t|\tloss: 1130.91\n",
      "Training Epoch 72  53.2% | batch:        50 of        94\t|\tloss: 1023.36\n",
      "Training Epoch 72  54.3% | batch:        51 of        94\t|\tloss: 719.07\n",
      "Training Epoch 72  55.3% | batch:        52 of        94\t|\tloss: 703.092\n",
      "Training Epoch 72  56.4% | batch:        53 of        94\t|\tloss: 1067.35\n",
      "Training Epoch 72  57.4% | batch:        54 of        94\t|\tloss: 1098.12\n",
      "Training Epoch 72  58.5% | batch:        55 of        94\t|\tloss: 742.11\n",
      "Training Epoch 72  59.6% | batch:        56 of        94\t|\tloss: 1156.48\n",
      "Training Epoch 72  60.6% | batch:        57 of        94\t|\tloss: 3330.8\n",
      "Training Epoch 72  61.7% | batch:        58 of        94\t|\tloss: 731.351\n",
      "Training Epoch 72  62.8% | batch:        59 of        94\t|\tloss: 2087.31\n",
      "Training Epoch 72  63.8% | batch:        60 of        94\t|\tloss: 748.291\n",
      "Training Epoch 72  64.9% | batch:        61 of        94\t|\tloss: 882.728\n",
      "Training Epoch 72  66.0% | batch:        62 of        94\t|\tloss: 934.416\n",
      "Training Epoch 72  67.0% | batch:        63 of        94\t|\tloss: 2009.68\n",
      "Training Epoch 72  68.1% | batch:        64 of        94\t|\tloss: 621.035\n",
      "Training Epoch 72  69.1% | batch:        65 of        94\t|\tloss: 837.994\n",
      "Training Epoch 72  70.2% | batch:        66 of        94\t|\tloss: 787.126\n",
      "Training Epoch 72  71.3% | batch:        67 of        94\t|\tloss: 1126.67\n",
      "Training Epoch 72  72.3% | batch:        68 of        94\t|\tloss: 813.739\n",
      "Training Epoch 72  73.4% | batch:        69 of        94\t|\tloss: 731.215\n",
      "Training Epoch 72  74.5% | batch:        70 of        94\t|\tloss: 926.826\n",
      "Training Epoch 72  75.5% | batch:        71 of        94\t|\tloss: 936.63\n",
      "Training Epoch 72  76.6% | batch:        72 of        94\t|\tloss: 972.722\n",
      "Training Epoch 72  77.7% | batch:        73 of        94\t|\tloss: 1058.24\n",
      "Training Epoch 72  78.7% | batch:        74 of        94\t|\tloss: 872.125\n",
      "Training Epoch 72  79.8% | batch:        75 of        94\t|\tloss: 821.31\n",
      "Training Epoch 72  80.9% | batch:        76 of        94\t|\tloss: 849.252\n",
      "Training Epoch 72  81.9% | batch:        77 of        94\t|\tloss: 762.101\n",
      "Training Epoch 72  83.0% | batch:        78 of        94\t|\tloss: 874.173\n",
      "Training Epoch 72  84.0% | batch:        79 of        94\t|\tloss: 1119.18\n",
      "Training Epoch 72  85.1% | batch:        80 of        94\t|\tloss: 1511.31\n",
      "Training Epoch 72  86.2% | batch:        81 of        94\t|\tloss: 874.674\n",
      "Training Epoch 72  87.2% | batch:        82 of        94\t|\tloss: 1046.44\n",
      "Training Epoch 72  88.3% | batch:        83 of        94\t|\tloss: 2096.95\n",
      "Training Epoch 72  89.4% | batch:        84 of        94\t|\tloss: 924.353\n",
      "Training Epoch 72  90.4% | batch:        85 of        94\t|\tloss: 530.535\n",
      "Training Epoch 72  91.5% | batch:        86 of        94\t|\tloss: 988.013\n",
      "Training Epoch 72  92.6% | batch:        87 of        94\t|\tloss: 1390.3\n",
      "Training Epoch 72  93.6% | batch:        88 of        94\t|\tloss: 1008.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:47,093 | INFO : Epoch 72 Training Summary: epoch: 72.000000 | loss: 1126.459050 | \n",
      "2023-05-09 14:22:47,093 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8038365840911865 seconds\n",
      "\n",
      "2023-05-09 14:22:47,094 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8270579245355394 seconds\n",
      "2023-05-09 14:22:47,095 | INFO : Avg batch train. time: 0.019436786431229144 seconds\n",
      "2023-05-09 14:22:47,095 | INFO : Avg sample train. time: 0.00015330239339952505 seconds\n",
      "2023-05-09 14:22:47,095 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 72  94.7% | batch:        89 of        94\t|\tloss: 1249.79\n",
      "Training Epoch 72  95.7% | batch:        90 of        94\t|\tloss: 1017.47\n",
      "Training Epoch 72  96.8% | batch:        91 of        94\t|\tloss: 676.683\n",
      "Training Epoch 72  97.9% | batch:        92 of        94\t|\tloss: 1066.23\n",
      "Training Epoch 72  98.9% | batch:        93 of        94\t|\tloss: 1084.53\n",
      "\n",
      "Evaluating Epoch 72   0.0% | batch:         0 of        40\t|\tloss: 6946.32\n",
      "Evaluating Epoch 72   2.5% | batch:         1 of        40\t|\tloss: 1337.73\n",
      "Evaluating Epoch 72   5.0% | batch:         2 of        40\t|\tloss: 3488.67\n",
      "Evaluating Epoch 72   7.5% | batch:         3 of        40\t|\tloss: 6784.58\n",
      "Evaluating Epoch 72  10.0% | batch:         4 of        40\t|\tloss: 2537.21\n",
      "Evaluating Epoch 72  12.5% | batch:         5 of        40\t|\tloss: 2362.42\n",
      "Evaluating Epoch 72  15.0% | batch:         6 of        40\t|\tloss: 8421.61\n",
      "Evaluating Epoch 72  17.5% | batch:         7 of        40\t|\tloss: 3723.22\n",
      "Evaluating Epoch 72  20.0% | batch:         8 of        40\t|\tloss: 2993.64\n",
      "Evaluating Epoch 72  22.5% | batch:         9 of        40\t|\tloss: 2166.54\n",
      "Evaluating Epoch 72  25.0% | batch:        10 of        40\t|\tloss: 5415.92\n",
      "Evaluating Epoch 72  27.5% | batch:        11 of        40\t|\tloss: 1605.41\n",
      "Evaluating Epoch 72  30.0% | batch:        12 of        40\t|\tloss: 6477.34\n",
      "Evaluating Epoch 72  32.5% | batch:        13 of        40\t|\tloss: 3645.42\n",
      "Evaluating Epoch 72  35.0% | batch:        14 of        40\t|\tloss: 2443.77\n",
      "Evaluating Epoch 72  37.5% | batch:        15 of        40\t|\tloss: 3844.63\n",
      "Evaluating Epoch 72  40.0% | batch:        16 of        40\t|\tloss: 4523.97\n",
      "Evaluating Epoch 72  42.5% | batch:        17 of        40\t|\tloss: 3358.55\n",
      "Evaluating Epoch 72  45.0% | batch:        18 of        40\t|\tloss: 2220.95\n",
      "Evaluating Epoch 72  47.5% | batch:        19 of        40\t|\tloss: 6528.55\n",
      "Evaluating Epoch 72  50.0% | batch:        20 of        40\t|\tloss: 5831.2\n",
      "Evaluating Epoch 72  52.5% | batch:        21 of        40\t|\tloss: 1293.83\n",
      "Evaluating Epoch 72  55.0% | batch:        22 of        40\t|\tloss: 4146.5\n",
      "Evaluating Epoch 72  57.5% | batch:        23 of        40\t|\tloss: 3727.91\n",
      "Evaluating Epoch 72  60.0% | batch:        24 of        40\t|\tloss: 1909.79\n",
      "Evaluating Epoch 72  62.5% | batch:        25 of        40\t|\tloss: 3779.62\n",
      "Evaluating Epoch 72  65.0% | batch:        26 of        40\t|\tloss: 11045.6\n",
      "Evaluating Epoch 72  67.5% | batch:        27 of        40\t|\tloss: 3201.14\n",
      "Evaluating Epoch 72  70.0% | batch:        28 of        40\t|\tloss: 1810.27\n",
      "Evaluating Epoch 72  72.5% | batch:        29 of        40\t|\tloss: 10220.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:47,550 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4539988040924072 seconds\n",
      "\n",
      "2023-05-09 14:22:47,550 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47544418510637787 seconds\n",
      "2023-05-09 14:22:47,551 | INFO : Avg batch val. time: 0.011886104627659447 seconds\n",
      "2023-05-09 14:22:47,551 | INFO : Avg sample val. time: 9.41846642445281e-05 seconds\n",
      "2023-05-09 14:22:47,552 | INFO : Epoch 72 Validation Summary: epoch: 72.000000 | loss: 4346.108815 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 72  75.0% | batch:        30 of        40\t|\tloss: 2156.44\n",
      "Evaluating Epoch 72  77.5% | batch:        31 of        40\t|\tloss: 1840.65\n",
      "Evaluating Epoch 72  80.0% | batch:        32 of        40\t|\tloss: 7310.8\n",
      "Evaluating Epoch 72  82.5% | batch:        33 of        40\t|\tloss: 6785.8\n",
      "Evaluating Epoch 72  85.0% | batch:        34 of        40\t|\tloss: 1194.17\n",
      "Evaluating Epoch 72  87.5% | batch:        35 of        40\t|\tloss: 5687.61\n",
      "Evaluating Epoch 72  90.0% | batch:        36 of        40\t|\tloss: 6926.82\n",
      "Evaluating Epoch 72  92.5% | batch:        37 of        40\t|\tloss: 3050.14\n",
      "Evaluating Epoch 72  95.0% | batch:        38 of        40\t|\tloss: 3610.34\n",
      "Evaluating Epoch 72  97.5% | batch:        39 of        40\t|\tloss: 11528.5\n",
      "\n",
      "Training Epoch 73   0.0% | batch:         0 of        94\t|\tloss: 931.675\n",
      "Training Epoch 73   1.1% | batch:         1 of        94\t|\tloss: 722.681\n",
      "Training Epoch 73   2.1% | batch:         2 of        94\t|\tloss: 626.855\n",
      "Training Epoch 73   3.2% | batch:         3 of        94\t|\tloss: 856.991\n",
      "Training Epoch 73   4.3% | batch:         4 of        94\t|\tloss: 1312.21\n",
      "Training Epoch 73   5.3% | batch:         5 of        94\t|\tloss: 763.066\n",
      "Training Epoch 73   6.4% | batch:         6 of        94\t|\tloss: 834.67\n",
      "Training Epoch 73   7.4% | batch:         7 of        94\t|\tloss: 1179.87\n",
      "Training Epoch 73   8.5% | batch:         8 of        94\t|\tloss: 1979.63\n",
      "Training Epoch 73   9.6% | batch:         9 of        94\t|\tloss: 1689.42\n",
      "Training Epoch 73  10.6% | batch:        10 of        94\t|\tloss: 676.568\n",
      "Training Epoch 73  11.7% | batch:        11 of        94\t|\tloss: 935.2\n",
      "Training Epoch 73  12.8% | batch:        12 of        94\t|\tloss: 2311.58\n",
      "Training Epoch 73  13.8% | batch:        13 of        94\t|\tloss: 831.995\n",
      "Training Epoch 73  14.9% | batch:        14 of        94\t|\tloss: 1122.79\n",
      "Training Epoch 73  16.0% | batch:        15 of        94\t|\tloss: 1468.66\n",
      "Training Epoch 73  17.0% | batch:        16 of        94\t|\tloss: 1596.29\n",
      "Training Epoch 73  18.1% | batch:        17 of        94\t|\tloss: 1052.76\n",
      "Training Epoch 73  19.1% | batch:        18 of        94\t|\tloss: 649.058\n",
      "Training Epoch 73  20.2% | batch:        19 of        94\t|\tloss: 1078.33\n",
      "Training Epoch 73  21.3% | batch:        20 of        94\t|\tloss: 906.789\n",
      "Training Epoch 73  22.3% | batch:        21 of        94\t|\tloss: 993.906\n",
      "Training Epoch 73  23.4% | batch:        22 of        94\t|\tloss: 666.314\n",
      "Training Epoch 73  24.5% | batch:        23 of        94\t|\tloss: 946.289\n",
      "Training Epoch 73  25.5% | batch:        24 of        94\t|\tloss: 840.621\n",
      "Training Epoch 73  26.6% | batch:        25 of        94\t|\tloss: 911.275\n",
      "Training Epoch 73  27.7% | batch:        26 of        94\t|\tloss: 1127.51\n",
      "Training Epoch 73  28.7% | batch:        27 of        94\t|\tloss: 1136.55\n",
      "Training Epoch 73  29.8% | batch:        28 of        94\t|\tloss: 2342.58\n",
      "Training Epoch 73  30.9% | batch:        29 of        94\t|\tloss: 933.608\n",
      "Training Epoch 73  31.9% | batch:        30 of        94\t|\tloss: 885.746\n",
      "Training Epoch 73  33.0% | batch:        31 of        94\t|\tloss: 828.748\n",
      "Training Epoch 73  34.0% | batch:        32 of        94\t|\tloss: 1078.28\n",
      "Training Epoch 73  35.1% | batch:        33 of        94\t|\tloss: 814.455\n",
      "Training Epoch 73  36.2% | batch:        34 of        94\t|\tloss: 837.106\n",
      "Training Epoch 73  37.2% | batch:        35 of        94\t|\tloss: 1727.22\n",
      "Training Epoch 73  38.3% | batch:        36 of        94\t|\tloss: 1420.88\n",
      "Training Epoch 73  39.4% | batch:        37 of        94\t|\tloss: 728.156\n",
      "Training Epoch 73  40.4% | batch:        38 of        94\t|\tloss: 981.174\n",
      "Training Epoch 73  41.5% | batch:        39 of        94\t|\tloss: 976.557\n",
      "Training Epoch 73  42.6% | batch:        40 of        94\t|\tloss: 914.967\n",
      "Training Epoch 73  43.6% | batch:        41 of        94\t|\tloss: 904.635\n",
      "Training Epoch 73  44.7% | batch:        42 of        94\t|\tloss: 986.741\n",
      "Training Epoch 73  45.7% | batch:        43 of        94\t|\tloss: 839.588\n",
      "Training Epoch 73  46.8% | batch:        44 of        94\t|\tloss: 955.257\n",
      "Training Epoch 73  47.9% | batch:        45 of        94\t|\tloss: 934.722\n",
      "Training Epoch 73  48.9% | batch:        46 of        94\t|\tloss: 1105.81\n",
      "Training Epoch 73  50.0% | batch:        47 of        94\t|\tloss: 2115.67\n",
      "Training Epoch 73  51.1% | batch:        48 of        94\t|\tloss: 901.03\n",
      "Training Epoch 73  52.1% | batch:        49 of        94\t|\tloss: 2232.33\n",
      "Training Epoch 73  53.2% | batch:        50 of        94\t|\tloss: 887.897\n",
      "Training Epoch 73  54.3% | batch:        51 of        94\t|\tloss: 952.913\n",
      "Training Epoch 73  55.3% | batch:        52 of        94\t|\tloss: 902.435\n",
      "Training Epoch 73  56.4% | batch:        53 of        94\t|\tloss: 1113.88\n",
      "Training Epoch 73  57.4% | batch:        54 of        94\t|\tloss: 941.896\n",
      "Training Epoch 73  58.5% | batch:        55 of        94\t|\tloss: 1282.34\n",
      "Training Epoch 73  59.6% | batch:        56 of        94\t|\tloss: 1123.21\n",
      "Training Epoch 73  60.6% | batch:        57 of        94\t|\tloss: 2261.55\n",
      "Training Epoch 73  61.7% | batch:        58 of        94\t|\tloss: 952.069\n",
      "Training Epoch 73  62.8% | batch:        59 of        94\t|\tloss: 943.512\n",
      "Training Epoch 73  63.8% | batch:        60 of        94\t|\tloss: 1824.8\n",
      "Training Epoch 73  64.9% | batch:        61 of        94\t|\tloss: 929.223\n",
      "Training Epoch 73  66.0% | batch:        62 of        94\t|\tloss: 1754.58\n",
      "Training Epoch 73  67.0% | batch:        63 of        94\t|\tloss: 1507.35\n",
      "Training Epoch 73  68.1% | batch:        64 of        94\t|\tloss: 1157.65\n",
      "Training Epoch 73  69.1% | batch:        65 of        94\t|\tloss: 996.155\n",
      "Training Epoch 73  70.2% | batch:        66 of        94\t|\tloss: 1544.14\n",
      "Training Epoch 73  71.3% | batch:        67 of        94\t|\tloss: 1371.8\n",
      "Training Epoch 73  72.3% | batch:        68 of        94\t|\tloss: 1144.7\n",
      "Training Epoch 73  73.4% | batch:        69 of        94\t|\tloss: 1128.13\n",
      "Training Epoch 73  74.5% | batch:        70 of        94\t|\tloss: 1209.17\n",
      "Training Epoch 73  75.5% | batch:        71 of        94\t|\tloss: 777.224\n",
      "Training Epoch 73  76.6% | batch:        72 of        94\t|\tloss: 1036.93\n",
      "Training Epoch 73  77.7% | batch:        73 of        94\t|\tloss: 992.73\n",
      "Training Epoch 73  78.7% | batch:        74 of        94\t|\tloss: 913.444\n",
      "Training Epoch 73  79.8% | batch:        75 of        94\t|\tloss: 774.118\n",
      "Training Epoch 73  80.9% | batch:        76 of        94\t|\tloss: 1195.79\n",
      "Training Epoch 73  81.9% | batch:        77 of        94\t|\tloss: 945.997\n",
      "Training Epoch 73  83.0% | batch:        78 of        94\t|\tloss: 816.527\n",
      "Training Epoch 73  84.0% | batch:        79 of        94\t|\tloss: 1138.2\n",
      "Training Epoch 73  85.1% | batch:        80 of        94\t|\tloss: 1524.3\n",
      "Training Epoch 73  86.2% | batch:        81 of        94\t|\tloss: 1149.66\n",
      "Training Epoch 73  87.2% | batch:        82 of        94\t|\tloss: 963.656\n",
      "Training Epoch 73  88.3% | batch:        83 of        94\t|\tloss: 868.532\n",
      "Training Epoch 73  89.4% | batch:        84 of        94\t|\tloss: 830.398\n",
      "Training Epoch 73  90.4% | batch:        85 of        94\t|\tloss: 1055.25\n",
      "Training Epoch 73  91.5% | batch:        86 of        94\t|\tloss: 978.956\n",
      "Training Epoch 73  92.6% | batch:        87 of        94\t|\tloss: 1065.92\n",
      "Training Epoch 73  93.6% | batch:        88 of        94\t|\tloss: 1006.29\n",
      "Training Epoch 73  94.7% | batch:        89 of        94\t|\tloss: 854.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:49,444 | INFO : Epoch 73 Training Summary: epoch: 73.000000 | loss: 1116.178488 | \n",
      "2023-05-09 14:22:49,445 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8709380626678467 seconds\n",
      "\n",
      "2023-05-09 14:22:49,445 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8276590223181737 seconds\n",
      "2023-05-09 14:22:49,445 | INFO : Avg batch train. time: 0.019443181088491208 seconds\n",
      "2023-05-09 14:22:49,446 | INFO : Avg sample train. time: 0.00015335282952829113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 73  95.7% | batch:        90 of        94\t|\tloss: 884.023\n",
      "Training Epoch 73  96.8% | batch:        91 of        94\t|\tloss: 1531.77\n",
      "Training Epoch 73  97.9% | batch:        92 of        94\t|\tloss: 1006.33\n",
      "Training Epoch 73  98.9% | batch:        93 of        94\t|\tloss: 837.877\n",
      "\n",
      "Training Epoch 74   0.0% | batch:         0 of        94\t|\tloss: 1714.11\n",
      "Training Epoch 74   1.1% | batch:         1 of        94\t|\tloss: 1258.22\n",
      "Training Epoch 74   2.1% | batch:         2 of        94\t|\tloss: 718.372\n",
      "Training Epoch 74   3.2% | batch:         3 of        94\t|\tloss: 916.236\n",
      "Training Epoch 74   4.3% | batch:         4 of        94\t|\tloss: 1439.35\n",
      "Training Epoch 74   5.3% | batch:         5 of        94\t|\tloss: 724.829\n",
      "Training Epoch 74   6.4% | batch:         6 of        94\t|\tloss: 1185.23\n",
      "Training Epoch 74   7.4% | batch:         7 of        94\t|\tloss: 1311.9\n",
      "Training Epoch 74   8.5% | batch:         8 of        94\t|\tloss: 881.364\n",
      "Training Epoch 74   9.6% | batch:         9 of        94\t|\tloss: 1053.3\n",
      "Training Epoch 74  10.6% | batch:        10 of        94\t|\tloss: 921.11\n",
      "Training Epoch 74  11.7% | batch:        11 of        94\t|\tloss: 669.52\n",
      "Training Epoch 74  12.8% | batch:        12 of        94\t|\tloss: 683.169\n",
      "Training Epoch 74  13.8% | batch:        13 of        94\t|\tloss: 1351.83\n",
      "Training Epoch 74  14.9% | batch:        14 of        94\t|\tloss: 1489.99\n",
      "Training Epoch 74  16.0% | batch:        15 of        94\t|\tloss: 769.078\n",
      "Training Epoch 74  17.0% | batch:        16 of        94\t|\tloss: 881.504\n",
      "Training Epoch 74  18.1% | batch:        17 of        94\t|\tloss: 1114.14\n",
      "Training Epoch 74  19.1% | batch:        18 of        94\t|\tloss: 1878.16\n",
      "Training Epoch 74  20.2% | batch:        19 of        94\t|\tloss: 851.134\n",
      "Training Epoch 74  21.3% | batch:        20 of        94\t|\tloss: 1112.71\n",
      "Training Epoch 74  22.3% | batch:        21 of        94\t|\tloss: 2110.42\n",
      "Training Epoch 74  23.4% | batch:        22 of        94\t|\tloss: 886.864\n",
      "Training Epoch 74  24.5% | batch:        23 of        94\t|\tloss: 1390.17\n",
      "Training Epoch 74  25.5% | batch:        24 of        94\t|\tloss: 1517.58\n",
      "Training Epoch 74  26.6% | batch:        25 of        94\t|\tloss: 1204.69\n",
      "Training Epoch 74  27.7% | batch:        26 of        94\t|\tloss: 1128.1\n",
      "Training Epoch 74  28.7% | batch:        27 of        94\t|\tloss: 1176.52\n",
      "Training Epoch 74  29.8% | batch:        28 of        94\t|\tloss: 911.746\n",
      "Training Epoch 74  30.9% | batch:        29 of        94\t|\tloss: 858.226\n",
      "Training Epoch 74  31.9% | batch:        30 of        94\t|\tloss: 936.468\n",
      "Training Epoch 74  33.0% | batch:        31 of        94\t|\tloss: 1184.68\n",
      "Training Epoch 74  34.0% | batch:        32 of        94\t|\tloss: 808.932\n",
      "Training Epoch 74  35.1% | batch:        33 of        94\t|\tloss: 1136.12\n",
      "Training Epoch 74  36.2% | batch:        34 of        94\t|\tloss: 1152.28\n",
      "Training Epoch 74  37.2% | batch:        35 of        94\t|\tloss: 1008.14\n",
      "Training Epoch 74  38.3% | batch:        36 of        94\t|\tloss: 965.267\n",
      "Training Epoch 74  39.4% | batch:        37 of        94\t|\tloss: 1007.62\n",
      "Training Epoch 74  40.4% | batch:        38 of        94\t|\tloss: 772.961\n",
      "Training Epoch 74  41.5% | batch:        39 of        94\t|\tloss: 1438.22\n",
      "Training Epoch 74  42.6% | batch:        40 of        94\t|\tloss: 778.599\n",
      "Training Epoch 74  43.6% | batch:        41 of        94\t|\tloss: 590.143\n",
      "Training Epoch 74  44.7% | batch:        42 of        94\t|\tloss: 973.469\n",
      "Training Epoch 74  45.7% | batch:        43 of        94\t|\tloss: 1478.51\n",
      "Training Epoch 74  46.8% | batch:        44 of        94\t|\tloss: 846.288\n",
      "Training Epoch 74  47.9% | batch:        45 of        94\t|\tloss: 621.345\n",
      "Training Epoch 74  48.9% | batch:        46 of        94\t|\tloss: 960.582\n",
      "Training Epoch 74  50.0% | batch:        47 of        94\t|\tloss: 803.554\n",
      "Training Epoch 74  51.1% | batch:        48 of        94\t|\tloss: 1277.17\n",
      "Training Epoch 74  52.1% | batch:        49 of        94\t|\tloss: 1192.56\n",
      "Training Epoch 74  53.2% | batch:        50 of        94\t|\tloss: 789.977\n",
      "Training Epoch 74  54.3% | batch:        51 of        94\t|\tloss: 716.757\n",
      "Training Epoch 74  55.3% | batch:        52 of        94\t|\tloss: 796.588\n",
      "Training Epoch 74  56.4% | batch:        53 of        94\t|\tloss: 794.218\n",
      "Training Epoch 74  57.4% | batch:        54 of        94\t|\tloss: 904.081\n",
      "Training Epoch 74  58.5% | batch:        55 of        94\t|\tloss: 1338.23\n",
      "Training Epoch 74  59.6% | batch:        56 of        94\t|\tloss: 1394.31\n",
      "Training Epoch 74  60.6% | batch:        57 of        94\t|\tloss: 887.763\n",
      "Training Epoch 74  61.7% | batch:        58 of        94\t|\tloss: 900.501\n",
      "Training Epoch 74  62.8% | batch:        59 of        94\t|\tloss: 739.512\n",
      "Training Epoch 74  63.8% | batch:        60 of        94\t|\tloss: 767.04\n",
      "Training Epoch 74  64.9% | batch:        61 of        94\t|\tloss: 1122.24\n",
      "Training Epoch 74  66.0% | batch:        62 of        94\t|\tloss: 1233.06\n",
      "Training Epoch 74  67.0% | batch:        63 of        94\t|\tloss: 980.024\n",
      "Training Epoch 74  68.1% | batch:        64 of        94\t|\tloss: 894.703\n",
      "Training Epoch 74  69.1% | batch:        65 of        94\t|\tloss: 1037.93\n",
      "Training Epoch 74  70.2% | batch:        66 of        94\t|\tloss: 1211.75\n",
      "Training Epoch 74  71.3% | batch:        67 of        94\t|\tloss: 843.77\n",
      "Training Epoch 74  72.3% | batch:        68 of        94\t|\tloss: 992.051\n",
      "Training Epoch 74  73.4% | batch:        69 of        94\t|\tloss: 1494.9\n",
      "Training Epoch 74  74.5% | batch:        70 of        94\t|\tloss: 708.274\n",
      "Training Epoch 74  75.5% | batch:        71 of        94\t|\tloss: 817.109\n",
      "Training Epoch 74  76.6% | batch:        72 of        94\t|\tloss: 975.394\n",
      "Training Epoch 74  77.7% | batch:        73 of        94\t|\tloss: 2589.04\n",
      "Training Epoch 74  78.7% | batch:        74 of        94\t|\tloss: 1140.38\n",
      "Training Epoch 74  79.8% | batch:        75 of        94\t|\tloss: 1105.39\n",
      "Training Epoch 74  80.9% | batch:        76 of        94\t|\tloss: 1191.17\n",
      "Training Epoch 74  81.9% | batch:        77 of        94\t|\tloss: 1066.53\n",
      "Training Epoch 74  83.0% | batch:        78 of        94\t|\tloss: 855.401\n",
      "Training Epoch 74  84.0% | batch:        79 of        94\t|\tloss: 987.537\n",
      "Training Epoch 74  85.1% | batch:        80 of        94\t|\tloss: 1228.67\n",
      "Training Epoch 74  86.2% | batch:        81 of        94\t|\tloss: 1641.29\n",
      "Training Epoch 74  87.2% | batch:        82 of        94\t|\tloss: 1057.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:51,281 | INFO : Epoch 74 Training Summary: epoch: 74.000000 | loss: 1062.219376 | \n",
      "2023-05-09 14:22:51,281 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8141100406646729 seconds\n",
      "\n",
      "2023-05-09 14:22:51,282 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.827475927971505 seconds\n",
      "2023-05-09 14:22:51,282 | INFO : Avg batch train. time: 0.019441233276292606 seconds\n",
      "2023-05-09 14:22:51,282 | INFO : Avg sample train. time: 0.00015333746668665086 seconds\n",
      "2023-05-09 14:22:51,283 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 74  88.3% | batch:        83 of        94\t|\tloss: 1035.01\n",
      "Training Epoch 74  89.4% | batch:        84 of        94\t|\tloss: 997.45\n",
      "Training Epoch 74  90.4% | batch:        85 of        94\t|\tloss: 653.328\n",
      "Training Epoch 74  91.5% | batch:        86 of        94\t|\tloss: 850.187\n",
      "Training Epoch 74  92.6% | batch:        87 of        94\t|\tloss: 730.848\n",
      "Training Epoch 74  93.6% | batch:        88 of        94\t|\tloss: 1493.14\n",
      "Training Epoch 74  94.7% | batch:        89 of        94\t|\tloss: 1209.11\n",
      "Training Epoch 74  95.7% | batch:        90 of        94\t|\tloss: 765.684\n",
      "Training Epoch 74  96.8% | batch:        91 of        94\t|\tloss: 994.97\n",
      "Training Epoch 74  97.9% | batch:        92 of        94\t|\tloss: 884.018\n",
      "Training Epoch 74  98.9% | batch:        93 of        94\t|\tloss: 392.306\n",
      "\n",
      "Evaluating Epoch 74   0.0% | batch:         0 of        40\t|\tloss: 7152.71\n",
      "Evaluating Epoch 74   2.5% | batch:         1 of        40\t|\tloss: 946.85\n",
      "Evaluating Epoch 74   5.0% | batch:         2 of        40\t|\tloss: 3725.25\n",
      "Evaluating Epoch 74   7.5% | batch:         3 of        40\t|\tloss: 6980.37\n",
      "Evaluating Epoch 74  10.0% | batch:         4 of        40\t|\tloss: 2724.85\n",
      "Evaluating Epoch 74  12.5% | batch:         5 of        40\t|\tloss: 2437.54\n",
      "Evaluating Epoch 74  15.0% | batch:         6 of        40\t|\tloss: 8963.34\n",
      "Evaluating Epoch 74  17.5% | batch:         7 of        40\t|\tloss: 3034.44\n",
      "Evaluating Epoch 74  20.0% | batch:         8 of        40\t|\tloss: 2891.7\n",
      "Evaluating Epoch 74  22.5% | batch:         9 of        40\t|\tloss: 2083.32\n",
      "Evaluating Epoch 74  25.0% | batch:        10 of        40\t|\tloss: 5226.58\n",
      "Evaluating Epoch 74  27.5% | batch:        11 of        40\t|\tloss: 1213.96\n",
      "Evaluating Epoch 74  30.0% | batch:        12 of        40\t|\tloss: 6535.03\n",
      "Evaluating Epoch 74  32.5% | batch:        13 of        40\t|\tloss: 3657\n",
      "Evaluating Epoch 74  35.0% | batch:        14 of        40\t|\tloss: 1971.09\n",
      "Evaluating Epoch 74  37.5% | batch:        15 of        40\t|\tloss: 2879.25\n",
      "Evaluating Epoch 74  40.0% | batch:        16 of        40\t|\tloss: 4294.24\n",
      "Evaluating Epoch 74  42.5% | batch:        17 of        40\t|\tloss: 2725.8\n",
      "Evaluating Epoch 74  45.0% | batch:        18 of        40\t|\tloss: 2386.94\n",
      "Evaluating Epoch 74  47.5% | batch:        19 of        40\t|\tloss: 5919.27\n",
      "Evaluating Epoch 74  50.0% | batch:        20 of        40\t|\tloss: 5350.64\n",
      "Evaluating Epoch 74  52.5% | batch:        21 of        40\t|\tloss: 1177.79\n",
      "Evaluating Epoch 74  55.0% | batch:        22 of        40\t|\tloss: 3541.12\n",
      "Evaluating Epoch 74  57.5% | batch:        23 of        40\t|\tloss: 3503.06\n",
      "Evaluating Epoch 74  60.0% | batch:        24 of        40\t|\tloss: 1627.37\n",
      "Evaluating Epoch 74  62.5% | batch:        25 of        40\t|\tloss: 3252.49\n",
      "Evaluating Epoch 74  65.0% | batch:        26 of        40\t|\tloss: 10191.9\n",
      "Evaluating Epoch 74  67.5% | batch:        27 of        40\t|\tloss: 2744.33\n",
      "Evaluating Epoch 74  70.0% | batch:        28 of        40\t|\tloss: 2153.39\n",
      "Evaluating Epoch 74  72.5% | batch:        29 of        40\t|\tloss: 9936.96\n",
      "Evaluating Epoch 74  75.0% | batch:        30 of        40\t|\tloss: 1995.38\n",
      "Evaluating Epoch 74  77.5% | batch:        31 of        40\t|\tloss: 1794.85\n",
      "Evaluating Epoch 74  80.0% | batch:        32 of        40\t|\tloss: 7471.78\n",
      "Evaluating Epoch 74  82.5% | batch:        33 of        40\t|\tloss: 6860.82\n",
      "Evaluating Epoch 74  85.0% | batch:        34 of        40\t|\tloss: 976.067\n",
      "Evaluating Epoch 74  87.5% | batch:        35 of        40\t|\tloss: 5285.92\n",
      "Evaluating Epoch 74  90.0% | batch:        36 of        40\t|\tloss: 6760.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:51,748 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4645247459411621 seconds\n",
      "\n",
      "2023-05-09 14:22:51,748 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4751641994867569 seconds\n",
      "2023-05-09 14:22:51,748 | INFO : Avg batch val. time: 0.011879104987168923 seconds\n",
      "2023-05-09 14:22:51,749 | INFO : Avg sample val. time: 9.412919958137024e-05 seconds\n",
      "2023-05-09 14:22:51,749 | INFO : Epoch 74 Validation Summary: epoch: 74.000000 | loss: 4140.296932 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 74  92.5% | batch:        37 of        40\t|\tloss: 2562.47\n",
      "Evaluating Epoch 74  95.0% | batch:        38 of        40\t|\tloss: 3009.7\n",
      "Evaluating Epoch 74  97.5% | batch:        39 of        40\t|\tloss: 12199.2\n",
      "\n",
      "Training Epoch 75   0.0% | batch:         0 of        94\t|\tloss: 850.695\n",
      "Training Epoch 75   1.1% | batch:         1 of        94\t|\tloss: 828.259\n",
      "Training Epoch 75   2.1% | batch:         2 of        94\t|\tloss: 1429.39\n",
      "Training Epoch 75   3.2% | batch:         3 of        94\t|\tloss: 2098.04\n",
      "Training Epoch 75   4.3% | batch:         4 of        94\t|\tloss: 808.802\n",
      "Training Epoch 75   5.3% | batch:         5 of        94\t|\tloss: 721.427\n",
      "Training Epoch 75   6.4% | batch:         6 of        94\t|\tloss: 954.355\n",
      "Training Epoch 75   7.4% | batch:         7 of        94\t|\tloss: 1891.78\n",
      "Training Epoch 75   8.5% | batch:         8 of        94\t|\tloss: 1044.49\n",
      "Training Epoch 75   9.6% | batch:         9 of        94\t|\tloss: 737.697\n",
      "Training Epoch 75  10.6% | batch:        10 of        94\t|\tloss: 938.316\n",
      "Training Epoch 75  11.7% | batch:        11 of        94\t|\tloss: 939.605\n",
      "Training Epoch 75  12.8% | batch:        12 of        94\t|\tloss: 935.143\n",
      "Training Epoch 75  13.8% | batch:        13 of        94\t|\tloss: 941.866\n",
      "Training Epoch 75  14.9% | batch:        14 of        94\t|\tloss: 822.432\n",
      "Training Epoch 75  16.0% | batch:        15 of        94\t|\tloss: 560.431\n",
      "Training Epoch 75  17.0% | batch:        16 of        94\t|\tloss: 1022.63\n",
      "Training Epoch 75  18.1% | batch:        17 of        94\t|\tloss: 1209.83\n",
      "Training Epoch 75  19.1% | batch:        18 of        94\t|\tloss: 1456.42\n",
      "Training Epoch 75  20.2% | batch:        19 of        94\t|\tloss: 1278.09\n",
      "Training Epoch 75  21.3% | batch:        20 of        94\t|\tloss: 889.563\n",
      "Training Epoch 75  22.3% | batch:        21 of        94\t|\tloss: 907.372\n",
      "Training Epoch 75  23.4% | batch:        22 of        94\t|\tloss: 855.136\n",
      "Training Epoch 75  24.5% | batch:        23 of        94\t|\tloss: 1132.19\n",
      "Training Epoch 75  25.5% | batch:        24 of        94\t|\tloss: 891.525\n",
      "Training Epoch 75  26.6% | batch:        25 of        94\t|\tloss: 521.057\n",
      "Training Epoch 75  27.7% | batch:        26 of        94\t|\tloss: 1271.87\n",
      "Training Epoch 75  28.7% | batch:        27 of        94\t|\tloss: 1175.46\n",
      "Training Epoch 75  29.8% | batch:        28 of        94\t|\tloss: 930.601\n",
      "Training Epoch 75  30.9% | batch:        29 of        94\t|\tloss: 1175.07\n",
      "Training Epoch 75  31.9% | batch:        30 of        94\t|\tloss: 745.358\n",
      "Training Epoch 75  33.0% | batch:        31 of        94\t|\tloss: 608.185\n",
      "Training Epoch 75  34.0% | batch:        32 of        94\t|\tloss: 883.019\n",
      "Training Epoch 75  35.1% | batch:        33 of        94\t|\tloss: 845.25\n",
      "Training Epoch 75  36.2% | batch:        34 of        94\t|\tloss: 1716.73\n",
      "Training Epoch 75  37.2% | batch:        35 of        94\t|\tloss: 958.334\n",
      "Training Epoch 75  38.3% | batch:        36 of        94\t|\tloss: 1395.63\n",
      "Training Epoch 75  39.4% | batch:        37 of        94\t|\tloss: 799.383\n",
      "Training Epoch 75  40.4% | batch:        38 of        94\t|\tloss: 1290.4\n",
      "Training Epoch 75  41.5% | batch:        39 of        94\t|\tloss: 1062.9\n",
      "Training Epoch 75  42.6% | batch:        40 of        94\t|\tloss: 874.54\n",
      "Training Epoch 75  43.6% | batch:        41 of        94\t|\tloss: 1297.99\n",
      "Training Epoch 75  44.7% | batch:        42 of        94\t|\tloss: 735.026\n",
      "Training Epoch 75  45.7% | batch:        43 of        94\t|\tloss: 1546.99\n",
      "Training Epoch 75  46.8% | batch:        44 of        94\t|\tloss: 1114.48\n",
      "Training Epoch 75  47.9% | batch:        45 of        94\t|\tloss: 564.051\n",
      "Training Epoch 75  48.9% | batch:        46 of        94\t|\tloss: 1969.22\n",
      "Training Epoch 75  50.0% | batch:        47 of        94\t|\tloss: 874.432\n",
      "Training Epoch 75  51.1% | batch:        48 of        94\t|\tloss: 871.412\n",
      "Training Epoch 75  52.1% | batch:        49 of        94\t|\tloss: 1297.29\n",
      "Training Epoch 75  53.2% | batch:        50 of        94\t|\tloss: 840.473\n",
      "Training Epoch 75  54.3% | batch:        51 of        94\t|\tloss: 605.769\n",
      "Training Epoch 75  55.3% | batch:        52 of        94\t|\tloss: 1029.23\n",
      "Training Epoch 75  56.4% | batch:        53 of        94\t|\tloss: 769.136\n",
      "Training Epoch 75  57.4% | batch:        54 of        94\t|\tloss: 654.17\n",
      "Training Epoch 75  58.5% | batch:        55 of        94\t|\tloss: 1116.7\n",
      "Training Epoch 75  59.6% | batch:        56 of        94\t|\tloss: 800.03\n",
      "Training Epoch 75  60.6% | batch:        57 of        94\t|\tloss: 1061.91\n",
      "Training Epoch 75  61.7% | batch:        58 of        94\t|\tloss: 920.841\n",
      "Training Epoch 75  62.8% | batch:        59 of        94\t|\tloss: 863.778\n",
      "Training Epoch 75  63.8% | batch:        60 of        94\t|\tloss: 923.981\n",
      "Training Epoch 75  64.9% | batch:        61 of        94\t|\tloss: 1821.02\n",
      "Training Epoch 75  66.0% | batch:        62 of        94\t|\tloss: 816.639\n",
      "Training Epoch 75  67.0% | batch:        63 of        94\t|\tloss: 545.215\n",
      "Training Epoch 75  68.1% | batch:        64 of        94\t|\tloss: 602.451\n",
      "Training Epoch 75  69.1% | batch:        65 of        94\t|\tloss: 1313.56\n",
      "Training Epoch 75  70.2% | batch:        66 of        94\t|\tloss: 1246.32\n",
      "Training Epoch 75  71.3% | batch:        67 of        94\t|\tloss: 1510.66\n",
      "Training Epoch 75  72.3% | batch:        68 of        94\t|\tloss: 750.603\n",
      "Training Epoch 75  73.4% | batch:        69 of        94\t|\tloss: 927.635\n",
      "Training Epoch 75  74.5% | batch:        70 of        94\t|\tloss: 1459.41\n",
      "Training Epoch 75  75.5% | batch:        71 of        94\t|\tloss: 895.792\n",
      "Training Epoch 75  76.6% | batch:        72 of        94\t|\tloss: 790.614\n",
      "Training Epoch 75  77.7% | batch:        73 of        94\t|\tloss: 1160.09\n",
      "Training Epoch 75  78.7% | batch:        74 of        94\t|\tloss: 1003.15\n",
      "Training Epoch 75  79.8% | batch:        75 of        94\t|\tloss: 713.824\n",
      "Training Epoch 75  80.9% | batch:        76 of        94\t|\tloss: 725.354\n",
      "Training Epoch 75  81.9% | batch:        77 of        94\t|\tloss: 1063.08\n",
      "Training Epoch 75  83.0% | batch:        78 of        94\t|\tloss: 673.504\n",
      "Training Epoch 75  84.0% | batch:        79 of        94\t|\tloss: 1083.11\n",
      "Training Epoch 75  85.1% | batch:        80 of        94\t|\tloss: 892.427\n",
      "Training Epoch 75  86.2% | batch:        81 of        94\t|\tloss: 773.444\n",
      "Training Epoch 75  87.2% | batch:        82 of        94\t|\tloss: 755.063\n",
      "Training Epoch 75  88.3% | batch:        83 of        94\t|\tloss: 817.854\n",
      "Training Epoch 75  89.4% | batch:        84 of        94\t|\tloss: 2680.59\n",
      "Training Epoch 75  90.4% | batch:        85 of        94\t|\tloss: 666.768\n",
      "Training Epoch 75  91.5% | batch:        86 of        94\t|\tloss: 953.591\n",
      "Training Epoch 75  92.6% | batch:        87 of        94\t|\tloss: 843.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:53,536 | INFO : Epoch 75 Training Summary: epoch: 75.000000 | loss: 1040.708000 | \n",
      "2023-05-09 14:22:53,536 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7660577297210693 seconds\n",
      "\n",
      "2023-05-09 14:22:53,537 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.826657018661499 seconds\n",
      "2023-05-09 14:22:53,537 | INFO : Avg batch train. time: 0.019432521475122328 seconds\n",
      "2023-05-09 14:22:53,538 | INFO : Avg sample train. time: 0.0001532687547123258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 75  93.6% | batch:        88 of        94\t|\tloss: 1407.99\n",
      "Training Epoch 75  94.7% | batch:        89 of        94\t|\tloss: 1881.33\n",
      "Training Epoch 75  95.7% | batch:        90 of        94\t|\tloss: 1055.03\n",
      "Training Epoch 75  96.8% | batch:        91 of        94\t|\tloss: 1600.78\n",
      "Training Epoch 75  97.9% | batch:        92 of        94\t|\tloss: 924.29\n",
      "Training Epoch 75  98.9% | batch:        93 of        94\t|\tloss: 2642\n",
      "\n",
      "Training Epoch 76   0.0% | batch:         0 of        94\t|\tloss: 1234.22\n",
      "Training Epoch 76   1.1% | batch:         1 of        94\t|\tloss: 910.381\n",
      "Training Epoch 76   2.1% | batch:         2 of        94\t|\tloss: 1621.41\n",
      "Training Epoch 76   3.2% | batch:         3 of        94\t|\tloss: 805.065\n",
      "Training Epoch 76   4.3% | batch:         4 of        94\t|\tloss: 644.017\n",
      "Training Epoch 76   5.3% | batch:         5 of        94\t|\tloss: 1312.08\n",
      "Training Epoch 76   6.4% | batch:         6 of        94\t|\tloss: 871.144\n",
      "Training Epoch 76   7.4% | batch:         7 of        94\t|\tloss: 865.661\n",
      "Training Epoch 76   8.5% | batch:         8 of        94\t|\tloss: 1917.41\n",
      "Training Epoch 76   9.6% | batch:         9 of        94\t|\tloss: 856.357\n",
      "Training Epoch 76  10.6% | batch:        10 of        94\t|\tloss: 627.69\n",
      "Training Epoch 76  11.7% | batch:        11 of        94\t|\tloss: 751.547\n",
      "Training Epoch 76  12.8% | batch:        12 of        94\t|\tloss: 1460.59\n",
      "Training Epoch 76  13.8% | batch:        13 of        94\t|\tloss: 3984.16\n",
      "Training Epoch 76  14.9% | batch:        14 of        94\t|\tloss: 1230.33\n",
      "Training Epoch 76  16.0% | batch:        15 of        94\t|\tloss: 1490.2\n",
      "Training Epoch 76  17.0% | batch:        16 of        94\t|\tloss: 1064.7\n",
      "Training Epoch 76  18.1% | batch:        17 of        94\t|\tloss: 787.594\n",
      "Training Epoch 76  19.1% | batch:        18 of        94\t|\tloss: 1077.51\n",
      "Training Epoch 76  20.2% | batch:        19 of        94\t|\tloss: 2137.44\n",
      "Training Epoch 76  21.3% | batch:        20 of        94\t|\tloss: 1402.65\n",
      "Training Epoch 76  22.3% | batch:        21 of        94\t|\tloss: 1047.24\n",
      "Training Epoch 76  23.4% | batch:        22 of        94\t|\tloss: 1578.79\n",
      "Training Epoch 76  24.5% | batch:        23 of        94\t|\tloss: 1369.94\n",
      "Training Epoch 76  25.5% | batch:        24 of        94\t|\tloss: 881.953\n",
      "Training Epoch 76  26.6% | batch:        25 of        94\t|\tloss: 916.335\n",
      "Training Epoch 76  27.7% | batch:        26 of        94\t|\tloss: 1163.38\n",
      "Training Epoch 76  28.7% | batch:        27 of        94\t|\tloss: 1430.94\n",
      "Training Epoch 76  29.8% | batch:        28 of        94\t|\tloss: 949.794\n",
      "Training Epoch 76  30.9% | batch:        29 of        94\t|\tloss: 1258.43\n",
      "Training Epoch 76  31.9% | batch:        30 of        94\t|\tloss: 879.15\n",
      "Training Epoch 76  33.0% | batch:        31 of        94\t|\tloss: 822.11\n",
      "Training Epoch 76  34.0% | batch:        32 of        94\t|\tloss: 945.278\n",
      "Training Epoch 76  35.1% | batch:        33 of        94\t|\tloss: 847.238\n",
      "Training Epoch 76  36.2% | batch:        34 of        94\t|\tloss: 831.543\n",
      "Training Epoch 76  37.2% | batch:        35 of        94\t|\tloss: 614.207\n",
      "Training Epoch 76  38.3% | batch:        36 of        94\t|\tloss: 765.326\n",
      "Training Epoch 76  39.4% | batch:        37 of        94\t|\tloss: 727.474\n",
      "Training Epoch 76  40.4% | batch:        38 of        94\t|\tloss: 1172.2\n",
      "Training Epoch 76  41.5% | batch:        39 of        94\t|\tloss: 1009.05\n",
      "Training Epoch 76  42.6% | batch:        40 of        94\t|\tloss: 1150.06\n",
      "Training Epoch 76  43.6% | batch:        41 of        94\t|\tloss: 815.521\n",
      "Training Epoch 76  44.7% | batch:        42 of        94\t|\tloss: 1572.21\n",
      "Training Epoch 76  45.7% | batch:        43 of        94\t|\tloss: 971.695\n",
      "Training Epoch 76  46.8% | batch:        44 of        94\t|\tloss: 1047.83\n",
      "Training Epoch 76  47.9% | batch:        45 of        94\t|\tloss: 676.274\n",
      "Training Epoch 76  48.9% | batch:        46 of        94\t|\tloss: 715.772\n",
      "Training Epoch 76  50.0% | batch:        47 of        94\t|\tloss: 1313.23\n",
      "Training Epoch 76  51.1% | batch:        48 of        94\t|\tloss: 875.279\n",
      "Training Epoch 76  52.1% | batch:        49 of        94\t|\tloss: 1372.38\n",
      "Training Epoch 76  53.2% | batch:        50 of        94\t|\tloss: 874.648\n",
      "Training Epoch 76  54.3% | batch:        51 of        94\t|\tloss: 932.216\n",
      "Training Epoch 76  55.3% | batch:        52 of        94\t|\tloss: 1396\n",
      "Training Epoch 76  56.4% | batch:        53 of        94\t|\tloss: 775.633\n",
      "Training Epoch 76  57.4% | batch:        54 of        94\t|\tloss: 916.386\n",
      "Training Epoch 76  58.5% | batch:        55 of        94\t|\tloss: 914.55\n",
      "Training Epoch 76  59.6% | batch:        56 of        94\t|\tloss: 1059.35\n",
      "Training Epoch 76  60.6% | batch:        57 of        94\t|\tloss: 982.182\n",
      "Training Epoch 76  61.7% | batch:        58 of        94\t|\tloss: 837.425\n",
      "Training Epoch 76  62.8% | batch:        59 of        94\t|\tloss: 894.554\n",
      "Training Epoch 76  63.8% | batch:        60 of        94\t|\tloss: 974.769\n",
      "Training Epoch 76  64.9% | batch:        61 of        94\t|\tloss: 769.095\n",
      "Training Epoch 76  66.0% | batch:        62 of        94\t|\tloss: 1471.46\n",
      "Training Epoch 76  67.0% | batch:        63 of        94\t|\tloss: 2407\n",
      "Training Epoch 76  68.1% | batch:        64 of        94\t|\tloss: 1001.31\n",
      "Training Epoch 76  69.1% | batch:        65 of        94\t|\tloss: 696.496\n",
      "Training Epoch 76  70.2% | batch:        66 of        94\t|\tloss: 943.044\n",
      "Training Epoch 76  71.3% | batch:        67 of        94\t|\tloss: 1087.82\n",
      "Training Epoch 76  72.3% | batch:        68 of        94\t|\tloss: 1037.98\n",
      "Training Epoch 76  73.4% | batch:        69 of        94\t|\tloss: 737.025\n",
      "Training Epoch 76  74.5% | batch:        70 of        94\t|\tloss: 815.34\n",
      "Training Epoch 76  75.5% | batch:        71 of        94\t|\tloss: 903.136\n",
      "Training Epoch 76  76.6% | batch:        72 of        94\t|\tloss: 759.484\n",
      "Training Epoch 76  77.7% | batch:        73 of        94\t|\tloss: 1397.74\n",
      "Training Epoch 76  78.7% | batch:        74 of        94\t|\tloss: 1021.88\n",
      "Training Epoch 76  79.8% | batch:        75 of        94\t|\tloss: 853.839\n",
      "Training Epoch 76  80.9% | batch:        76 of        94\t|\tloss: 1020.07\n",
      "Training Epoch 76  81.9% | batch:        77 of        94\t|\tloss: 1108.05\n",
      "Training Epoch 76  83.0% | batch:        78 of        94\t|\tloss: 679.931\n",
      "Training Epoch 76  84.0% | batch:        79 of        94\t|\tloss: 851.546\n",
      "Training Epoch 76  85.1% | batch:        80 of        94\t|\tloss: 1127.96\n",
      "Training Epoch 76  86.2% | batch:        81 of        94\t|\tloss: 711.432\n",
      "Training Epoch 76  87.2% | batch:        82 of        94\t|\tloss: 1865.33\n",
      "Training Epoch 76  88.3% | batch:        83 of        94\t|\tloss: 1895.2\n",
      "Training Epoch 76  89.4% | batch:        84 of        94\t|\tloss: 941.875\n",
      "Training Epoch 76  90.4% | batch:        85 of        94\t|\tloss: 1066.15\n",
      "Training Epoch 76  91.5% | batch:        86 of        94\t|\tloss: 1116.63\n",
      "Training Epoch 76  92.6% | batch:        87 of        94\t|\tloss: 756.554\n",
      "Training Epoch 76  93.6% | batch:        88 of        94\t|\tloss: 1223.39\n",
      "Training Epoch 76  94.7% | batch:        89 of        94\t|\tloss: 845.505\n",
      "Training Epoch 76  95.7% | batch:        90 of        94\t|\tloss: 1095.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:55,413 | INFO : Epoch 76 Training Summary: epoch: 76.000000 | loss: 1088.441644 | \n",
      "2023-05-09 14:22:55,414 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8544895648956299 seconds\n",
      "\n",
      "2023-05-09 14:22:55,415 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.827023236375106 seconds\n",
      "2023-05-09 14:22:55,415 | INFO : Avg batch train. time: 0.01943641740824581 seconds\n",
      "2023-05-09 14:22:55,415 | INFO : Avg sample train. time: 0.00015329948283060126 seconds\n",
      "2023-05-09 14:22:55,416 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 76  96.8% | batch:        91 of        94\t|\tloss: 925.731\n",
      "Training Epoch 76  97.9% | batch:        92 of        94\t|\tloss: 778.008\n",
      "Training Epoch 76  98.9% | batch:        93 of        94\t|\tloss: 930.087\n",
      "\n",
      "Evaluating Epoch 76   0.0% | batch:         0 of        40\t|\tloss: 7706.14\n",
      "Evaluating Epoch 76   2.5% | batch:         1 of        40\t|\tloss: 1102.31\n",
      "Evaluating Epoch 76   5.0% | batch:         2 of        40\t|\tloss: 3370.2\n",
      "Evaluating Epoch 76   7.5% | batch:         3 of        40\t|\tloss: 6928.54\n",
      "Evaluating Epoch 76  10.0% | batch:         4 of        40\t|\tloss: 2859.5\n",
      "Evaluating Epoch 76  12.5% | batch:         5 of        40\t|\tloss: 2463.38\n",
      "Evaluating Epoch 76  15.0% | batch:         6 of        40\t|\tloss: 8197.59\n",
      "Evaluating Epoch 76  17.5% | batch:         7 of        40\t|\tloss: 3457.2\n",
      "Evaluating Epoch 76  20.0% | batch:         8 of        40\t|\tloss: 2711.51\n",
      "Evaluating Epoch 76  22.5% | batch:         9 of        40\t|\tloss: 1905.08\n",
      "Evaluating Epoch 76  25.0% | batch:        10 of        40\t|\tloss: 5552.31\n",
      "Evaluating Epoch 76  27.5% | batch:        11 of        40\t|\tloss: 1568.37\n",
      "Evaluating Epoch 76  30.0% | batch:        12 of        40\t|\tloss: 6874.7\n",
      "Evaluating Epoch 76  32.5% | batch:        13 of        40\t|\tloss: 4017.57\n",
      "Evaluating Epoch 76  35.0% | batch:        14 of        40\t|\tloss: 2398.75\n",
      "Evaluating Epoch 76  37.5% | batch:        15 of        40\t|\tloss: 3013.98\n",
      "Evaluating Epoch 76  40.0% | batch:        16 of        40\t|\tloss: 4450.96\n",
      "Evaluating Epoch 76  42.5% | batch:        17 of        40\t|\tloss: 3261.7\n",
      "Evaluating Epoch 76  45.0% | batch:        18 of        40\t|\tloss: 2288.66\n",
      "Evaluating Epoch 76  47.5% | batch:        19 of        40\t|\tloss: 5951.17\n",
      "Evaluating Epoch 76  50.0% | batch:        20 of        40\t|\tloss: 5415.4\n",
      "Evaluating Epoch 76  52.5% | batch:        21 of        40\t|\tloss: 1155.81\n",
      "Evaluating Epoch 76  55.0% | batch:        22 of        40\t|\tloss: 3672.65\n",
      "Evaluating Epoch 76  57.5% | batch:        23 of        40\t|\tloss: 4286.35\n",
      "Evaluating Epoch 76  60.0% | batch:        24 of        40\t|\tloss: 1737.33\n",
      "Evaluating Epoch 76  62.5% | batch:        25 of        40\t|\tloss: 3140.64\n",
      "Evaluating Epoch 76  65.0% | batch:        26 of        40\t|\tloss: 10152.5\n",
      "Evaluating Epoch 76  67.5% | batch:        27 of        40\t|\tloss: 2805.65\n",
      "Evaluating Epoch 76  70.0% | batch:        28 of        40\t|\tloss: 2041.88\n",
      "Evaluating Epoch 76  72.5% | batch:        29 of        40\t|\tloss: 9686.61\n",
      "Evaluating Epoch 76  75.0% | batch:        30 of        40\t|\tloss: 2235.2\n",
      "Evaluating Epoch 76  77.5% | batch:        31 of        40\t|\tloss: 1464.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:55,876 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4597043991088867 seconds\n",
      "\n",
      "2023-05-09 14:22:55,877 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47477770447731016 seconds\n",
      "2023-05-09 14:22:55,877 | INFO : Avg batch val. time: 0.011869442611932754 seconds\n",
      "2023-05-09 14:22:55,878 | INFO : Avg sample val. time: 9.405263559376192e-05 seconds\n",
      "2023-05-09 14:22:55,878 | INFO : Epoch 76 Validation Summary: epoch: 76.000000 | loss: 4239.379550 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 76  80.0% | batch:        32 of        40\t|\tloss: 6589.44\n",
      "Evaluating Epoch 76  82.5% | batch:        33 of        40\t|\tloss: 7380.53\n",
      "Evaluating Epoch 76  85.0% | batch:        34 of        40\t|\tloss: 994.118\n",
      "Evaluating Epoch 76  87.5% | batch:        35 of        40\t|\tloss: 4806.12\n",
      "Evaluating Epoch 76  90.0% | batch:        36 of        40\t|\tloss: 7631.39\n",
      "Evaluating Epoch 76  92.5% | batch:        37 of        40\t|\tloss: 2742.28\n",
      "Evaluating Epoch 76  95.0% | batch:        38 of        40\t|\tloss: 3518.99\n",
      "Evaluating Epoch 76  97.5% | batch:        39 of        40\t|\tloss: 12922.6\n",
      "\n",
      "Training Epoch 77   0.0% | batch:         0 of        94\t|\tloss: 1303.12\n",
      "Training Epoch 77   1.1% | batch:         1 of        94\t|\tloss: 1622.97\n",
      "Training Epoch 77   2.1% | batch:         2 of        94\t|\tloss: 685.161\n",
      "Training Epoch 77   3.2% | batch:         3 of        94\t|\tloss: 2947.67\n",
      "Training Epoch 77   4.3% | batch:         4 of        94\t|\tloss: 1138.68\n",
      "Training Epoch 77   5.3% | batch:         5 of        94\t|\tloss: 1065.99\n",
      "Training Epoch 77   6.4% | batch:         6 of        94\t|\tloss: 1326.49\n",
      "Training Epoch 77   7.4% | batch:         7 of        94\t|\tloss: 843.727\n",
      "Training Epoch 77   8.5% | batch:         8 of        94\t|\tloss: 677.817\n",
      "Training Epoch 77   9.6% | batch:         9 of        94\t|\tloss: 959.756\n",
      "Training Epoch 77  10.6% | batch:        10 of        94\t|\tloss: 2047.91\n",
      "Training Epoch 77  11.7% | batch:        11 of        94\t|\tloss: 801.838\n",
      "Training Epoch 77  12.8% | batch:        12 of        94\t|\tloss: 1153.69\n",
      "Training Epoch 77  13.8% | batch:        13 of        94\t|\tloss: 1001.48\n",
      "Training Epoch 77  14.9% | batch:        14 of        94\t|\tloss: 908.694\n",
      "Training Epoch 77  16.0% | batch:        15 of        94\t|\tloss: 946.624\n",
      "Training Epoch 77  17.0% | batch:        16 of        94\t|\tloss: 1064.07\n",
      "Training Epoch 77  18.1% | batch:        17 of        94\t|\tloss: 800.087\n",
      "Training Epoch 77  19.1% | batch:        18 of        94\t|\tloss: 1081.63\n",
      "Training Epoch 77  20.2% | batch:        19 of        94\t|\tloss: 738.528\n",
      "Training Epoch 77  21.3% | batch:        20 of        94\t|\tloss: 1295.74\n",
      "Training Epoch 77  22.3% | batch:        21 of        94\t|\tloss: 1087.39\n",
      "Training Epoch 77  23.4% | batch:        22 of        94\t|\tloss: 952.867\n",
      "Training Epoch 77  24.5% | batch:        23 of        94\t|\tloss: 983.467\n",
      "Training Epoch 77  25.5% | batch:        24 of        94\t|\tloss: 1200.69\n",
      "Training Epoch 77  26.6% | batch:        25 of        94\t|\tloss: 783.892\n",
      "Training Epoch 77  27.7% | batch:        26 of        94\t|\tloss: 800.269\n",
      "Training Epoch 77  28.7% | batch:        27 of        94\t|\tloss: 1018.73\n",
      "Training Epoch 77  29.8% | batch:        28 of        94\t|\tloss: 996.252\n",
      "Training Epoch 77  30.9% | batch:        29 of        94\t|\tloss: 965.069\n",
      "Training Epoch 77  31.9% | batch:        30 of        94\t|\tloss: 624.888\n",
      "Training Epoch 77  33.0% | batch:        31 of        94\t|\tloss: 790.231\n",
      "Training Epoch 77  34.0% | batch:        32 of        94\t|\tloss: 876.798\n",
      "Training Epoch 77  35.1% | batch:        33 of        94\t|\tloss: 1033.55\n",
      "Training Epoch 77  36.2% | batch:        34 of        94\t|\tloss: 1494.29\n",
      "Training Epoch 77  37.2% | batch:        35 of        94\t|\tloss: 629.67\n",
      "Training Epoch 77  38.3% | batch:        36 of        94\t|\tloss: 2480.89\n",
      "Training Epoch 77  39.4% | batch:        37 of        94\t|\tloss: 1588.83\n",
      "Training Epoch 77  40.4% | batch:        38 of        94\t|\tloss: 676.304\n",
      "Training Epoch 77  41.5% | batch:        39 of        94\t|\tloss: 1437.46\n",
      "Training Epoch 77  42.6% | batch:        40 of        94\t|\tloss: 1585.53\n",
      "Training Epoch 77  43.6% | batch:        41 of        94\t|\tloss: 1152.24\n",
      "Training Epoch 77  44.7% | batch:        42 of        94\t|\tloss: 875.029\n",
      "Training Epoch 77  45.7% | batch:        43 of        94\t|\tloss: 1092.7\n",
      "Training Epoch 77  46.8% | batch:        44 of        94\t|\tloss: 1035.32\n",
      "Training Epoch 77  47.9% | batch:        45 of        94\t|\tloss: 947.015\n",
      "Training Epoch 77  48.9% | batch:        46 of        94\t|\tloss: 1582.55\n",
      "Training Epoch 77  50.0% | batch:        47 of        94\t|\tloss: 865.357\n",
      "Training Epoch 77  51.1% | batch:        48 of        94\t|\tloss: 1054.64\n",
      "Training Epoch 77  52.1% | batch:        49 of        94\t|\tloss: 752.393\n",
      "Training Epoch 77  53.2% | batch:        50 of        94\t|\tloss: 834.477\n",
      "Training Epoch 77  54.3% | batch:        51 of        94\t|\tloss: 799.444\n",
      "Training Epoch 77  55.3% | batch:        52 of        94\t|\tloss: 1213.9\n",
      "Training Epoch 77  56.4% | batch:        53 of        94\t|\tloss: 1273.16\n",
      "Training Epoch 77  57.4% | batch:        54 of        94\t|\tloss: 1047.98\n",
      "Training Epoch 77  58.5% | batch:        55 of        94\t|\tloss: 1166.6\n",
      "Training Epoch 77  59.6% | batch:        56 of        94\t|\tloss: 1116.98\n",
      "Training Epoch 77  60.6% | batch:        57 of        94\t|\tloss: 997.881\n",
      "Training Epoch 77  61.7% | batch:        58 of        94\t|\tloss: 1036.18\n",
      "Training Epoch 77  62.8% | batch:        59 of        94\t|\tloss: 1152.6\n",
      "Training Epoch 77  63.8% | batch:        60 of        94\t|\tloss: 759.013\n",
      "Training Epoch 77  64.9% | batch:        61 of        94\t|\tloss: 1016.92\n",
      "Training Epoch 77  66.0% | batch:        62 of        94\t|\tloss: 885.909\n",
      "Training Epoch 77  67.0% | batch:        63 of        94\t|\tloss: 970.335\n",
      "Training Epoch 77  68.1% | batch:        64 of        94\t|\tloss: 655.349\n",
      "Training Epoch 77  69.1% | batch:        65 of        94\t|\tloss: 1078.66\n",
      "Training Epoch 77  70.2% | batch:        66 of        94\t|\tloss: 912.781\n",
      "Training Epoch 77  71.3% | batch:        67 of        94\t|\tloss: 1139.73\n",
      "Training Epoch 77  72.3% | batch:        68 of        94\t|\tloss: 971.185\n",
      "Training Epoch 77  73.4% | batch:        69 of        94\t|\tloss: 1070.6\n",
      "Training Epoch 77  74.5% | batch:        70 of        94\t|\tloss: 989.508\n",
      "Training Epoch 77  75.5% | batch:        71 of        94\t|\tloss: 1270.31\n",
      "Training Epoch 77  76.6% | batch:        72 of        94\t|\tloss: 1512.53\n",
      "Training Epoch 77  77.7% | batch:        73 of        94\t|\tloss: 1007.74\n",
      "Training Epoch 77  78.7% | batch:        74 of        94\t|\tloss: 810.563\n",
      "Training Epoch 77  79.8% | batch:        75 of        94\t|\tloss: 648.602\n",
      "Training Epoch 77  80.9% | batch:        76 of        94\t|\tloss: 528.781\n",
      "Training Epoch 77  81.9% | batch:        77 of        94\t|\tloss: 1003.63\n",
      "Training Epoch 77  83.0% | batch:        78 of        94\t|\tloss: 1040.11\n",
      "Training Epoch 77  84.0% | batch:        79 of        94\t|\tloss: 913.09\n",
      "Training Epoch 77  85.1% | batch:        80 of        94\t|\tloss: 1089.28\n",
      "Training Epoch 77  86.2% | batch:        81 of        94\t|\tloss: 1733.89\n",
      "Training Epoch 77  87.2% | batch:        82 of        94\t|\tloss: 1289.75\n",
      "Training Epoch 77  88.3% | batch:        83 of        94\t|\tloss: 762.464\n",
      "Training Epoch 77  89.4% | batch:        84 of        94\t|\tloss: 862.862\n",
      "Training Epoch 77  90.4% | batch:        85 of        94\t|\tloss: 985.597\n",
      "Training Epoch 77  91.5% | batch:        86 of        94\t|\tloss: 649.51\n",
      "Training Epoch 77  92.6% | batch:        87 of        94\t|\tloss: 757.433\n",
      "Training Epoch 77  93.6% | batch:        88 of        94\t|\tloss: 1122.37\n",
      "Training Epoch 77  94.7% | batch:        89 of        94\t|\tloss: 3020.67\n",
      "Training Epoch 77  95.7% | batch:        90 of        94\t|\tloss: 922.441\n",
      "Training Epoch 77  96.8% | batch:        91 of        94\t|\tloss: 897.557\n",
      "Training Epoch 77  97.9% | batch:        92 of        94\t|\tloss: 1372.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:57,745 | INFO : Epoch 77 Training Summary: epoch: 77.000000 | loss: 1086.452832 | \n",
      "2023-05-09 14:22:57,746 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8535969257354736 seconds\n",
      "\n",
      "2023-05-09 14:22:57,746 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8273683492239419 seconds\n",
      "2023-05-09 14:22:57,747 | INFO : Avg batch train. time: 0.019440088821531296 seconds\n",
      "2023-05-09 14:22:57,747 | INFO : Avg sample train. time: 0.00015332844010940947 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 77  98.9% | batch:        93 of        94\t|\tloss: 843.666\n",
      "\n",
      "Training Epoch 78   0.0% | batch:         0 of        94\t|\tloss: 1988.77\n",
      "Training Epoch 78   1.1% | batch:         1 of        94\t|\tloss: 1468.32\n",
      "Training Epoch 78   2.1% | batch:         2 of        94\t|\tloss: 1003.29\n",
      "Training Epoch 78   3.2% | batch:         3 of        94\t|\tloss: 1033.65\n",
      "Training Epoch 78   4.3% | batch:         4 of        94\t|\tloss: 912.17\n",
      "Training Epoch 78   5.3% | batch:         5 of        94\t|\tloss: 2568.49\n",
      "Training Epoch 78   6.4% | batch:         6 of        94\t|\tloss: 802.23\n",
      "Training Epoch 78   7.4% | batch:         7 of        94\t|\tloss: 615.203\n",
      "Training Epoch 78   8.5% | batch:         8 of        94\t|\tloss: 845.744\n",
      "Training Epoch 78   9.6% | batch:         9 of        94\t|\tloss: 1191.09\n",
      "Training Epoch 78  10.6% | batch:        10 of        94\t|\tloss: 885.387\n",
      "Training Epoch 78  11.7% | batch:        11 of        94\t|\tloss: 1205.86\n",
      "Training Epoch 78  12.8% | batch:        12 of        94\t|\tloss: 1319.32\n",
      "Training Epoch 78  13.8% | batch:        13 of        94\t|\tloss: 990.258\n",
      "Training Epoch 78  14.9% | batch:        14 of        94\t|\tloss: 850.417\n",
      "Training Epoch 78  16.0% | batch:        15 of        94\t|\tloss: 848.008\n",
      "Training Epoch 78  17.0% | batch:        16 of        94\t|\tloss: 767.495\n",
      "Training Epoch 78  18.1% | batch:        17 of        94\t|\tloss: 1140.05\n",
      "Training Epoch 78  19.1% | batch:        18 of        94\t|\tloss: 908.128\n",
      "Training Epoch 78  20.2% | batch:        19 of        94\t|\tloss: 932.022\n",
      "Training Epoch 78  21.3% | batch:        20 of        94\t|\tloss: 2306.7\n",
      "Training Epoch 78  22.3% | batch:        21 of        94\t|\tloss: 990.836\n",
      "Training Epoch 78  23.4% | batch:        22 of        94\t|\tloss: 1099.28\n",
      "Training Epoch 78  24.5% | batch:        23 of        94\t|\tloss: 768.704\n",
      "Training Epoch 78  25.5% | batch:        24 of        94\t|\tloss: 1021.51\n",
      "Training Epoch 78  26.6% | batch:        25 of        94\t|\tloss: 695.409\n",
      "Training Epoch 78  27.7% | batch:        26 of        94\t|\tloss: 792.086\n",
      "Training Epoch 78  28.7% | batch:        27 of        94\t|\tloss: 977.336\n",
      "Training Epoch 78  29.8% | batch:        28 of        94\t|\tloss: 1069.65\n",
      "Training Epoch 78  30.9% | batch:        29 of        94\t|\tloss: 700.414\n",
      "Training Epoch 78  31.9% | batch:        30 of        94\t|\tloss: 678.105\n",
      "Training Epoch 78  33.0% | batch:        31 of        94\t|\tloss: 902.013\n",
      "Training Epoch 78  34.0% | batch:        32 of        94\t|\tloss: 674.193\n",
      "Training Epoch 78  35.1% | batch:        33 of        94\t|\tloss: 586.814\n",
      "Training Epoch 78  36.2% | batch:        34 of        94\t|\tloss: 715.829\n",
      "Training Epoch 78  37.2% | batch:        35 of        94\t|\tloss: 891.579\n",
      "Training Epoch 78  38.3% | batch:        36 of        94\t|\tloss: 731.14\n",
      "Training Epoch 78  39.4% | batch:        37 of        94\t|\tloss: 1271.09\n",
      "Training Epoch 78  40.4% | batch:        38 of        94\t|\tloss: 679.712\n",
      "Training Epoch 78  41.5% | batch:        39 of        94\t|\tloss: 657.039\n",
      "Training Epoch 78  42.6% | batch:        40 of        94\t|\tloss: 694.533\n",
      "Training Epoch 78  43.6% | batch:        41 of        94\t|\tloss: 968.936\n",
      "Training Epoch 78  44.7% | batch:        42 of        94\t|\tloss: 841.166\n",
      "Training Epoch 78  45.7% | batch:        43 of        94\t|\tloss: 1287.07\n",
      "Training Epoch 78  46.8% | batch:        44 of        94\t|\tloss: 559.194\n",
      "Training Epoch 78  47.9% | batch:        45 of        94\t|\tloss: 618.143\n",
      "Training Epoch 78  48.9% | batch:        46 of        94\t|\tloss: 881.399\n",
      "Training Epoch 78  50.0% | batch:        47 of        94\t|\tloss: 1729.59\n",
      "Training Epoch 78  51.1% | batch:        48 of        94\t|\tloss: 1074.02\n",
      "Training Epoch 78  52.1% | batch:        49 of        94\t|\tloss: 771.878\n",
      "Training Epoch 78  53.2% | batch:        50 of        94\t|\tloss: 953.701\n",
      "Training Epoch 78  54.3% | batch:        51 of        94\t|\tloss: 1080.06\n",
      "Training Epoch 78  55.3% | batch:        52 of        94\t|\tloss: 941.951\n",
      "Training Epoch 78  56.4% | batch:        53 of        94\t|\tloss: 896.003\n",
      "Training Epoch 78  57.4% | batch:        54 of        94\t|\tloss: 721.056\n",
      "Training Epoch 78  58.5% | batch:        55 of        94\t|\tloss: 1067.01\n",
      "Training Epoch 78  59.6% | batch:        56 of        94\t|\tloss: 1167.24\n",
      "Training Epoch 78  60.6% | batch:        57 of        94\t|\tloss: 834.811\n",
      "Training Epoch 78  61.7% | batch:        58 of        94\t|\tloss: 780.115\n",
      "Training Epoch 78  62.8% | batch:        59 of        94\t|\tloss: 1106.65\n",
      "Training Epoch 78  63.8% | batch:        60 of        94\t|\tloss: 617.082\n",
      "Training Epoch 78  64.9% | batch:        61 of        94\t|\tloss: 1207.21\n",
      "Training Epoch 78  66.0% | batch:        62 of        94\t|\tloss: 986.1\n",
      "Training Epoch 78  67.0% | batch:        63 of        94\t|\tloss: 921.418\n",
      "Training Epoch 78  68.1% | batch:        64 of        94\t|\tloss: 995.469\n",
      "Training Epoch 78  69.1% | batch:        65 of        94\t|\tloss: 1251.81\n",
      "Training Epoch 78  70.2% | batch:        66 of        94\t|\tloss: 1131.24\n",
      "Training Epoch 78  71.3% | batch:        67 of        94\t|\tloss: 837.413\n",
      "Training Epoch 78  72.3% | batch:        68 of        94\t|\tloss: 884.354\n",
      "Training Epoch 78  73.4% | batch:        69 of        94\t|\tloss: 1121.96\n",
      "Training Epoch 78  74.5% | batch:        70 of        94\t|\tloss: 1080.74\n",
      "Training Epoch 78  75.5% | batch:        71 of        94\t|\tloss: 902.184\n",
      "Training Epoch 78  76.6% | batch:        72 of        94\t|\tloss: 773.561\n",
      "Training Epoch 78  77.7% | batch:        73 of        94\t|\tloss: 779.381\n",
      "Training Epoch 78  78.7% | batch:        74 of        94\t|\tloss: 948.136\n",
      "Training Epoch 78  79.8% | batch:        75 of        94\t|\tloss: 1076.24\n",
      "Training Epoch 78  80.9% | batch:        76 of        94\t|\tloss: 873.685\n",
      "Training Epoch 78  81.9% | batch:        77 of        94\t|\tloss: 652.404\n",
      "Training Epoch 78  83.0% | batch:        78 of        94\t|\tloss: 1118.89\n",
      "Training Epoch 78  84.0% | batch:        79 of        94\t|\tloss: 2779.86\n",
      "Training Epoch 78  85.1% | batch:        80 of        94\t|\tloss: 1272.59\n",
      "Training Epoch 78  86.2% | batch:        81 of        94\t|\tloss: 1660.68\n",
      "Training Epoch 78  87.2% | batch:        82 of        94\t|\tloss: 862.191\n",
      "Training Epoch 78  88.3% | batch:        83 of        94\t|\tloss: 491.854\n",
      "Training Epoch 78  89.4% | batch:        84 of        94\t|\tloss: 824.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:22:59,598 | INFO : Epoch 78 Training Summary: epoch: 78.000000 | loss: 1037.903441 | \n",
      "2023-05-09 14:22:59,599 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8303523063659668 seconds\n",
      "\n",
      "2023-05-09 14:22:59,599 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.827406605084737 seconds\n",
      "2023-05-09 14:22:59,599 | INFO : Avg batch train. time: 0.0194404957987738 seconds\n",
      "2023-05-09 14:22:59,600 | INFO : Avg sample train. time: 0.00015333165003228203 seconds\n",
      "2023-05-09 14:22:59,600 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 78  90.4% | batch:        85 of        94\t|\tloss: 2217.04\n",
      "Training Epoch 78  91.5% | batch:        86 of        94\t|\tloss: 1876.37\n",
      "Training Epoch 78  92.6% | batch:        87 of        94\t|\tloss: 1274.63\n",
      "Training Epoch 78  93.6% | batch:        88 of        94\t|\tloss: 1310.08\n",
      "Training Epoch 78  94.7% | batch:        89 of        94\t|\tloss: 913.627\n",
      "Training Epoch 78  95.7% | batch:        90 of        94\t|\tloss: 753.535\n",
      "Training Epoch 78  96.8% | batch:        91 of        94\t|\tloss: 829.334\n",
      "Training Epoch 78  97.9% | batch:        92 of        94\t|\tloss: 1863.9\n",
      "Training Epoch 78  98.9% | batch:        93 of        94\t|\tloss: 814.452\n",
      "\n",
      "Evaluating Epoch 78   0.0% | batch:         0 of        40\t|\tloss: 6969.55\n",
      "Evaluating Epoch 78   2.5% | batch:         1 of        40\t|\tloss: 1032.72\n",
      "Evaluating Epoch 78   5.0% | batch:         2 of        40\t|\tloss: 4337.09\n",
      "Evaluating Epoch 78   7.5% | batch:         3 of        40\t|\tloss: 7491.59\n",
      "Evaluating Epoch 78  10.0% | batch:         4 of        40\t|\tloss: 3262.81\n",
      "Evaluating Epoch 78  12.5% | batch:         5 of        40\t|\tloss: 3545.65\n",
      "Evaluating Epoch 78  15.0% | batch:         6 of        40\t|\tloss: 9330.03\n",
      "Evaluating Epoch 78  17.5% | batch:         7 of        40\t|\tloss: 3318.89\n",
      "Evaluating Epoch 78  20.0% | batch:         8 of        40\t|\tloss: 2988.89\n",
      "Evaluating Epoch 78  22.5% | batch:         9 of        40\t|\tloss: 2143.87\n",
      "Evaluating Epoch 78  25.0% | batch:        10 of        40\t|\tloss: 5022.51\n",
      "Evaluating Epoch 78  27.5% | batch:        11 of        40\t|\tloss: 1755.92\n",
      "Evaluating Epoch 78  30.0% | batch:        12 of        40\t|\tloss: 6958.37\n",
      "Evaluating Epoch 78  32.5% | batch:        13 of        40\t|\tloss: 3672.88\n",
      "Evaluating Epoch 78  35.0% | batch:        14 of        40\t|\tloss: 2095.71\n",
      "Evaluating Epoch 78  37.5% | batch:        15 of        40\t|\tloss: 3415.84\n",
      "Evaluating Epoch 78  40.0% | batch:        16 of        40\t|\tloss: 5449.69\n",
      "Evaluating Epoch 78  42.5% | batch:        17 of        40\t|\tloss: 2972.53\n",
      "Evaluating Epoch 78  45.0% | batch:        18 of        40\t|\tloss: 2293.28\n",
      "Evaluating Epoch 78  47.5% | batch:        19 of        40\t|\tloss: 6948.27\n",
      "Evaluating Epoch 78  50.0% | batch:        20 of        40\t|\tloss: 5495.06\n",
      "Evaluating Epoch 78  52.5% | batch:        21 of        40\t|\tloss: 1337.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:00,058 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45765018463134766 seconds\n",
      "\n",
      "2023-05-09 14:23:00,059 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47435996009082326 seconds\n",
      "2023-05-09 14:23:00,059 | INFO : Avg batch val. time: 0.011858999002270582 seconds\n",
      "2023-05-09 14:23:00,060 | INFO : Avg sample val. time: 9.396988115903789e-05 seconds\n",
      "2023-05-09 14:23:00,060 | INFO : Epoch 78 Validation Summary: epoch: 78.000000 | loss: 4409.219892 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 78  55.0% | batch:        22 of        40\t|\tloss: 3943.27\n",
      "Evaluating Epoch 78  57.5% | batch:        23 of        40\t|\tloss: 3664.88\n",
      "Evaluating Epoch 78  60.0% | batch:        24 of        40\t|\tloss: 1916.66\n",
      "Evaluating Epoch 78  62.5% | batch:        25 of        40\t|\tloss: 3600.16\n",
      "Evaluating Epoch 78  65.0% | batch:        26 of        40\t|\tloss: 10781.2\n",
      "Evaluating Epoch 78  67.5% | batch:        27 of        40\t|\tloss: 2986.35\n",
      "Evaluating Epoch 78  70.0% | batch:        28 of        40\t|\tloss: 2178.29\n",
      "Evaluating Epoch 78  72.5% | batch:        29 of        40\t|\tloss: 10050.9\n",
      "Evaluating Epoch 78  75.0% | batch:        30 of        40\t|\tloss: 2103.49\n",
      "Evaluating Epoch 78  77.5% | batch:        31 of        40\t|\tloss: 1985.75\n",
      "Evaluating Epoch 78  80.0% | batch:        32 of        40\t|\tloss: 7185.52\n",
      "Evaluating Epoch 78  82.5% | batch:        33 of        40\t|\tloss: 6599.38\n",
      "Evaluating Epoch 78  85.0% | batch:        34 of        40\t|\tloss: 1031.02\n",
      "Evaluating Epoch 78  87.5% | batch:        35 of        40\t|\tloss: 5885.06\n",
      "Evaluating Epoch 78  90.0% | batch:        36 of        40\t|\tloss: 6158.47\n",
      "Evaluating Epoch 78  92.5% | batch:        37 of        40\t|\tloss: 2630.22\n",
      "Evaluating Epoch 78  95.0% | batch:        38 of        40\t|\tloss: 3380.01\n",
      "Evaluating Epoch 78  97.5% | batch:        39 of        40\t|\tloss: 13644\n",
      "\n",
      "Training Epoch 79   0.0% | batch:         0 of        94\t|\tloss: 1272.82\n",
      "Training Epoch 79   1.1% | batch:         1 of        94\t|\tloss: 1032.35\n",
      "Training Epoch 79   2.1% | batch:         2 of        94\t|\tloss: 764.797\n",
      "Training Epoch 79   3.2% | batch:         3 of        94\t|\tloss: 794.681\n",
      "Training Epoch 79   4.3% | batch:         4 of        94\t|\tloss: 1092.07\n",
      "Training Epoch 79   5.3% | batch:         5 of        94\t|\tloss: 1531.84\n",
      "Training Epoch 79   6.4% | batch:         6 of        94\t|\tloss: 854.169\n",
      "Training Epoch 79   7.4% | batch:         7 of        94\t|\tloss: 952.111\n",
      "Training Epoch 79   8.5% | batch:         8 of        94\t|\tloss: 1016.48\n",
      "Training Epoch 79   9.6% | batch:         9 of        94\t|\tloss: 699.803\n",
      "Training Epoch 79  10.6% | batch:        10 of        94\t|\tloss: 812.065\n",
      "Training Epoch 79  11.7% | batch:        11 of        94\t|\tloss: 724.074\n",
      "Training Epoch 79  12.8% | batch:        12 of        94\t|\tloss: 1009.61\n",
      "Training Epoch 79  13.8% | batch:        13 of        94\t|\tloss: 857.502\n",
      "Training Epoch 79  14.9% | batch:        14 of        94\t|\tloss: 1048.81\n",
      "Training Epoch 79  16.0% | batch:        15 of        94\t|\tloss: 1294.43\n",
      "Training Epoch 79  17.0% | batch:        16 of        94\t|\tloss: 1033.45\n",
      "Training Epoch 79  18.1% | batch:        17 of        94\t|\tloss: 1729.79\n",
      "Training Epoch 79  19.1% | batch:        18 of        94\t|\tloss: 899.557\n",
      "Training Epoch 79  20.2% | batch:        19 of        94\t|\tloss: 821.026\n",
      "Training Epoch 79  21.3% | batch:        20 of        94\t|\tloss: 802.878\n",
      "Training Epoch 79  22.3% | batch:        21 of        94\t|\tloss: 1356.11\n",
      "Training Epoch 79  23.4% | batch:        22 of        94\t|\tloss: 1272.46\n",
      "Training Epoch 79  24.5% | batch:        23 of        94\t|\tloss: 723.019\n",
      "Training Epoch 79  25.5% | batch:        24 of        94\t|\tloss: 714.211\n",
      "Training Epoch 79  26.6% | batch:        25 of        94\t|\tloss: 782.774\n",
      "Training Epoch 79  27.7% | batch:        26 of        94\t|\tloss: 778.083\n",
      "Training Epoch 79  28.7% | batch:        27 of        94\t|\tloss: 1130.08\n",
      "Training Epoch 79  29.8% | batch:        28 of        94\t|\tloss: 2063.35\n",
      "Training Epoch 79  30.9% | batch:        29 of        94\t|\tloss: 1020.6\n",
      "Training Epoch 79  31.9% | batch:        30 of        94\t|\tloss: 817.307\n",
      "Training Epoch 79  33.0% | batch:        31 of        94\t|\tloss: 614.237\n",
      "Training Epoch 79  34.0% | batch:        32 of        94\t|\tloss: 853.317\n",
      "Training Epoch 79  35.1% | batch:        33 of        94\t|\tloss: 2054.46\n",
      "Training Epoch 79  36.2% | batch:        34 of        94\t|\tloss: 965.149\n",
      "Training Epoch 79  37.2% | batch:        35 of        94\t|\tloss: 494.061\n",
      "Training Epoch 79  38.3% | batch:        36 of        94\t|\tloss: 943.581\n",
      "Training Epoch 79  39.4% | batch:        37 of        94\t|\tloss: 1018.49\n",
      "Training Epoch 79  40.4% | batch:        38 of        94\t|\tloss: 741.904\n",
      "Training Epoch 79  41.5% | batch:        39 of        94\t|\tloss: 848.907\n",
      "Training Epoch 79  42.6% | batch:        40 of        94\t|\tloss: 1025.07\n",
      "Training Epoch 79  43.6% | batch:        41 of        94\t|\tloss: 608.595\n",
      "Training Epoch 79  44.7% | batch:        42 of        94\t|\tloss: 531.88\n",
      "Training Epoch 79  45.7% | batch:        43 of        94\t|\tloss: 1191.25\n",
      "Training Epoch 79  46.8% | batch:        44 of        94\t|\tloss: 800.924\n",
      "Training Epoch 79  47.9% | batch:        45 of        94\t|\tloss: 695.466\n",
      "Training Epoch 79  48.9% | batch:        46 of        94\t|\tloss: 982.764\n",
      "Training Epoch 79  50.0% | batch:        47 of        94\t|\tloss: 1126.53\n",
      "Training Epoch 79  51.1% | batch:        48 of        94\t|\tloss: 1288.81\n",
      "Training Epoch 79  52.1% | batch:        49 of        94\t|\tloss: 926.748\n",
      "Training Epoch 79  53.2% | batch:        50 of        94\t|\tloss: 1068.58\n",
      "Training Epoch 79  54.3% | batch:        51 of        94\t|\tloss: 650.844\n",
      "Training Epoch 79  55.3% | batch:        52 of        94\t|\tloss: 854.497\n",
      "Training Epoch 79  56.4% | batch:        53 of        94\t|\tloss: 892.117\n",
      "Training Epoch 79  57.4% | batch:        54 of        94\t|\tloss: 883.921\n",
      "Training Epoch 79  58.5% | batch:        55 of        94\t|\tloss: 873.545\n",
      "Training Epoch 79  59.6% | batch:        56 of        94\t|\tloss: 865.721\n",
      "Training Epoch 79  60.6% | batch:        57 of        94\t|\tloss: 1039.52\n",
      "Training Epoch 79  61.7% | batch:        58 of        94\t|\tloss: 1095.9\n",
      "Training Epoch 79  62.8% | batch:        59 of        94\t|\tloss: 1142.28\n",
      "Training Epoch 79  63.8% | batch:        60 of        94\t|\tloss: 1009.51\n",
      "Training Epoch 79  64.9% | batch:        61 of        94\t|\tloss: 704.679\n",
      "Training Epoch 79  66.0% | batch:        62 of        94\t|\tloss: 793.159\n",
      "Training Epoch 79  67.0% | batch:        63 of        94\t|\tloss: 758.551\n",
      "Training Epoch 79  68.1% | batch:        64 of        94\t|\tloss: 722.194\n",
      "Training Epoch 79  69.1% | batch:        65 of        94\t|\tloss: 1433.25\n",
      "Training Epoch 79  70.2% | batch:        66 of        94\t|\tloss: 1038.67\n",
      "Training Epoch 79  71.3% | batch:        67 of        94\t|\tloss: 999.283\n",
      "Training Epoch 79  72.3% | batch:        68 of        94\t|\tloss: 1844.1\n",
      "Training Epoch 79  73.4% | batch:        69 of        94\t|\tloss: 1336.97\n",
      "Training Epoch 79  74.5% | batch:        70 of        94\t|\tloss: 926.677\n",
      "Training Epoch 79  75.5% | batch:        71 of        94\t|\tloss: 666.041\n",
      "Training Epoch 79  76.6% | batch:        72 of        94\t|\tloss: 1289.04\n",
      "Training Epoch 79  77.7% | batch:        73 of        94\t|\tloss: 736.694\n",
      "Training Epoch 79  78.7% | batch:        74 of        94\t|\tloss: 857.478\n",
      "Training Epoch 79  79.8% | batch:        75 of        94\t|\tloss: 790.561\n",
      "Training Epoch 79  80.9% | batch:        76 of        94\t|\tloss: 2592.61\n",
      "Training Epoch 79  81.9% | batch:        77 of        94\t|\tloss: 694.02\n",
      "Training Epoch 79  83.0% | batch:        78 of        94\t|\tloss: 658.979\n",
      "Training Epoch 79  84.0% | batch:        79 of        94\t|\tloss: 1975.71\n",
      "Training Epoch 79  85.1% | batch:        80 of        94\t|\tloss: 870.021\n",
      "Training Epoch 79  86.2% | batch:        81 of        94\t|\tloss: 1224.86\n",
      "Training Epoch 79  87.2% | batch:        82 of        94\t|\tloss: 961.058\n",
      "Training Epoch 79  88.3% | batch:        83 of        94\t|\tloss: 1000.09\n",
      "Training Epoch 79  89.4% | batch:        84 of        94\t|\tloss: 1186.35\n",
      "Training Epoch 79  90.4% | batch:        85 of        94\t|\tloss: 1003.77\n",
      "Training Epoch 79  91.5% | batch:        86 of        94\t|\tloss: 1339.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:01,936 | INFO : Epoch 79 Training Summary: epoch: 79.000000 | loss: 1030.076838 | \n",
      "2023-05-09 14:23:01,937 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8542218208312988 seconds\n",
      "\n",
      "2023-05-09 14:23:01,938 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8277460381954531 seconds\n",
      "2023-05-09 14:23:01,938 | INFO : Avg batch train. time: 0.019444106789313333 seconds\n",
      "2023-05-09 14:23:01,938 | INFO : Avg sample train. time: 0.0001533601307430318 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 79  92.6% | batch:        87 of        94\t|\tloss: 1557.24\n",
      "Training Epoch 79  93.6% | batch:        88 of        94\t|\tloss: 1354.01\n",
      "Training Epoch 79  94.7% | batch:        89 of        94\t|\tloss: 923.108\n",
      "Training Epoch 79  95.7% | batch:        90 of        94\t|\tloss: 1412.19\n",
      "Training Epoch 79  96.8% | batch:        91 of        94\t|\tloss: 1447.39\n",
      "Training Epoch 79  97.9% | batch:        92 of        94\t|\tloss: 952.671\n",
      "Training Epoch 79  98.9% | batch:        93 of        94\t|\tloss: 617.457\n",
      "\n",
      "Training Epoch 80   0.0% | batch:         0 of        94\t|\tloss: 619.003\n",
      "Training Epoch 80   1.1% | batch:         1 of        94\t|\tloss: 1307.99\n",
      "Training Epoch 80   2.1% | batch:         2 of        94\t|\tloss: 888.195\n",
      "Training Epoch 80   3.2% | batch:         3 of        94\t|\tloss: 627.076\n",
      "Training Epoch 80   4.3% | batch:         4 of        94\t|\tloss: 953.417\n",
      "Training Epoch 80   5.3% | batch:         5 of        94\t|\tloss: 632.547\n",
      "Training Epoch 80   6.4% | batch:         6 of        94\t|\tloss: 1016.17\n",
      "Training Epoch 80   7.4% | batch:         7 of        94\t|\tloss: 1071.99\n",
      "Training Epoch 80   8.5% | batch:         8 of        94\t|\tloss: 980.823\n",
      "Training Epoch 80   9.6% | batch:         9 of        94\t|\tloss: 977.135\n",
      "Training Epoch 80  10.6% | batch:        10 of        94\t|\tloss: 1137.13\n",
      "Training Epoch 80  11.7% | batch:        11 of        94\t|\tloss: 527.326\n",
      "Training Epoch 80  12.8% | batch:        12 of        94\t|\tloss: 1078.67\n",
      "Training Epoch 80  13.8% | batch:        13 of        94\t|\tloss: 976.146\n",
      "Training Epoch 80  14.9% | batch:        14 of        94\t|\tloss: 1738.17\n",
      "Training Epoch 80  16.0% | batch:        15 of        94\t|\tloss: 960.804\n",
      "Training Epoch 80  17.0% | batch:        16 of        94\t|\tloss: 1119.21\n",
      "Training Epoch 80  18.1% | batch:        17 of        94\t|\tloss: 871.696\n",
      "Training Epoch 80  19.1% | batch:        18 of        94\t|\tloss: 2487.38\n",
      "Training Epoch 80  20.2% | batch:        19 of        94\t|\tloss: 1510.26\n",
      "Training Epoch 80  21.3% | batch:        20 of        94\t|\tloss: 1501.64\n",
      "Training Epoch 80  22.3% | batch:        21 of        94\t|\tloss: 1608.42\n",
      "Training Epoch 80  23.4% | batch:        22 of        94\t|\tloss: 1180.51\n",
      "Training Epoch 80  24.5% | batch:        23 of        94\t|\tloss: 607.284\n",
      "Training Epoch 80  25.5% | batch:        24 of        94\t|\tloss: 1208.29\n",
      "Training Epoch 80  26.6% | batch:        25 of        94\t|\tloss: 940.112\n",
      "Training Epoch 80  27.7% | batch:        26 of        94\t|\tloss: 926.896\n",
      "Training Epoch 80  28.7% | batch:        27 of        94\t|\tloss: 825.203\n",
      "Training Epoch 80  29.8% | batch:        28 of        94\t|\tloss: 829.641\n",
      "Training Epoch 80  30.9% | batch:        29 of        94\t|\tloss: 979.353\n",
      "Training Epoch 80  31.9% | batch:        30 of        94\t|\tloss: 649.824\n",
      "Training Epoch 80  33.0% | batch:        31 of        94\t|\tloss: 1166.44\n",
      "Training Epoch 80  34.0% | batch:        32 of        94\t|\tloss: 956.763\n",
      "Training Epoch 80  35.1% | batch:        33 of        94\t|\tloss: 1474.82\n",
      "Training Epoch 80  36.2% | batch:        34 of        94\t|\tloss: 730.053\n",
      "Training Epoch 80  37.2% | batch:        35 of        94\t|\tloss: 737.661\n",
      "Training Epoch 80  38.3% | batch:        36 of        94\t|\tloss: 973.357\n",
      "Training Epoch 80  39.4% | batch:        37 of        94\t|\tloss: 855.125\n",
      "Training Epoch 80  40.4% | batch:        38 of        94\t|\tloss: 1162.86\n",
      "Training Epoch 80  41.5% | batch:        39 of        94\t|\tloss: 871.578\n",
      "Training Epoch 80  42.6% | batch:        40 of        94\t|\tloss: 801.497\n",
      "Training Epoch 80  43.6% | batch:        41 of        94\t|\tloss: 949.904\n",
      "Training Epoch 80  44.7% | batch:        42 of        94\t|\tloss: 1223.08\n",
      "Training Epoch 80  45.7% | batch:        43 of        94\t|\tloss: 693.224\n",
      "Training Epoch 80  46.8% | batch:        44 of        94\t|\tloss: 896.942\n",
      "Training Epoch 80  47.9% | batch:        45 of        94\t|\tloss: 869.75\n",
      "Training Epoch 80  48.9% | batch:        46 of        94\t|\tloss: 956.476\n",
      "Training Epoch 80  50.0% | batch:        47 of        94\t|\tloss: 823.522\n",
      "Training Epoch 80  51.1% | batch:        48 of        94\t|\tloss: 2508.22\n",
      "Training Epoch 80  52.1% | batch:        49 of        94\t|\tloss: 991.977\n",
      "Training Epoch 80  53.2% | batch:        50 of        94\t|\tloss: 905.235\n",
      "Training Epoch 80  54.3% | batch:        51 of        94\t|\tloss: 732.057\n",
      "Training Epoch 80  55.3% | batch:        52 of        94\t|\tloss: 724.7\n",
      "Training Epoch 80  56.4% | batch:        53 of        94\t|\tloss: 870.521\n",
      "Training Epoch 80  57.4% | batch:        54 of        94\t|\tloss: 822.489\n",
      "Training Epoch 80  58.5% | batch:        55 of        94\t|\tloss: 576.546\n",
      "Training Epoch 80  59.6% | batch:        56 of        94\t|\tloss: 776.324\n",
      "Training Epoch 80  60.6% | batch:        57 of        94\t|\tloss: 903.772\n",
      "Training Epoch 80  61.7% | batch:        58 of        94\t|\tloss: 1999.73\n",
      "Training Epoch 80  62.8% | batch:        59 of        94\t|\tloss: 762.453\n",
      "Training Epoch 80  63.8% | batch:        60 of        94\t|\tloss: 878.077\n",
      "Training Epoch 80  64.9% | batch:        61 of        94\t|\tloss: 1871.74\n",
      "Training Epoch 80  66.0% | batch:        62 of        94\t|\tloss: 1031.43\n",
      "Training Epoch 80  67.0% | batch:        63 of        94\t|\tloss: 752.326\n",
      "Training Epoch 80  68.1% | batch:        64 of        94\t|\tloss: 790.526\n",
      "Training Epoch 80  69.1% | batch:        65 of        94\t|\tloss: 608.934\n",
      "Training Epoch 80  70.2% | batch:        66 of        94\t|\tloss: 983.049\n",
      "Training Epoch 80  71.3% | batch:        67 of        94\t|\tloss: 1825.25\n",
      "Training Epoch 80  72.3% | batch:        68 of        94\t|\tloss: 1048.33\n",
      "Training Epoch 80  73.4% | batch:        69 of        94\t|\tloss: 1565.55\n",
      "Training Epoch 80  74.5% | batch:        70 of        94\t|\tloss: 990.742\n",
      "Training Epoch 80  75.5% | batch:        71 of        94\t|\tloss: 1484.27\n",
      "Training Epoch 80  76.6% | batch:        72 of        94\t|\tloss: 804.13\n",
      "Training Epoch 80  77.7% | batch:        73 of        94\t|\tloss: 1148.55\n",
      "Training Epoch 80  78.7% | batch:        74 of        94\t|\tloss: 694.198\n",
      "Training Epoch 80  79.8% | batch:        75 of        94\t|\tloss: 847.478\n",
      "Training Epoch 80  80.9% | batch:        76 of        94\t|\tloss: 1180.84\n",
      "Training Epoch 80  81.9% | batch:        77 of        94\t|\tloss: 1633.77\n",
      "Training Epoch 80  83.0% | batch:        78 of        94\t|\tloss: 949.289\n",
      "Training Epoch 80  84.0% | batch:        79 of        94\t|\tloss: 1040.11\n",
      "Training Epoch 80  85.1% | batch:        80 of        94\t|\tloss: 1475.39\n",
      "Training Epoch 80  86.2% | batch:        81 of        94\t|\tloss: 1123.36\n",
      "Training Epoch 80  87.2% | batch:        82 of        94\t|\tloss: 1295.48\n",
      "Training Epoch 80  88.3% | batch:        83 of        94\t|\tloss: 881.766\n",
      "Training Epoch 80  89.4% | batch:        84 of        94\t|\tloss: 860.26\n",
      "Training Epoch 80  90.4% | batch:        85 of        94\t|\tloss: 870.999\n",
      "Training Epoch 80  91.5% | batch:        86 of        94\t|\tloss: 1555.03\n",
      "Training Epoch 80  92.6% | batch:        87 of        94\t|\tloss: 788.163\n",
      "Training Epoch 80  93.6% | batch:        88 of        94\t|\tloss: 841.91\n",
      "Training Epoch 80  94.7% | batch:        89 of        94\t|\tloss: 1099.03\n",
      "Training Epoch 80  95.7% | batch:        90 of        94\t|\tloss: 1259.1\n",
      "Training Epoch 80  96.8% | batch:        91 of        94\t|\tloss: 996.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:03,770 | INFO : Epoch 80 Training Summary: epoch: 80.000000 | loss: 1050.673320 | \n",
      "2023-05-09 14:23:03,771 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8201298713684082 seconds\n",
      "\n",
      "2023-05-09 14:23:03,772 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8276508361101151 seconds\n",
      "2023-05-09 14:23:03,772 | INFO : Avg batch train. time: 0.01944309400117144 seconds\n",
      "2023-05-09 14:23:03,772 | INFO : Avg sample train. time: 0.00015335214265062218 seconds\n",
      "2023-05-09 14:23:03,773 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 80  97.9% | batch:        92 of        94\t|\tloss: 1018.35\n",
      "Training Epoch 80  98.9% | batch:        93 of        94\t|\tloss: 1628.7\n",
      "\n",
      "Evaluating Epoch 80   0.0% | batch:         0 of        40\t|\tloss: 6888.99\n",
      "Evaluating Epoch 80   2.5% | batch:         1 of        40\t|\tloss: 1225.22\n",
      "Evaluating Epoch 80   5.0% | batch:         2 of        40\t|\tloss: 4323.7\n",
      "Evaluating Epoch 80   7.5% | batch:         3 of        40\t|\tloss: 6153.42\n",
      "Evaluating Epoch 80  10.0% | batch:         4 of        40\t|\tloss: 2635.26\n",
      "Evaluating Epoch 80  12.5% | batch:         5 of        40\t|\tloss: 2546.5\n",
      "Evaluating Epoch 80  15.0% | batch:         6 of        40\t|\tloss: 9025.53\n",
      "Evaluating Epoch 80  17.5% | batch:         7 of        40\t|\tloss: 3485.96\n",
      "Evaluating Epoch 80  20.0% | batch:         8 of        40\t|\tloss: 2914.6\n",
      "Evaluating Epoch 80  22.5% | batch:         9 of        40\t|\tloss: 2516.54\n",
      "Evaluating Epoch 80  25.0% | batch:        10 of        40\t|\tloss: 4662.15\n",
      "Evaluating Epoch 80  27.5% | batch:        11 of        40\t|\tloss: 1499.98\n",
      "Evaluating Epoch 80  30.0% | batch:        12 of        40\t|\tloss: 6914.76\n",
      "Evaluating Epoch 80  32.5% | batch:        13 of        40\t|\tloss: 3376.89\n",
      "Evaluating Epoch 80  35.0% | batch:        14 of        40\t|\tloss: 2302.97\n",
      "Evaluating Epoch 80  37.5% | batch:        15 of        40\t|\tloss: 3570.11\n",
      "Evaluating Epoch 80  40.0% | batch:        16 of        40\t|\tloss: 4267.63\n",
      "Evaluating Epoch 80  42.5% | batch:        17 of        40\t|\tloss: 3129.47\n",
      "Evaluating Epoch 80  45.0% | batch:        18 of        40\t|\tloss: 2679.24\n",
      "Evaluating Epoch 80  47.5% | batch:        19 of        40\t|\tloss: 6617.97\n",
      "Evaluating Epoch 80  50.0% | batch:        20 of        40\t|\tloss: 6226.51\n",
      "Evaluating Epoch 80  52.5% | batch:        21 of        40\t|\tloss: 1288.76\n",
      "Evaluating Epoch 80  55.0% | batch:        22 of        40\t|\tloss: 3787.38\n",
      "Evaluating Epoch 80  57.5% | batch:        23 of        40\t|\tloss: 3614.93\n",
      "Evaluating Epoch 80  60.0% | batch:        24 of        40\t|\tloss: 1681.43\n",
      "Evaluating Epoch 80  62.5% | batch:        25 of        40\t|\tloss: 3804.94\n",
      "Evaluating Epoch 80  65.0% | batch:        26 of        40\t|\tloss: 9541.52\n",
      "Evaluating Epoch 80  67.5% | batch:        27 of        40\t|\tloss: 3151.03\n",
      "Evaluating Epoch 80  70.0% | batch:        28 of        40\t|\tloss: 2172.37\n",
      "Evaluating Epoch 80  72.5% | batch:        29 of        40\t|\tloss: 9843.02\n",
      "Evaluating Epoch 80  75.0% | batch:        30 of        40\t|\tloss: 2117.67\n",
      "Evaluating Epoch 80  77.5% | batch:        31 of        40\t|\tloss: 1771.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:04,246 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.472888708114624 seconds\n",
      "\n",
      "2023-05-09 14:23:04,247 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4743249302818662 seconds\n",
      "2023-05-09 14:23:04,247 | INFO : Avg batch val. time: 0.011858123257046655 seconds\n",
      "2023-05-09 14:23:04,248 | INFO : Avg sample val. time: 9.396294181494972e-05 seconds\n",
      "2023-05-09 14:23:04,248 | INFO : Epoch 80 Validation Summary: epoch: 80.000000 | loss: 4252.005952 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 80  80.0% | batch:        32 of        40\t|\tloss: 7993.37\n",
      "Evaluating Epoch 80  82.5% | batch:        33 of        40\t|\tloss: 5803.26\n",
      "Evaluating Epoch 80  85.0% | batch:        34 of        40\t|\tloss: 1029.47\n",
      "Evaluating Epoch 80  87.5% | batch:        35 of        40\t|\tloss: 5970.92\n",
      "Evaluating Epoch 80  90.0% | batch:        36 of        40\t|\tloss: 5025.97\n",
      "Evaluating Epoch 80  92.5% | batch:        37 of        40\t|\tloss: 2724.87\n",
      "Evaluating Epoch 80  95.0% | batch:        38 of        40\t|\tloss: 3700.09\n",
      "Evaluating Epoch 80  97.5% | batch:        39 of        40\t|\tloss: 13034.3\n",
      "\n",
      "Training Epoch 81   0.0% | batch:         0 of        94\t|\tloss: 758.251\n",
      "Training Epoch 81   1.1% | batch:         1 of        94\t|\tloss: 991.211\n",
      "Training Epoch 81   2.1% | batch:         2 of        94\t|\tloss: 2582.08\n",
      "Training Epoch 81   3.2% | batch:         3 of        94\t|\tloss: 987.734\n",
      "Training Epoch 81   4.3% | batch:         4 of        94\t|\tloss: 1054.08\n",
      "Training Epoch 81   5.3% | batch:         5 of        94\t|\tloss: 865.925\n",
      "Training Epoch 81   6.4% | batch:         6 of        94\t|\tloss: 743.226\n",
      "Training Epoch 81   7.4% | batch:         7 of        94\t|\tloss: 872.181\n",
      "Training Epoch 81   8.5% | batch:         8 of        94\t|\tloss: 633.891\n",
      "Training Epoch 81   9.6% | batch:         9 of        94\t|\tloss: 969.579\n",
      "Training Epoch 81  10.6% | batch:        10 of        94\t|\tloss: 857.49\n",
      "Training Epoch 81  11.7% | batch:        11 of        94\t|\tloss: 627.831\n",
      "Training Epoch 81  12.8% | batch:        12 of        94\t|\tloss: 1346.96\n",
      "Training Epoch 81  13.8% | batch:        13 of        94\t|\tloss: 933.926\n",
      "Training Epoch 81  14.9% | batch:        14 of        94\t|\tloss: 1225.85\n",
      "Training Epoch 81  16.0% | batch:        15 of        94\t|\tloss: 765.011\n",
      "Training Epoch 81  17.0% | batch:        16 of        94\t|\tloss: 781.766\n",
      "Training Epoch 81  18.1% | batch:        17 of        94\t|\tloss: 1451.45\n",
      "Training Epoch 81  19.1% | batch:        18 of        94\t|\tloss: 806.293\n",
      "Training Epoch 81  20.2% | batch:        19 of        94\t|\tloss: 1148.23\n",
      "Training Epoch 81  21.3% | batch:        20 of        94\t|\tloss: 908.244\n",
      "Training Epoch 81  22.3% | batch:        21 of        94\t|\tloss: 1040.76\n",
      "Training Epoch 81  23.4% | batch:        22 of        94\t|\tloss: 652.739\n",
      "Training Epoch 81  24.5% | batch:        23 of        94\t|\tloss: 730.983\n",
      "Training Epoch 81  25.5% | batch:        24 of        94\t|\tloss: 1023.94\n",
      "Training Epoch 81  26.6% | batch:        25 of        94\t|\tloss: 840.846\n",
      "Training Epoch 81  27.7% | batch:        26 of        94\t|\tloss: 1691.39\n",
      "Training Epoch 81  28.7% | batch:        27 of        94\t|\tloss: 1346.35\n",
      "Training Epoch 81  29.8% | batch:        28 of        94\t|\tloss: 1095.32\n",
      "Training Epoch 81  30.9% | batch:        29 of        94\t|\tloss: 865.309\n",
      "Training Epoch 81  31.9% | batch:        30 of        94\t|\tloss: 661.524\n",
      "Training Epoch 81  33.0% | batch:        31 of        94\t|\tloss: 815.261\n",
      "Training Epoch 81  34.0% | batch:        32 of        94\t|\tloss: 748.427\n",
      "Training Epoch 81  35.1% | batch:        33 of        94\t|\tloss: 1029.33\n",
      "Training Epoch 81  36.2% | batch:        34 of        94\t|\tloss: 1188.03\n",
      "Training Epoch 81  37.2% | batch:        35 of        94\t|\tloss: 877.455\n",
      "Training Epoch 81  38.3% | batch:        36 of        94\t|\tloss: 819.322\n",
      "Training Epoch 81  39.4% | batch:        37 of        94\t|\tloss: 1432.41\n",
      "Training Epoch 81  40.4% | batch:        38 of        94\t|\tloss: 1059.17\n",
      "Training Epoch 81  41.5% | batch:        39 of        94\t|\tloss: 1091.92\n",
      "Training Epoch 81  42.6% | batch:        40 of        94\t|\tloss: 1494.46\n",
      "Training Epoch 81  43.6% | batch:        41 of        94\t|\tloss: 833.494\n",
      "Training Epoch 81  44.7% | batch:        42 of        94\t|\tloss: 1073.09\n",
      "Training Epoch 81  45.7% | batch:        43 of        94\t|\tloss: 843.142\n",
      "Training Epoch 81  46.8% | batch:        44 of        94\t|\tloss: 1531.31\n",
      "Training Epoch 81  47.9% | batch:        45 of        94\t|\tloss: 1146.96\n",
      "Training Epoch 81  48.9% | batch:        46 of        94\t|\tloss: 1027.46\n",
      "Training Epoch 81  50.0% | batch:        47 of        94\t|\tloss: 1223.68\n",
      "Training Epoch 81  51.1% | batch:        48 of        94\t|\tloss: 587.998\n",
      "Training Epoch 81  52.1% | batch:        49 of        94\t|\tloss: 754.011\n",
      "Training Epoch 81  53.2% | batch:        50 of        94\t|\tloss: 580.13\n",
      "Training Epoch 81  54.3% | batch:        51 of        94\t|\tloss: 1142.35\n",
      "Training Epoch 81  55.3% | batch:        52 of        94\t|\tloss: 1228.58\n",
      "Training Epoch 81  56.4% | batch:        53 of        94\t|\tloss: 1565.16\n",
      "Training Epoch 81  57.4% | batch:        54 of        94\t|\tloss: 1038.26\n",
      "Training Epoch 81  58.5% | batch:        55 of        94\t|\tloss: 1125.74\n",
      "Training Epoch 81  59.6% | batch:        56 of        94\t|\tloss: 920.683\n",
      "Training Epoch 81  60.6% | batch:        57 of        94\t|\tloss: 884.851\n",
      "Training Epoch 81  61.7% | batch:        58 of        94\t|\tloss: 1129.97\n",
      "Training Epoch 81  62.8% | batch:        59 of        94\t|\tloss: 709.955\n",
      "Training Epoch 81  63.8% | batch:        60 of        94\t|\tloss: 1283.56\n",
      "Training Epoch 81  64.9% | batch:        61 of        94\t|\tloss: 1042.84\n",
      "Training Epoch 81  66.0% | batch:        62 of        94\t|\tloss: 1554.16\n",
      "Training Epoch 81  67.0% | batch:        63 of        94\t|\tloss: 1029.37\n",
      "Training Epoch 81  68.1% | batch:        64 of        94\t|\tloss: 1312.15\n",
      "Training Epoch 81  69.1% | batch:        65 of        94\t|\tloss: 1762.55\n",
      "Training Epoch 81  70.2% | batch:        66 of        94\t|\tloss: 1000.98\n",
      "Training Epoch 81  71.3% | batch:        67 of        94\t|\tloss: 1578.63\n",
      "Training Epoch 81  72.3% | batch:        68 of        94\t|\tloss: 1211.3\n",
      "Training Epoch 81  73.4% | batch:        69 of        94\t|\tloss: 1106.15\n",
      "Training Epoch 81  74.5% | batch:        70 of        94\t|\tloss: 729.912\n",
      "Training Epoch 81  75.5% | batch:        71 of        94\t|\tloss: 1373.72\n",
      "Training Epoch 81  76.6% | batch:        72 of        94\t|\tloss: 1110.94\n",
      "Training Epoch 81  77.7% | batch:        73 of        94\t|\tloss: 882.534\n",
      "Training Epoch 81  78.7% | batch:        74 of        94\t|\tloss: 1167.23\n",
      "Training Epoch 81  79.8% | batch:        75 of        94\t|\tloss: 1228.79\n",
      "Training Epoch 81  80.9% | batch:        76 of        94\t|\tloss: 1909.72\n",
      "Training Epoch 81  81.9% | batch:        77 of        94\t|\tloss: 712.744\n",
      "Training Epoch 81  83.0% | batch:        78 of        94\t|\tloss: 1100.95\n",
      "Training Epoch 81  84.0% | batch:        79 of        94\t|\tloss: 1084.5\n",
      "Training Epoch 81  85.1% | batch:        80 of        94\t|\tloss: 626.511\n",
      "Training Epoch 81  86.2% | batch:        81 of        94\t|\tloss: 692.264\n",
      "Training Epoch 81  87.2% | batch:        82 of        94\t|\tloss: 978.674\n",
      "Training Epoch 81  88.3% | batch:        83 of        94\t|\tloss: 1452.25\n",
      "Training Epoch 81  89.4% | batch:        84 of        94\t|\tloss: 1004.3\n",
      "Training Epoch 81  90.4% | batch:        85 of        94\t|\tloss: 1238.47\n",
      "Training Epoch 81  91.5% | batch:        86 of        94\t|\tloss: 1381.82\n",
      "Training Epoch 81  92.6% | batch:        87 of        94\t|\tloss: 1321.19\n",
      "Training Epoch 81  93.6% | batch:        88 of        94\t|\tloss: 1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:06,136 | INFO : Epoch 81 Training Summary: epoch: 81.000000 | loss: 1063.890568 | \n",
      "2023-05-09 14:23:06,136 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8607866764068604 seconds\n",
      "\n",
      "2023-05-09 14:23:06,137 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.828059920558223 seconds\n",
      "2023-05-09 14:23:06,137 | INFO : Avg batch train. time: 0.01944744596338535 seconds\n",
      "2023-05-09 14:23:06,138 | INFO : Avg sample train. time: 0.00015338646757494739 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 81  94.7% | batch:        89 of        94\t|\tloss: 853.507\n",
      "Training Epoch 81  95.7% | batch:        90 of        94\t|\tloss: 897.242\n",
      "Training Epoch 81  96.8% | batch:        91 of        94\t|\tloss: 814.878\n",
      "Training Epoch 81  97.9% | batch:        92 of        94\t|\tloss: 1023.11\n",
      "Training Epoch 81  98.9% | batch:        93 of        94\t|\tloss: 1071.91\n",
      "\n",
      "Training Epoch 82   0.0% | batch:         0 of        94\t|\tloss: 1661.38\n",
      "Training Epoch 82   1.1% | batch:         1 of        94\t|\tloss: 1217.1\n",
      "Training Epoch 82   2.1% | batch:         2 of        94\t|\tloss: 1148.13\n",
      "Training Epoch 82   3.2% | batch:         3 of        94\t|\tloss: 1190.2\n",
      "Training Epoch 82   4.3% | batch:         4 of        94\t|\tloss: 1163.91\n",
      "Training Epoch 82   5.3% | batch:         5 of        94\t|\tloss: 809.395\n",
      "Training Epoch 82   6.4% | batch:         6 of        94\t|\tloss: 791.305\n",
      "Training Epoch 82   7.4% | batch:         7 of        94\t|\tloss: 1501.82\n",
      "Training Epoch 82   8.5% | batch:         8 of        94\t|\tloss: 1147.07\n",
      "Training Epoch 82   9.6% | batch:         9 of        94\t|\tloss: 762.67\n",
      "Training Epoch 82  10.6% | batch:        10 of        94\t|\tloss: 835.663\n",
      "Training Epoch 82  11.7% | batch:        11 of        94\t|\tloss: 1055.74\n",
      "Training Epoch 82  12.8% | batch:        12 of        94\t|\tloss: 1227.23\n",
      "Training Epoch 82  13.8% | batch:        13 of        94\t|\tloss: 864.479\n",
      "Training Epoch 82  14.9% | batch:        14 of        94\t|\tloss: 728.182\n",
      "Training Epoch 82  16.0% | batch:        15 of        94\t|\tloss: 854.538\n",
      "Training Epoch 82  17.0% | batch:        16 of        94\t|\tloss: 793.875\n",
      "Training Epoch 82  18.1% | batch:        17 of        94\t|\tloss: 1206.34\n",
      "Training Epoch 82  19.1% | batch:        18 of        94\t|\tloss: 705.354\n",
      "Training Epoch 82  20.2% | batch:        19 of        94\t|\tloss: 612.664\n",
      "Training Epoch 82  21.3% | batch:        20 of        94\t|\tloss: 921.718\n",
      "Training Epoch 82  22.3% | batch:        21 of        94\t|\tloss: 1324.42\n",
      "Training Epoch 82  23.4% | batch:        22 of        94\t|\tloss: 892.183\n",
      "Training Epoch 82  24.5% | batch:        23 of        94\t|\tloss: 591.783\n",
      "Training Epoch 82  25.5% | batch:        24 of        94\t|\tloss: 959.222\n",
      "Training Epoch 82  26.6% | batch:        25 of        94\t|\tloss: 2791.41\n",
      "Training Epoch 82  27.7% | batch:        26 of        94\t|\tloss: 788.493\n",
      "Training Epoch 82  28.7% | batch:        27 of        94\t|\tloss: 963.551\n",
      "Training Epoch 82  29.8% | batch:        28 of        94\t|\tloss: 1095.65\n",
      "Training Epoch 82  30.9% | batch:        29 of        94\t|\tloss: 913.762\n",
      "Training Epoch 82  31.9% | batch:        30 of        94\t|\tloss: 729.707\n",
      "Training Epoch 82  33.0% | batch:        31 of        94\t|\tloss: 890.702\n",
      "Training Epoch 82  34.0% | batch:        32 of        94\t|\tloss: 739.34\n",
      "Training Epoch 82  35.1% | batch:        33 of        94\t|\tloss: 1149.4\n",
      "Training Epoch 82  36.2% | batch:        34 of        94\t|\tloss: 1671.07\n",
      "Training Epoch 82  37.2% | batch:        35 of        94\t|\tloss: 758.419\n",
      "Training Epoch 82  38.3% | batch:        36 of        94\t|\tloss: 1364.11\n",
      "Training Epoch 82  39.4% | batch:        37 of        94\t|\tloss: 1290.57\n",
      "Training Epoch 82  40.4% | batch:        38 of        94\t|\tloss: 824.581\n",
      "Training Epoch 82  41.5% | batch:        39 of        94\t|\tloss: 855.062\n",
      "Training Epoch 82  42.6% | batch:        40 of        94\t|\tloss: 841.584\n",
      "Training Epoch 82  43.6% | batch:        41 of        94\t|\tloss: 1234.34\n",
      "Training Epoch 82  44.7% | batch:        42 of        94\t|\tloss: 829.821\n",
      "Training Epoch 82  45.7% | batch:        43 of        94\t|\tloss: 985.074\n",
      "Training Epoch 82  46.8% | batch:        44 of        94\t|\tloss: 1601.35\n",
      "Training Epoch 82  47.9% | batch:        45 of        94\t|\tloss: 1199.2\n",
      "Training Epoch 82  48.9% | batch:        46 of        94\t|\tloss: 1490.02\n",
      "Training Epoch 82  50.0% | batch:        47 of        94\t|\tloss: 1329.31\n",
      "Training Epoch 82  51.1% | batch:        48 of        94\t|\tloss: 860.413\n",
      "Training Epoch 82  52.1% | batch:        49 of        94\t|\tloss: 809.521\n",
      "Training Epoch 82  53.2% | batch:        50 of        94\t|\tloss: 879.498\n",
      "Training Epoch 82  54.3% | batch:        51 of        94\t|\tloss: 1181.3\n",
      "Training Epoch 82  55.3% | batch:        52 of        94\t|\tloss: 902.52\n",
      "Training Epoch 82  56.4% | batch:        53 of        94\t|\tloss: 915.289\n",
      "Training Epoch 82  57.4% | batch:        54 of        94\t|\tloss: 1044.26\n",
      "Training Epoch 82  58.5% | batch:        55 of        94\t|\tloss: 925.891\n",
      "Training Epoch 82  59.6% | batch:        56 of        94\t|\tloss: 1039.33\n",
      "Training Epoch 82  60.6% | batch:        57 of        94\t|\tloss: 1065.18\n",
      "Training Epoch 82  61.7% | batch:        58 of        94\t|\tloss: 1082.24\n",
      "Training Epoch 82  62.8% | batch:        59 of        94\t|\tloss: 1237.46\n",
      "Training Epoch 82  63.8% | batch:        60 of        94\t|\tloss: 820.839\n",
      "Training Epoch 82  64.9% | batch:        61 of        94\t|\tloss: 1083.3\n",
      "Training Epoch 82  66.0% | batch:        62 of        94\t|\tloss: 1555.52\n",
      "Training Epoch 82  67.0% | batch:        63 of        94\t|\tloss: 1244.2\n",
      "Training Epoch 82  68.1% | batch:        64 of        94\t|\tloss: 1126.47\n",
      "Training Epoch 82  69.1% | batch:        65 of        94\t|\tloss: 1098.3\n",
      "Training Epoch 82  70.2% | batch:        66 of        94\t|\tloss: 665.523\n",
      "Training Epoch 82  71.3% | batch:        67 of        94\t|\tloss: 1051.05\n",
      "Training Epoch 82  72.3% | batch:        68 of        94\t|\tloss: 1336.85\n",
      "Training Epoch 82  73.4% | batch:        69 of        94\t|\tloss: 558.752\n",
      "Training Epoch 82  74.5% | batch:        70 of        94\t|\tloss: 1802.04\n",
      "Training Epoch 82  75.5% | batch:        71 of        94\t|\tloss: 884.012\n",
      "Training Epoch 82  76.6% | batch:        72 of        94\t|\tloss: 973.792\n",
      "Training Epoch 82  77.7% | batch:        73 of        94\t|\tloss: 750.532\n",
      "Training Epoch 82  78.7% | batch:        74 of        94\t|\tloss: 1069.59\n",
      "Training Epoch 82  79.8% | batch:        75 of        94\t|\tloss: 1353.86\n",
      "Training Epoch 82  80.9% | batch:        76 of        94\t|\tloss: 869.47\n",
      "Training Epoch 82  81.9% | batch:        77 of        94\t|\tloss: 1233.02\n",
      "Training Epoch 82  83.0% | batch:        78 of        94\t|\tloss: 931.009\n",
      "Training Epoch 82  84.0% | batch:        79 of        94\t|\tloss: 937.041\n",
      "Training Epoch 82  85.1% | batch:        80 of        94\t|\tloss: 1104.54\n",
      "Training Epoch 82  86.2% | batch:        81 of        94\t|\tloss: 799.978\n",
      "Training Epoch 82  87.2% | batch:        82 of        94\t|\tloss: 1083.99\n",
      "Training Epoch 82  88.3% | batch:        83 of        94\t|\tloss: 842.266\n",
      "Training Epoch 82  89.4% | batch:        84 of        94\t|\tloss: 1053.09\n",
      "Training Epoch 82  90.4% | batch:        85 of        94\t|\tloss: 1310.25\n",
      "Training Epoch 82  91.5% | batch:        86 of        94\t|\tloss: 1233.21\n",
      "Training Epoch 82  92.6% | batch:        87 of        94\t|\tloss: 1530.53\n",
      "Training Epoch 82  93.6% | batch:        88 of        94\t|\tloss: 615.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:08,037 | INFO : Epoch 82 Training Summary: epoch: 82.000000 | loss: 1052.490477 | \n",
      "2023-05-09 14:23:08,038 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8782627582550049 seconds\n",
      "\n",
      "2023-05-09 14:23:08,038 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8286721502862326 seconds\n",
      "2023-05-09 14:23:08,039 | INFO : Avg batch train. time: 0.01945395904559822 seconds\n",
      "2023-05-09 14:23:08,040 | INFO : Avg sample train. time: 0.00015343783774846725 seconds\n",
      "2023-05-09 14:23:08,040 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 82  94.7% | batch:        89 of        94\t|\tloss: 918.649\n",
      "Training Epoch 82  95.7% | batch:        90 of        94\t|\tloss: 769.037\n",
      "Training Epoch 82  96.8% | batch:        91 of        94\t|\tloss: 1188.7\n",
      "Training Epoch 82  97.9% | batch:        92 of        94\t|\tloss: 869.393\n",
      "Training Epoch 82  98.9% | batch:        93 of        94\t|\tloss: 796.167\n",
      "\n",
      "Evaluating Epoch 82   0.0% | batch:         0 of        40\t|\tloss: 6464.71\n",
      "Evaluating Epoch 82   2.5% | batch:         1 of        40\t|\tloss: 1115.38\n",
      "Evaluating Epoch 82   5.0% | batch:         2 of        40\t|\tloss: 4107.53\n",
      "Evaluating Epoch 82   7.5% | batch:         3 of        40\t|\tloss: 6202.41\n",
      "Evaluating Epoch 82  10.0% | batch:         4 of        40\t|\tloss: 3038.04\n",
      "Evaluating Epoch 82  12.5% | batch:         5 of        40\t|\tloss: 2659.45\n",
      "Evaluating Epoch 82  15.0% | batch:         6 of        40\t|\tloss: 8240.58\n",
      "Evaluating Epoch 82  17.5% | batch:         7 of        40\t|\tloss: 3037.57\n",
      "Evaluating Epoch 82  20.0% | batch:         8 of        40\t|\tloss: 2758.12\n",
      "Evaluating Epoch 82  22.5% | batch:         9 of        40\t|\tloss: 2555.33\n",
      "Evaluating Epoch 82  25.0% | batch:        10 of        40\t|\tloss: 5110.61\n",
      "Evaluating Epoch 82  27.5% | batch:        11 of        40\t|\tloss: 1513.1\n",
      "Evaluating Epoch 82  30.0% | batch:        12 of        40\t|\tloss: 6541.37\n",
      "Evaluating Epoch 82  32.5% | batch:        13 of        40\t|\tloss: 3484.99\n",
      "Evaluating Epoch 82  35.0% | batch:        14 of        40\t|\tloss: 2446.28\n",
      "Evaluating Epoch 82  37.5% | batch:        15 of        40\t|\tloss: 3703.63\n",
      "Evaluating Epoch 82  40.0% | batch:        16 of        40\t|\tloss: 3667.81\n",
      "Evaluating Epoch 82  42.5% | batch:        17 of        40\t|\tloss: 3172.2\n",
      "Evaluating Epoch 82  45.0% | batch:        18 of        40\t|\tloss: 2484.43\n",
      "Evaluating Epoch 82  47.5% | batch:        19 of        40\t|\tloss: 5962.36\n",
      "Evaluating Epoch 82  50.0% | batch:        20 of        40\t|\tloss: 5532.6\n",
      "Evaluating Epoch 82  52.5% | batch:        21 of        40\t|\tloss: 1131.16\n",
      "Evaluating Epoch 82  55.0% | batch:        22 of        40\t|\tloss: 3593.81\n",
      "Evaluating Epoch 82  57.5% | batch:        23 of        40\t|\tloss: 3851.31\n",
      "Evaluating Epoch 82  60.0% | batch:        24 of        40\t|\tloss: 1772.46\n",
      "Evaluating Epoch 82  62.5% | batch:        25 of        40\t|\tloss: 3741.92\n",
      "Evaluating Epoch 82  65.0% | batch:        26 of        40\t|\tloss: 9649.29\n",
      "Evaluating Epoch 82  67.5% | batch:        27 of        40\t|\tloss: 2779\n",
      "Evaluating Epoch 82  70.0% | batch:        28 of        40\t|\tloss: 1904.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:08,494 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45316052436828613 seconds\n",
      "\n",
      "2023-05-09 14:23:08,494 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47383273479550386 seconds\n",
      "2023-05-09 14:23:08,494 | INFO : Avg batch val. time: 0.011845818369887597 seconds\n",
      "2023-05-09 14:23:08,495 | INFO : Avg sample val. time: 9.386543874712835e-05 seconds\n",
      "2023-05-09 14:23:08,495 | INFO : Epoch 82 Validation Summary: epoch: 82.000000 | loss: 4089.291947 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 82  72.5% | batch:        29 of        40\t|\tloss: 9218.08\n",
      "Evaluating Epoch 82  75.0% | batch:        30 of        40\t|\tloss: 2262.95\n",
      "Evaluating Epoch 82  77.5% | batch:        31 of        40\t|\tloss: 1940.37\n",
      "Evaluating Epoch 82  80.0% | batch:        32 of        40\t|\tloss: 7469.91\n",
      "Evaluating Epoch 82  82.5% | batch:        33 of        40\t|\tloss: 5893.12\n",
      "Evaluating Epoch 82  85.0% | batch:        34 of        40\t|\tloss: 1077.09\n",
      "Evaluating Epoch 82  87.5% | batch:        35 of        40\t|\tloss: 4905.81\n",
      "Evaluating Epoch 82  90.0% | batch:        36 of        40\t|\tloss: 4892.61\n",
      "Evaluating Epoch 82  92.5% | batch:        37 of        40\t|\tloss: 2881.07\n",
      "Evaluating Epoch 82  95.0% | batch:        38 of        40\t|\tloss: 3754.9\n",
      "Evaluating Epoch 82  97.5% | batch:        39 of        40\t|\tloss: 10865.4\n",
      "\n",
      "Training Epoch 83   0.0% | batch:         0 of        94\t|\tloss: 996.778\n",
      "Training Epoch 83   1.1% | batch:         1 of        94\t|\tloss: 1117.03\n",
      "Training Epoch 83   2.1% | batch:         2 of        94\t|\tloss: 835.664\n",
      "Training Epoch 83   3.2% | batch:         3 of        94\t|\tloss: 911.427\n",
      "Training Epoch 83   4.3% | batch:         4 of        94\t|\tloss: 641.431\n",
      "Training Epoch 83   5.3% | batch:         5 of        94\t|\tloss: 754.485\n",
      "Training Epoch 83   6.4% | batch:         6 of        94\t|\tloss: 923.202\n",
      "Training Epoch 83   7.4% | batch:         7 of        94\t|\tloss: 929.268\n",
      "Training Epoch 83   8.5% | batch:         8 of        94\t|\tloss: 935.809\n",
      "Training Epoch 83   9.6% | batch:         9 of        94\t|\tloss: 962.224\n",
      "Training Epoch 83  10.6% | batch:        10 of        94\t|\tloss: 705.229\n",
      "Training Epoch 83  11.7% | batch:        11 of        94\t|\tloss: 774.136\n",
      "Training Epoch 83  12.8% | batch:        12 of        94\t|\tloss: 713.994\n",
      "Training Epoch 83  13.8% | batch:        13 of        94\t|\tloss: 623.705\n",
      "Training Epoch 83  14.9% | batch:        14 of        94\t|\tloss: 706.67\n",
      "Training Epoch 83  16.0% | batch:        15 of        94\t|\tloss: 1005.97\n",
      "Training Epoch 83  17.0% | batch:        16 of        94\t|\tloss: 3074.59\n",
      "Training Epoch 83  18.1% | batch:        17 of        94\t|\tloss: 689.63\n",
      "Training Epoch 83  19.1% | batch:        18 of        94\t|\tloss: 659.824\n",
      "Training Epoch 83  20.2% | batch:        19 of        94\t|\tloss: 561.31\n",
      "Training Epoch 83  21.3% | batch:        20 of        94\t|\tloss: 961.019\n",
      "Training Epoch 83  22.3% | batch:        21 of        94\t|\tloss: 945.476\n",
      "Training Epoch 83  23.4% | batch:        22 of        94\t|\tloss: 1920.26\n",
      "Training Epoch 83  24.5% | batch:        23 of        94\t|\tloss: 895.793\n",
      "Training Epoch 83  25.5% | batch:        24 of        94\t|\tloss: 909.562\n",
      "Training Epoch 83  26.6% | batch:        25 of        94\t|\tloss: 786.019\n",
      "Training Epoch 83  27.7% | batch:        26 of        94\t|\tloss: 687.709\n",
      "Training Epoch 83  28.7% | batch:        27 of        94\t|\tloss: 1022.08\n",
      "Training Epoch 83  29.8% | batch:        28 of        94\t|\tloss: 754.058\n",
      "Training Epoch 83  30.9% | batch:        29 of        94\t|\tloss: 1093.2\n",
      "Training Epoch 83  31.9% | batch:        30 of        94\t|\tloss: 762.855\n",
      "Training Epoch 83  33.0% | batch:        31 of        94\t|\tloss: 888.115\n",
      "Training Epoch 83  34.0% | batch:        32 of        94\t|\tloss: 922.52\n",
      "Training Epoch 83  35.1% | batch:        33 of        94\t|\tloss: 1456.73\n",
      "Training Epoch 83  36.2% | batch:        34 of        94\t|\tloss: 846.165\n",
      "Training Epoch 83  37.2% | batch:        35 of        94\t|\tloss: 1093.86\n",
      "Training Epoch 83  38.3% | batch:        36 of        94\t|\tloss: 541.961\n",
      "Training Epoch 83  39.4% | batch:        37 of        94\t|\tloss: 1149.89\n",
      "Training Epoch 83  40.4% | batch:        38 of        94\t|\tloss: 587.844\n",
      "Training Epoch 83  41.5% | batch:        39 of        94\t|\tloss: 667.403\n",
      "Training Epoch 83  42.6% | batch:        40 of        94\t|\tloss: 794.543\n",
      "Training Epoch 83  43.6% | batch:        41 of        94\t|\tloss: 791.752\n",
      "Training Epoch 83  44.7% | batch:        42 of        94\t|\tloss: 881.067\n",
      "Training Epoch 83  45.7% | batch:        43 of        94\t|\tloss: 1483.32\n",
      "Training Epoch 83  46.8% | batch:        44 of        94\t|\tloss: 2061.88\n",
      "Training Epoch 83  47.9% | batch:        45 of        94\t|\tloss: 885.199\n",
      "Training Epoch 83  48.9% | batch:        46 of        94\t|\tloss: 1600.3\n",
      "Training Epoch 83  50.0% | batch:        47 of        94\t|\tloss: 746.005\n",
      "Training Epoch 83  51.1% | batch:        48 of        94\t|\tloss: 839.559\n",
      "Training Epoch 83  52.1% | batch:        49 of        94\t|\tloss: 805.42\n",
      "Training Epoch 83  53.2% | batch:        50 of        94\t|\tloss: 671.208\n",
      "Training Epoch 83  54.3% | batch:        51 of        94\t|\tloss: 1473.35\n",
      "Training Epoch 83  55.3% | batch:        52 of        94\t|\tloss: 913.143\n",
      "Training Epoch 83  56.4% | batch:        53 of        94\t|\tloss: 787.909\n",
      "Training Epoch 83  57.4% | batch:        54 of        94\t|\tloss: 987.054\n",
      "Training Epoch 83  58.5% | batch:        55 of        94\t|\tloss: 1068.51\n",
      "Training Epoch 83  59.6% | batch:        56 of        94\t|\tloss: 781.769\n",
      "Training Epoch 83  60.6% | batch:        57 of        94\t|\tloss: 827.675\n",
      "Training Epoch 83  61.7% | batch:        58 of        94\t|\tloss: 755.051\n",
      "Training Epoch 83  62.8% | batch:        59 of        94\t|\tloss: 823.023\n",
      "Training Epoch 83  63.8% | batch:        60 of        94\t|\tloss: 1131.89\n",
      "Training Epoch 83  64.9% | batch:        61 of        94\t|\tloss: 957.956\n",
      "Training Epoch 83  66.0% | batch:        62 of        94\t|\tloss: 1434.46\n",
      "Training Epoch 83  67.0% | batch:        63 of        94\t|\tloss: 809.15\n",
      "Training Epoch 83  68.1% | batch:        64 of        94\t|\tloss: 1323.28\n",
      "Training Epoch 83  69.1% | batch:        65 of        94\t|\tloss: 1466.51\n",
      "Training Epoch 83  70.2% | batch:        66 of        94\t|\tloss: 1132.64\n",
      "Training Epoch 83  71.3% | batch:        67 of        94\t|\tloss: 618.761\n",
      "Training Epoch 83  72.3% | batch:        68 of        94\t|\tloss: 706.349\n",
      "Training Epoch 83  73.4% | batch:        69 of        94\t|\tloss: 1121.38\n",
      "Training Epoch 83  74.5% | batch:        70 of        94\t|\tloss: 824.086\n",
      "Training Epoch 83  75.5% | batch:        71 of        94\t|\tloss: 855.625\n",
      "Training Epoch 83  76.6% | batch:        72 of        94\t|\tloss: 1642.77\n",
      "Training Epoch 83  77.7% | batch:        73 of        94\t|\tloss: 927.252\n",
      "Training Epoch 83  78.7% | batch:        74 of        94\t|\tloss: 617.639\n",
      "Training Epoch 83  79.8% | batch:        75 of        94\t|\tloss: 1409.8\n",
      "Training Epoch 83  80.9% | batch:        76 of        94\t|\tloss: 980.02\n",
      "Training Epoch 83  81.9% | batch:        77 of        94\t|\tloss: 1108.44\n",
      "Training Epoch 83  83.0% | batch:        78 of        94\t|\tloss: 1280.8\n",
      "Training Epoch 83  84.0% | batch:        79 of        94\t|\tloss: 970.383\n",
      "Training Epoch 83  85.1% | batch:        80 of        94\t|\tloss: 771.11\n",
      "Training Epoch 83  86.2% | batch:        81 of        94\t|\tloss: 1915.35\n",
      "Training Epoch 83  87.2% | batch:        82 of        94\t|\tloss: 871.885\n",
      "Training Epoch 83  88.3% | batch:        83 of        94\t|\tloss: 937.22\n",
      "Training Epoch 83  89.4% | batch:        84 of        94\t|\tloss: 918.379\n",
      "Training Epoch 83  90.4% | batch:        85 of        94\t|\tloss: 1550.48\n",
      "Training Epoch 83  91.5% | batch:        86 of        94\t|\tloss: 707.057\n",
      "Training Epoch 83  92.6% | batch:        87 of        94\t|\tloss: 712.268\n",
      "Training Epoch 83  93.6% | batch:        88 of        94\t|\tloss: 741.024\n",
      "Training Epoch 83  94.7% | batch:        89 of        94\t|\tloss: 1362.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:10,322 | INFO : Epoch 83 Training Summary: epoch: 83.000000 | loss: 989.042763 | \n",
      "2023-05-09 14:23:10,323 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.805440902709961 seconds\n",
      "\n",
      "2023-05-09 14:23:10,324 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8283922557371208 seconds\n",
      "2023-05-09 14:23:10,324 | INFO : Avg batch train. time: 0.019450981444011924 seconds\n",
      "2023-05-09 14:23:10,325 | INFO : Avg sample train. time: 0.00015341435272169164 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 83  95.7% | batch:        90 of        94\t|\tloss: 813.226\n",
      "Training Epoch 83  96.8% | batch:        91 of        94\t|\tloss: 927.331\n",
      "Training Epoch 83  97.9% | batch:        92 of        94\t|\tloss: 789.514\n",
      "Training Epoch 83  98.9% | batch:        93 of        94\t|\tloss: 3294.88\n",
      "\n",
      "Training Epoch 84   0.0% | batch:         0 of        94\t|\tloss: 789.689\n",
      "Training Epoch 84   1.1% | batch:         1 of        94\t|\tloss: 962.415\n",
      "Training Epoch 84   2.1% | batch:         2 of        94\t|\tloss: 842.159\n",
      "Training Epoch 84   3.2% | batch:         3 of        94\t|\tloss: 1825.13\n",
      "Training Epoch 84   4.3% | batch:         4 of        94\t|\tloss: 694.385\n",
      "Training Epoch 84   5.3% | batch:         5 of        94\t|\tloss: 864.13\n",
      "Training Epoch 84   6.4% | batch:         6 of        94\t|\tloss: 641.374\n",
      "Training Epoch 84   7.4% | batch:         7 of        94\t|\tloss: 1209.65\n",
      "Training Epoch 84   8.5% | batch:         8 of        94\t|\tloss: 982.386\n",
      "Training Epoch 84   9.6% | batch:         9 of        94\t|\tloss: 904.599\n",
      "Training Epoch 84  10.6% | batch:        10 of        94\t|\tloss: 1036.06\n",
      "Training Epoch 84  11.7% | batch:        11 of        94\t|\tloss: 912.997\n",
      "Training Epoch 84  12.8% | batch:        12 of        94\t|\tloss: 952.093\n",
      "Training Epoch 84  13.8% | batch:        13 of        94\t|\tloss: 842.15\n",
      "Training Epoch 84  14.9% | batch:        14 of        94\t|\tloss: 870.239\n",
      "Training Epoch 84  16.0% | batch:        15 of        94\t|\tloss: 1189.48\n",
      "Training Epoch 84  17.0% | batch:        16 of        94\t|\tloss: 690.012\n",
      "Training Epoch 84  18.1% | batch:        17 of        94\t|\tloss: 1225.67\n",
      "Training Epoch 84  19.1% | batch:        18 of        94\t|\tloss: 944.202\n",
      "Training Epoch 84  20.2% | batch:        19 of        94\t|\tloss: 691.969\n",
      "Training Epoch 84  21.3% | batch:        20 of        94\t|\tloss: 714.693\n",
      "Training Epoch 84  22.3% | batch:        21 of        94\t|\tloss: 868.278\n",
      "Training Epoch 84  23.4% | batch:        22 of        94\t|\tloss: 1094.97\n",
      "Training Epoch 84  24.5% | batch:        23 of        94\t|\tloss: 699.974\n",
      "Training Epoch 84  25.5% | batch:        24 of        94\t|\tloss: 1152.56\n",
      "Training Epoch 84  26.6% | batch:        25 of        94\t|\tloss: 1015.14\n",
      "Training Epoch 84  27.7% | batch:        26 of        94\t|\tloss: 1281.04\n",
      "Training Epoch 84  28.7% | batch:        27 of        94\t|\tloss: 1065.86\n",
      "Training Epoch 84  29.8% | batch:        28 of        94\t|\tloss: 1008.65\n",
      "Training Epoch 84  30.9% | batch:        29 of        94\t|\tloss: 1683.75\n",
      "Training Epoch 84  31.9% | batch:        30 of        94\t|\tloss: 810.137\n",
      "Training Epoch 84  33.0% | batch:        31 of        94\t|\tloss: 1511.06\n",
      "Training Epoch 84  34.0% | batch:        32 of        94\t|\tloss: 671.467\n",
      "Training Epoch 84  35.1% | batch:        33 of        94\t|\tloss: 1180.36\n",
      "Training Epoch 84  36.2% | batch:        34 of        94\t|\tloss: 776.003\n",
      "Training Epoch 84  37.2% | batch:        35 of        94\t|\tloss: 787.892\n",
      "Training Epoch 84  38.3% | batch:        36 of        94\t|\tloss: 1558.1\n",
      "Training Epoch 84  39.4% | batch:        37 of        94\t|\tloss: 891.542\n",
      "Training Epoch 84  40.4% | batch:        38 of        94\t|\tloss: 851.548\n",
      "Training Epoch 84  41.5% | batch:        39 of        94\t|\tloss: 821.937\n",
      "Training Epoch 84  42.6% | batch:        40 of        94\t|\tloss: 775.688\n",
      "Training Epoch 84  43.6% | batch:        41 of        94\t|\tloss: 1730.43\n",
      "Training Epoch 84  44.7% | batch:        42 of        94\t|\tloss: 1172.84\n",
      "Training Epoch 84  45.7% | batch:        43 of        94\t|\tloss: 706.751\n",
      "Training Epoch 84  46.8% | batch:        44 of        94\t|\tloss: 676.974\n",
      "Training Epoch 84  47.9% | batch:        45 of        94\t|\tloss: 911.368\n",
      "Training Epoch 84  48.9% | batch:        46 of        94\t|\tloss: 646.601\n",
      "Training Epoch 84  50.0% | batch:        47 of        94\t|\tloss: 815.535\n",
      "Training Epoch 84  51.1% | batch:        48 of        94\t|\tloss: 1049.13\n",
      "Training Epoch 84  52.1% | batch:        49 of        94\t|\tloss: 695.231\n",
      "Training Epoch 84  53.2% | batch:        50 of        94\t|\tloss: 1620.98\n",
      "Training Epoch 84  54.3% | batch:        51 of        94\t|\tloss: 917.168\n",
      "Training Epoch 84  55.3% | batch:        52 of        94\t|\tloss: 2211.22\n",
      "Training Epoch 84  56.4% | batch:        53 of        94\t|\tloss: 578.451\n",
      "Training Epoch 84  57.4% | batch:        54 of        94\t|\tloss: 884.095\n",
      "Training Epoch 84  58.5% | batch:        55 of        94\t|\tloss: 867.212\n",
      "Training Epoch 84  59.6% | batch:        56 of        94\t|\tloss: 871.47\n",
      "Training Epoch 84  60.6% | batch:        57 of        94\t|\tloss: 1046.48\n",
      "Training Epoch 84  61.7% | batch:        58 of        94\t|\tloss: 802.846\n",
      "Training Epoch 84  62.8% | batch:        59 of        94\t|\tloss: 951.448\n",
      "Training Epoch 84  63.8% | batch:        60 of        94\t|\tloss: 902.483\n",
      "Training Epoch 84  64.9% | batch:        61 of        94\t|\tloss: 3328.49\n",
      "Training Epoch 84  66.0% | batch:        62 of        94\t|\tloss: 2547.73\n",
      "Training Epoch 84  67.0% | batch:        63 of        94\t|\tloss: 1486.31\n",
      "Training Epoch 84  68.1% | batch:        64 of        94\t|\tloss: 1248.16\n",
      "Training Epoch 84  69.1% | batch:        65 of        94\t|\tloss: 688.014\n",
      "Training Epoch 84  70.2% | batch:        66 of        94\t|\tloss: 1128.09\n",
      "Training Epoch 84  71.3% | batch:        67 of        94\t|\tloss: 867.999\n",
      "Training Epoch 84  72.3% | batch:        68 of        94\t|\tloss: 1468.17\n",
      "Training Epoch 84  73.4% | batch:        69 of        94\t|\tloss: 1532.9\n",
      "Training Epoch 84  74.5% | batch:        70 of        94\t|\tloss: 791.995\n",
      "Training Epoch 84  75.5% | batch:        71 of        94\t|\tloss: 930.919\n",
      "Training Epoch 84  76.6% | batch:        72 of        94\t|\tloss: 883.639\n",
      "Training Epoch 84  77.7% | batch:        73 of        94\t|\tloss: 841.417\n",
      "Training Epoch 84  78.7% | batch:        74 of        94\t|\tloss: 744.748\n",
      "Training Epoch 84  79.8% | batch:        75 of        94\t|\tloss: 1065.94\n",
      "Training Epoch 84  80.9% | batch:        76 of        94\t|\tloss: 839.255\n",
      "Training Epoch 84  81.9% | batch:        77 of        94\t|\tloss: 564.201\n",
      "Training Epoch 84  83.0% | batch:        78 of        94\t|\tloss: 1285.7\n",
      "Training Epoch 84  84.0% | batch:        79 of        94\t|\tloss: 580.57\n",
      "Training Epoch 84  85.1% | batch:        80 of        94\t|\tloss: 847.73\n",
      "Training Epoch 84  86.2% | batch:        81 of        94\t|\tloss: 863.856\n",
      "Training Epoch 84  87.2% | batch:        82 of        94\t|\tloss: 1414.8\n",
      "Training Epoch 84  88.3% | batch:        83 of        94\t|\tloss: 815.166\n",
      "Training Epoch 84  89.4% | batch:        84 of        94\t|\tloss: 1196.66\n",
      "Training Epoch 84  90.4% | batch:        85 of        94\t|\tloss: 1546.35\n",
      "Training Epoch 84  91.5% | batch:        86 of        94\t|\tloss: 914.714\n",
      "Training Epoch 84  92.6% | batch:        87 of        94\t|\tloss: 1288.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:12,236 | INFO : Epoch 84 Training Summary: epoch: 84.000000 | loss: 1043.381436 | \n",
      "2023-05-09 14:23:12,237 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8897037506103516 seconds\n",
      "\n",
      "2023-05-09 14:23:12,238 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8291221544856118 seconds\n",
      "2023-05-09 14:23:12,238 | INFO : Avg batch train. time: 0.01945874632431502 seconds\n",
      "2023-05-09 14:23:12,239 | INFO : Avg sample train. time: 0.0001534755961139127 seconds\n",
      "2023-05-09 14:23:12,240 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 84  93.6% | batch:        88 of        94\t|\tloss: 1037.88\n",
      "Training Epoch 84  94.7% | batch:        89 of        94\t|\tloss: 961.383\n",
      "Training Epoch 84  95.7% | batch:        90 of        94\t|\tloss: 885.03\n",
      "Training Epoch 84  96.8% | batch:        91 of        94\t|\tloss: 1151.43\n",
      "Training Epoch 84  97.9% | batch:        92 of        94\t|\tloss: 768.051\n",
      "Training Epoch 84  98.9% | batch:        93 of        94\t|\tloss: 2585.41\n",
      "\n",
      "Evaluating Epoch 84   0.0% | batch:         0 of        40\t|\tloss: 6685.47\n",
      "Evaluating Epoch 84   2.5% | batch:         1 of        40\t|\tloss: 1126.85\n",
      "Evaluating Epoch 84   5.0% | batch:         2 of        40\t|\tloss: 3428.12\n",
      "Evaluating Epoch 84   7.5% | batch:         3 of        40\t|\tloss: 6392.08\n",
      "Evaluating Epoch 84  10.0% | batch:         4 of        40\t|\tloss: 3124.48\n",
      "Evaluating Epoch 84  12.5% | batch:         5 of        40\t|\tloss: 2718.57\n",
      "Evaluating Epoch 84  15.0% | batch:         6 of        40\t|\tloss: 8725.62\n",
      "Evaluating Epoch 84  17.5% | batch:         7 of        40\t|\tloss: 3113.91\n",
      "Evaluating Epoch 84  20.0% | batch:         8 of        40\t|\tloss: 2989.6\n",
      "Evaluating Epoch 84  22.5% | batch:         9 of        40\t|\tloss: 2316.84\n",
      "Evaluating Epoch 84  25.0% | batch:        10 of        40\t|\tloss: 5005.62\n",
      "Evaluating Epoch 84  27.5% | batch:        11 of        40\t|\tloss: 1396.28\n",
      "Evaluating Epoch 84  30.0% | batch:        12 of        40\t|\tloss: 7120.57\n",
      "Evaluating Epoch 84  32.5% | batch:        13 of        40\t|\tloss: 3327.37\n",
      "Evaluating Epoch 84  35.0% | batch:        14 of        40\t|\tloss: 2107.03\n",
      "Evaluating Epoch 84  37.5% | batch:        15 of        40\t|\tloss: 3516.31\n",
      "Evaluating Epoch 84  40.0% | batch:        16 of        40\t|\tloss: 3832.49\n",
      "Evaluating Epoch 84  42.5% | batch:        17 of        40\t|\tloss: 2910.03\n",
      "Evaluating Epoch 84  45.0% | batch:        18 of        40\t|\tloss: 2447.94\n",
      "Evaluating Epoch 84  47.5% | batch:        19 of        40\t|\tloss: 6216.9\n",
      "Evaluating Epoch 84  50.0% | batch:        20 of        40\t|\tloss: 5322.28\n",
      "Evaluating Epoch 84  52.5% | batch:        21 of        40\t|\tloss: 1181.33\n",
      "Evaluating Epoch 84  55.0% | batch:        22 of        40\t|\tloss: 3637.25\n",
      "Evaluating Epoch 84  57.5% | batch:        23 of        40\t|\tloss: 3429.74\n",
      "Evaluating Epoch 84  60.0% | batch:        24 of        40\t|\tloss: 1611.85\n",
      "Evaluating Epoch 84  62.5% | batch:        25 of        40\t|\tloss: 3658.89\n",
      "Evaluating Epoch 84  65.0% | batch:        26 of        40\t|\tloss: 9764.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:12,715 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4739038944244385 seconds\n",
      "\n",
      "2023-05-09 14:23:12,715 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4738343520597978 seconds\n",
      "2023-05-09 14:23:12,716 | INFO : Avg batch val. time: 0.011845858801494944 seconds\n",
      "2023-05-09 14:23:12,716 | INFO : Avg sample val. time: 9.386575912436565e-05 seconds\n",
      "2023-05-09 14:23:12,717 | INFO : Epoch 84 Validation Summary: epoch: 84.000000 | loss: 4110.935383 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 84  67.5% | batch:        27 of        40\t|\tloss: 2666.16\n",
      "Evaluating Epoch 84  70.0% | batch:        28 of        40\t|\tloss: 2341.18\n",
      "Evaluating Epoch 84  72.5% | batch:        29 of        40\t|\tloss: 9297.07\n",
      "Evaluating Epoch 84  75.0% | batch:        30 of        40\t|\tloss: 2087.04\n",
      "Evaluating Epoch 84  77.5% | batch:        31 of        40\t|\tloss: 1660.59\n",
      "Evaluating Epoch 84  80.0% | batch:        32 of        40\t|\tloss: 7511.24\n",
      "Evaluating Epoch 84  82.5% | batch:        33 of        40\t|\tloss: 6078.08\n",
      "Evaluating Epoch 84  85.0% | batch:        34 of        40\t|\tloss: 892.894\n",
      "Evaluating Epoch 84  87.5% | batch:        35 of        40\t|\tloss: 4930.82\n",
      "Evaluating Epoch 84  90.0% | batch:        36 of        40\t|\tloss: 6206.01\n",
      "Evaluating Epoch 84  92.5% | batch:        37 of        40\t|\tloss: 2822.16\n",
      "Evaluating Epoch 84  95.0% | batch:        38 of        40\t|\tloss: 3493.82\n",
      "Evaluating Epoch 84  97.5% | batch:        39 of        40\t|\tloss: 11497.7\n",
      "\n",
      "Training Epoch 85   0.0% | batch:         0 of        94\t|\tloss: 1643.03\n",
      "Training Epoch 85   1.1% | batch:         1 of        94\t|\tloss: 1643.62\n",
      "Training Epoch 85   2.1% | batch:         2 of        94\t|\tloss: 1136.56\n",
      "Training Epoch 85   3.2% | batch:         3 of        94\t|\tloss: 1759.97\n",
      "Training Epoch 85   4.3% | batch:         4 of        94\t|\tloss: 1015.92\n",
      "Training Epoch 85   5.3% | batch:         5 of        94\t|\tloss: 899.055\n",
      "Training Epoch 85   6.4% | batch:         6 of        94\t|\tloss: 702.93\n",
      "Training Epoch 85   7.4% | batch:         7 of        94\t|\tloss: 1076.69\n",
      "Training Epoch 85   8.5% | batch:         8 of        94\t|\tloss: 1285.36\n",
      "Training Epoch 85   9.6% | batch:         9 of        94\t|\tloss: 783.771\n",
      "Training Epoch 85  10.6% | batch:        10 of        94\t|\tloss: 1323.92\n",
      "Training Epoch 85  11.7% | batch:        11 of        94\t|\tloss: 951.78\n",
      "Training Epoch 85  12.8% | batch:        12 of        94\t|\tloss: 916.383\n",
      "Training Epoch 85  13.8% | batch:        13 of        94\t|\tloss: 1141.49\n",
      "Training Epoch 85  14.9% | batch:        14 of        94\t|\tloss: 799.192\n",
      "Training Epoch 85  16.0% | batch:        15 of        94\t|\tloss: 1032.28\n",
      "Training Epoch 85  17.0% | batch:        16 of        94\t|\tloss: 1064.98\n",
      "Training Epoch 85  18.1% | batch:        17 of        94\t|\tloss: 964.704\n",
      "Training Epoch 85  19.1% | batch:        18 of        94\t|\tloss: 977.068\n",
      "Training Epoch 85  20.2% | batch:        19 of        94\t|\tloss: 648.274\n",
      "Training Epoch 85  21.3% | batch:        20 of        94\t|\tloss: 850.624\n",
      "Training Epoch 85  22.3% | batch:        21 of        94\t|\tloss: 786.264\n",
      "Training Epoch 85  23.4% | batch:        22 of        94\t|\tloss: 1154.75\n",
      "Training Epoch 85  24.5% | batch:        23 of        94\t|\tloss: 667.571\n",
      "Training Epoch 85  25.5% | batch:        24 of        94\t|\tloss: 499.856\n",
      "Training Epoch 85  26.6% | batch:        25 of        94\t|\tloss: 1372.35\n",
      "Training Epoch 85  27.7% | batch:        26 of        94\t|\tloss: 702.325\n",
      "Training Epoch 85  28.7% | batch:        27 of        94\t|\tloss: 688.895\n",
      "Training Epoch 85  29.8% | batch:        28 of        94\t|\tloss: 1324.91\n",
      "Training Epoch 85  30.9% | batch:        29 of        94\t|\tloss: 565.509\n",
      "Training Epoch 85  31.9% | batch:        30 of        94\t|\tloss: 890.274\n",
      "Training Epoch 85  33.0% | batch:        31 of        94\t|\tloss: 1015.93\n",
      "Training Epoch 85  34.0% | batch:        32 of        94\t|\tloss: 986.239\n",
      "Training Epoch 85  35.1% | batch:        33 of        94\t|\tloss: 1095.98\n",
      "Training Epoch 85  36.2% | batch:        34 of        94\t|\tloss: 1048.01\n",
      "Training Epoch 85  37.2% | batch:        35 of        94\t|\tloss: 900.028\n",
      "Training Epoch 85  38.3% | batch:        36 of        94\t|\tloss: 957.819\n",
      "Training Epoch 85  39.4% | batch:        37 of        94\t|\tloss: 1086.55\n",
      "Training Epoch 85  40.4% | batch:        38 of        94\t|\tloss: 777.032\n",
      "Training Epoch 85  41.5% | batch:        39 of        94\t|\tloss: 973.103\n",
      "Training Epoch 85  42.6% | batch:        40 of        94\t|\tloss: 956.808\n",
      "Training Epoch 85  43.6% | batch:        41 of        94\t|\tloss: 609.489\n",
      "Training Epoch 85  44.7% | batch:        42 of        94\t|\tloss: 777.345\n",
      "Training Epoch 85  45.7% | batch:        43 of        94\t|\tloss: 904.819\n",
      "Training Epoch 85  46.8% | batch:        44 of        94\t|\tloss: 1619.35\n",
      "Training Epoch 85  47.9% | batch:        45 of        94\t|\tloss: 763.746\n",
      "Training Epoch 85  48.9% | batch:        46 of        94\t|\tloss: 853.078\n",
      "Training Epoch 85  50.0% | batch:        47 of        94\t|\tloss: 1140.13\n",
      "Training Epoch 85  51.1% | batch:        48 of        94\t|\tloss: 999.507\n",
      "Training Epoch 85  52.1% | batch:        49 of        94\t|\tloss: 947.352\n",
      "Training Epoch 85  53.2% | batch:        50 of        94\t|\tloss: 784.271\n",
      "Training Epoch 85  54.3% | batch:        51 of        94\t|\tloss: 1078.5\n",
      "Training Epoch 85  55.3% | batch:        52 of        94\t|\tloss: 2284.79\n",
      "Training Epoch 85  56.4% | batch:        53 of        94\t|\tloss: 733.088\n",
      "Training Epoch 85  57.4% | batch:        54 of        94\t|\tloss: 764.942\n",
      "Training Epoch 85  58.5% | batch:        55 of        94\t|\tloss: 1458.19\n",
      "Training Epoch 85  59.6% | batch:        56 of        94\t|\tloss: 1299.84\n",
      "Training Epoch 85  60.6% | batch:        57 of        94\t|\tloss: 977.222\n",
      "Training Epoch 85  61.7% | batch:        58 of        94\t|\tloss: 853.939\n",
      "Training Epoch 85  62.8% | batch:        59 of        94\t|\tloss: 815.789\n",
      "Training Epoch 85  63.8% | batch:        60 of        94\t|\tloss: 916.869\n",
      "Training Epoch 85  64.9% | batch:        61 of        94\t|\tloss: 2454.65\n",
      "Training Epoch 85  66.0% | batch:        62 of        94\t|\tloss: 574.098\n",
      "Training Epoch 85  67.0% | batch:        63 of        94\t|\tloss: 755.035\n",
      "Training Epoch 85  68.1% | batch:        64 of        94\t|\tloss: 1010.68\n",
      "Training Epoch 85  69.1% | batch:        65 of        94\t|\tloss: 1269.99\n",
      "Training Epoch 85  70.2% | batch:        66 of        94\t|\tloss: 718.367\n",
      "Training Epoch 85  71.3% | batch:        67 of        94\t|\tloss: 799.245\n",
      "Training Epoch 85  72.3% | batch:        68 of        94\t|\tloss: 709.969\n",
      "Training Epoch 85  73.4% | batch:        69 of        94\t|\tloss: 952.747\n",
      "Training Epoch 85  74.5% | batch:        70 of        94\t|\tloss: 935.782\n",
      "Training Epoch 85  75.5% | batch:        71 of        94\t|\tloss: 1004.3\n",
      "Training Epoch 85  76.6% | batch:        72 of        94\t|\tloss: 1042.28\n",
      "Training Epoch 85  77.7% | batch:        73 of        94\t|\tloss: 2666.75\n",
      "Training Epoch 85  78.7% | batch:        74 of        94\t|\tloss: 884.776\n",
      "Training Epoch 85  79.8% | batch:        75 of        94\t|\tloss: 1332.66\n",
      "Training Epoch 85  80.9% | batch:        76 of        94\t|\tloss: 969.202\n",
      "Training Epoch 85  81.9% | batch:        77 of        94\t|\tloss: 737.348\n",
      "Training Epoch 85  83.0% | batch:        78 of        94\t|\tloss: 656.607\n",
      "Training Epoch 85  84.0% | batch:        79 of        94\t|\tloss: 894.569\n",
      "Training Epoch 85  85.1% | batch:        80 of        94\t|\tloss: 840.206\n",
      "Training Epoch 85  86.2% | batch:        81 of        94\t|\tloss: 1352.63\n",
      "Training Epoch 85  87.2% | batch:        82 of        94\t|\tloss: 588.246\n",
      "Training Epoch 85  88.3% | batch:        83 of        94\t|\tloss: 1291.54\n",
      "Training Epoch 85  89.4% | batch:        84 of        94\t|\tloss: 652.239\n",
      "Training Epoch 85  90.4% | batch:        85 of        94\t|\tloss: 852.378\n",
      "Training Epoch 85  91.5% | batch:        86 of        94\t|\tloss: 712.239\n",
      "Training Epoch 85  92.6% | batch:        87 of        94\t|\tloss: 1462.61\n",
      "Training Epoch 85  93.6% | batch:        88 of        94\t|\tloss: 845.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:14,579 | INFO : Epoch 85 Training Summary: epoch: 85.000000 | loss: 1017.972459 | \n",
      "2023-05-09 14:23:14,580 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.849982500076294 seconds\n",
      "\n",
      "2023-05-09 14:23:14,580 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8293675703160903 seconds\n",
      "2023-05-09 14:23:14,581 | INFO : Avg batch train. time: 0.019461357131022237 seconds\n",
      "2023-05-09 14:23:14,582 | INFO : Avg sample train. time: 0.00015349618814533398 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 85  94.7% | batch:        89 of        94\t|\tloss: 841.102\n",
      "Training Epoch 85  95.7% | batch:        90 of        94\t|\tloss: 1433.12\n",
      "Training Epoch 85  96.8% | batch:        91 of        94\t|\tloss: 880.831\n",
      "Training Epoch 85  97.9% | batch:        92 of        94\t|\tloss: 830.651\n",
      "Training Epoch 85  98.9% | batch:        93 of        94\t|\tloss: 1650.44\n",
      "\n",
      "Training Epoch 86   0.0% | batch:         0 of        94\t|\tloss: 675.65\n",
      "Training Epoch 86   1.1% | batch:         1 of        94\t|\tloss: 683.29\n",
      "Training Epoch 86   2.1% | batch:         2 of        94\t|\tloss: 701.199\n",
      "Training Epoch 86   3.2% | batch:         3 of        94\t|\tloss: 1099.76\n",
      "Training Epoch 86   4.3% | batch:         4 of        94\t|\tloss: 1117.91\n",
      "Training Epoch 86   5.3% | batch:         5 of        94\t|\tloss: 1021.31\n",
      "Training Epoch 86   6.4% | batch:         6 of        94\t|\tloss: 761.695\n",
      "Training Epoch 86   7.4% | batch:         7 of        94\t|\tloss: 1171.19\n",
      "Training Epoch 86   8.5% | batch:         8 of        94\t|\tloss: 767.787\n",
      "Training Epoch 86   9.6% | batch:         9 of        94\t|\tloss: 1190.11\n",
      "Training Epoch 86  10.6% | batch:        10 of        94\t|\tloss: 767.871\n",
      "Training Epoch 86  11.7% | batch:        11 of        94\t|\tloss: 874.038\n",
      "Training Epoch 86  12.8% | batch:        12 of        94\t|\tloss: 888.396\n",
      "Training Epoch 86  13.8% | batch:        13 of        94\t|\tloss: 1891.6\n",
      "Training Epoch 86  14.9% | batch:        14 of        94\t|\tloss: 695.031\n",
      "Training Epoch 86  16.0% | batch:        15 of        94\t|\tloss: 1114.15\n",
      "Training Epoch 86  17.0% | batch:        16 of        94\t|\tloss: 1314.07\n",
      "Training Epoch 86  18.1% | batch:        17 of        94\t|\tloss: 1142.7\n",
      "Training Epoch 86  19.1% | batch:        18 of        94\t|\tloss: 851.801\n",
      "Training Epoch 86  20.2% | batch:        19 of        94\t|\tloss: 981.017\n",
      "Training Epoch 86  21.3% | batch:        20 of        94\t|\tloss: 949.579\n",
      "Training Epoch 86  22.3% | batch:        21 of        94\t|\tloss: 706.946\n",
      "Training Epoch 86  23.4% | batch:        22 of        94\t|\tloss: 839.483\n",
      "Training Epoch 86  24.5% | batch:        23 of        94\t|\tloss: 1130.11\n",
      "Training Epoch 86  25.5% | batch:        24 of        94\t|\tloss: 820.949\n",
      "Training Epoch 86  26.6% | batch:        25 of        94\t|\tloss: 1505.8\n",
      "Training Epoch 86  27.7% | batch:        26 of        94\t|\tloss: 941.723\n",
      "Training Epoch 86  28.7% | batch:        27 of        94\t|\tloss: 779.583\n",
      "Training Epoch 86  29.8% | batch:        28 of        94\t|\tloss: 756.448\n",
      "Training Epoch 86  30.9% | batch:        29 of        94\t|\tloss: 709.728\n",
      "Training Epoch 86  31.9% | batch:        30 of        94\t|\tloss: 763.4\n",
      "Training Epoch 86  33.0% | batch:        31 of        94\t|\tloss: 956.473\n",
      "Training Epoch 86  34.0% | batch:        32 of        94\t|\tloss: 800.017\n",
      "Training Epoch 86  35.1% | batch:        33 of        94\t|\tloss: 755.741\n",
      "Training Epoch 86  36.2% | batch:        34 of        94\t|\tloss: 1189.39\n",
      "Training Epoch 86  37.2% | batch:        35 of        94\t|\tloss: 684.413\n",
      "Training Epoch 86  38.3% | batch:        36 of        94\t|\tloss: 1048.17\n",
      "Training Epoch 86  39.4% | batch:        37 of        94\t|\tloss: 2529.82\n",
      "Training Epoch 86  40.4% | batch:        38 of        94\t|\tloss: 627.467\n",
      "Training Epoch 86  41.5% | batch:        39 of        94\t|\tloss: 759.095\n",
      "Training Epoch 86  42.6% | batch:        40 of        94\t|\tloss: 1029.63\n",
      "Training Epoch 86  43.6% | batch:        41 of        94\t|\tloss: 619.284\n",
      "Training Epoch 86  44.7% | batch:        42 of        94\t|\tloss: 801.034\n",
      "Training Epoch 86  45.7% | batch:        43 of        94\t|\tloss: 1241.05\n",
      "Training Epoch 86  46.8% | batch:        44 of        94\t|\tloss: 669.212\n",
      "Training Epoch 86  47.9% | batch:        45 of        94\t|\tloss: 889.456\n",
      "Training Epoch 86  48.9% | batch:        46 of        94\t|\tloss: 891.584\n",
      "Training Epoch 86  50.0% | batch:        47 of        94\t|\tloss: 1340.11\n",
      "Training Epoch 86  51.1% | batch:        48 of        94\t|\tloss: 1364.96\n",
      "Training Epoch 86  52.1% | batch:        49 of        94\t|\tloss: 1355.11\n",
      "Training Epoch 86  53.2% | batch:        50 of        94\t|\tloss: 836.698\n",
      "Training Epoch 86  54.3% | batch:        51 of        94\t|\tloss: 855.85\n",
      "Training Epoch 86  55.3% | batch:        52 of        94\t|\tloss: 1313.5\n",
      "Training Epoch 86  56.4% | batch:        53 of        94\t|\tloss: 923.361\n",
      "Training Epoch 86  57.4% | batch:        54 of        94\t|\tloss: 656.914\n",
      "Training Epoch 86  58.5% | batch:        55 of        94\t|\tloss: 607.217\n",
      "Training Epoch 86  59.6% | batch:        56 of        94\t|\tloss: 697.04\n",
      "Training Epoch 86  60.6% | batch:        57 of        94\t|\tloss: 984.316\n",
      "Training Epoch 86  61.7% | batch:        58 of        94\t|\tloss: 491.122\n",
      "Training Epoch 86  62.8% | batch:        59 of        94\t|\tloss: 701.211\n",
      "Training Epoch 86  63.8% | batch:        60 of        94\t|\tloss: 804.313\n",
      "Training Epoch 86  64.9% | batch:        61 of        94\t|\tloss: 732.038\n",
      "Training Epoch 86  66.0% | batch:        62 of        94\t|\tloss: 1092.6\n",
      "Training Epoch 86  67.0% | batch:        63 of        94\t|\tloss: 1310.53\n",
      "Training Epoch 86  68.1% | batch:        64 of        94\t|\tloss: 744.916\n",
      "Training Epoch 86  69.1% | batch:        65 of        94\t|\tloss: 1166.67\n",
      "Training Epoch 86  70.2% | batch:        66 of        94\t|\tloss: 1101.86\n",
      "Training Epoch 86  71.3% | batch:        67 of        94\t|\tloss: 738.258\n",
      "Training Epoch 86  72.3% | batch:        68 of        94\t|\tloss: 1173.51\n",
      "Training Epoch 86  73.4% | batch:        69 of        94\t|\tloss: 916.651\n",
      "Training Epoch 86  74.5% | batch:        70 of        94\t|\tloss: 525.982\n",
      "Training Epoch 86  75.5% | batch:        71 of        94\t|\tloss: 681.482\n",
      "Training Epoch 86  76.6% | batch:        72 of        94\t|\tloss: 1510.36\n",
      "Training Epoch 86  77.7% | batch:        73 of        94\t|\tloss: 1133.78\n",
      "Training Epoch 86  78.7% | batch:        74 of        94\t|\tloss: 1056.83\n",
      "Training Epoch 86  79.8% | batch:        75 of        94\t|\tloss: 1071.02\n",
      "Training Epoch 86  80.9% | batch:        76 of        94\t|\tloss: 780.239\n",
      "Training Epoch 86  81.9% | batch:        77 of        94\t|\tloss: 946.685\n",
      "Training Epoch 86  83.0% | batch:        78 of        94\t|\tloss: 1277.2\n",
      "Training Epoch 86  84.0% | batch:        79 of        94\t|\tloss: 771.872\n",
      "Training Epoch 86  85.1% | batch:        80 of        94\t|\tloss: 1156.73\n",
      "Training Epoch 86  86.2% | batch:        81 of        94\t|\tloss: 787.483\n",
      "Training Epoch 86  87.2% | batch:        82 of        94\t|\tloss: 879.577\n",
      "Training Epoch 86  88.3% | batch:        83 of        94\t|\tloss: 883.857\n",
      "Training Epoch 86  89.4% | batch:        84 of        94\t|\tloss: 1038.21\n",
      "Training Epoch 86  90.4% | batch:        85 of        94\t|\tloss: 1675.92\n",
      "Training Epoch 86  91.5% | batch:        86 of        94\t|\tloss: 767.88\n",
      "Training Epoch 86  92.6% | batch:        87 of        94\t|\tloss: 582.105\n",
      "Training Epoch 86  93.6% | batch:        88 of        94\t|\tloss: 657.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:16,510 | INFO : Epoch 86 Training Summary: epoch: 86.000000 | loss: 948.594900 | \n",
      "2023-05-09 14:23:16,510 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.9070227146148682 seconds\n",
      "\n",
      "2023-05-09 14:23:16,511 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.830270537110262 seconds\n",
      "2023-05-09 14:23:16,511 | INFO : Avg batch train. time: 0.01947096316074747 seconds\n",
      "2023-05-09 14:23:16,512 | INFO : Avg sample train. time: 0.0001535719531054088 seconds\n",
      "2023-05-09 14:23:16,512 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 86  94.7% | batch:        89 of        94\t|\tloss: 766.121\n",
      "Training Epoch 86  95.7% | batch:        90 of        94\t|\tloss: 435.034\n",
      "Training Epoch 86  96.8% | batch:        91 of        94\t|\tloss: 924.807\n",
      "Training Epoch 86  97.9% | batch:        92 of        94\t|\tloss: 950.025\n",
      "Training Epoch 86  98.9% | batch:        93 of        94\t|\tloss: 435.287\n",
      "\n",
      "Evaluating Epoch 86   0.0% | batch:         0 of        40\t|\tloss: 6413.17\n",
      "Evaluating Epoch 86   2.5% | batch:         1 of        40\t|\tloss: 1525.93\n",
      "Evaluating Epoch 86   5.0% | batch:         2 of        40\t|\tloss: 5180.7\n",
      "Evaluating Epoch 86   7.5% | batch:         3 of        40\t|\tloss: 6583.94\n",
      "Evaluating Epoch 86  10.0% | batch:         4 of        40\t|\tloss: 3046.1\n",
      "Evaluating Epoch 86  12.5% | batch:         5 of        40\t|\tloss: 2792.65\n",
      "Evaluating Epoch 86  15.0% | batch:         6 of        40\t|\tloss: 10204.7\n",
      "Evaluating Epoch 86  17.5% | batch:         7 of        40\t|\tloss: 3580.75\n",
      "Evaluating Epoch 86  20.0% | batch:         8 of        40\t|\tloss: 3200.05\n",
      "Evaluating Epoch 86  22.5% | batch:         9 of        40\t|\tloss: 2738.08\n",
      "Evaluating Epoch 86  25.0% | batch:        10 of        40\t|\tloss: 4499.4\n",
      "Evaluating Epoch 86  27.5% | batch:        11 of        40\t|\tloss: 1625.42\n",
      "Evaluating Epoch 86  30.0% | batch:        12 of        40\t|\tloss: 6696.41\n",
      "Evaluating Epoch 86  32.5% | batch:        13 of        40\t|\tloss: 2980.63\n",
      "Evaluating Epoch 86  35.0% | batch:        14 of        40\t|\tloss: 2476.31\n",
      "Evaluating Epoch 86  37.5% | batch:        15 of        40\t|\tloss: 3791.02\n",
      "Evaluating Epoch 86  40.0% | batch:        16 of        40\t|\tloss: 3722.27\n",
      "Evaluating Epoch 86  42.5% | batch:        17 of        40\t|\tloss: 3468.16\n",
      "Evaluating Epoch 86  45.0% | batch:        18 of        40\t|\tloss: 2563.9\n",
      "Evaluating Epoch 86  47.5% | batch:        19 of        40\t|\tloss: 5874.86\n",
      "Evaluating Epoch 86  50.0% | batch:        20 of        40\t|\tloss: 5837.63\n",
      "Evaluating Epoch 86  52.5% | batch:        21 of        40\t|\tloss: 1360.28\n",
      "Evaluating Epoch 86  55.0% | batch:        22 of        40\t|\tloss: 4288.52\n",
      "Evaluating Epoch 86  57.5% | batch:        23 of        40\t|\tloss: 3460.94\n",
      "Evaluating Epoch 86  60.0% | batch:        24 of        40\t|\tloss: 1841.29\n",
      "Evaluating Epoch 86  62.5% | batch:        25 of        40\t|\tloss: 4043.03\n",
      "Evaluating Epoch 86  65.0% | batch:        26 of        40\t|\tloss: 8276.38\n",
      "Evaluating Epoch 86  67.5% | batch:        27 of        40\t|\tloss: 3074.92\n",
      "Evaluating Epoch 86  70.0% | batch:        28 of        40\t|\tloss: 2372.1\n",
      "Evaluating Epoch 86  72.5% | batch:        29 of        40\t|\tloss: 9297.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:16,961 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44890260696411133 seconds\n",
      "\n",
      "2023-05-09 14:23:16,962 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47328031327989367 seconds\n",
      "2023-05-09 14:23:16,962 | INFO : Avg batch val. time: 0.011832007831997341 seconds\n",
      "2023-05-09 14:23:16,963 | INFO : Avg sample val. time: 9.375600500790287e-05 seconds\n",
      "2023-05-09 14:23:16,963 | INFO : Epoch 86 Validation Summary: epoch: 86.000000 | loss: 4330.274078 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 86  75.0% | batch:        30 of        40\t|\tloss: 2255.77\n",
      "Evaluating Epoch 86  77.5% | batch:        31 of        40\t|\tloss: 1904.3\n",
      "Evaluating Epoch 86  80.0% | batch:        32 of        40\t|\tloss: 9252.71\n",
      "Evaluating Epoch 86  82.5% | batch:        33 of        40\t|\tloss: 5712.49\n",
      "Evaluating Epoch 86  85.0% | batch:        34 of        40\t|\tloss: 1291.02\n",
      "Evaluating Epoch 86  87.5% | batch:        35 of        40\t|\tloss: 6320.8\n",
      "Evaluating Epoch 86  90.0% | batch:        36 of        40\t|\tloss: 5388.53\n",
      "Evaluating Epoch 86  92.5% | batch:        37 of        40\t|\tloss: 3011.36\n",
      "Evaluating Epoch 86  95.0% | batch:        38 of        40\t|\tloss: 4060.08\n",
      "Evaluating Epoch 86  97.5% | batch:        39 of        40\t|\tloss: 10883.6\n",
      "\n",
      "Training Epoch 87   0.0% | batch:         0 of        94\t|\tloss: 1590.45\n",
      "Training Epoch 87   1.1% | batch:         1 of        94\t|\tloss: 1126.55\n",
      "Training Epoch 87   2.1% | batch:         2 of        94\t|\tloss: 1076.56\n",
      "Training Epoch 87   3.2% | batch:         3 of        94\t|\tloss: 1107.05\n",
      "Training Epoch 87   4.3% | batch:         4 of        94\t|\tloss: 971.944\n",
      "Training Epoch 87   5.3% | batch:         5 of        94\t|\tloss: 908.024\n",
      "Training Epoch 87   6.4% | batch:         6 of        94\t|\tloss: 1608.78\n",
      "Training Epoch 87   7.4% | batch:         7 of        94\t|\tloss: 1234.1\n",
      "Training Epoch 87   8.5% | batch:         8 of        94\t|\tloss: 735.736\n",
      "Training Epoch 87   9.6% | batch:         9 of        94\t|\tloss: 1062.86\n",
      "Training Epoch 87  10.6% | batch:        10 of        94\t|\tloss: 824.08\n",
      "Training Epoch 87  11.7% | batch:        11 of        94\t|\tloss: 717.2\n",
      "Training Epoch 87  12.8% | batch:        12 of        94\t|\tloss: 1240.93\n",
      "Training Epoch 87  13.8% | batch:        13 of        94\t|\tloss: 1032.76\n",
      "Training Epoch 87  14.9% | batch:        14 of        94\t|\tloss: 694.413\n",
      "Training Epoch 87  16.0% | batch:        15 of        94\t|\tloss: 1071.55\n",
      "Training Epoch 87  17.0% | batch:        16 of        94\t|\tloss: 993.819\n",
      "Training Epoch 87  18.1% | batch:        17 of        94\t|\tloss: 957.635\n",
      "Training Epoch 87  19.1% | batch:        18 of        94\t|\tloss: 757.954\n",
      "Training Epoch 87  20.2% | batch:        19 of        94\t|\tloss: 660.351\n",
      "Training Epoch 87  21.3% | batch:        20 of        94\t|\tloss: 637.161\n",
      "Training Epoch 87  22.3% | batch:        21 of        94\t|\tloss: 1290.65\n",
      "Training Epoch 87  23.4% | batch:        22 of        94\t|\tloss: 1345.29\n",
      "Training Epoch 87  24.5% | batch:        23 of        94\t|\tloss: 1366.73\n",
      "Training Epoch 87  25.5% | batch:        24 of        94\t|\tloss: 2359.04\n",
      "Training Epoch 87  26.6% | batch:        25 of        94\t|\tloss: 847.241\n",
      "Training Epoch 87  27.7% | batch:        26 of        94\t|\tloss: 899.145\n",
      "Training Epoch 87  28.7% | batch:        27 of        94\t|\tloss: 1361.5\n",
      "Training Epoch 87  29.8% | batch:        28 of        94\t|\tloss: 1037.14\n",
      "Training Epoch 87  30.9% | batch:        29 of        94\t|\tloss: 725.495\n",
      "Training Epoch 87  31.9% | batch:        30 of        94\t|\tloss: 750.041\n",
      "Training Epoch 87  33.0% | batch:        31 of        94\t|\tloss: 930.756\n",
      "Training Epoch 87  34.0% | batch:        32 of        94\t|\tloss: 1504.44\n",
      "Training Epoch 87  35.1% | batch:        33 of        94\t|\tloss: 756.159\n",
      "Training Epoch 87  36.2% | batch:        34 of        94\t|\tloss: 979.671\n",
      "Training Epoch 87  37.2% | batch:        35 of        94\t|\tloss: 775.991\n",
      "Training Epoch 87  38.3% | batch:        36 of        94\t|\tloss: 823.05\n",
      "Training Epoch 87  39.4% | batch:        37 of        94\t|\tloss: 986.557\n",
      "Training Epoch 87  40.4% | batch:        38 of        94\t|\tloss: 635.2\n",
      "Training Epoch 87  41.5% | batch:        39 of        94\t|\tloss: 1037.02\n",
      "Training Epoch 87  42.6% | batch:        40 of        94\t|\tloss: 608.423\n",
      "Training Epoch 87  43.6% | batch:        41 of        94\t|\tloss: 912.502\n",
      "Training Epoch 87  44.7% | batch:        42 of        94\t|\tloss: 778.445\n",
      "Training Epoch 87  45.7% | batch:        43 of        94\t|\tloss: 1481.23\n",
      "Training Epoch 87  46.8% | batch:        44 of        94\t|\tloss: 923.233\n",
      "Training Epoch 87  47.9% | batch:        45 of        94\t|\tloss: 1988.96\n",
      "Training Epoch 87  48.9% | batch:        46 of        94\t|\tloss: 1028.85\n",
      "Training Epoch 87  50.0% | batch:        47 of        94\t|\tloss: 566.825\n",
      "Training Epoch 87  51.1% | batch:        48 of        94\t|\tloss: 1093.16\n",
      "Training Epoch 87  52.1% | batch:        49 of        94\t|\tloss: 2480.93\n",
      "Training Epoch 87  53.2% | batch:        50 of        94\t|\tloss: 1165.68\n",
      "Training Epoch 87  54.3% | batch:        51 of        94\t|\tloss: 786.982\n",
      "Training Epoch 87  55.3% | batch:        52 of        94\t|\tloss: 876.278\n",
      "Training Epoch 87  56.4% | batch:        53 of        94\t|\tloss: 904.823\n",
      "Training Epoch 87  57.4% | batch:        54 of        94\t|\tloss: 1183.34\n",
      "Training Epoch 87  58.5% | batch:        55 of        94\t|\tloss: 778.906\n",
      "Training Epoch 87  59.6% | batch:        56 of        94\t|\tloss: 912.137\n",
      "Training Epoch 87  60.6% | batch:        57 of        94\t|\tloss: 910.598\n",
      "Training Epoch 87  61.7% | batch:        58 of        94\t|\tloss: 1131.98\n",
      "Training Epoch 87  62.8% | batch:        59 of        94\t|\tloss: 705.416\n",
      "Training Epoch 87  63.8% | batch:        60 of        94\t|\tloss: 1533.72\n",
      "Training Epoch 87  64.9% | batch:        61 of        94\t|\tloss: 624.009\n",
      "Training Epoch 87  66.0% | batch:        62 of        94\t|\tloss: 940.801\n",
      "Training Epoch 87  67.0% | batch:        63 of        94\t|\tloss: 681.224\n",
      "Training Epoch 87  68.1% | batch:        64 of        94\t|\tloss: 798.013\n",
      "Training Epoch 87  69.1% | batch:        65 of        94\t|\tloss: 989.968\n",
      "Training Epoch 87  70.2% | batch:        66 of        94\t|\tloss: 1046.35\n",
      "Training Epoch 87  71.3% | batch:        67 of        94\t|\tloss: 942.775\n",
      "Training Epoch 87  72.3% | batch:        68 of        94\t|\tloss: 1203.64\n",
      "Training Epoch 87  73.4% | batch:        69 of        94\t|\tloss: 747.636\n",
      "Training Epoch 87  74.5% | batch:        70 of        94\t|\tloss: 667.787\n",
      "Training Epoch 87  75.5% | batch:        71 of        94\t|\tloss: 876.2\n",
      "Training Epoch 87  76.6% | batch:        72 of        94\t|\tloss: 1551.16\n",
      "Training Epoch 87  77.7% | batch:        73 of        94\t|\tloss: 907.977\n",
      "Training Epoch 87  78.7% | batch:        74 of        94\t|\tloss: 1235.76\n",
      "Training Epoch 87  79.8% | batch:        75 of        94\t|\tloss: 1049.97\n",
      "Training Epoch 87  80.9% | batch:        76 of        94\t|\tloss: 774.035\n",
      "Training Epoch 87  81.9% | batch:        77 of        94\t|\tloss: 934.305\n",
      "Training Epoch 87  83.0% | batch:        78 of        94\t|\tloss: 858.834\n",
      "Training Epoch 87  84.0% | batch:        79 of        94\t|\tloss: 953.426\n",
      "Training Epoch 87  85.1% | batch:        80 of        94\t|\tloss: 879.603\n",
      "Training Epoch 87  86.2% | batch:        81 of        94\t|\tloss: 819.872\n",
      "Training Epoch 87  87.2% | batch:        82 of        94\t|\tloss: 692.931\n",
      "Training Epoch 87  88.3% | batch:        83 of        94\t|\tloss: 691.055\n",
      "Training Epoch 87  89.4% | batch:        84 of        94\t|\tloss: 1156.48\n",
      "Training Epoch 87  90.4% | batch:        85 of        94\t|\tloss: 1139.45\n",
      "Training Epoch 87  91.5% | batch:        86 of        94\t|\tloss: 1312.71\n",
      "Training Epoch 87  92.6% | batch:        87 of        94\t|\tloss: 832.027\n",
      "Training Epoch 87  93.6% | batch:        88 of        94\t|\tloss: 796.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:18,897 | INFO : Epoch 87 Training Summary: epoch: 87.000000 | loss: 1001.014899 | \n",
      "2023-05-09 14:23:18,898 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.9129745960235596 seconds\n",
      "\n",
      "2023-05-09 14:23:18,899 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8312211584770817 seconds\n",
      "2023-05-09 14:23:18,899 | INFO : Avg batch train. time: 0.01948107615401151 seconds\n",
      "2023-05-09 14:23:18,900 | INFO : Avg sample train. time: 0.00015365171660321208 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 87  94.7% | batch:        89 of        94\t|\tloss: 567.937\n",
      "Training Epoch 87  95.7% | batch:        90 of        94\t|\tloss: 947.788\n",
      "Training Epoch 87  96.8% | batch:        91 of        94\t|\tloss: 581.854\n",
      "Training Epoch 87  97.9% | batch:        92 of        94\t|\tloss: 712.06\n",
      "Training Epoch 87  98.9% | batch:        93 of        94\t|\tloss: 1062.73\n",
      "\n",
      "Training Epoch 88   0.0% | batch:         0 of        94\t|\tloss: 710.864\n",
      "Training Epoch 88   1.1% | batch:         1 of        94\t|\tloss: 840.499\n",
      "Training Epoch 88   2.1% | batch:         2 of        94\t|\tloss: 743.794\n",
      "Training Epoch 88   3.2% | batch:         3 of        94\t|\tloss: 732.834\n",
      "Training Epoch 88   4.3% | batch:         4 of        94\t|\tloss: 961.487\n",
      "Training Epoch 88   5.3% | batch:         5 of        94\t|\tloss: 612.806\n",
      "Training Epoch 88   6.4% | batch:         6 of        94\t|\tloss: 915.629\n",
      "Training Epoch 88   7.4% | batch:         7 of        94\t|\tloss: 1789.83\n",
      "Training Epoch 88   8.5% | batch:         8 of        94\t|\tloss: 901.681\n",
      "Training Epoch 88   9.6% | batch:         9 of        94\t|\tloss: 1016.37\n",
      "Training Epoch 88  10.6% | batch:        10 of        94\t|\tloss: 1029.97\n",
      "Training Epoch 88  11.7% | batch:        11 of        94\t|\tloss: 543.446\n",
      "Training Epoch 88  12.8% | batch:        12 of        94\t|\tloss: 1064.23\n",
      "Training Epoch 88  13.8% | batch:        13 of        94\t|\tloss: 830.016\n",
      "Training Epoch 88  14.9% | batch:        14 of        94\t|\tloss: 580.63\n",
      "Training Epoch 88  16.0% | batch:        15 of        94\t|\tloss: 353.83\n",
      "Training Epoch 88  17.0% | batch:        16 of        94\t|\tloss: 1066.19\n",
      "Training Epoch 88  18.1% | batch:        17 of        94\t|\tloss: 1155.64\n",
      "Training Epoch 88  19.1% | batch:        18 of        94\t|\tloss: 1073.51\n",
      "Training Epoch 88  20.2% | batch:        19 of        94\t|\tloss: 810.093\n",
      "Training Epoch 88  21.3% | batch:        20 of        94\t|\tloss: 1036.65\n",
      "Training Epoch 88  22.3% | batch:        21 of        94\t|\tloss: 1177.36\n",
      "Training Epoch 88  23.4% | batch:        22 of        94\t|\tloss: 1363.52\n",
      "Training Epoch 88  24.5% | batch:        23 of        94\t|\tloss: 699.692\n",
      "Training Epoch 88  25.5% | batch:        24 of        94\t|\tloss: 1378.7\n",
      "Training Epoch 88  26.6% | batch:        25 of        94\t|\tloss: 994.631\n",
      "Training Epoch 88  27.7% | batch:        26 of        94\t|\tloss: 749.596\n",
      "Training Epoch 88  28.7% | batch:        27 of        94\t|\tloss: 834.989\n",
      "Training Epoch 88  29.8% | batch:        28 of        94\t|\tloss: 883.158\n",
      "Training Epoch 88  30.9% | batch:        29 of        94\t|\tloss: 863.781\n",
      "Training Epoch 88  31.9% | batch:        30 of        94\t|\tloss: 738.911\n",
      "Training Epoch 88  33.0% | batch:        31 of        94\t|\tloss: 1386.35\n",
      "Training Epoch 88  34.0% | batch:        32 of        94\t|\tloss: 2826.44\n",
      "Training Epoch 88  35.1% | batch:        33 of        94\t|\tloss: 762.184\n",
      "Training Epoch 88  36.2% | batch:        34 of        94\t|\tloss: 849.637\n",
      "Training Epoch 88  37.2% | batch:        35 of        94\t|\tloss: 799.905\n",
      "Training Epoch 88  38.3% | batch:        36 of        94\t|\tloss: 902.431\n",
      "Training Epoch 88  39.4% | batch:        37 of        94\t|\tloss: 894.453\n",
      "Training Epoch 88  40.4% | batch:        38 of        94\t|\tloss: 875.07\n",
      "Training Epoch 88  41.5% | batch:        39 of        94\t|\tloss: 784.369\n",
      "Training Epoch 88  42.6% | batch:        40 of        94\t|\tloss: 924.938\n",
      "Training Epoch 88  43.6% | batch:        41 of        94\t|\tloss: 1274.86\n",
      "Training Epoch 88  44.7% | batch:        42 of        94\t|\tloss: 668.82\n",
      "Training Epoch 88  45.7% | batch:        43 of        94\t|\tloss: 554.951\n",
      "Training Epoch 88  46.8% | batch:        44 of        94\t|\tloss: 753.211\n",
      "Training Epoch 88  47.9% | batch:        45 of        94\t|\tloss: 587.29\n",
      "Training Epoch 88  48.9% | batch:        46 of        94\t|\tloss: 943.193\n",
      "Training Epoch 88  50.0% | batch:        47 of        94\t|\tloss: 679.133\n",
      "Training Epoch 88  51.1% | batch:        48 of        94\t|\tloss: 1575.6\n",
      "Training Epoch 88  52.1% | batch:        49 of        94\t|\tloss: 945.019\n",
      "Training Epoch 88  53.2% | batch:        50 of        94\t|\tloss: 827.059\n",
      "Training Epoch 88  54.3% | batch:        51 of        94\t|\tloss: 693.412\n",
      "Training Epoch 88  55.3% | batch:        52 of        94\t|\tloss: 1177.97\n",
      "Training Epoch 88  56.4% | batch:        53 of        94\t|\tloss: 1092.05\n",
      "Training Epoch 88  57.4% | batch:        54 of        94\t|\tloss: 892.165\n",
      "Training Epoch 88  58.5% | batch:        55 of        94\t|\tloss: 1034.25\n",
      "Training Epoch 88  59.6% | batch:        56 of        94\t|\tloss: 672.989\n",
      "Training Epoch 88  60.6% | batch:        57 of        94\t|\tloss: 1106.69\n",
      "Training Epoch 88  61.7% | batch:        58 of        94\t|\tloss: 926.055\n",
      "Training Epoch 88  62.8% | batch:        59 of        94\t|\tloss: 1174.1\n",
      "Training Epoch 88  63.8% | batch:        60 of        94\t|\tloss: 1066.73\n",
      "Training Epoch 88  64.9% | batch:        61 of        94\t|\tloss: 659.914\n",
      "Training Epoch 88  66.0% | batch:        62 of        94\t|\tloss: 1017.16\n",
      "Training Epoch 88  67.0% | batch:        63 of        94\t|\tloss: 814.209\n",
      "Training Epoch 88  68.1% | batch:        64 of        94\t|\tloss: 1100.77\n",
      "Training Epoch 88  69.1% | batch:        65 of        94\t|\tloss: 823.06\n",
      "Training Epoch 88  70.2% | batch:        66 of        94\t|\tloss: 963.607\n",
      "Training Epoch 88  71.3% | batch:        67 of        94\t|\tloss: 757.072\n",
      "Training Epoch 88  72.3% | batch:        68 of        94\t|\tloss: 798.937\n",
      "Training Epoch 88  73.4% | batch:        69 of        94\t|\tloss: 814.465\n",
      "Training Epoch 88  74.5% | batch:        70 of        94\t|\tloss: 859.342\n",
      "Training Epoch 88  75.5% | batch:        71 of        94\t|\tloss: 929.018\n",
      "Training Epoch 88  76.6% | batch:        72 of        94\t|\tloss: 1043.79\n",
      "Training Epoch 88  77.7% | batch:        73 of        94\t|\tloss: 878.306\n",
      "Training Epoch 88  78.7% | batch:        74 of        94\t|\tloss: 942.929\n",
      "Training Epoch 88  79.8% | batch:        75 of        94\t|\tloss: 1132.31\n",
      "Training Epoch 88  80.9% | batch:        76 of        94\t|\tloss: 1540.67\n",
      "Training Epoch 88  81.9% | batch:        77 of        94\t|\tloss: 825.628\n",
      "Training Epoch 88  83.0% | batch:        78 of        94\t|\tloss: 680.013\n",
      "Training Epoch 88  84.0% | batch:        79 of        94\t|\tloss: 1691\n",
      "Training Epoch 88  85.1% | batch:        80 of        94\t|\tloss: 897.099\n",
      "Training Epoch 88  86.2% | batch:        81 of        94\t|\tloss: 1785.88\n",
      "Training Epoch 88  87.2% | batch:        82 of        94\t|\tloss: 1743.57\n",
      "Training Epoch 88  88.3% | batch:        83 of        94\t|\tloss: 1661.73\n",
      "Training Epoch 88  89.4% | batch:        84 of        94\t|\tloss: 813.492\n",
      "Training Epoch 88  90.4% | batch:        85 of        94\t|\tloss: 812.511\n",
      "Training Epoch 88  91.5% | batch:        86 of        94\t|\tloss: 1258.13\n",
      "Training Epoch 88  92.6% | batch:        87 of        94\t|\tloss: 959.263\n",
      "Training Epoch 88  93.6% | batch:        88 of        94\t|\tloss: 964.74\n",
      "Training Epoch 88  94.7% | batch:        89 of        94\t|\tloss: 1431.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:20,786 | INFO : Epoch 88 Training Summary: epoch: 88.000000 | loss: 987.467692 | \n",
      "2023-05-09 14:23:20,786 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8650307655334473 seconds\n",
      "\n",
      "2023-05-09 14:23:20,787 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8316053585572676 seconds\n",
      "2023-05-09 14:23:20,787 | INFO : Avg batch train. time: 0.0194851633889071 seconds\n",
      "2023-05-09 14:23:20,788 | INFO : Avg sample train. time: 0.00015368395356244903 seconds\n",
      "2023-05-09 14:23:20,788 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 88  95.7% | batch:        90 of        94\t|\tloss: 1060.22\n",
      "Training Epoch 88  96.8% | batch:        91 of        94\t|\tloss: 1120.03\n",
      "Training Epoch 88  97.9% | batch:        92 of        94\t|\tloss: 849.883\n",
      "Training Epoch 88  98.9% | batch:        93 of        94\t|\tloss: 1887.16\n",
      "\n",
      "Evaluating Epoch 88   0.0% | batch:         0 of        40\t|\tloss: 7389.47\n",
      "Evaluating Epoch 88   2.5% | batch:         1 of        40\t|\tloss: 1196.52\n",
      "Evaluating Epoch 88   5.0% | batch:         2 of        40\t|\tloss: 3756.4\n",
      "Evaluating Epoch 88   7.5% | batch:         3 of        40\t|\tloss: 7088.43\n",
      "Evaluating Epoch 88  10.0% | batch:         4 of        40\t|\tloss: 2536.54\n",
      "Evaluating Epoch 88  12.5% | batch:         5 of        40\t|\tloss: 2531.09\n",
      "Evaluating Epoch 88  15.0% | batch:         6 of        40\t|\tloss: 9290.24\n",
      "Evaluating Epoch 88  17.5% | batch:         7 of        40\t|\tloss: 3366.16\n",
      "Evaluating Epoch 88  20.0% | batch:         8 of        40\t|\tloss: 3054.37\n",
      "Evaluating Epoch 88  22.5% | batch:         9 of        40\t|\tloss: 2092.34\n",
      "Evaluating Epoch 88  25.0% | batch:        10 of        40\t|\tloss: 5599.57\n",
      "Evaluating Epoch 88  27.5% | batch:        11 of        40\t|\tloss: 1378.04\n",
      "Evaluating Epoch 88  30.0% | batch:        12 of        40\t|\tloss: 6239.62\n",
      "Evaluating Epoch 88  32.5% | batch:        13 of        40\t|\tloss: 3444.21\n",
      "Evaluating Epoch 88  35.0% | batch:        14 of        40\t|\tloss: 2249.05\n",
      "Evaluating Epoch 88  37.5% | batch:        15 of        40\t|\tloss: 3032.97\n",
      "Evaluating Epoch 88  40.0% | batch:        16 of        40\t|\tloss: 3753.85\n",
      "Evaluating Epoch 88  42.5% | batch:        17 of        40\t|\tloss: 3189.68\n",
      "Evaluating Epoch 88  45.0% | batch:        18 of        40\t|\tloss: 2582.87\n",
      "Evaluating Epoch 88  47.5% | batch:        19 of        40\t|\tloss: 6617.93\n",
      "Evaluating Epoch 88  50.0% | batch:        20 of        40\t|\tloss: 5947.85\n",
      "Evaluating Epoch 88  52.5% | batch:        21 of        40\t|\tloss: 1447.36\n",
      "Evaluating Epoch 88  55.0% | batch:        22 of        40\t|\tloss: 3778.51\n",
      "Evaluating Epoch 88  57.5% | batch:        23 of        40\t|\tloss: 3419.63\n",
      "Evaluating Epoch 88  60.0% | batch:        24 of        40\t|\tloss: 1756.82\n",
      "Evaluating Epoch 88  62.5% | batch:        25 of        40\t|\tloss: 3445.94\n",
      "Evaluating Epoch 88  65.0% | batch:        26 of        40\t|\tloss: 9633.34\n",
      "Evaluating Epoch 88  67.5% | batch:        27 of        40\t|\tloss: 3293.86\n",
      "Evaluating Epoch 88  70.0% | batch:        28 of        40\t|\tloss: 2443.88\n",
      "Evaluating Epoch 88  72.5% | batch:        29 of        40\t|\tloss: 9017.12\n",
      "Evaluating Epoch 88  75.0% | batch:        30 of        40\t|\tloss: 2080.83\n",
      "Evaluating Epoch 88  77.5% | batch:        31 of        40\t|\tloss: 1790.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:21,235 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.446242094039917 seconds\n",
      "\n",
      "2023-05-09 14:23:21,235 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47269252590511157 seconds\n",
      "2023-05-09 14:23:21,236 | INFO : Avg batch val. time: 0.01181731314762779 seconds\n",
      "2023-05-09 14:23:21,236 | INFO : Avg sample val. time: 9.36395653536275e-05 seconds\n",
      "2023-05-09 14:23:21,237 | INFO : Epoch 88 Validation Summary: epoch: 88.000000 | loss: 4280.182600 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 88  80.0% | batch:        32 of        40\t|\tloss: 8299.99\n",
      "Evaluating Epoch 88  82.5% | batch:        33 of        40\t|\tloss: 6715.11\n",
      "Evaluating Epoch 88  85.0% | batch:        34 of        40\t|\tloss: 914.644\n",
      "Evaluating Epoch 88  87.5% | batch:        35 of        40\t|\tloss: 6437.27\n",
      "Evaluating Epoch 88  90.0% | batch:        36 of        40\t|\tloss: 6764.48\n",
      "Evaluating Epoch 88  92.5% | batch:        37 of        40\t|\tloss: 2990.97\n",
      "Evaluating Epoch 88  95.0% | batch:        38 of        40\t|\tloss: 3329.3\n",
      "Evaluating Epoch 88  97.5% | batch:        39 of        40\t|\tloss: 11207.7\n",
      "\n",
      "Training Epoch 89   0.0% | batch:         0 of        94\t|\tloss: 1093.24\n",
      "Training Epoch 89   1.1% | batch:         1 of        94\t|\tloss: 1115.71\n",
      "Training Epoch 89   2.1% | batch:         2 of        94\t|\tloss: 1201.34\n",
      "Training Epoch 89   3.2% | batch:         3 of        94\t|\tloss: 799.709\n",
      "Training Epoch 89   4.3% | batch:         4 of        94\t|\tloss: 924.36\n",
      "Training Epoch 89   5.3% | batch:         5 of        94\t|\tloss: 629.352\n",
      "Training Epoch 89   6.4% | batch:         6 of        94\t|\tloss: 708.355\n",
      "Training Epoch 89   7.4% | batch:         7 of        94\t|\tloss: 1344.4\n",
      "Training Epoch 89   8.5% | batch:         8 of        94\t|\tloss: 880.193\n",
      "Training Epoch 89   9.6% | batch:         9 of        94\t|\tloss: 664.172\n",
      "Training Epoch 89  10.6% | batch:        10 of        94\t|\tloss: 765.329\n",
      "Training Epoch 89  11.7% | batch:        11 of        94\t|\tloss: 1234.76\n",
      "Training Epoch 89  12.8% | batch:        12 of        94\t|\tloss: 762.644\n",
      "Training Epoch 89  13.8% | batch:        13 of        94\t|\tloss: 730.016\n",
      "Training Epoch 89  14.9% | batch:        14 of        94\t|\tloss: 1166.26\n",
      "Training Epoch 89  16.0% | batch:        15 of        94\t|\tloss: 1246.95\n",
      "Training Epoch 89  17.0% | batch:        16 of        94\t|\tloss: 2023.91\n",
      "Training Epoch 89  18.1% | batch:        17 of        94\t|\tloss: 780.042\n",
      "Training Epoch 89  19.1% | batch:        18 of        94\t|\tloss: 862.357\n",
      "Training Epoch 89  20.2% | batch:        19 of        94\t|\tloss: 1203.92\n",
      "Training Epoch 89  21.3% | batch:        20 of        94\t|\tloss: 655.712\n",
      "Training Epoch 89  22.3% | batch:        21 of        94\t|\tloss: 825.995\n",
      "Training Epoch 89  23.4% | batch:        22 of        94\t|\tloss: 512.578\n",
      "Training Epoch 89  24.5% | batch:        23 of        94\t|\tloss: 739.663\n",
      "Training Epoch 89  25.5% | batch:        24 of        94\t|\tloss: 796.034\n",
      "Training Epoch 89  26.6% | batch:        25 of        94\t|\tloss: 1495.91\n",
      "Training Epoch 89  27.7% | batch:        26 of        94\t|\tloss: 875.549\n",
      "Training Epoch 89  28.7% | batch:        27 of        94\t|\tloss: 1143.95\n",
      "Training Epoch 89  29.8% | batch:        28 of        94\t|\tloss: 760.491\n",
      "Training Epoch 89  30.9% | batch:        29 of        94\t|\tloss: 808.089\n",
      "Training Epoch 89  31.9% | batch:        30 of        94\t|\tloss: 866.892\n",
      "Training Epoch 89  33.0% | batch:        31 of        94\t|\tloss: 1268.81\n",
      "Training Epoch 89  34.0% | batch:        32 of        94\t|\tloss: 1110.87\n",
      "Training Epoch 89  35.1% | batch:        33 of        94\t|\tloss: 667.269\n",
      "Training Epoch 89  36.2% | batch:        34 of        94\t|\tloss: 604.529\n",
      "Training Epoch 89  37.2% | batch:        35 of        94\t|\tloss: 611.438\n",
      "Training Epoch 89  38.3% | batch:        36 of        94\t|\tloss: 1105.15\n",
      "Training Epoch 89  39.4% | batch:        37 of        94\t|\tloss: 1008.32\n",
      "Training Epoch 89  40.4% | batch:        38 of        94\t|\tloss: 1104.19\n",
      "Training Epoch 89  41.5% | batch:        39 of        94\t|\tloss: 974.216\n",
      "Training Epoch 89  42.6% | batch:        40 of        94\t|\tloss: 1773.53\n",
      "Training Epoch 89  43.6% | batch:        41 of        94\t|\tloss: 934.334\n",
      "Training Epoch 89  44.7% | batch:        42 of        94\t|\tloss: 833.263\n",
      "Training Epoch 89  45.7% | batch:        43 of        94\t|\tloss: 602.303\n",
      "Training Epoch 89  46.8% | batch:        44 of        94\t|\tloss: 1373.04\n",
      "Training Epoch 89  47.9% | batch:        45 of        94\t|\tloss: 455.579\n",
      "Training Epoch 89  48.9% | batch:        46 of        94\t|\tloss: 965.832\n",
      "Training Epoch 89  50.0% | batch:        47 of        94\t|\tloss: 983.324\n",
      "Training Epoch 89  51.1% | batch:        48 of        94\t|\tloss: 731.107\n",
      "Training Epoch 89  52.1% | batch:        49 of        94\t|\tloss: 938.043\n",
      "Training Epoch 89  53.2% | batch:        50 of        94\t|\tloss: 992.458\n",
      "Training Epoch 89  54.3% | batch:        51 of        94\t|\tloss: 647.523\n",
      "Training Epoch 89  55.3% | batch:        52 of        94\t|\tloss: 666.959\n",
      "Training Epoch 89  56.4% | batch:        53 of        94\t|\tloss: 839.378\n",
      "Training Epoch 89  57.4% | batch:        54 of        94\t|\tloss: 777.844\n",
      "Training Epoch 89  58.5% | batch:        55 of        94\t|\tloss: 896.651\n",
      "Training Epoch 89  59.6% | batch:        56 of        94\t|\tloss: 1026.49\n",
      "Training Epoch 89  60.6% | batch:        57 of        94\t|\tloss: 1891.22\n",
      "Training Epoch 89  61.7% | batch:        58 of        94\t|\tloss: 893.768\n",
      "Training Epoch 89  62.8% | batch:        59 of        94\t|\tloss: 676.554\n",
      "Training Epoch 89  63.8% | batch:        60 of        94\t|\tloss: 655.749\n",
      "Training Epoch 89  64.9% | batch:        61 of        94\t|\tloss: 670.745\n",
      "Training Epoch 89  66.0% | batch:        62 of        94\t|\tloss: 1000.51\n",
      "Training Epoch 89  67.0% | batch:        63 of        94\t|\tloss: 1475.41\n",
      "Training Epoch 89  68.1% | batch:        64 of        94\t|\tloss: 1619.97\n",
      "Training Epoch 89  69.1% | batch:        65 of        94\t|\tloss: 763.425\n",
      "Training Epoch 89  70.2% | batch:        66 of        94\t|\tloss: 1137.49\n",
      "Training Epoch 89  71.3% | batch:        67 of        94\t|\tloss: 911.725\n",
      "Training Epoch 89  72.3% | batch:        68 of        94\t|\tloss: 927.984\n",
      "Training Epoch 89  73.4% | batch:        69 of        94\t|\tloss: 615.088\n",
      "Training Epoch 89  74.5% | batch:        70 of        94\t|\tloss: 807.835\n",
      "Training Epoch 89  75.5% | batch:        71 of        94\t|\tloss: 2560.95\n",
      "Training Epoch 89  76.6% | batch:        72 of        94\t|\tloss: 856.774\n",
      "Training Epoch 89  77.7% | batch:        73 of        94\t|\tloss: 757.198\n",
      "Training Epoch 89  78.7% | batch:        74 of        94\t|\tloss: 1146.84\n",
      "Training Epoch 89  79.8% | batch:        75 of        94\t|\tloss: 666.556\n",
      "Training Epoch 89  80.9% | batch:        76 of        94\t|\tloss: 985.017\n",
      "Training Epoch 89  81.9% | batch:        77 of        94\t|\tloss: 693.714\n",
      "Training Epoch 89  83.0% | batch:        78 of        94\t|\tloss: 771.599\n",
      "Training Epoch 89  84.0% | batch:        79 of        94\t|\tloss: 880.232\n",
      "Training Epoch 89  85.1% | batch:        80 of        94\t|\tloss: 962.228\n",
      "Training Epoch 89  86.2% | batch:        81 of        94\t|\tloss: 1235.31\n",
      "Training Epoch 89  87.2% | batch:        82 of        94\t|\tloss: 1306.61\n",
      "Training Epoch 89  88.3% | batch:        83 of        94\t|\tloss: 999.918\n",
      "Training Epoch 89  89.4% | batch:        84 of        94\t|\tloss: 1078.72\n",
      "Training Epoch 89  90.4% | batch:        85 of        94\t|\tloss: 959.506\n",
      "Training Epoch 89  91.5% | batch:        86 of        94\t|\tloss: 1258.72\n",
      "Training Epoch 89  92.6% | batch:        87 of        94\t|\tloss: 659.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:22,946 | INFO : Epoch 89 Training Summary: epoch: 89.000000 | loss: 968.311233 | \n",
      "2023-05-09 14:23:22,947 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.6882600784301758 seconds\n",
      "\n",
      "2023-05-09 14:23:22,947 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.829994737432244 seconds\n",
      "2023-05-09 14:23:22,948 | INFO : Avg batch train. time: 0.01946802912161962 seconds\n",
      "2023-05-09 14:23:22,948 | INFO : Avg sample train. time: 0.0001535488116657362 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 89  93.6% | batch:        88 of        94\t|\tloss: 933.884\n",
      "Training Epoch 89  94.7% | batch:        89 of        94\t|\tloss: 706.62\n",
      "Training Epoch 89  95.7% | batch:        90 of        94\t|\tloss: 722.191\n",
      "Training Epoch 89  96.8% | batch:        91 of        94\t|\tloss: 793.178\n",
      "Training Epoch 89  97.9% | batch:        92 of        94\t|\tloss: 1589.67\n",
      "Training Epoch 89  98.9% | batch:        93 of        94\t|\tloss: 697.99\n",
      "\n",
      "Training Epoch 90   0.0% | batch:         0 of        94\t|\tloss: 871.252\n",
      "Training Epoch 90   1.1% | batch:         1 of        94\t|\tloss: 865.772\n",
      "Training Epoch 90   2.1% | batch:         2 of        94\t|\tloss: 1167.79\n",
      "Training Epoch 90   3.2% | batch:         3 of        94\t|\tloss: 861.329\n",
      "Training Epoch 90   4.3% | batch:         4 of        94\t|\tloss: 740.386\n",
      "Training Epoch 90   5.3% | batch:         5 of        94\t|\tloss: 650.243\n",
      "Training Epoch 90   6.4% | batch:         6 of        94\t|\tloss: 652.018\n",
      "Training Epoch 90   7.4% | batch:         7 of        94\t|\tloss: 1111.25\n",
      "Training Epoch 90   8.5% | batch:         8 of        94\t|\tloss: 954.989\n",
      "Training Epoch 90   9.6% | batch:         9 of        94\t|\tloss: 1285.84\n",
      "Training Epoch 90  10.6% | batch:        10 of        94\t|\tloss: 1663.31\n",
      "Training Epoch 90  11.7% | batch:        11 of        94\t|\tloss: 804.652\n",
      "Training Epoch 90  12.8% | batch:        12 of        94\t|\tloss: 785.053\n",
      "Training Epoch 90  13.8% | batch:        13 of        94\t|\tloss: 820.827\n",
      "Training Epoch 90  14.9% | batch:        14 of        94\t|\tloss: 873.295\n",
      "Training Epoch 90  16.0% | batch:        15 of        94\t|\tloss: 736.426\n",
      "Training Epoch 90  17.0% | batch:        16 of        94\t|\tloss: 1007.94\n",
      "Training Epoch 90  18.1% | batch:        17 of        94\t|\tloss: 903.526\n",
      "Training Epoch 90  19.1% | batch:        18 of        94\t|\tloss: 997.902\n",
      "Training Epoch 90  20.2% | batch:        19 of        94\t|\tloss: 643.423\n",
      "Training Epoch 90  21.3% | batch:        20 of        94\t|\tloss: 613.996\n",
      "Training Epoch 90  22.3% | batch:        21 of        94\t|\tloss: 1376.41\n",
      "Training Epoch 90  23.4% | batch:        22 of        94\t|\tloss: 757.921\n",
      "Training Epoch 90  24.5% | batch:        23 of        94\t|\tloss: 1095.31\n",
      "Training Epoch 90  25.5% | batch:        24 of        94\t|\tloss: 519.595\n",
      "Training Epoch 90  26.6% | batch:        25 of        94\t|\tloss: 720.068\n",
      "Training Epoch 90  27.7% | batch:        26 of        94\t|\tloss: 870.054\n",
      "Training Epoch 90  28.7% | batch:        27 of        94\t|\tloss: 842.772\n",
      "Training Epoch 90  29.8% | batch:        28 of        94\t|\tloss: 831.948\n",
      "Training Epoch 90  30.9% | batch:        29 of        94\t|\tloss: 1629.4\n",
      "Training Epoch 90  31.9% | batch:        30 of        94\t|\tloss: 850.044\n",
      "Training Epoch 90  33.0% | batch:        31 of        94\t|\tloss: 1067.69\n",
      "Training Epoch 90  34.0% | batch:        32 of        94\t|\tloss: 522.773\n",
      "Training Epoch 90  35.1% | batch:        33 of        94\t|\tloss: 699.605\n",
      "Training Epoch 90  36.2% | batch:        34 of        94\t|\tloss: 667.069\n",
      "Training Epoch 90  37.2% | batch:        35 of        94\t|\tloss: 461.427\n",
      "Training Epoch 90  38.3% | batch:        36 of        94\t|\tloss: 732.758\n",
      "Training Epoch 90  39.4% | batch:        37 of        94\t|\tloss: 863.58\n",
      "Training Epoch 90  40.4% | batch:        38 of        94\t|\tloss: 570.055\n",
      "Training Epoch 90  41.5% | batch:        39 of        94\t|\tloss: 827.503\n",
      "Training Epoch 90  42.6% | batch:        40 of        94\t|\tloss: 574.232\n",
      "Training Epoch 90  43.6% | batch:        41 of        94\t|\tloss: 1103.3\n",
      "Training Epoch 90  44.7% | batch:        42 of        94\t|\tloss: 876.512\n",
      "Training Epoch 90  45.7% | batch:        43 of        94\t|\tloss: 983.032\n",
      "Training Epoch 90  46.8% | batch:        44 of        94\t|\tloss: 676.317\n",
      "Training Epoch 90  47.9% | batch:        45 of        94\t|\tloss: 721.323\n",
      "Training Epoch 90  48.9% | batch:        46 of        94\t|\tloss: 782.62\n",
      "Training Epoch 90  50.0% | batch:        47 of        94\t|\tloss: 882.077\n",
      "Training Epoch 90  51.1% | batch:        48 of        94\t|\tloss: 1123.08\n",
      "Training Epoch 90  52.1% | batch:        49 of        94\t|\tloss: 1010.16\n",
      "Training Epoch 90  53.2% | batch:        50 of        94\t|\tloss: 751.032\n",
      "Training Epoch 90  54.3% | batch:        51 of        94\t|\tloss: 1071.13\n",
      "Training Epoch 90  55.3% | batch:        52 of        94\t|\tloss: 1367.69\n",
      "Training Epoch 90  56.4% | batch:        53 of        94\t|\tloss: 1284.22\n",
      "Training Epoch 90  57.4% | batch:        54 of        94\t|\tloss: 1055.4\n",
      "Training Epoch 90  58.5% | batch:        55 of        94\t|\tloss: 678.04\n",
      "Training Epoch 90  59.6% | batch:        56 of        94\t|\tloss: 814.719\n",
      "Training Epoch 90  60.6% | batch:        57 of        94\t|\tloss: 985.507\n",
      "Training Epoch 90  61.7% | batch:        58 of        94\t|\tloss: 866.943\n",
      "Training Epoch 90  62.8% | batch:        59 of        94\t|\tloss: 1702.75\n",
      "Training Epoch 90  63.8% | batch:        60 of        94\t|\tloss: 861.924\n",
      "Training Epoch 90  64.9% | batch:        61 of        94\t|\tloss: 770.769\n",
      "Training Epoch 90  66.0% | batch:        62 of        94\t|\tloss: 1024.9\n",
      "Training Epoch 90  67.0% | batch:        63 of        94\t|\tloss: 884.61\n",
      "Training Epoch 90  68.1% | batch:        64 of        94\t|\tloss: 651.639\n",
      "Training Epoch 90  69.1% | batch:        65 of        94\t|\tloss: 980.126\n",
      "Training Epoch 90  70.2% | batch:        66 of        94\t|\tloss: 743.751\n",
      "Training Epoch 90  71.3% | batch:        67 of        94\t|\tloss: 1137.4\n",
      "Training Epoch 90  72.3% | batch:        68 of        94\t|\tloss: 1216.58\n",
      "Training Epoch 90  73.4% | batch:        69 of        94\t|\tloss: 831.646\n",
      "Training Epoch 90  74.5% | batch:        70 of        94\t|\tloss: 1047.03\n",
      "Training Epoch 90  75.5% | batch:        71 of        94\t|\tloss: 619.361\n",
      "Training Epoch 90  76.6% | batch:        72 of        94\t|\tloss: 832.073\n",
      "Training Epoch 90  77.7% | batch:        73 of        94\t|\tloss: 1919.64\n",
      "Training Epoch 90  78.7% | batch:        74 of        94\t|\tloss: 1161.76\n",
      "Training Epoch 90  79.8% | batch:        75 of        94\t|\tloss: 470.575\n",
      "Training Epoch 90  80.9% | batch:        76 of        94\t|\tloss: 910.398\n",
      "Training Epoch 90  81.9% | batch:        77 of        94\t|\tloss: 1057.96\n",
      "Training Epoch 90  83.0% | batch:        78 of        94\t|\tloss: 1107.11\n",
      "Training Epoch 90  84.0% | batch:        79 of        94\t|\tloss: 586.943\n",
      "Training Epoch 90  85.1% | batch:        80 of        94\t|\tloss: 642.58\n",
      "Training Epoch 90  86.2% | batch:        81 of        94\t|\tloss: 700.182\n",
      "Training Epoch 90  87.2% | batch:        82 of        94\t|\tloss: 840.671\n",
      "Training Epoch 90  88.3% | batch:        83 of        94\t|\tloss: 3033.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:24,744 | INFO : Epoch 90 Training Summary: epoch: 90.000000 | loss: 917.457589 | \n",
      "2023-05-09 14:23:24,745 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.775885820388794 seconds\n",
      "\n",
      "2023-05-09 14:23:24,745 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8293935272428725 seconds\n",
      "2023-05-09 14:23:24,746 | INFO : Avg batch train. time: 0.0194616332685412 seconds\n",
      "2023-05-09 14:23:24,746 | INFO : Avg sample train. time: 0.0001534983661052922 seconds\n",
      "2023-05-09 14:23:24,746 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 90  89.4% | batch:        84 of        94\t|\tloss: 846.781\n",
      "Training Epoch 90  90.4% | batch:        85 of        94\t|\tloss: 629.614\n",
      "Training Epoch 90  91.5% | batch:        86 of        94\t|\tloss: 801.758\n",
      "Training Epoch 90  92.6% | batch:        87 of        94\t|\tloss: 926.676\n",
      "Training Epoch 90  93.6% | batch:        88 of        94\t|\tloss: 804.385\n",
      "Training Epoch 90  94.7% | batch:        89 of        94\t|\tloss: 663.1\n",
      "Training Epoch 90  95.7% | batch:        90 of        94\t|\tloss: 749.772\n",
      "Training Epoch 90  96.8% | batch:        91 of        94\t|\tloss: 766.1\n",
      "Training Epoch 90  97.9% | batch:        92 of        94\t|\tloss: 910.286\n",
      "Training Epoch 90  98.9% | batch:        93 of        94\t|\tloss: 590.115\n",
      "\n",
      "Evaluating Epoch 90   0.0% | batch:         0 of        40\t|\tloss: 7066.96\n",
      "Evaluating Epoch 90   2.5% | batch:         1 of        40\t|\tloss: 1177.22\n",
      "Evaluating Epoch 90   5.0% | batch:         2 of        40\t|\tloss: 2984.31\n",
      "Evaluating Epoch 90   7.5% | batch:         3 of        40\t|\tloss: 6873.9\n",
      "Evaluating Epoch 90  10.0% | batch:         4 of        40\t|\tloss: 2362.34\n",
      "Evaluating Epoch 90  12.5% | batch:         5 of        40\t|\tloss: 2375.37\n",
      "Evaluating Epoch 90  15.0% | batch:         6 of        40\t|\tloss: 8653.03\n",
      "Evaluating Epoch 90  17.5% | batch:         7 of        40\t|\tloss: 3170.64\n",
      "Evaluating Epoch 90  20.0% | batch:         8 of        40\t|\tloss: 3010.66\n",
      "Evaluating Epoch 90  22.5% | batch:         9 of        40\t|\tloss: 1967.68\n",
      "Evaluating Epoch 90  25.0% | batch:        10 of        40\t|\tloss: 5066.94\n",
      "Evaluating Epoch 90  27.5% | batch:        11 of        40\t|\tloss: 1498.26\n",
      "Evaluating Epoch 90  30.0% | batch:        12 of        40\t|\tloss: 6126.6\n",
      "Evaluating Epoch 90  32.5% | batch:        13 of        40\t|\tloss: 3513.84\n",
      "Evaluating Epoch 90  35.0% | batch:        14 of        40\t|\tloss: 2127.35\n",
      "Evaluating Epoch 90  37.5% | batch:        15 of        40\t|\tloss: 3027.3\n",
      "Evaluating Epoch 90  40.0% | batch:        16 of        40\t|\tloss: 4047.02\n",
      "Evaluating Epoch 90  42.5% | batch:        17 of        40\t|\tloss: 3120.11\n",
      "Evaluating Epoch 90  45.0% | batch:        18 of        40\t|\tloss: 2545.77\n",
      "Evaluating Epoch 90  47.5% | batch:        19 of        40\t|\tloss: 5498.35\n",
      "Evaluating Epoch 90  50.0% | batch:        20 of        40\t|\tloss: 5603.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:25,192 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4459044933319092 seconds\n",
      "\n",
      "2023-05-09 14:23:25,193 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4721225677652562 seconds\n",
      "2023-05-09 14:23:25,193 | INFO : Avg batch val. time: 0.011803064194131404 seconds\n",
      "2023-05-09 14:23:25,194 | INFO : Avg sample val. time: 9.352665763971002e-05 seconds\n",
      "2023-05-09 14:23:25,194 | INFO : Epoch 90 Validation Summary: epoch: 90.000000 | loss: 4072.995496 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 90  52.5% | batch:        21 of        40\t|\tloss: 1525.11\n",
      "Evaluating Epoch 90  55.0% | batch:        22 of        40\t|\tloss: 3676.67\n",
      "Evaluating Epoch 90  57.5% | batch:        23 of        40\t|\tloss: 3483.64\n",
      "Evaluating Epoch 90  60.0% | batch:        24 of        40\t|\tloss: 1627.2\n",
      "Evaluating Epoch 90  62.5% | batch:        25 of        40\t|\tloss: 3355.56\n",
      "Evaluating Epoch 90  65.0% | batch:        26 of        40\t|\tloss: 9956.33\n",
      "Evaluating Epoch 90  67.5% | batch:        27 of        40\t|\tloss: 3193.54\n",
      "Evaluating Epoch 90  70.0% | batch:        28 of        40\t|\tloss: 1861.56\n",
      "Evaluating Epoch 90  72.5% | batch:        29 of        40\t|\tloss: 8826.46\n",
      "Evaluating Epoch 90  75.0% | batch:        30 of        40\t|\tloss: 2047.3\n",
      "Evaluating Epoch 90  77.5% | batch:        31 of        40\t|\tloss: 1726.89\n",
      "Evaluating Epoch 90  80.0% | batch:        32 of        40\t|\tloss: 7590.82\n",
      "Evaluating Epoch 90  82.5% | batch:        33 of        40\t|\tloss: 6504.46\n",
      "Evaluating Epoch 90  85.0% | batch:        34 of        40\t|\tloss: 955.18\n",
      "Evaluating Epoch 90  87.5% | batch:        35 of        40\t|\tloss: 5103.11\n",
      "Evaluating Epoch 90  90.0% | batch:        36 of        40\t|\tloss: 6482.32\n",
      "Evaluating Epoch 90  92.5% | batch:        37 of        40\t|\tloss: 2907.58\n",
      "Evaluating Epoch 90  95.0% | batch:        38 of        40\t|\tloss: 3208.73\n",
      "Evaluating Epoch 90  97.5% | batch:        39 of        40\t|\tloss: 10923.2\n",
      "\n",
      "Training Epoch 91   0.0% | batch:         0 of        94\t|\tloss: 1555.36\n",
      "Training Epoch 91   1.1% | batch:         1 of        94\t|\tloss: 692.021\n",
      "Training Epoch 91   2.1% | batch:         2 of        94\t|\tloss: 860.683\n",
      "Training Epoch 91   3.2% | batch:         3 of        94\t|\tloss: 738.418\n",
      "Training Epoch 91   4.3% | batch:         4 of        94\t|\tloss: 484.891\n",
      "Training Epoch 91   5.3% | batch:         5 of        94\t|\tloss: 837.57\n",
      "Training Epoch 91   6.4% | batch:         6 of        94\t|\tloss: 643.194\n",
      "Training Epoch 91   7.4% | batch:         7 of        94\t|\tloss: 625.434\n",
      "Training Epoch 91   8.5% | batch:         8 of        94\t|\tloss: 1294.83\n",
      "Training Epoch 91   9.6% | batch:         9 of        94\t|\tloss: 877.749\n",
      "Training Epoch 91  10.6% | batch:        10 of        94\t|\tloss: 644.469\n",
      "Training Epoch 91  11.7% | batch:        11 of        94\t|\tloss: 910.764\n",
      "Training Epoch 91  12.8% | batch:        12 of        94\t|\tloss: 622.246\n",
      "Training Epoch 91  13.8% | batch:        13 of        94\t|\tloss: 863.13\n",
      "Training Epoch 91  14.9% | batch:        14 of        94\t|\tloss: 739.26\n",
      "Training Epoch 91  16.0% | batch:        15 of        94\t|\tloss: 1243.86\n",
      "Training Epoch 91  17.0% | batch:        16 of        94\t|\tloss: 1037.58\n",
      "Training Epoch 91  18.1% | batch:        17 of        94\t|\tloss: 1159.31\n",
      "Training Epoch 91  19.1% | batch:        18 of        94\t|\tloss: 678.035\n",
      "Training Epoch 91  20.2% | batch:        19 of        94\t|\tloss: 1445.34\n",
      "Training Epoch 91  21.3% | batch:        20 of        94\t|\tloss: 729.034\n",
      "Training Epoch 91  22.3% | batch:        21 of        94\t|\tloss: 718.121\n",
      "Training Epoch 91  23.4% | batch:        22 of        94\t|\tloss: 752.787\n",
      "Training Epoch 91  24.5% | batch:        23 of        94\t|\tloss: 841.396\n",
      "Training Epoch 91  25.5% | batch:        24 of        94\t|\tloss: 667.462\n",
      "Training Epoch 91  26.6% | batch:        25 of        94\t|\tloss: 729.609\n",
      "Training Epoch 91  27.7% | batch:        26 of        94\t|\tloss: 712.379\n",
      "Training Epoch 91  28.7% | batch:        27 of        94\t|\tloss: 1728.16\n",
      "Training Epoch 91  29.8% | batch:        28 of        94\t|\tloss: 957.251\n",
      "Training Epoch 91  30.9% | batch:        29 of        94\t|\tloss: 1046.69\n",
      "Training Epoch 91  31.9% | batch:        30 of        94\t|\tloss: 691.147\n",
      "Training Epoch 91  33.0% | batch:        31 of        94\t|\tloss: 1218.46\n",
      "Training Epoch 91  34.0% | batch:        32 of        94\t|\tloss: 696.456\n",
      "Training Epoch 91  35.1% | batch:        33 of        94\t|\tloss: 1322.2\n",
      "Training Epoch 91  36.2% | batch:        34 of        94\t|\tloss: 756.867\n",
      "Training Epoch 91  37.2% | batch:        35 of        94\t|\tloss: 776.88\n",
      "Training Epoch 91  38.3% | batch:        36 of        94\t|\tloss: 1373.9\n",
      "Training Epoch 91  39.4% | batch:        37 of        94\t|\tloss: 1279.11\n",
      "Training Epoch 91  40.4% | batch:        38 of        94\t|\tloss: 898.107\n",
      "Training Epoch 91  41.5% | batch:        39 of        94\t|\tloss: 568.832\n",
      "Training Epoch 91  42.6% | batch:        40 of        94\t|\tloss: 890.97\n",
      "Training Epoch 91  43.6% | batch:        41 of        94\t|\tloss: 448.725\n",
      "Training Epoch 91  44.7% | batch:        42 of        94\t|\tloss: 1315.84\n",
      "Training Epoch 91  45.7% | batch:        43 of        94\t|\tloss: 817.579\n",
      "Training Epoch 91  46.8% | batch:        44 of        94\t|\tloss: 744.532\n",
      "Training Epoch 91  47.9% | batch:        45 of        94\t|\tloss: 973.52\n",
      "Training Epoch 91  48.9% | batch:        46 of        94\t|\tloss: 1074.49\n",
      "Training Epoch 91  50.0% | batch:        47 of        94\t|\tloss: 918.745\n",
      "Training Epoch 91  51.1% | batch:        48 of        94\t|\tloss: 540.904\n",
      "Training Epoch 91  52.1% | batch:        49 of        94\t|\tloss: 1182.3\n",
      "Training Epoch 91  53.2% | batch:        50 of        94\t|\tloss: 844.706\n",
      "Training Epoch 91  54.3% | batch:        51 of        94\t|\tloss: 838.908\n",
      "Training Epoch 91  55.3% | batch:        52 of        94\t|\tloss: 1065.54\n",
      "Training Epoch 91  56.4% | batch:        53 of        94\t|\tloss: 781.46\n",
      "Training Epoch 91  57.4% | batch:        54 of        94\t|\tloss: 1279.84\n",
      "Training Epoch 91  58.5% | batch:        55 of        94\t|\tloss: 649.416\n",
      "Training Epoch 91  59.6% | batch:        56 of        94\t|\tloss: 733.737\n",
      "Training Epoch 91  60.6% | batch:        57 of        94\t|\tloss: 1298.64\n",
      "Training Epoch 91  61.7% | batch:        58 of        94\t|\tloss: 704.957\n",
      "Training Epoch 91  62.8% | batch:        59 of        94\t|\tloss: 703.263\n",
      "Training Epoch 91  63.8% | batch:        60 of        94\t|\tloss: 1354.88\n",
      "Training Epoch 91  64.9% | batch:        61 of        94\t|\tloss: 2581.45\n",
      "Training Epoch 91  66.0% | batch:        62 of        94\t|\tloss: 556.044\n",
      "Training Epoch 91  67.0% | batch:        63 of        94\t|\tloss: 905.031\n",
      "Training Epoch 91  68.1% | batch:        64 of        94\t|\tloss: 588.565\n",
      "Training Epoch 91  69.1% | batch:        65 of        94\t|\tloss: 788.863\n",
      "Training Epoch 91  70.2% | batch:        66 of        94\t|\tloss: 871.338\n",
      "Training Epoch 91  71.3% | batch:        67 of        94\t|\tloss: 1073.5\n",
      "Training Epoch 91  72.3% | batch:        68 of        94\t|\tloss: 1195.89\n",
      "Training Epoch 91  73.4% | batch:        69 of        94\t|\tloss: 779.165\n",
      "Training Epoch 91  74.5% | batch:        70 of        94\t|\tloss: 1031.27\n",
      "Training Epoch 91  75.5% | batch:        71 of        94\t|\tloss: 584.016\n",
      "Training Epoch 91  76.6% | batch:        72 of        94\t|\tloss: 708.162\n",
      "Training Epoch 91  77.7% | batch:        73 of        94\t|\tloss: 1077.63\n",
      "Training Epoch 91  78.7% | batch:        74 of        94\t|\tloss: 842.745\n",
      "Training Epoch 91  79.8% | batch:        75 of        94\t|\tloss: 678.933\n",
      "Training Epoch 91  80.9% | batch:        76 of        94\t|\tloss: 567.734\n",
      "Training Epoch 91  81.9% | batch:        77 of        94\t|\tloss: 561.178\n",
      "Training Epoch 91  83.0% | batch:        78 of        94\t|\tloss: 1105.75\n",
      "Training Epoch 91  84.0% | batch:        79 of        94\t|\tloss: 1316.54\n",
      "Training Epoch 91  85.1% | batch:        80 of        94\t|\tloss: 947.829\n",
      "Training Epoch 91  86.2% | batch:        81 of        94\t|\tloss: 578.272\n",
      "Training Epoch 91  87.2% | batch:        82 of        94\t|\tloss: 746.209\n",
      "Training Epoch 91  88.3% | batch:        83 of        94\t|\tloss: 667.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:27,088 | INFO : Epoch 91 Training Summary: epoch: 91.000000 | loss: 920.526261 | \n",
      "2023-05-09 14:23:27,089 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8722152709960938 seconds\n",
      "\n",
      "2023-05-09 14:23:27,089 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8298640958555452 seconds\n",
      "2023-05-09 14:23:27,090 | INFO : Avg batch train. time: 0.019466639317612184 seconds\n",
      "2023-05-09 14:23:27,090 | INFO : Avg sample train. time: 0.00015353784996270726 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 91  89.4% | batch:        84 of        94\t|\tloss: 1295.64\n",
      "Training Epoch 91  90.4% | batch:        85 of        94\t|\tloss: 932.679\n",
      "Training Epoch 91  91.5% | batch:        86 of        94\t|\tloss: 899.388\n",
      "Training Epoch 91  92.6% | batch:        87 of        94\t|\tloss: 879.408\n",
      "Training Epoch 91  93.6% | batch:        88 of        94\t|\tloss: 968.403\n",
      "Training Epoch 91  94.7% | batch:        89 of        94\t|\tloss: 1432.63\n",
      "Training Epoch 91  95.7% | batch:        90 of        94\t|\tloss: 1206.77\n",
      "Training Epoch 91  96.8% | batch:        91 of        94\t|\tloss: 679.86\n",
      "Training Epoch 91  97.9% | batch:        92 of        94\t|\tloss: 901.643\n",
      "Training Epoch 91  98.9% | batch:        93 of        94\t|\tloss: 1622.57\n",
      "\n",
      "Training Epoch 92   0.0% | batch:         0 of        94\t|\tloss: 983.247\n",
      "Training Epoch 92   1.1% | batch:         1 of        94\t|\tloss: 763.226\n",
      "Training Epoch 92   2.1% | batch:         2 of        94\t|\tloss: 629.451\n",
      "Training Epoch 92   3.2% | batch:         3 of        94\t|\tloss: 949.391\n",
      "Training Epoch 92   4.3% | batch:         4 of        94\t|\tloss: 928.773\n",
      "Training Epoch 92   5.3% | batch:         5 of        94\t|\tloss: 887.917\n",
      "Training Epoch 92   6.4% | batch:         6 of        94\t|\tloss: 997.823\n",
      "Training Epoch 92   7.4% | batch:         7 of        94\t|\tloss: 1512.26\n",
      "Training Epoch 92   8.5% | batch:         8 of        94\t|\tloss: 1147.76\n",
      "Training Epoch 92   9.6% | batch:         9 of        94\t|\tloss: 567.656\n",
      "Training Epoch 92  10.6% | batch:        10 of        94\t|\tloss: 644.442\n",
      "Training Epoch 92  11.7% | batch:        11 of        94\t|\tloss: 846.339\n",
      "Training Epoch 92  12.8% | batch:        12 of        94\t|\tloss: 891.703\n",
      "Training Epoch 92  13.8% | batch:        13 of        94\t|\tloss: 1027.18\n",
      "Training Epoch 92  14.9% | batch:        14 of        94\t|\tloss: 887.582\n",
      "Training Epoch 92  16.0% | batch:        15 of        94\t|\tloss: 664.644\n",
      "Training Epoch 92  17.0% | batch:        16 of        94\t|\tloss: 1072.2\n",
      "Training Epoch 92  18.1% | batch:        17 of        94\t|\tloss: 809.547\n",
      "Training Epoch 92  19.1% | batch:        18 of        94\t|\tloss: 1262.75\n",
      "Training Epoch 92  20.2% | batch:        19 of        94\t|\tloss: 764.561\n",
      "Training Epoch 92  21.3% | batch:        20 of        94\t|\tloss: 701.931\n",
      "Training Epoch 92  22.3% | batch:        21 of        94\t|\tloss: 873.976\n",
      "Training Epoch 92  23.4% | batch:        22 of        94\t|\tloss: 1153.96\n",
      "Training Epoch 92  24.5% | batch:        23 of        94\t|\tloss: 620.288\n",
      "Training Epoch 92  25.5% | batch:        24 of        94\t|\tloss: 759.113\n",
      "Training Epoch 92  26.6% | batch:        25 of        94\t|\tloss: 1031.07\n",
      "Training Epoch 92  27.7% | batch:        26 of        94\t|\tloss: 671.173\n",
      "Training Epoch 92  28.7% | batch:        27 of        94\t|\tloss: 1335.4\n",
      "Training Epoch 92  29.8% | batch:        28 of        94\t|\tloss: 1068.96\n",
      "Training Epoch 92  30.9% | batch:        29 of        94\t|\tloss: 678.067\n",
      "Training Epoch 92  31.9% | batch:        30 of        94\t|\tloss: 851.609\n",
      "Training Epoch 92  33.0% | batch:        31 of        94\t|\tloss: 1155\n",
      "Training Epoch 92  34.0% | batch:        32 of        94\t|\tloss: 1011.67\n",
      "Training Epoch 92  35.1% | batch:        33 of        94\t|\tloss: 618.368\n",
      "Training Epoch 92  36.2% | batch:        34 of        94\t|\tloss: 691.168\n",
      "Training Epoch 92  37.2% | batch:        35 of        94\t|\tloss: 1094.79\n",
      "Training Epoch 92  38.3% | batch:        36 of        94\t|\tloss: 738.487\n",
      "Training Epoch 92  39.4% | batch:        37 of        94\t|\tloss: 795.933\n",
      "Training Epoch 92  40.4% | batch:        38 of        94\t|\tloss: 1518.49\n",
      "Training Epoch 92  41.5% | batch:        39 of        94\t|\tloss: 641.248\n",
      "Training Epoch 92  42.6% | batch:        40 of        94\t|\tloss: 711.02\n",
      "Training Epoch 92  43.6% | batch:        41 of        94\t|\tloss: 736.874\n",
      "Training Epoch 92  44.7% | batch:        42 of        94\t|\tloss: 778.853\n",
      "Training Epoch 92  45.7% | batch:        43 of        94\t|\tloss: 1053.59\n",
      "Training Epoch 92  46.8% | batch:        44 of        94\t|\tloss: 790.971\n",
      "Training Epoch 92  47.9% | batch:        45 of        94\t|\tloss: 1052.37\n",
      "Training Epoch 92  48.9% | batch:        46 of        94\t|\tloss: 1050.16\n",
      "Training Epoch 92  50.0% | batch:        47 of        94\t|\tloss: 1081.74\n",
      "Training Epoch 92  51.1% | batch:        48 of        94\t|\tloss: 1518.83\n",
      "Training Epoch 92  52.1% | batch:        49 of        94\t|\tloss: 759.022\n",
      "Training Epoch 92  53.2% | batch:        50 of        94\t|\tloss: 684.823\n",
      "Training Epoch 92  54.3% | batch:        51 of        94\t|\tloss: 947.113\n",
      "Training Epoch 92  55.3% | batch:        52 of        94\t|\tloss: 2108.07\n",
      "Training Epoch 92  56.4% | batch:        53 of        94\t|\tloss: 965.751\n",
      "Training Epoch 92  57.4% | batch:        54 of        94\t|\tloss: 1086.08\n",
      "Training Epoch 92  58.5% | batch:        55 of        94\t|\tloss: 974.27\n",
      "Training Epoch 92  59.6% | batch:        56 of        94\t|\tloss: 605.601\n",
      "Training Epoch 92  60.6% | batch:        57 of        94\t|\tloss: 1268.9\n",
      "Training Epoch 92  61.7% | batch:        58 of        94\t|\tloss: 578.474\n",
      "Training Epoch 92  62.8% | batch:        59 of        94\t|\tloss: 769.875\n",
      "Training Epoch 92  63.8% | batch:        60 of        94\t|\tloss: 1030.46\n",
      "Training Epoch 92  64.9% | batch:        61 of        94\t|\tloss: 810.6\n",
      "Training Epoch 92  66.0% | batch:        62 of        94\t|\tloss: 1637.96\n",
      "Training Epoch 92  67.0% | batch:        63 of        94\t|\tloss: 625.496\n",
      "Training Epoch 92  68.1% | batch:        64 of        94\t|\tloss: 940.644\n",
      "Training Epoch 92  69.1% | batch:        65 of        94\t|\tloss: 1222.72\n",
      "Training Epoch 92  70.2% | batch:        66 of        94\t|\tloss: 935.409\n",
      "Training Epoch 92  71.3% | batch:        67 of        94\t|\tloss: 818.211\n",
      "Training Epoch 92  72.3% | batch:        68 of        94\t|\tloss: 811.05\n",
      "Training Epoch 92  73.4% | batch:        69 of        94\t|\tloss: 3090.54\n",
      "Training Epoch 92  74.5% | batch:        70 of        94\t|\tloss: 1064.71\n",
      "Training Epoch 92  75.5% | batch:        71 of        94\t|\tloss: 687.395\n",
      "Training Epoch 92  76.6% | batch:        72 of        94\t|\tloss: 838.43\n",
      "Training Epoch 92  77.7% | batch:        73 of        94\t|\tloss: 695.018\n",
      "Training Epoch 92  78.7% | batch:        74 of        94\t|\tloss: 681.106\n",
      "Training Epoch 92  79.8% | batch:        75 of        94\t|\tloss: 710.451\n",
      "Training Epoch 92  80.9% | batch:        76 of        94\t|\tloss: 764.698\n",
      "Training Epoch 92  81.9% | batch:        77 of        94\t|\tloss: 701.454\n",
      "Training Epoch 92  83.0% | batch:        78 of        94\t|\tloss: 1255.97\n",
      "Training Epoch 92  84.0% | batch:        79 of        94\t|\tloss: 1085.62\n",
      "Training Epoch 92  85.1% | batch:        80 of        94\t|\tloss: 1019.26\n",
      "Training Epoch 92  86.2% | batch:        81 of        94\t|\tloss: 769.885\n",
      "Training Epoch 92  87.2% | batch:        82 of        94\t|\tloss: 864.418\n",
      "Training Epoch 92  88.3% | batch:        83 of        94\t|\tloss: 1389.11\n",
      "Training Epoch 92  89.4% | batch:        84 of        94\t|\tloss: 984.974\n",
      "Training Epoch 92  90.4% | batch:        85 of        94\t|\tloss: 824.878\n",
      "Training Epoch 92  91.5% | batch:        86 of        94\t|\tloss: 802.916\n",
      "Training Epoch 92  92.6% | batch:        87 of        94\t|\tloss: 915.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:28,925 | INFO : Epoch 92 Training Summary: epoch: 92.000000 | loss: 952.394389 | \n",
      "2023-05-09 14:23:28,925 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8134455680847168 seconds\n",
      "\n",
      "2023-05-09 14:23:28,926 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8296856335971667 seconds\n",
      "2023-05-09 14:23:28,926 | INFO : Avg batch train. time: 0.019464740782948582 seconds\n",
      "2023-05-09 14:23:28,926 | INFO : Avg sample train. time: 0.00015352287578428988 seconds\n",
      "2023-05-09 14:23:28,927 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 92  93.6% | batch:        88 of        94\t|\tloss: 645.984\n",
      "Training Epoch 92  94.7% | batch:        89 of        94\t|\tloss: 796.522\n",
      "Training Epoch 92  95.7% | batch:        90 of        94\t|\tloss: 1502.62\n",
      "Training Epoch 92  96.8% | batch:        91 of        94\t|\tloss: 1086.17\n",
      "Training Epoch 92  97.9% | batch:        92 of        94\t|\tloss: 768.278\n",
      "Training Epoch 92  98.9% | batch:        93 of        94\t|\tloss: 1159.23\n",
      "\n",
      "Evaluating Epoch 92   0.0% | batch:         0 of        40\t|\tloss: 6893.88\n",
      "Evaluating Epoch 92   2.5% | batch:         1 of        40\t|\tloss: 1254.18\n",
      "Evaluating Epoch 92   5.0% | batch:         2 of        40\t|\tloss: 3895.18\n",
      "Evaluating Epoch 92   7.5% | batch:         3 of        40\t|\tloss: 6405.84\n",
      "Evaluating Epoch 92  10.0% | batch:         4 of        40\t|\tloss: 2670.96\n",
      "Evaluating Epoch 92  12.5% | batch:         5 of        40\t|\tloss: 2889.07\n",
      "Evaluating Epoch 92  15.0% | batch:         6 of        40\t|\tloss: 8326.59\n",
      "Evaluating Epoch 92  17.5% | batch:         7 of        40\t|\tloss: 3413.74\n",
      "Evaluating Epoch 92  20.0% | batch:         8 of        40\t|\tloss: 3117.08\n",
      "Evaluating Epoch 92  22.5% | batch:         9 of        40\t|\tloss: 2118.7\n",
      "Evaluating Epoch 92  25.0% | batch:        10 of        40\t|\tloss: 5346.91\n",
      "Evaluating Epoch 92  27.5% | batch:        11 of        40\t|\tloss: 1453.76\n",
      "Evaluating Epoch 92  30.0% | batch:        12 of        40\t|\tloss: 6361.34\n",
      "Evaluating Epoch 92  32.5% | batch:        13 of        40\t|\tloss: 3796.02\n",
      "Evaluating Epoch 92  35.0% | batch:        14 of        40\t|\tloss: 2296.8\n",
      "Evaluating Epoch 92  37.5% | batch:        15 of        40\t|\tloss: 3683.89\n",
      "Evaluating Epoch 92  40.0% | batch:        16 of        40\t|\tloss: 4016.47\n",
      "Evaluating Epoch 92  42.5% | batch:        17 of        40\t|\tloss: 3180.26\n",
      "Evaluating Epoch 92  45.0% | batch:        18 of        40\t|\tloss: 2621.33\n",
      "Evaluating Epoch 92  47.5% | batch:        19 of        40\t|\tloss: 5562.37\n",
      "Evaluating Epoch 92  50.0% | batch:        20 of        40\t|\tloss: 5541.15\n",
      "Evaluating Epoch 92  52.5% | batch:        21 of        40\t|\tloss: 1605.72\n",
      "Evaluating Epoch 92  55.0% | batch:        22 of        40\t|\tloss: 4126.83\n",
      "Evaluating Epoch 92  57.5% | batch:        23 of        40\t|\tloss: 3389.74\n",
      "Evaluating Epoch 92  60.0% | batch:        24 of        40\t|\tloss: 1832.38\n",
      "Evaluating Epoch 92  62.5% | batch:        25 of        40\t|\tloss: 3676.91\n",
      "Evaluating Epoch 92  65.0% | batch:        26 of        40\t|\tloss: 10255.6\n",
      "Evaluating Epoch 92  67.5% | batch:        27 of        40\t|\tloss: 3527.37\n",
      "Evaluating Epoch 92  70.0% | batch:        28 of        40\t|\tloss: 1960.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:29,373 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.44554877281188965 seconds\n",
      "\n",
      "2023-05-09 14:23:29,374 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47156894703706104 seconds\n",
      "2023-05-09 14:23:29,374 | INFO : Avg batch val. time: 0.011789223675926526 seconds\n",
      "2023-05-09 14:23:29,375 | INFO : Avg sample val. time: 9.341698633856202e-05 seconds\n",
      "2023-05-09 14:23:29,375 | INFO : Epoch 92 Validation Summary: epoch: 92.000000 | loss: 4299.348873 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 92  72.5% | batch:        29 of        40\t|\tloss: 9904.5\n",
      "Evaluating Epoch 92  75.0% | batch:        30 of        40\t|\tloss: 2122.51\n",
      "Evaluating Epoch 92  77.5% | batch:        31 of        40\t|\tloss: 1794.19\n",
      "Evaluating Epoch 92  80.0% | batch:        32 of        40\t|\tloss: 8172.4\n",
      "Evaluating Epoch 92  82.5% | batch:        33 of        40\t|\tloss: 6795.73\n",
      "Evaluating Epoch 92  85.0% | batch:        34 of        40\t|\tloss: 1111.94\n",
      "Evaluating Epoch 92  87.5% | batch:        35 of        40\t|\tloss: 5810.29\n",
      "Evaluating Epoch 92  90.0% | batch:        36 of        40\t|\tloss: 6699.81\n",
      "Evaluating Epoch 92  92.5% | batch:        37 of        40\t|\tloss: 2997.31\n",
      "Evaluating Epoch 92  95.0% | batch:        38 of        40\t|\tloss: 3518.07\n",
      "Evaluating Epoch 92  97.5% | batch:        39 of        40\t|\tloss: 12361.2\n",
      "\n",
      "Training Epoch 93   0.0% | batch:         0 of        94\t|\tloss: 641.43\n",
      "Training Epoch 93   1.1% | batch:         1 of        94\t|\tloss: 1085.82\n",
      "Training Epoch 93   2.1% | batch:         2 of        94\t|\tloss: 1076.2\n",
      "Training Epoch 93   3.2% | batch:         3 of        94\t|\tloss: 1046.44\n",
      "Training Epoch 93   4.3% | batch:         4 of        94\t|\tloss: 1469.88\n",
      "Training Epoch 93   5.3% | batch:         5 of        94\t|\tloss: 519.33\n",
      "Training Epoch 93   6.4% | batch:         6 of        94\t|\tloss: 574.957\n",
      "Training Epoch 93   7.4% | batch:         7 of        94\t|\tloss: 662.893\n",
      "Training Epoch 93   8.5% | batch:         8 of        94\t|\tloss: 652.505\n",
      "Training Epoch 93   9.6% | batch:         9 of        94\t|\tloss: 616.284\n",
      "Training Epoch 93  10.6% | batch:        10 of        94\t|\tloss: 784.826\n",
      "Training Epoch 93  11.7% | batch:        11 of        94\t|\tloss: 924.504\n",
      "Training Epoch 93  12.8% | batch:        12 of        94\t|\tloss: 741.974\n",
      "Training Epoch 93  13.8% | batch:        13 of        94\t|\tloss: 921.558\n",
      "Training Epoch 93  14.9% | batch:        14 of        94\t|\tloss: 1190.71\n",
      "Training Epoch 93  16.0% | batch:        15 of        94\t|\tloss: 1122.74\n",
      "Training Epoch 93  17.0% | batch:        16 of        94\t|\tloss: 717.806\n",
      "Training Epoch 93  18.1% | batch:        17 of        94\t|\tloss: 705.782\n",
      "Training Epoch 93  19.1% | batch:        18 of        94\t|\tloss: 1216.6\n",
      "Training Epoch 93  20.2% | batch:        19 of        94\t|\tloss: 839.094\n",
      "Training Epoch 93  21.3% | batch:        20 of        94\t|\tloss: 1374.12\n",
      "Training Epoch 93  22.3% | batch:        21 of        94\t|\tloss: 672.615\n",
      "Training Epoch 93  23.4% | batch:        22 of        94\t|\tloss: 961.293\n",
      "Training Epoch 93  24.5% | batch:        23 of        94\t|\tloss: 658.202\n",
      "Training Epoch 93  25.5% | batch:        24 of        94\t|\tloss: 1022.1\n",
      "Training Epoch 93  26.6% | batch:        25 of        94\t|\tloss: 1191.71\n",
      "Training Epoch 93  27.7% | batch:        26 of        94\t|\tloss: 1936.23\n",
      "Training Epoch 93  28.7% | batch:        27 of        94\t|\tloss: 838.449\n",
      "Training Epoch 93  29.8% | batch:        28 of        94\t|\tloss: 771.386\n",
      "Training Epoch 93  30.9% | batch:        29 of        94\t|\tloss: 1265.68\n",
      "Training Epoch 93  31.9% | batch:        30 of        94\t|\tloss: 936.991\n",
      "Training Epoch 93  33.0% | batch:        31 of        94\t|\tloss: 857.895\n",
      "Training Epoch 93  34.0% | batch:        32 of        94\t|\tloss: 820.146\n",
      "Training Epoch 93  35.1% | batch:        33 of        94\t|\tloss: 575.942\n",
      "Training Epoch 93  36.2% | batch:        34 of        94\t|\tloss: 1086.43\n",
      "Training Epoch 93  37.2% | batch:        35 of        94\t|\tloss: 682.829\n",
      "Training Epoch 93  38.3% | batch:        36 of        94\t|\tloss: 625.972\n",
      "Training Epoch 93  39.4% | batch:        37 of        94\t|\tloss: 862.028\n",
      "Training Epoch 93  40.4% | batch:        38 of        94\t|\tloss: 902.324\n",
      "Training Epoch 93  41.5% | batch:        39 of        94\t|\tloss: 1281.65\n",
      "Training Epoch 93  42.6% | batch:        40 of        94\t|\tloss: 1049.95\n",
      "Training Epoch 93  43.6% | batch:        41 of        94\t|\tloss: 1253.34\n",
      "Training Epoch 93  44.7% | batch:        42 of        94\t|\tloss: 678.593\n",
      "Training Epoch 93  45.7% | batch:        43 of        94\t|\tloss: 1368.77\n",
      "Training Epoch 93  46.8% | batch:        44 of        94\t|\tloss: 869.898\n",
      "Training Epoch 93  47.9% | batch:        45 of        94\t|\tloss: 1062.95\n",
      "Training Epoch 93  48.9% | batch:        46 of        94\t|\tloss: 876.998\n",
      "Training Epoch 93  50.0% | batch:        47 of        94\t|\tloss: 909.408\n",
      "Training Epoch 93  51.1% | batch:        48 of        94\t|\tloss: 1491.27\n",
      "Training Epoch 93  52.1% | batch:        49 of        94\t|\tloss: 1069.85\n",
      "Training Epoch 93  53.2% | batch:        50 of        94\t|\tloss: 643.179\n",
      "Training Epoch 93  54.3% | batch:        51 of        94\t|\tloss: 1059\n",
      "Training Epoch 93  55.3% | batch:        52 of        94\t|\tloss: 627.786\n",
      "Training Epoch 93  56.4% | batch:        53 of        94\t|\tloss: 557.869\n",
      "Training Epoch 93  57.4% | batch:        54 of        94\t|\tloss: 594.2\n",
      "Training Epoch 93  58.5% | batch:        55 of        94\t|\tloss: 902.677\n",
      "Training Epoch 93  59.6% | batch:        56 of        94\t|\tloss: 970.129\n",
      "Training Epoch 93  60.6% | batch:        57 of        94\t|\tloss: 771.651\n",
      "Training Epoch 93  61.7% | batch:        58 of        94\t|\tloss: 1617.71\n",
      "Training Epoch 93  62.8% | batch:        59 of        94\t|\tloss: 1168.8\n",
      "Training Epoch 93  63.8% | batch:        60 of        94\t|\tloss: 769.634\n",
      "Training Epoch 93  64.9% | batch:        61 of        94\t|\tloss: 1266.73\n",
      "Training Epoch 93  66.0% | batch:        62 of        94\t|\tloss: 646.397\n",
      "Training Epoch 93  67.0% | batch:        63 of        94\t|\tloss: 793.482\n",
      "Training Epoch 93  68.1% | batch:        64 of        94\t|\tloss: 789.625\n",
      "Training Epoch 93  69.1% | batch:        65 of        94\t|\tloss: 906.258\n",
      "Training Epoch 93  70.2% | batch:        66 of        94\t|\tloss: 785.793\n",
      "Training Epoch 93  71.3% | batch:        67 of        94\t|\tloss: 1173.01\n",
      "Training Epoch 93  72.3% | batch:        68 of        94\t|\tloss: 1343.42\n",
      "Training Epoch 93  73.4% | batch:        69 of        94\t|\tloss: 996.139\n",
      "Training Epoch 93  74.5% | batch:        70 of        94\t|\tloss: 853.216\n",
      "Training Epoch 93  75.5% | batch:        71 of        94\t|\tloss: 931.915\n",
      "Training Epoch 93  76.6% | batch:        72 of        94\t|\tloss: 648.754\n",
      "Training Epoch 93  77.7% | batch:        73 of        94\t|\tloss: 834.551\n",
      "Training Epoch 93  78.7% | batch:        74 of        94\t|\tloss: 789.275\n",
      "Training Epoch 93  79.8% | batch:        75 of        94\t|\tloss: 788.623\n",
      "Training Epoch 93  80.9% | batch:        76 of        94\t|\tloss: 1142.59\n",
      "Training Epoch 93  81.9% | batch:        77 of        94\t|\tloss: 779.781\n",
      "Training Epoch 93  83.0% | batch:        78 of        94\t|\tloss: 1256.62\n",
      "Training Epoch 93  84.0% | batch:        79 of        94\t|\tloss: 930.677\n",
      "Training Epoch 93  85.1% | batch:        80 of        94\t|\tloss: 2690.84\n",
      "Training Epoch 93  86.2% | batch:        81 of        94\t|\tloss: 1495.7\n",
      "Training Epoch 93  87.2% | batch:        82 of        94\t|\tloss: 715.784\n",
      "Training Epoch 93  88.3% | batch:        83 of        94\t|\tloss: 870.923\n",
      "Training Epoch 93  89.4% | batch:        84 of        94\t|\tloss: 715.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:31,125 | INFO : Epoch 93 Training Summary: epoch: 93.000000 | loss: 960.350651 | \n",
      "2023-05-09 14:23:31,126 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7293710708618164 seconds\n",
      "\n",
      "2023-05-09 14:23:31,127 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8286069823849587 seconds\n",
      "2023-05-09 14:23:31,127 | INFO : Avg batch train. time: 0.01945326577005275 seconds\n",
      "2023-05-09 14:23:31,128 | INFO : Avg sample train. time: 0.0001534323697252021 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 93  90.4% | batch:        85 of        94\t|\tloss: 557.004\n",
      "Training Epoch 93  91.5% | batch:        86 of        94\t|\tloss: 800.24\n",
      "Training Epoch 93  92.6% | batch:        87 of        94\t|\tloss: 838.599\n",
      "Training Epoch 93  93.6% | batch:        88 of        94\t|\tloss: 955.63\n",
      "Training Epoch 93  94.7% | batch:        89 of        94\t|\tloss: 797.497\n",
      "Training Epoch 93  95.7% | batch:        90 of        94\t|\tloss: 1338.99\n",
      "Training Epoch 93  96.8% | batch:        91 of        94\t|\tloss: 1738.41\n",
      "Training Epoch 93  97.9% | batch:        92 of        94\t|\tloss: 645.755\n",
      "Training Epoch 93  98.9% | batch:        93 of        94\t|\tloss: 4120.6\n",
      "\n",
      "Training Epoch 94   0.0% | batch:         0 of        94\t|\tloss: 670.459\n",
      "Training Epoch 94   1.1% | batch:         1 of        94\t|\tloss: 600.735\n",
      "Training Epoch 94   2.1% | batch:         2 of        94\t|\tloss: 1586.68\n",
      "Training Epoch 94   3.2% | batch:         3 of        94\t|\tloss: 1081.06\n",
      "Training Epoch 94   4.3% | batch:         4 of        94\t|\tloss: 559.786\n",
      "Training Epoch 94   5.3% | batch:         5 of        94\t|\tloss: 831.258\n",
      "Training Epoch 94   6.4% | batch:         6 of        94\t|\tloss: 1411.71\n",
      "Training Epoch 94   7.4% | batch:         7 of        94\t|\tloss: 856.049\n",
      "Training Epoch 94   8.5% | batch:         8 of        94\t|\tloss: 511.139\n",
      "Training Epoch 94   9.6% | batch:         9 of        94\t|\tloss: 982.478\n",
      "Training Epoch 94  10.6% | batch:        10 of        94\t|\tloss: 1026.75\n",
      "Training Epoch 94  11.7% | batch:        11 of        94\t|\tloss: 768.031\n",
      "Training Epoch 94  12.8% | batch:        12 of        94\t|\tloss: 850.148\n",
      "Training Epoch 94  13.8% | batch:        13 of        94\t|\tloss: 722.91\n",
      "Training Epoch 94  14.9% | batch:        14 of        94\t|\tloss: 957.627\n",
      "Training Epoch 94  16.0% | batch:        15 of        94\t|\tloss: 850.114\n",
      "Training Epoch 94  17.0% | batch:        16 of        94\t|\tloss: 652.086\n",
      "Training Epoch 94  18.1% | batch:        17 of        94\t|\tloss: 1183.04\n",
      "Training Epoch 94  19.1% | batch:        18 of        94\t|\tloss: 806.9\n",
      "Training Epoch 94  20.2% | batch:        19 of        94\t|\tloss: 1306.09\n",
      "Training Epoch 94  21.3% | batch:        20 of        94\t|\tloss: 686.87\n",
      "Training Epoch 94  22.3% | batch:        21 of        94\t|\tloss: 743.861\n",
      "Training Epoch 94  23.4% | batch:        22 of        94\t|\tloss: 928.401\n",
      "Training Epoch 94  24.5% | batch:        23 of        94\t|\tloss: 625.322\n",
      "Training Epoch 94  25.5% | batch:        24 of        94\t|\tloss: 924.038\n",
      "Training Epoch 94  26.6% | batch:        25 of        94\t|\tloss: 663.196\n",
      "Training Epoch 94  27.7% | batch:        26 of        94\t|\tloss: 692.148\n",
      "Training Epoch 94  28.7% | batch:        27 of        94\t|\tloss: 959.673\n",
      "Training Epoch 94  29.8% | batch:        28 of        94\t|\tloss: 662.354\n",
      "Training Epoch 94  30.9% | batch:        29 of        94\t|\tloss: 631.836\n",
      "Training Epoch 94  31.9% | batch:        30 of        94\t|\tloss: 693.245\n",
      "Training Epoch 94  33.0% | batch:        31 of        94\t|\tloss: 550.17\n",
      "Training Epoch 94  34.0% | batch:        32 of        94\t|\tloss: 1507.2\n",
      "Training Epoch 94  35.1% | batch:        33 of        94\t|\tloss: 1142.76\n",
      "Training Epoch 94  36.2% | batch:        34 of        94\t|\tloss: 926.544\n",
      "Training Epoch 94  37.2% | batch:        35 of        94\t|\tloss: 918.161\n",
      "Training Epoch 94  38.3% | batch:        36 of        94\t|\tloss: 758.312\n",
      "Training Epoch 94  39.4% | batch:        37 of        94\t|\tloss: 1326.53\n",
      "Training Epoch 94  40.4% | batch:        38 of        94\t|\tloss: 873.117\n",
      "Training Epoch 94  41.5% | batch:        39 of        94\t|\tloss: 1143.65\n",
      "Training Epoch 94  42.6% | batch:        40 of        94\t|\tloss: 967.294\n",
      "Training Epoch 94  43.6% | batch:        41 of        94\t|\tloss: 883.084\n",
      "Training Epoch 94  44.7% | batch:        42 of        94\t|\tloss: 795.842\n",
      "Training Epoch 94  45.7% | batch:        43 of        94\t|\tloss: 1417.95\n",
      "Training Epoch 94  46.8% | batch:        44 of        94\t|\tloss: 1271.98\n",
      "Training Epoch 94  47.9% | batch:        45 of        94\t|\tloss: 688.195\n",
      "Training Epoch 94  48.9% | batch:        46 of        94\t|\tloss: 603.481\n",
      "Training Epoch 94  50.0% | batch:        47 of        94\t|\tloss: 969.453\n",
      "Training Epoch 94  51.1% | batch:        48 of        94\t|\tloss: 755.733\n",
      "Training Epoch 94  52.1% | batch:        49 of        94\t|\tloss: 891.739\n",
      "Training Epoch 94  53.2% | batch:        50 of        94\t|\tloss: 863.552\n",
      "Training Epoch 94  54.3% | batch:        51 of        94\t|\tloss: 1052.44\n",
      "Training Epoch 94  55.3% | batch:        52 of        94\t|\tloss: 697.386\n",
      "Training Epoch 94  56.4% | batch:        53 of        94\t|\tloss: 743.048\n",
      "Training Epoch 94  57.4% | batch:        54 of        94\t|\tloss: 1032.92\n",
      "Training Epoch 94  58.5% | batch:        55 of        94\t|\tloss: 648.539\n",
      "Training Epoch 94  59.6% | batch:        56 of        94\t|\tloss: 962.904\n",
      "Training Epoch 94  60.6% | batch:        57 of        94\t|\tloss: 908.506\n",
      "Training Epoch 94  61.7% | batch:        58 of        94\t|\tloss: 1501.23\n",
      "Training Epoch 94  62.8% | batch:        59 of        94\t|\tloss: 898.198\n",
      "Training Epoch 94  63.8% | batch:        60 of        94\t|\tloss: 1931.24\n",
      "Training Epoch 94  64.9% | batch:        61 of        94\t|\tloss: 914.369\n",
      "Training Epoch 94  66.0% | batch:        62 of        94\t|\tloss: 990.763\n",
      "Training Epoch 94  67.0% | batch:        63 of        94\t|\tloss: 1141.84\n",
      "Training Epoch 94  68.1% | batch:        64 of        94\t|\tloss: 1207.33\n",
      "Training Epoch 94  69.1% | batch:        65 of        94\t|\tloss: 841.845\n",
      "Training Epoch 94  70.2% | batch:        66 of        94\t|\tloss: 999.669\n",
      "Training Epoch 94  71.3% | batch:        67 of        94\t|\tloss: 1244.11\n",
      "Training Epoch 94  72.3% | batch:        68 of        94\t|\tloss: 843.955\n",
      "Training Epoch 94  73.4% | batch:        69 of        94\t|\tloss: 1068\n",
      "Training Epoch 94  74.5% | batch:        70 of        94\t|\tloss: 647.921\n",
      "Training Epoch 94  75.5% | batch:        71 of        94\t|\tloss: 838.521\n",
      "Training Epoch 94  76.6% | batch:        72 of        94\t|\tloss: 709.549\n",
      "Training Epoch 94  77.7% | batch:        73 of        94\t|\tloss: 705.15\n",
      "Training Epoch 94  78.7% | batch:        74 of        94\t|\tloss: 1722.95\n",
      "Training Epoch 94  79.8% | batch:        75 of        94\t|\tloss: 674.156\n",
      "Training Epoch 94  80.9% | batch:        76 of        94\t|\tloss: 1120.6\n",
      "Training Epoch 94  81.9% | batch:        77 of        94\t|\tloss: 1141.6\n",
      "Training Epoch 94  83.0% | batch:        78 of        94\t|\tloss: 884.585\n",
      "Training Epoch 94  84.0% | batch:        79 of        94\t|\tloss: 1526.21\n",
      "Training Epoch 94  85.1% | batch:        80 of        94\t|\tloss: 928.231\n",
      "Training Epoch 94  86.2% | batch:        81 of        94\t|\tloss: 733.368\n",
      "Training Epoch 94  87.2% | batch:        82 of        94\t|\tloss: 725.824\n",
      "Training Epoch 94  88.3% | batch:        83 of        94\t|\tloss: 744.612\n",
      "Training Epoch 94  89.4% | batch:        84 of        94\t|\tloss: 1250\n",
      "Training Epoch 94  90.4% | batch:        85 of        94\t|\tloss: 772.441\n",
      "Training Epoch 94  91.5% | batch:        86 of        94\t|\tloss: 737.783\n",
      "Training Epoch 94  92.6% | batch:        87 of        94\t|\tloss: 1006.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:32,999 | INFO : Epoch 94 Training Summary: epoch: 94.000000 | loss: 920.987689 | \n",
      "2023-05-09 14:23:32,999 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8494889736175537 seconds\n",
      "\n",
      "2023-05-09 14:23:33,000 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8288291312278586 seconds\n",
      "2023-05-09 14:23:33,000 | INFO : Avg batch train. time: 0.019455629055615518 seconds\n",
      "2023-05-09 14:23:33,001 | INFO : Avg sample train. time: 0.0001534510095005755 seconds\n",
      "2023-05-09 14:23:33,001 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 94  93.6% | batch:        88 of        94\t|\tloss: 688.393\n",
      "Training Epoch 94  94.7% | batch:        89 of        94\t|\tloss: 742.394\n",
      "Training Epoch 94  95.7% | batch:        90 of        94\t|\tloss: 794.523\n",
      "Training Epoch 94  96.8% | batch:        91 of        94\t|\tloss: 574.629\n",
      "Training Epoch 94  97.9% | batch:        92 of        94\t|\tloss: 615.037\n",
      "Training Epoch 94  98.9% | batch:        93 of        94\t|\tloss: 1450.42\n",
      "\n",
      "Evaluating Epoch 94   0.0% | batch:         0 of        40\t|\tloss: 6924.53\n",
      "Evaluating Epoch 94   2.5% | batch:         1 of        40\t|\tloss: 1390.38\n",
      "Evaluating Epoch 94   5.0% | batch:         2 of        40\t|\tloss: 3553.57\n",
      "Evaluating Epoch 94   7.5% | batch:         3 of        40\t|\tloss: 6972.05\n",
      "Evaluating Epoch 94  10.0% | batch:         4 of        40\t|\tloss: 3025.73\n",
      "Evaluating Epoch 94  12.5% | batch:         5 of        40\t|\tloss: 2463.71\n",
      "Evaluating Epoch 94  15.0% | batch:         6 of        40\t|\tloss: 9621.8\n",
      "Evaluating Epoch 94  17.5% | batch:         7 of        40\t|\tloss: 3588.19\n",
      "Evaluating Epoch 94  20.0% | batch:         8 of        40\t|\tloss: 3031.23\n",
      "Evaluating Epoch 94  22.5% | batch:         9 of        40\t|\tloss: 2041.05\n",
      "Evaluating Epoch 94  25.0% | batch:        10 of        40\t|\tloss: 5635.06\n",
      "Evaluating Epoch 94  27.5% | batch:        11 of        40\t|\tloss: 1462.83\n",
      "Evaluating Epoch 94  30.0% | batch:        12 of        40\t|\tloss: 5932.09\n",
      "Evaluating Epoch 94  32.5% | batch:        13 of        40\t|\tloss: 3616.31\n",
      "Evaluating Epoch 94  35.0% | batch:        14 of        40\t|\tloss: 2508.66\n",
      "Evaluating Epoch 94  37.5% | batch:        15 of        40\t|\tloss: 3278.48\n",
      "Evaluating Epoch 94  40.0% | batch:        16 of        40\t|\tloss: 3953.38\n",
      "Evaluating Epoch 94  42.5% | batch:        17 of        40\t|\tloss: 3634.34\n",
      "Evaluating Epoch 94  45.0% | batch:        18 of        40\t|\tloss: 2791.83\n",
      "Evaluating Epoch 94  47.5% | batch:        19 of        40\t|\tloss: 4821.87\n",
      "Evaluating Epoch 94  50.0% | batch:        20 of        40\t|\tloss: 5927.23\n",
      "Evaluating Epoch 94  52.5% | batch:        21 of        40\t|\tloss: 1211.8\n",
      "Evaluating Epoch 94  55.0% | batch:        22 of        40\t|\tloss: 3743.84\n",
      "Evaluating Epoch 94  57.5% | batch:        23 of        40\t|\tloss: 3583.23\n",
      "Evaluating Epoch 94  60.0% | batch:        24 of        40\t|\tloss: 1966.89\n",
      "Evaluating Epoch 94  62.5% | batch:        25 of        40\t|\tloss: 3293.5\n",
      "Evaluating Epoch 94  65.0% | batch:        26 of        40\t|\tloss: 9480.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:33,463 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.46088743209838867 seconds\n",
      "\n",
      "2023-05-09 14:23:33,463 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4713509569362718 seconds\n",
      "2023-05-09 14:23:33,464 | INFO : Avg batch val. time: 0.011783773923406796 seconds\n",
      "2023-05-09 14:23:33,464 | INFO : Avg sample val. time: 9.337380287961011e-05 seconds\n",
      "2023-05-09 14:23:33,465 | INFO : Epoch 94 Validation Summary: epoch: 94.000000 | loss: 4155.700299 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 94  67.5% | batch:        27 of        40\t|\tloss: 3383.75\n",
      "Evaluating Epoch 94  70.0% | batch:        28 of        40\t|\tloss: 1999.05\n",
      "Evaluating Epoch 94  72.5% | batch:        29 of        40\t|\tloss: 8778.28\n",
      "Evaluating Epoch 94  75.0% | batch:        30 of        40\t|\tloss: 2275.69\n",
      "Evaluating Epoch 94  77.5% | batch:        31 of        40\t|\tloss: 1834.33\n",
      "Evaluating Epoch 94  80.0% | batch:        32 of        40\t|\tloss: 7176.44\n",
      "Evaluating Epoch 94  82.5% | batch:        33 of        40\t|\tloss: 6412.43\n",
      "Evaluating Epoch 94  85.0% | batch:        34 of        40\t|\tloss: 1156.68\n",
      "Evaluating Epoch 94  87.5% | batch:        35 of        40\t|\tloss: 4954.11\n",
      "Evaluating Epoch 94  90.0% | batch:        36 of        40\t|\tloss: 5757.9\n",
      "Evaluating Epoch 94  92.5% | batch:        37 of        40\t|\tloss: 2915.69\n",
      "Evaluating Epoch 94  95.0% | batch:        38 of        40\t|\tloss: 3291.34\n",
      "Evaluating Epoch 94  97.5% | batch:        39 of        40\t|\tloss: 10286.5\n",
      "\n",
      "Training Epoch 95   0.0% | batch:         0 of        94\t|\tloss: 768.957\n",
      "Training Epoch 95   1.1% | batch:         1 of        94\t|\tloss: 1460.16\n",
      "Training Epoch 95   2.1% | batch:         2 of        94\t|\tloss: 1186.28\n",
      "Training Epoch 95   3.2% | batch:         3 of        94\t|\tloss: 689.466\n",
      "Training Epoch 95   4.3% | batch:         4 of        94\t|\tloss: 850.449\n",
      "Training Epoch 95   5.3% | batch:         5 of        94\t|\tloss: 752.68\n",
      "Training Epoch 95   6.4% | batch:         6 of        94\t|\tloss: 588.291\n",
      "Training Epoch 95   7.4% | batch:         7 of        94\t|\tloss: 615.089\n",
      "Training Epoch 95   8.5% | batch:         8 of        94\t|\tloss: 950.57\n",
      "Training Epoch 95   9.6% | batch:         9 of        94\t|\tloss: 828.237\n",
      "Training Epoch 95  10.6% | batch:        10 of        94\t|\tloss: 693.578\n",
      "Training Epoch 95  11.7% | batch:        11 of        94\t|\tloss: 620.313\n",
      "Training Epoch 95  12.8% | batch:        12 of        94\t|\tloss: 616.569\n",
      "Training Epoch 95  13.8% | batch:        13 of        94\t|\tloss: 537.555\n",
      "Training Epoch 95  14.9% | batch:        14 of        94\t|\tloss: 1092.91\n",
      "Training Epoch 95  16.0% | batch:        15 of        94\t|\tloss: 1189.34\n",
      "Training Epoch 95  17.0% | batch:        16 of        94\t|\tloss: 845.3\n",
      "Training Epoch 95  18.1% | batch:        17 of        94\t|\tloss: 457.446\n",
      "Training Epoch 95  19.1% | batch:        18 of        94\t|\tloss: 685.796\n",
      "Training Epoch 95  20.2% | batch:        19 of        94\t|\tloss: 1661.57\n",
      "Training Epoch 95  21.3% | batch:        20 of        94\t|\tloss: 852.574\n",
      "Training Epoch 95  22.3% | batch:        21 of        94\t|\tloss: 869.91\n",
      "Training Epoch 95  23.4% | batch:        22 of        94\t|\tloss: 580.68\n",
      "Training Epoch 95  24.5% | batch:        23 of        94\t|\tloss: 857.292\n",
      "Training Epoch 95  25.5% | batch:        24 of        94\t|\tloss: 757.372\n",
      "Training Epoch 95  26.6% | batch:        25 of        94\t|\tloss: 1123.38\n",
      "Training Epoch 95  27.7% | batch:        26 of        94\t|\tloss: 785.471\n",
      "Training Epoch 95  28.7% | batch:        27 of        94\t|\tloss: 1413.37\n",
      "Training Epoch 95  29.8% | batch:        28 of        94\t|\tloss: 1230.38\n",
      "Training Epoch 95  30.9% | batch:        29 of        94\t|\tloss: 988.687\n",
      "Training Epoch 95  31.9% | batch:        30 of        94\t|\tloss: 1177.89\n",
      "Training Epoch 95  33.0% | batch:        31 of        94\t|\tloss: 798.96\n",
      "Training Epoch 95  34.0% | batch:        32 of        94\t|\tloss: 809.45\n",
      "Training Epoch 95  35.1% | batch:        33 of        94\t|\tloss: 1883.25\n",
      "Training Epoch 95  36.2% | batch:        34 of        94\t|\tloss: 1291.61\n",
      "Training Epoch 95  37.2% | batch:        35 of        94\t|\tloss: 1240.64\n",
      "Training Epoch 95  38.3% | batch:        36 of        94\t|\tloss: 1011.25\n",
      "Training Epoch 95  39.4% | batch:        37 of        94\t|\tloss: 652.308\n",
      "Training Epoch 95  40.4% | batch:        38 of        94\t|\tloss: 658.577\n",
      "Training Epoch 95  41.5% | batch:        39 of        94\t|\tloss: 775.559\n",
      "Training Epoch 95  42.6% | batch:        40 of        94\t|\tloss: 1091.62\n",
      "Training Epoch 95  43.6% | batch:        41 of        94\t|\tloss: 984.169\n",
      "Training Epoch 95  44.7% | batch:        42 of        94\t|\tloss: 1019.83\n",
      "Training Epoch 95  45.7% | batch:        43 of        94\t|\tloss: 813.927\n",
      "Training Epoch 95  46.8% | batch:        44 of        94\t|\tloss: 1002.62\n",
      "Training Epoch 95  47.9% | batch:        45 of        94\t|\tloss: 1422.29\n",
      "Training Epoch 95  48.9% | batch:        46 of        94\t|\tloss: 1132.2\n",
      "Training Epoch 95  50.0% | batch:        47 of        94\t|\tloss: 600.71\n",
      "Training Epoch 95  51.1% | batch:        48 of        94\t|\tloss: 965.431\n",
      "Training Epoch 95  52.1% | batch:        49 of        94\t|\tloss: 978.065\n",
      "Training Epoch 95  53.2% | batch:        50 of        94\t|\tloss: 766.448\n",
      "Training Epoch 95  54.3% | batch:        51 of        94\t|\tloss: 713.917\n",
      "Training Epoch 95  55.3% | batch:        52 of        94\t|\tloss: 692.502\n",
      "Training Epoch 95  56.4% | batch:        53 of        94\t|\tloss: 1276.54\n",
      "Training Epoch 95  57.4% | batch:        54 of        94\t|\tloss: 949.35\n",
      "Training Epoch 95  58.5% | batch:        55 of        94\t|\tloss: 777.042\n",
      "Training Epoch 95  59.6% | batch:        56 of        94\t|\tloss: 930.555\n",
      "Training Epoch 95  60.6% | batch:        57 of        94\t|\tloss: 592.591\n",
      "Training Epoch 95  61.7% | batch:        58 of        94\t|\tloss: 729.274\n",
      "Training Epoch 95  62.8% | batch:        59 of        94\t|\tloss: 1474.72\n",
      "Training Epoch 95  63.8% | batch:        60 of        94\t|\tloss: 654.91\n",
      "Training Epoch 95  64.9% | batch:        61 of        94\t|\tloss: 861.707\n",
      "Training Epoch 95  66.0% | batch:        62 of        94\t|\tloss: 834.727\n",
      "Training Epoch 95  67.0% | batch:        63 of        94\t|\tloss: 912.034\n",
      "Training Epoch 95  68.1% | batch:        64 of        94\t|\tloss: 752.366\n",
      "Training Epoch 95  69.1% | batch:        65 of        94\t|\tloss: 911.5\n",
      "Training Epoch 95  70.2% | batch:        66 of        94\t|\tloss: 823.615\n",
      "Training Epoch 95  71.3% | batch:        67 of        94\t|\tloss: 924.35\n",
      "Training Epoch 95  72.3% | batch:        68 of        94\t|\tloss: 854.464\n",
      "Training Epoch 95  73.4% | batch:        69 of        94\t|\tloss: 637.894\n",
      "Training Epoch 95  74.5% | batch:        70 of        94\t|\tloss: 1319.77\n",
      "Training Epoch 95  75.5% | batch:        71 of        94\t|\tloss: 686.039\n",
      "Training Epoch 95  76.6% | batch:        72 of        94\t|\tloss: 1154.97\n",
      "Training Epoch 95  77.7% | batch:        73 of        94\t|\tloss: 863.243\n",
      "Training Epoch 95  78.7% | batch:        74 of        94\t|\tloss: 769.199\n",
      "Training Epoch 95  79.8% | batch:        75 of        94\t|\tloss: 1494.44\n",
      "Training Epoch 95  80.9% | batch:        76 of        94\t|\tloss: 1638.45\n",
      "Training Epoch 95  81.9% | batch:        77 of        94\t|\tloss: 620.813\n",
      "Training Epoch 95  83.0% | batch:        78 of        94\t|\tloss: 816.452\n",
      "Training Epoch 95  84.0% | batch:        79 of        94\t|\tloss: 833.812\n",
      "Training Epoch 95  85.1% | batch:        80 of        94\t|\tloss: 894.627\n",
      "Training Epoch 95  86.2% | batch:        81 of        94\t|\tloss: 614.09\n",
      "Training Epoch 95  87.2% | batch:        82 of        94\t|\tloss: 1038.12\n",
      "Training Epoch 95  88.3% | batch:        83 of        94\t|\tloss: 796.642\n",
      "Training Epoch 95  89.4% | batch:        84 of        94\t|\tloss: 655.605\n",
      "Training Epoch 95  90.4% | batch:        85 of        94\t|\tloss: 1574\n",
      "Training Epoch 95  91.5% | batch:        86 of        94\t|\tloss: 678.659\n",
      "Training Epoch 95  92.6% | batch:        87 of        94\t|\tloss: 660.865\n",
      "Training Epoch 95  93.6% | batch:        88 of        94\t|\tloss: 642.626\n",
      "Training Epoch 95  94.7% | batch:        89 of        94\t|\tloss: 841.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:35,322 | INFO : Epoch 95 Training Summary: epoch: 95.000000 | loss: 919.491126 | \n",
      "2023-05-09 14:23:35,322 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8359644412994385 seconds\n",
      "\n",
      "2023-05-09 14:23:35,323 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8289042397549278 seconds\n",
      "2023-05-09 14:23:35,323 | INFO : Avg batch train. time: 0.01945642808249923 seconds\n",
      "2023-05-09 14:23:35,324 | INFO : Avg sample train. time: 0.00015345731160890482 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 95  95.7% | batch:        90 of        94\t|\tloss: 677.715\n",
      "Training Epoch 95  96.8% | batch:        91 of        94\t|\tloss: 1176.69\n",
      "Training Epoch 95  97.9% | batch:        92 of        94\t|\tloss: 1179.69\n",
      "Training Epoch 95  98.9% | batch:        93 of        94\t|\tloss: 498.773\n",
      "\n",
      "Training Epoch 96   0.0% | batch:         0 of        94\t|\tloss: 766.588\n",
      "Training Epoch 96   1.1% | batch:         1 of        94\t|\tloss: 586.288\n",
      "Training Epoch 96   2.1% | batch:         2 of        94\t|\tloss: 717.317\n",
      "Training Epoch 96   3.2% | batch:         3 of        94\t|\tloss: 518.39\n",
      "Training Epoch 96   4.3% | batch:         4 of        94\t|\tloss: 1155.14\n",
      "Training Epoch 96   5.3% | batch:         5 of        94\t|\tloss: 905.811\n",
      "Training Epoch 96   6.4% | batch:         6 of        94\t|\tloss: 757.471\n",
      "Training Epoch 96   7.4% | batch:         7 of        94\t|\tloss: 693.306\n",
      "Training Epoch 96   8.5% | batch:         8 of        94\t|\tloss: 677.175\n",
      "Training Epoch 96   9.6% | batch:         9 of        94\t|\tloss: 827.834\n",
      "Training Epoch 96  10.6% | batch:        10 of        94\t|\tloss: 837.73\n",
      "Training Epoch 96  11.7% | batch:        11 of        94\t|\tloss: 604.464\n",
      "Training Epoch 96  12.8% | batch:        12 of        94\t|\tloss: 653.216\n",
      "Training Epoch 96  13.8% | batch:        13 of        94\t|\tloss: 698.744\n",
      "Training Epoch 96  14.9% | batch:        14 of        94\t|\tloss: 629.311\n",
      "Training Epoch 96  16.0% | batch:        15 of        94\t|\tloss: 774.199\n",
      "Training Epoch 96  17.0% | batch:        16 of        94\t|\tloss: 768.457\n",
      "Training Epoch 96  18.1% | batch:        17 of        94\t|\tloss: 745.042\n",
      "Training Epoch 96  19.1% | batch:        18 of        94\t|\tloss: 628.851\n",
      "Training Epoch 96  20.2% | batch:        19 of        94\t|\tloss: 1033.32\n",
      "Training Epoch 96  21.3% | batch:        20 of        94\t|\tloss: 640.103\n",
      "Training Epoch 96  22.3% | batch:        21 of        94\t|\tloss: 633.287\n",
      "Training Epoch 96  23.4% | batch:        22 of        94\t|\tloss: 1058.46\n",
      "Training Epoch 96  24.5% | batch:        23 of        94\t|\tloss: 1093.71\n",
      "Training Epoch 96  25.5% | batch:        24 of        94\t|\tloss: 486.154\n",
      "Training Epoch 96  26.6% | batch:        25 of        94\t|\tloss: 726.823\n",
      "Training Epoch 96  27.7% | batch:        26 of        94\t|\tloss: 647.024\n",
      "Training Epoch 96  28.7% | batch:        27 of        94\t|\tloss: 777.327\n",
      "Training Epoch 96  29.8% | batch:        28 of        94\t|\tloss: 1020.83\n",
      "Training Epoch 96  30.9% | batch:        29 of        94\t|\tloss: 1104.2\n",
      "Training Epoch 96  31.9% | batch:        30 of        94\t|\tloss: 581.051\n",
      "Training Epoch 96  33.0% | batch:        31 of        94\t|\tloss: 1044.38\n",
      "Training Epoch 96  34.0% | batch:        32 of        94\t|\tloss: 1149.62\n",
      "Training Epoch 96  35.1% | batch:        33 of        94\t|\tloss: 836.062\n",
      "Training Epoch 96  36.2% | batch:        34 of        94\t|\tloss: 974.46\n",
      "Training Epoch 96  37.2% | batch:        35 of        94\t|\tloss: 707.178\n",
      "Training Epoch 96  38.3% | batch:        36 of        94\t|\tloss: 905.77\n",
      "Training Epoch 96  39.4% | batch:        37 of        94\t|\tloss: 1278.37\n",
      "Training Epoch 96  40.4% | batch:        38 of        94\t|\tloss: 774.791\n",
      "Training Epoch 96  41.5% | batch:        39 of        94\t|\tloss: 802.264\n",
      "Training Epoch 96  42.6% | batch:        40 of        94\t|\tloss: 962.283\n",
      "Training Epoch 96  43.6% | batch:        41 of        94\t|\tloss: 695.171\n",
      "Training Epoch 96  44.7% | batch:        42 of        94\t|\tloss: 654.408\n",
      "Training Epoch 96  45.7% | batch:        43 of        94\t|\tloss: 814.895\n",
      "Training Epoch 96  46.8% | batch:        44 of        94\t|\tloss: 2993.25\n",
      "Training Epoch 96  47.9% | batch:        45 of        94\t|\tloss: 1044.09\n",
      "Training Epoch 96  48.9% | batch:        46 of        94\t|\tloss: 689.004\n",
      "Training Epoch 96  50.0% | batch:        47 of        94\t|\tloss: 737.904\n",
      "Training Epoch 96  51.1% | batch:        48 of        94\t|\tloss: 761.428\n",
      "Training Epoch 96  52.1% | batch:        49 of        94\t|\tloss: 649.379\n",
      "Training Epoch 96  53.2% | batch:        50 of        94\t|\tloss: 1272.48\n",
      "Training Epoch 96  54.3% | batch:        51 of        94\t|\tloss: 1040.03\n",
      "Training Epoch 96  55.3% | batch:        52 of        94\t|\tloss: 859.951\n",
      "Training Epoch 96  56.4% | batch:        53 of        94\t|\tloss: 1029.01\n",
      "Training Epoch 96  57.4% | batch:        54 of        94\t|\tloss: 1573.18\n",
      "Training Epoch 96  58.5% | batch:        55 of        94\t|\tloss: 724.275\n",
      "Training Epoch 96  59.6% | batch:        56 of        94\t|\tloss: 979.21\n",
      "Training Epoch 96  60.6% | batch:        57 of        94\t|\tloss: 789.592\n",
      "Training Epoch 96  61.7% | batch:        58 of        94\t|\tloss: 1077.22\n",
      "Training Epoch 96  62.8% | batch:        59 of        94\t|\tloss: 1357.29\n",
      "Training Epoch 96  63.8% | batch:        60 of        94\t|\tloss: 1238.39\n",
      "Training Epoch 96  64.9% | batch:        61 of        94\t|\tloss: 733.428\n",
      "Training Epoch 96  66.0% | batch:        62 of        94\t|\tloss: 764.501\n",
      "Training Epoch 96  67.0% | batch:        63 of        94\t|\tloss: 809.122\n",
      "Training Epoch 96  68.1% | batch:        64 of        94\t|\tloss: 1053.17\n",
      "Training Epoch 96  69.1% | batch:        65 of        94\t|\tloss: 1007.09\n",
      "Training Epoch 96  70.2% | batch:        66 of        94\t|\tloss: 709.184\n",
      "Training Epoch 96  71.3% | batch:        67 of        94\t|\tloss: 991.039\n",
      "Training Epoch 96  72.3% | batch:        68 of        94\t|\tloss: 1104.89\n",
      "Training Epoch 96  73.4% | batch:        69 of        94\t|\tloss: 898.245\n",
      "Training Epoch 96  74.5% | batch:        70 of        94\t|\tloss: 731.125\n",
      "Training Epoch 96  75.5% | batch:        71 of        94\t|\tloss: 1091.42\n",
      "Training Epoch 96  76.6% | batch:        72 of        94\t|\tloss: 739.302\n",
      "Training Epoch 96  77.7% | batch:        73 of        94\t|\tloss: 1231.56\n",
      "Training Epoch 96  78.7% | batch:        74 of        94\t|\tloss: 847.189\n",
      "Training Epoch 96  79.8% | batch:        75 of        94\t|\tloss: 979.75\n",
      "Training Epoch 96  80.9% | batch:        76 of        94\t|\tloss: 2341.17\n",
      "Training Epoch 96  81.9% | batch:        77 of        94\t|\tloss: 972.793\n",
      "Training Epoch 96  83.0% | batch:        78 of        94\t|\tloss: 1461.61\n",
      "Training Epoch 96  84.0% | batch:        79 of        94\t|\tloss: 1051.13\n",
      "Training Epoch 96  85.1% | batch:        80 of        94\t|\tloss: 862.507\n",
      "Training Epoch 96  86.2% | batch:        81 of        94\t|\tloss: 693.596\n",
      "Training Epoch 96  87.2% | batch:        82 of        94\t|\tloss: 1367.48\n",
      "Training Epoch 96  88.3% | batch:        83 of        94\t|\tloss: 429.346\n",
      "Training Epoch 96  89.4% | batch:        84 of        94\t|\tloss: 790.937\n",
      "Training Epoch 96  90.4% | batch:        85 of        94\t|\tloss: 843.947\n",
      "Training Epoch 96  91.5% | batch:        86 of        94\t|\tloss: 1440.73\n",
      "Training Epoch 96  92.6% | batch:        87 of        94\t|\tloss: 1172.35\n",
      "Training Epoch 96  93.6% | batch:        88 of        94\t|\tloss: 1026.16\n",
      "Training Epoch 96  94.7% | batch:        89 of        94\t|\tloss: 796.085\n",
      "Training Epoch 96  95.7% | batch:        90 of        94\t|\tloss: 948.124\n",
      "Training Epoch 96  96.8% | batch:        91 of        94\t|\tloss: 750.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:37,237 | INFO : Epoch 96 Training Summary: epoch: 96.000000 | loss: 921.825682 | \n",
      "2023-05-09 14:23:37,238 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8927690982818604 seconds\n",
      "\n",
      "2023-05-09 14:23:37,238 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8295694986979167 seconds\n",
      "2023-05-09 14:23:37,239 | INFO : Avg batch train. time: 0.019463505305296988 seconds\n",
      "2023-05-09 14:23:37,239 | INFO : Avg sample train. time: 0.00015351313128863204 seconds\n",
      "2023-05-09 14:23:37,240 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 96  97.9% | batch:        92 of        94\t|\tloss: 656.633\n",
      "Training Epoch 96  98.9% | batch:        93 of        94\t|\tloss: 3400.83\n",
      "\n",
      "Evaluating Epoch 96   0.0% | batch:         0 of        40\t|\tloss: 7542.56\n",
      "Evaluating Epoch 96   2.5% | batch:         1 of        40\t|\tloss: 1223.27\n",
      "Evaluating Epoch 96   5.0% | batch:         2 of        40\t|\tloss: 3860.35\n",
      "Evaluating Epoch 96   7.5% | batch:         3 of        40\t|\tloss: 7581.48\n",
      "Evaluating Epoch 96  10.0% | batch:         4 of        40\t|\tloss: 2329.03\n",
      "Evaluating Epoch 96  12.5% | batch:         5 of        40\t|\tloss: 2630.97\n",
      "Evaluating Epoch 96  15.0% | batch:         6 of        40\t|\tloss: 9992.53\n",
      "Evaluating Epoch 96  17.5% | batch:         7 of        40\t|\tloss: 3053.54\n",
      "Evaluating Epoch 96  20.0% | batch:         8 of        40\t|\tloss: 3170.68\n",
      "Evaluating Epoch 96  22.5% | batch:         9 of        40\t|\tloss: 2761.82\n",
      "Evaluating Epoch 96  25.0% | batch:        10 of        40\t|\tloss: 5333.94\n",
      "Evaluating Epoch 96  27.5% | batch:        11 of        40\t|\tloss: 1725\n",
      "Evaluating Epoch 96  30.0% | batch:        12 of        40\t|\tloss: 6496.7\n",
      "Evaluating Epoch 96  32.5% | batch:        13 of        40\t|\tloss: 3566.01\n",
      "Evaluating Epoch 96  35.0% | batch:        14 of        40\t|\tloss: 2113.39\n",
      "Evaluating Epoch 96  37.5% | batch:        15 of        40\t|\tloss: 3701.62\n",
      "Evaluating Epoch 96  40.0% | batch:        16 of        40\t|\tloss: 4304.47\n",
      "Evaluating Epoch 96  42.5% | batch:        17 of        40\t|\tloss: 3321.14\n",
      "Evaluating Epoch 96  45.0% | batch:        18 of        40\t|\tloss: 2528.98\n",
      "Evaluating Epoch 96  47.5% | batch:        19 of        40\t|\tloss: 7442.68\n",
      "Evaluating Epoch 96  50.0% | batch:        20 of        40\t|\tloss: 5862.32\n",
      "Evaluating Epoch 96  52.5% | batch:        21 of        40\t|\tloss: 1432.98\n",
      "Evaluating Epoch 96  55.0% | batch:        22 of        40\t|\tloss: 4622.83\n",
      "Evaluating Epoch 96  57.5% | batch:        23 of        40\t|\tloss: 3444.07\n",
      "Evaluating Epoch 96  60.0% | batch:        24 of        40\t|\tloss: 1709.17\n",
      "Evaluating Epoch 96  62.5% | batch:        25 of        40\t|\tloss: 4040.81\n",
      "Evaluating Epoch 96  65.0% | batch:        26 of        40\t|\tloss: 10768.7\n",
      "Evaluating Epoch 96  67.5% | batch:        27 of        40\t|\tloss: 2946.33\n",
      "Evaluating Epoch 96  70.0% | batch:        28 of        40\t|\tloss: 2244.43\n",
      "Evaluating Epoch 96  72.5% | batch:        29 of        40\t|\tloss: 10344.3\n",
      "Evaluating Epoch 96  75.0% | batch:        30 of        40\t|\tloss: 2049.83\n",
      "Evaluating Epoch 96  77.5% | batch:        31 of        40\t|\tloss: 1996.76\n",
      "Evaluating Epoch 96  80.0% | batch:        32 of        40\t|\tloss: 8757.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:37,711 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.47095465660095215 seconds\n",
      "\n",
      "2023-05-09 14:23:37,711 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4713430309295654 seconds\n",
      "2023-05-09 14:23:37,712 | INFO : Avg batch val. time: 0.011783575773239135 seconds\n",
      "2023-05-09 14:23:37,712 | INFO : Avg sample val. time: 9.33722327514987e-05 seconds\n",
      "2023-05-09 14:23:37,713 | INFO : Epoch 96 Validation Summary: epoch: 96.000000 | loss: 4492.118401 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 96  82.5% | batch:        33 of        40\t|\tloss: 6931.63\n",
      "Evaluating Epoch 96  85.0% | batch:        34 of        40\t|\tloss: 1038.38\n",
      "Evaluating Epoch 96  87.5% | batch:        35 of        40\t|\tloss: 6474.48\n",
      "Evaluating Epoch 96  90.0% | batch:        36 of        40\t|\tloss: 6125.51\n",
      "Evaluating Epoch 96  92.5% | batch:        37 of        40\t|\tloss: 2806.64\n",
      "Evaluating Epoch 96  95.0% | batch:        38 of        40\t|\tloss: 4114.35\n",
      "Evaluating Epoch 96  97.5% | batch:        39 of        40\t|\tloss: 10895.7\n",
      "\n",
      "Training Epoch 97   0.0% | batch:         0 of        94\t|\tloss: 606.108\n",
      "Training Epoch 97   1.1% | batch:         1 of        94\t|\tloss: 561.058\n",
      "Training Epoch 97   2.1% | batch:         2 of        94\t|\tloss: 933.418\n",
      "Training Epoch 97   3.2% | batch:         3 of        94\t|\tloss: 756.856\n",
      "Training Epoch 97   4.3% | batch:         4 of        94\t|\tloss: 804.648\n",
      "Training Epoch 97   5.3% | batch:         5 of        94\t|\tloss: 1123.1\n",
      "Training Epoch 97   6.4% | batch:         6 of        94\t|\tloss: 979.526\n",
      "Training Epoch 97   7.4% | batch:         7 of        94\t|\tloss: 990.226\n",
      "Training Epoch 97   8.5% | batch:         8 of        94\t|\tloss: 1019.28\n",
      "Training Epoch 97   9.6% | batch:         9 of        94\t|\tloss: 1444.82\n",
      "Training Epoch 97  10.6% | batch:        10 of        94\t|\tloss: 762.771\n",
      "Training Epoch 97  11.7% | batch:        11 of        94\t|\tloss: 956.563\n",
      "Training Epoch 97  12.8% | batch:        12 of        94\t|\tloss: 617.191\n",
      "Training Epoch 97  13.8% | batch:        13 of        94\t|\tloss: 780.094\n",
      "Training Epoch 97  14.9% | batch:        14 of        94\t|\tloss: 762.718\n",
      "Training Epoch 97  16.0% | batch:        15 of        94\t|\tloss: 708.616\n",
      "Training Epoch 97  17.0% | batch:        16 of        94\t|\tloss: 744.765\n",
      "Training Epoch 97  18.1% | batch:        17 of        94\t|\tloss: 748.702\n",
      "Training Epoch 97  19.1% | batch:        18 of        94\t|\tloss: 1460.46\n",
      "Training Epoch 97  20.2% | batch:        19 of        94\t|\tloss: 929.325\n",
      "Training Epoch 97  21.3% | batch:        20 of        94\t|\tloss: 849.746\n",
      "Training Epoch 97  22.3% | batch:        21 of        94\t|\tloss: 809.629\n",
      "Training Epoch 97  23.4% | batch:        22 of        94\t|\tloss: 1040.37\n",
      "Training Epoch 97  24.5% | batch:        23 of        94\t|\tloss: 707.585\n",
      "Training Epoch 97  25.5% | batch:        24 of        94\t|\tloss: 909.479\n",
      "Training Epoch 97  26.6% | batch:        25 of        94\t|\tloss: 1033.37\n",
      "Training Epoch 97  27.7% | batch:        26 of        94\t|\tloss: 978.521\n",
      "Training Epoch 97  28.7% | batch:        27 of        94\t|\tloss: 851.912\n",
      "Training Epoch 97  29.8% | batch:        28 of        94\t|\tloss: 1135.65\n",
      "Training Epoch 97  30.9% | batch:        29 of        94\t|\tloss: 630.515\n",
      "Training Epoch 97  31.9% | batch:        30 of        94\t|\tloss: 739.424\n",
      "Training Epoch 97  33.0% | batch:        31 of        94\t|\tloss: 687.245\n",
      "Training Epoch 97  34.0% | batch:        32 of        94\t|\tloss: 632.229\n",
      "Training Epoch 97  35.1% | batch:        33 of        94\t|\tloss: 517.165\n",
      "Training Epoch 97  36.2% | batch:        34 of        94\t|\tloss: 987.394\n",
      "Training Epoch 97  37.2% | batch:        35 of        94\t|\tloss: 547.725\n",
      "Training Epoch 97  38.3% | batch:        36 of        94\t|\tloss: 1270.02\n",
      "Training Epoch 97  39.4% | batch:        37 of        94\t|\tloss: 1074.75\n",
      "Training Epoch 97  40.4% | batch:        38 of        94\t|\tloss: 605.177\n",
      "Training Epoch 97  41.5% | batch:        39 of        94\t|\tloss: 671.158\n",
      "Training Epoch 97  42.6% | batch:        40 of        94\t|\tloss: 1183.03\n",
      "Training Epoch 97  43.6% | batch:        41 of        94\t|\tloss: 1255.47\n",
      "Training Epoch 97  44.7% | batch:        42 of        94\t|\tloss: 1480.42\n",
      "Training Epoch 97  45.7% | batch:        43 of        94\t|\tloss: 848.603\n",
      "Training Epoch 97  46.8% | batch:        44 of        94\t|\tloss: 646.16\n",
      "Training Epoch 97  47.9% | batch:        45 of        94\t|\tloss: 1275.72\n",
      "Training Epoch 97  48.9% | batch:        46 of        94\t|\tloss: 1155.89\n",
      "Training Epoch 97  50.0% | batch:        47 of        94\t|\tloss: 2338.45\n",
      "Training Epoch 97  51.1% | batch:        48 of        94\t|\tloss: 597.318\n",
      "Training Epoch 97  52.1% | batch:        49 of        94\t|\tloss: 553.509\n",
      "Training Epoch 97  53.2% | batch:        50 of        94\t|\tloss: 1072.22\n",
      "Training Epoch 97  54.3% | batch:        51 of        94\t|\tloss: 1182.11\n",
      "Training Epoch 97  55.3% | batch:        52 of        94\t|\tloss: 506.013\n",
      "Training Epoch 97  56.4% | batch:        53 of        94\t|\tloss: 736.977\n",
      "Training Epoch 97  57.4% | batch:        54 of        94\t|\tloss: 681.866\n",
      "Training Epoch 97  58.5% | batch:        55 of        94\t|\tloss: 732.32\n",
      "Training Epoch 97  59.6% | batch:        56 of        94\t|\tloss: 771.974\n",
      "Training Epoch 97  60.6% | batch:        57 of        94\t|\tloss: 989.153\n",
      "Training Epoch 97  61.7% | batch:        58 of        94\t|\tloss: 1226.16\n",
      "Training Epoch 97  62.8% | batch:        59 of        94\t|\tloss: 766.65\n",
      "Training Epoch 97  63.8% | batch:        60 of        94\t|\tloss: 687.951\n",
      "Training Epoch 97  64.9% | batch:        61 of        94\t|\tloss: 983.746\n",
      "Training Epoch 97  66.0% | batch:        62 of        94\t|\tloss: 833.274\n",
      "Training Epoch 97  67.0% | batch:        63 of        94\t|\tloss: 746.608\n",
      "Training Epoch 97  68.1% | batch:        64 of        94\t|\tloss: 583.007\n",
      "Training Epoch 97  69.1% | batch:        65 of        94\t|\tloss: 993.206\n",
      "Training Epoch 97  70.2% | batch:        66 of        94\t|\tloss: 1216.7\n",
      "Training Epoch 97  71.3% | batch:        67 of        94\t|\tloss: 619.619\n",
      "Training Epoch 97  72.3% | batch:        68 of        94\t|\tloss: 985.672\n",
      "Training Epoch 97  73.4% | batch:        69 of        94\t|\tloss: 737.932\n",
      "Training Epoch 97  74.5% | batch:        70 of        94\t|\tloss: 844.11\n",
      "Training Epoch 97  75.5% | batch:        71 of        94\t|\tloss: 677.787\n",
      "Training Epoch 97  76.6% | batch:        72 of        94\t|\tloss: 655.592\n",
      "Training Epoch 97  77.7% | batch:        73 of        94\t|\tloss: 1537.42\n",
      "Training Epoch 97  78.7% | batch:        74 of        94\t|\tloss: 811.999\n",
      "Training Epoch 97  79.8% | batch:        75 of        94\t|\tloss: 662.411\n",
      "Training Epoch 97  80.9% | batch:        76 of        94\t|\tloss: 797.399\n",
      "Training Epoch 97  81.9% | batch:        77 of        94\t|\tloss: 625.974\n",
      "Training Epoch 97  83.0% | batch:        78 of        94\t|\tloss: 1610.9\n",
      "Training Epoch 97  84.0% | batch:        79 of        94\t|\tloss: 839.805\n",
      "Training Epoch 97  85.1% | batch:        80 of        94\t|\tloss: 1196.16\n",
      "Training Epoch 97  86.2% | batch:        81 of        94\t|\tloss: 1145.65\n",
      "Training Epoch 97  87.2% | batch:        82 of        94\t|\tloss: 1273.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:39,519 | INFO : Epoch 97 Training Summary: epoch: 97.000000 | loss: 915.225924 | \n",
      "2023-05-09 14:23:39,520 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.7815628051757812 seconds\n",
      "\n",
      "2023-05-09 14:23:39,521 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.829074584331709 seconds\n",
      "2023-05-09 14:23:39,521 | INFO : Avg batch train. time: 0.01945824025884797 seconds\n",
      "2023-05-09 14:23:39,522 | INFO : Avg sample train. time: 0.00015347160465948223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 97  88.3% | batch:        83 of        94\t|\tloss: 691.361\n",
      "Training Epoch 97  89.4% | batch:        84 of        94\t|\tloss: 578.667\n",
      "Training Epoch 97  90.4% | batch:        85 of        94\t|\tloss: 792.104\n",
      "Training Epoch 97  91.5% | batch:        86 of        94\t|\tloss: 795.655\n",
      "Training Epoch 97  92.6% | batch:        87 of        94\t|\tloss: 1397.12\n",
      "Training Epoch 97  93.6% | batch:        88 of        94\t|\tloss: 761.197\n",
      "Training Epoch 97  94.7% | batch:        89 of        94\t|\tloss: 1022.42\n",
      "Training Epoch 97  95.7% | batch:        90 of        94\t|\tloss: 1065.26\n",
      "Training Epoch 97  96.8% | batch:        91 of        94\t|\tloss: 787.423\n",
      "Training Epoch 97  97.9% | batch:        92 of        94\t|\tloss: 1364.59\n",
      "Training Epoch 97  98.9% | batch:        93 of        94\t|\tloss: 4797.16\n",
      "\n",
      "Training Epoch 98   0.0% | batch:         0 of        94\t|\tloss: 490.298\n",
      "Training Epoch 98   1.1% | batch:         1 of        94\t|\tloss: 1535.59\n",
      "Training Epoch 98   2.1% | batch:         2 of        94\t|\tloss: 725.203\n",
      "Training Epoch 98   3.2% | batch:         3 of        94\t|\tloss: 1404.97\n",
      "Training Epoch 98   4.3% | batch:         4 of        94\t|\tloss: 713.895\n",
      "Training Epoch 98   5.3% | batch:         5 of        94\t|\tloss: 603.187\n",
      "Training Epoch 98   6.4% | batch:         6 of        94\t|\tloss: 695.881\n",
      "Training Epoch 98   7.4% | batch:         7 of        94\t|\tloss: 1377.38\n",
      "Training Epoch 98   8.5% | batch:         8 of        94\t|\tloss: 734.482\n",
      "Training Epoch 98   9.6% | batch:         9 of        94\t|\tloss: 864.665\n",
      "Training Epoch 98  10.6% | batch:        10 of        94\t|\tloss: 924.472\n",
      "Training Epoch 98  11.7% | batch:        11 of        94\t|\tloss: 889.918\n",
      "Training Epoch 98  12.8% | batch:        12 of        94\t|\tloss: 873.92\n",
      "Training Epoch 98  13.8% | batch:        13 of        94\t|\tloss: 736.01\n",
      "Training Epoch 98  14.9% | batch:        14 of        94\t|\tloss: 576.553\n",
      "Training Epoch 98  16.0% | batch:        15 of        94\t|\tloss: 934.642\n",
      "Training Epoch 98  17.0% | batch:        16 of        94\t|\tloss: 573.048\n",
      "Training Epoch 98  18.1% | batch:        17 of        94\t|\tloss: 829.13\n",
      "Training Epoch 98  19.1% | batch:        18 of        94\t|\tloss: 733.366\n",
      "Training Epoch 98  20.2% | batch:        19 of        94\t|\tloss: 646.867\n",
      "Training Epoch 98  21.3% | batch:        20 of        94\t|\tloss: 1015.03\n",
      "Training Epoch 98  22.3% | batch:        21 of        94\t|\tloss: 687.855\n",
      "Training Epoch 98  23.4% | batch:        22 of        94\t|\tloss: 1054.83\n",
      "Training Epoch 98  24.5% | batch:        23 of        94\t|\tloss: 956.573\n",
      "Training Epoch 98  25.5% | batch:        24 of        94\t|\tloss: 758.989\n",
      "Training Epoch 98  26.6% | batch:        25 of        94\t|\tloss: 519.089\n",
      "Training Epoch 98  27.7% | batch:        26 of        94\t|\tloss: 695.713\n",
      "Training Epoch 98  28.7% | batch:        27 of        94\t|\tloss: 1100.66\n",
      "Training Epoch 98  29.8% | batch:        28 of        94\t|\tloss: 618.82\n",
      "Training Epoch 98  30.9% | batch:        29 of        94\t|\tloss: 798.248\n",
      "Training Epoch 98  31.9% | batch:        30 of        94\t|\tloss: 736.633\n",
      "Training Epoch 98  33.0% | batch:        31 of        94\t|\tloss: 1221.26\n",
      "Training Epoch 98  34.0% | batch:        32 of        94\t|\tloss: 767.53\n",
      "Training Epoch 98  35.1% | batch:        33 of        94\t|\tloss: 847.053\n",
      "Training Epoch 98  36.2% | batch:        34 of        94\t|\tloss: 711.378\n",
      "Training Epoch 98  37.2% | batch:        35 of        94\t|\tloss: 637.23\n",
      "Training Epoch 98  38.3% | batch:        36 of        94\t|\tloss: 843.405\n",
      "Training Epoch 98  39.4% | batch:        37 of        94\t|\tloss: 662.296\n",
      "Training Epoch 98  40.4% | batch:        38 of        94\t|\tloss: 603.34\n",
      "Training Epoch 98  41.5% | batch:        39 of        94\t|\tloss: 883.744\n",
      "Training Epoch 98  42.6% | batch:        40 of        94\t|\tloss: 730.032\n",
      "Training Epoch 98  43.6% | batch:        41 of        94\t|\tloss: 666.177\n",
      "Training Epoch 98  44.7% | batch:        42 of        94\t|\tloss: 1155.38\n",
      "Training Epoch 98  45.7% | batch:        43 of        94\t|\tloss: 1054.8\n",
      "Training Epoch 98  46.8% | batch:        44 of        94\t|\tloss: 1025.22\n",
      "Training Epoch 98  47.9% | batch:        45 of        94\t|\tloss: 1144.11\n",
      "Training Epoch 98  48.9% | batch:        46 of        94\t|\tloss: 557.23\n",
      "Training Epoch 98  50.0% | batch:        47 of        94\t|\tloss: 902.718\n",
      "Training Epoch 98  51.1% | batch:        48 of        94\t|\tloss: 1061.28\n",
      "Training Epoch 98  52.1% | batch:        49 of        94\t|\tloss: 725.441\n",
      "Training Epoch 98  53.2% | batch:        50 of        94\t|\tloss: 1279.36\n",
      "Training Epoch 98  54.3% | batch:        51 of        94\t|\tloss: 930.134\n",
      "Training Epoch 98  55.3% | batch:        52 of        94\t|\tloss: 899.576\n",
      "Training Epoch 98  56.4% | batch:        53 of        94\t|\tloss: 725.012\n",
      "Training Epoch 98  57.4% | batch:        54 of        94\t|\tloss: 842.729\n",
      "Training Epoch 98  58.5% | batch:        55 of        94\t|\tloss: 1282.56\n",
      "Training Epoch 98  59.6% | batch:        56 of        94\t|\tloss: 817.052\n",
      "Training Epoch 98  60.6% | batch:        57 of        94\t|\tloss: 1131.78\n",
      "Training Epoch 98  61.7% | batch:        58 of        94\t|\tloss: 666.722\n",
      "Training Epoch 98  62.8% | batch:        59 of        94\t|\tloss: 749.779\n",
      "Training Epoch 98  63.8% | batch:        60 of        94\t|\tloss: 751.875\n",
      "Training Epoch 98  64.9% | batch:        61 of        94\t|\tloss: 758.085\n",
      "Training Epoch 98  66.0% | batch:        62 of        94\t|\tloss: 834.035\n",
      "Training Epoch 98  67.0% | batch:        63 of        94\t|\tloss: 908.536\n",
      "Training Epoch 98  68.1% | batch:        64 of        94\t|\tloss: 514.566\n",
      "Training Epoch 98  69.1% | batch:        65 of        94\t|\tloss: 625.413\n",
      "Training Epoch 98  70.2% | batch:        66 of        94\t|\tloss: 615.004\n",
      "Training Epoch 98  71.3% | batch:        67 of        94\t|\tloss: 807.853\n",
      "Training Epoch 98  72.3% | batch:        68 of        94\t|\tloss: 607.847\n",
      "Training Epoch 98  73.4% | batch:        69 of        94\t|\tloss: 1014.49\n",
      "Training Epoch 98  74.5% | batch:        70 of        94\t|\tloss: 947.43\n",
      "Training Epoch 98  75.5% | batch:        71 of        94\t|\tloss: 847.765\n",
      "Training Epoch 98  76.6% | batch:        72 of        94\t|\tloss: 599.406\n",
      "Training Epoch 98  77.7% | batch:        73 of        94\t|\tloss: 1074.25\n",
      "Training Epoch 98  78.7% | batch:        74 of        94\t|\tloss: 1393.7\n",
      "Training Epoch 98  79.8% | batch:        75 of        94\t|\tloss: 561.626\n",
      "Training Epoch 98  80.9% | batch:        76 of        94\t|\tloss: 964.823\n",
      "Training Epoch 98  81.9% | batch:        77 of        94\t|\tloss: 2624.45\n",
      "Training Epoch 98  83.0% | batch:        78 of        94\t|\tloss: 1188.48\n",
      "Training Epoch 98  84.0% | batch:        79 of        94\t|\tloss: 1101.73\n",
      "Training Epoch 98  85.1% | batch:        80 of        94\t|\tloss: 640.237\n",
      "Training Epoch 98  86.2% | batch:        81 of        94\t|\tloss: 753.776\n",
      "Training Epoch 98  87.2% | batch:        82 of        94\t|\tloss: 1018.61\n",
      "Training Epoch 98  88.3% | batch:        83 of        94\t|\tloss: 965.142\n",
      "Training Epoch 98  89.4% | batch:        84 of        94\t|\tloss: 981.131\n",
      "Training Epoch 98  90.4% | batch:        85 of        94\t|\tloss: 1204.85\n",
      "Training Epoch 98  91.5% | batch:        86 of        94\t|\tloss: 517.061\n",
      "Training Epoch 98  92.6% | batch:        87 of        94\t|\tloss: 864.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:41,357 | INFO : Epoch 98 Training Summary: epoch: 98.000000 | loss: 878.237451 | \n",
      "2023-05-09 14:23:41,358 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.8149802684783936 seconds\n",
      "\n",
      "2023-05-09 14:23:41,359 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8289307647821855 seconds\n",
      "2023-05-09 14:23:41,359 | INFO : Avg batch train. time: 0.01945671026364027 seconds\n",
      "2023-05-09 14:23:41,360 | INFO : Avg sample train. time: 0.0001534595372362968 seconds\n",
      "2023-05-09 14:23:41,360 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 98  93.6% | batch:        88 of        94\t|\tloss: 708.471\n",
      "Training Epoch 98  94.7% | batch:        89 of        94\t|\tloss: 724.708\n",
      "Training Epoch 98  95.7% | batch:        90 of        94\t|\tloss: 987.016\n",
      "Training Epoch 98  96.8% | batch:        91 of        94\t|\tloss: 947.121\n",
      "Training Epoch 98  97.9% | batch:        92 of        94\t|\tloss: 815.024\n",
      "Training Epoch 98  98.9% | batch:        93 of        94\t|\tloss: 5236.08\n",
      "\n",
      "Evaluating Epoch 98   0.0% | batch:         0 of        40\t|\tloss: 6030.99\n",
      "Evaluating Epoch 98   2.5% | batch:         1 of        40\t|\tloss: 1199.5\n",
      "Evaluating Epoch 98   5.0% | batch:         2 of        40\t|\tloss: 3875.12\n",
      "Evaluating Epoch 98   7.5% | batch:         3 of        40\t|\tloss: 5984.5\n",
      "Evaluating Epoch 98  10.0% | batch:         4 of        40\t|\tloss: 3721.42\n",
      "Evaluating Epoch 98  12.5% | batch:         5 of        40\t|\tloss: 3008.24\n",
      "Evaluating Epoch 98  15.0% | batch:         6 of        40\t|\tloss: 8870.35\n",
      "Evaluating Epoch 98  17.5% | batch:         7 of        40\t|\tloss: 3680.11\n",
      "Evaluating Epoch 98  20.0% | batch:         8 of        40\t|\tloss: 3004.83\n",
      "Evaluating Epoch 98  22.5% | batch:         9 of        40\t|\tloss: 2473.93\n",
      "Evaluating Epoch 98  25.0% | batch:        10 of        40\t|\tloss: 5308.84\n",
      "Evaluating Epoch 98  27.5% | batch:        11 of        40\t|\tloss: 1451.89\n",
      "Evaluating Epoch 98  30.0% | batch:        12 of        40\t|\tloss: 5597.2\n",
      "Evaluating Epoch 98  32.5% | batch:        13 of        40\t|\tloss: 3445.29\n",
      "Evaluating Epoch 98  35.0% | batch:        14 of        40\t|\tloss: 2516.58\n",
      "Evaluating Epoch 98  37.5% | batch:        15 of        40\t|\tloss: 3592.42\n",
      "Evaluating Epoch 98  40.0% | batch:        16 of        40\t|\tloss: 3306.89\n",
      "Evaluating Epoch 98  42.5% | batch:        17 of        40\t|\tloss: 3534.67\n",
      "Evaluating Epoch 98  45.0% | batch:        18 of        40\t|\tloss: 2393.98\n",
      "Evaluating Epoch 98  47.5% | batch:        19 of        40\t|\tloss: 5533.16\n",
      "Evaluating Epoch 98  50.0% | batch:        20 of        40\t|\tloss: 6305.48\n",
      "Evaluating Epoch 98  52.5% | batch:        21 of        40\t|\tloss: 1158.8\n",
      "Evaluating Epoch 98  55.0% | batch:        22 of        40\t|\tloss: 4438.8\n",
      "Evaluating Epoch 98  57.5% | batch:        23 of        40\t|\tloss: 3856.85\n",
      "Evaluating Epoch 98  60.0% | batch:        24 of        40\t|\tloss: 1932.54\n",
      "Evaluating Epoch 98  62.5% | batch:        25 of        40\t|\tloss: 3730.59\n",
      "Evaluating Epoch 98  65.0% | batch:        26 of        40\t|\tloss: 8992.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:41,827 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.4663832187652588 seconds\n",
      "\n",
      "2023-05-09 14:23:41,828 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.47124577971065745 seconds\n",
      "2023-05-09 14:23:41,828 | INFO : Avg batch val. time: 0.011781144492766436 seconds\n",
      "2023-05-09 14:23:41,829 | INFO : Avg sample val. time: 9.335296745456764e-05 seconds\n",
      "2023-05-09 14:23:41,829 | INFO : Epoch 98 Validation Summary: epoch: 98.000000 | loss: 4136.257778 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 98  67.5% | batch:        27 of        40\t|\tloss: 3248.5\n",
      "Evaluating Epoch 98  70.0% | batch:        28 of        40\t|\tloss: 2306.41\n",
      "Evaluating Epoch 98  72.5% | batch:        29 of        40\t|\tloss: 8644.3\n",
      "Evaluating Epoch 98  75.0% | batch:        30 of        40\t|\tloss: 2103.52\n",
      "Evaluating Epoch 98  77.5% | batch:        31 of        40\t|\tloss: 1843.83\n",
      "Evaluating Epoch 98  80.0% | batch:        32 of        40\t|\tloss: 8094.62\n",
      "Evaluating Epoch 98  82.5% | batch:        33 of        40\t|\tloss: 5749.05\n",
      "Evaluating Epoch 98  85.0% | batch:        34 of        40\t|\tloss: 1147.26\n",
      "Evaluating Epoch 98  87.5% | batch:        35 of        40\t|\tloss: 5516.54\n",
      "Evaluating Epoch 98  90.0% | batch:        36 of        40\t|\tloss: 5352.6\n",
      "Evaluating Epoch 98  92.5% | batch:        37 of        40\t|\tloss: 2871.1\n",
      "Evaluating Epoch 98  95.0% | batch:        38 of        40\t|\tloss: 3235.32\n",
      "Evaluating Epoch 98  97.5% | batch:        39 of        40\t|\tloss: 9291.32\n",
      "\n",
      "Training Epoch 99   0.0% | batch:         0 of        94\t|\tloss: 1356.7\n",
      "Training Epoch 99   1.1% | batch:         1 of        94\t|\tloss: 681.931\n",
      "Training Epoch 99   2.1% | batch:         2 of        94\t|\tloss: 674.825\n",
      "Training Epoch 99   3.2% | batch:         3 of        94\t|\tloss: 963.481\n",
      "Training Epoch 99   4.3% | batch:         4 of        94\t|\tloss: 632.366\n",
      "Training Epoch 99   5.3% | batch:         5 of        94\t|\tloss: 941.725\n",
      "Training Epoch 99   6.4% | batch:         6 of        94\t|\tloss: 444.989\n",
      "Training Epoch 99   7.4% | batch:         7 of        94\t|\tloss: 791.761\n",
      "Training Epoch 99   8.5% | batch:         8 of        94\t|\tloss: 902.926\n",
      "Training Epoch 99   9.6% | batch:         9 of        94\t|\tloss: 773.573\n",
      "Training Epoch 99  10.6% | batch:        10 of        94\t|\tloss: 743.709\n",
      "Training Epoch 99  11.7% | batch:        11 of        94\t|\tloss: 1587.3\n",
      "Training Epoch 99  12.8% | batch:        12 of        94\t|\tloss: 763.765\n",
      "Training Epoch 99  13.8% | batch:        13 of        94\t|\tloss: 840.944\n",
      "Training Epoch 99  14.9% | batch:        14 of        94\t|\tloss: 782.915\n",
      "Training Epoch 99  16.0% | batch:        15 of        94\t|\tloss: 734.392\n",
      "Training Epoch 99  17.0% | batch:        16 of        94\t|\tloss: 978.733\n",
      "Training Epoch 99  18.1% | batch:        17 of        94\t|\tloss: 502.232\n",
      "Training Epoch 99  19.1% | batch:        18 of        94\t|\tloss: 959.349\n",
      "Training Epoch 99  20.2% | batch:        19 of        94\t|\tloss: 995.205\n",
      "Training Epoch 99  21.3% | batch:        20 of        94\t|\tloss: 790.362\n",
      "Training Epoch 99  22.3% | batch:        21 of        94\t|\tloss: 1019.03\n",
      "Training Epoch 99  23.4% | batch:        22 of        94\t|\tloss: 906.95\n",
      "Training Epoch 99  24.5% | batch:        23 of        94\t|\tloss: 979.201\n",
      "Training Epoch 99  25.5% | batch:        24 of        94\t|\tloss: 647.238\n",
      "Training Epoch 99  26.6% | batch:        25 of        94\t|\tloss: 1190.83\n",
      "Training Epoch 99  27.7% | batch:        26 of        94\t|\tloss: 506.779\n",
      "Training Epoch 99  28.7% | batch:        27 of        94\t|\tloss: 533.345\n",
      "Training Epoch 99  29.8% | batch:        28 of        94\t|\tloss: 830.905\n",
      "Training Epoch 99  30.9% | batch:        29 of        94\t|\tloss: 662.919\n",
      "Training Epoch 99  31.9% | batch:        30 of        94\t|\tloss: 693.955\n",
      "Training Epoch 99  33.0% | batch:        31 of        94\t|\tloss: 691.184\n",
      "Training Epoch 99  34.0% | batch:        32 of        94\t|\tloss: 650.218\n",
      "Training Epoch 99  35.1% | batch:        33 of        94\t|\tloss: 834.37\n",
      "Training Epoch 99  36.2% | batch:        34 of        94\t|\tloss: 840.996\n",
      "Training Epoch 99  37.2% | batch:        35 of        94\t|\tloss: 685.043\n",
      "Training Epoch 99  38.3% | batch:        36 of        94\t|\tloss: 1422.78\n",
      "Training Epoch 99  39.4% | batch:        37 of        94\t|\tloss: 761.343\n",
      "Training Epoch 99  40.4% | batch:        38 of        94\t|\tloss: 675.583\n",
      "Training Epoch 99  41.5% | batch:        39 of        94\t|\tloss: 792.79\n",
      "Training Epoch 99  42.6% | batch:        40 of        94\t|\tloss: 945.97\n",
      "Training Epoch 99  43.6% | batch:        41 of        94\t|\tloss: 738.812\n",
      "Training Epoch 99  44.7% | batch:        42 of        94\t|\tloss: 608.763\n",
      "Training Epoch 99  45.7% | batch:        43 of        94\t|\tloss: 533.544\n",
      "Training Epoch 99  46.8% | batch:        44 of        94\t|\tloss: 767.806\n",
      "Training Epoch 99  47.9% | batch:        45 of        94\t|\tloss: 2062.11\n",
      "Training Epoch 99  48.9% | batch:        46 of        94\t|\tloss: 1055.02\n",
      "Training Epoch 99  50.0% | batch:        47 of        94\t|\tloss: 652.672\n",
      "Training Epoch 99  51.1% | batch:        48 of        94\t|\tloss: 873.497\n",
      "Training Epoch 99  52.1% | batch:        49 of        94\t|\tloss: 952.019\n",
      "Training Epoch 99  53.2% | batch:        50 of        94\t|\tloss: 877.86\n",
      "Training Epoch 99  54.3% | batch:        51 of        94\t|\tloss: 673.958\n",
      "Training Epoch 99  55.3% | batch:        52 of        94\t|\tloss: 1152.42\n",
      "Training Epoch 99  56.4% | batch:        53 of        94\t|\tloss: 809.735\n",
      "Training Epoch 99  57.4% | batch:        54 of        94\t|\tloss: 792.812\n",
      "Training Epoch 99  58.5% | batch:        55 of        94\t|\tloss: 959.633\n",
      "Training Epoch 99  59.6% | batch:        56 of        94\t|\tloss: 678.858\n",
      "Training Epoch 99  60.6% | batch:        57 of        94\t|\tloss: 916.446\n",
      "Training Epoch 99  61.7% | batch:        58 of        94\t|\tloss: 712.057\n",
      "Training Epoch 99  62.8% | batch:        59 of        94\t|\tloss: 704.094\n",
      "Training Epoch 99  63.8% | batch:        60 of        94\t|\tloss: 669.932\n",
      "Training Epoch 99  64.9% | batch:        61 of        94\t|\tloss: 730.872\n",
      "Training Epoch 99  66.0% | batch:        62 of        94\t|\tloss: 852.717\n",
      "Training Epoch 99  67.0% | batch:        63 of        94\t|\tloss: 1437.08\n",
      "Training Epoch 99  68.1% | batch:        64 of        94\t|\tloss: 1458.48\n",
      "Training Epoch 99  69.1% | batch:        65 of        94\t|\tloss: 1128.34\n",
      "Training Epoch 99  70.2% | batch:        66 of        94\t|\tloss: 985.664\n",
      "Training Epoch 99  71.3% | batch:        67 of        94\t|\tloss: 779.625\n",
      "Training Epoch 99  72.3% | batch:        68 of        94\t|\tloss: 1124.28\n",
      "Training Epoch 99  73.4% | batch:        69 of        94\t|\tloss: 588.419\n",
      "Training Epoch 99  74.5% | batch:        70 of        94\t|\tloss: 488.638\n",
      "Training Epoch 99  75.5% | batch:        71 of        94\t|\tloss: 1026.36\n",
      "Training Epoch 99  76.6% | batch:        72 of        94\t|\tloss: 1066.66\n",
      "Training Epoch 99  77.7% | batch:        73 of        94\t|\tloss: 1035.14\n",
      "Training Epoch 99  78.7% | batch:        74 of        94\t|\tloss: 608.904\n",
      "Training Epoch 99  79.8% | batch:        75 of        94\t|\tloss: 784.11\n",
      "Training Epoch 99  80.9% | batch:        76 of        94\t|\tloss: 762.19\n",
      "Training Epoch 99  81.9% | batch:        77 of        94\t|\tloss: 794.632\n",
      "Training Epoch 99  83.0% | batch:        78 of        94\t|\tloss: 678.676\n",
      "Training Epoch 99  84.0% | batch:        79 of        94\t|\tloss: 902.682\n",
      "Training Epoch 99  85.1% | batch:        80 of        94\t|\tloss: 674.537\n",
      "Training Epoch 99  86.2% | batch:        81 of        94\t|\tloss: 1043.79\n",
      "Training Epoch 99  87.2% | batch:        82 of        94\t|\tloss: 1285.53\n",
      "Training Epoch 99  88.3% | batch:        83 of        94\t|\tloss: 1258.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:43,797 | INFO : Epoch 99 Training Summary: epoch: 99.000000 | loss: 881.385683 | \n",
      "2023-05-09 14:23:43,798 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.946284294128418 seconds\n",
      "\n",
      "2023-05-09 14:23:43,798 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.830116153967501 seconds\n",
      "2023-05-09 14:23:43,799 | INFO : Avg batch train. time: 0.01946932078688831 seconds\n",
      "2023-05-09 14:23:43,799 | INFO : Avg sample train. time: 0.00015355899932601954 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 99  89.4% | batch:        84 of        94\t|\tloss: 991.82\n",
      "Training Epoch 99  90.4% | batch:        85 of        94\t|\tloss: 810.623\n",
      "Training Epoch 99  91.5% | batch:        86 of        94\t|\tloss: 989.236\n",
      "Training Epoch 99  92.6% | batch:        87 of        94\t|\tloss: 949.921\n",
      "Training Epoch 99  93.6% | batch:        88 of        94\t|\tloss: 655.108\n",
      "Training Epoch 99  94.7% | batch:        89 of        94\t|\tloss: 1273.02\n",
      "Training Epoch 99  95.7% | batch:        90 of        94\t|\tloss: 1079.98\n",
      "Training Epoch 99  96.8% | batch:        91 of        94\t|\tloss: 943.654\n",
      "Training Epoch 99  97.9% | batch:        92 of        94\t|\tloss: 1391.99\n",
      "Training Epoch 99  98.9% | batch:        93 of        94\t|\tloss: 1626.18\n",
      "\n",
      "Training Epoch 100   0.0% | batch:         0 of        94\t|\tloss: 1145.46\n",
      "Training Epoch 100   1.1% | batch:         1 of        94\t|\tloss: 1158.03\n",
      "Training Epoch 100   2.1% | batch:         2 of        94\t|\tloss: 1155.51\n",
      "Training Epoch 100   3.2% | batch:         3 of        94\t|\tloss: 965.756\n",
      "Training Epoch 100   4.3% | batch:         4 of        94\t|\tloss: 1051.12\n",
      "Training Epoch 100   5.3% | batch:         5 of        94\t|\tloss: 1079.92\n",
      "Training Epoch 100   6.4% | batch:         6 of        94\t|\tloss: 768.407\n",
      "Training Epoch 100   7.4% | batch:         7 of        94\t|\tloss: 735.961\n",
      "Training Epoch 100   8.5% | batch:         8 of        94\t|\tloss: 761.021\n",
      "Training Epoch 100   9.6% | batch:         9 of        94\t|\tloss: 1192.23\n",
      "Training Epoch 100  10.6% | batch:        10 of        94\t|\tloss: 598.533\n",
      "Training Epoch 100  11.7% | batch:        11 of        94\t|\tloss: 659.341\n",
      "Training Epoch 100  12.8% | batch:        12 of        94\t|\tloss: 826.645\n",
      "Training Epoch 100  13.8% | batch:        13 of        94\t|\tloss: 609.006\n",
      "Training Epoch 100  14.9% | batch:        14 of        94\t|\tloss: 772.913\n",
      "Training Epoch 100  16.0% | batch:        15 of        94\t|\tloss: 567.092\n",
      "Training Epoch 100  17.0% | batch:        16 of        94\t|\tloss: 1030.5\n",
      "Training Epoch 100  18.1% | batch:        17 of        94\t|\tloss: 848.095\n",
      "Training Epoch 100  19.1% | batch:        18 of        94\t|\tloss: 897.664\n",
      "Training Epoch 100  20.2% | batch:        19 of        94\t|\tloss: 537.469\n",
      "Training Epoch 100  21.3% | batch:        20 of        94\t|\tloss: 1068.9\n",
      "Training Epoch 100  22.3% | batch:        21 of        94\t|\tloss: 1233.88\n",
      "Training Epoch 100  23.4% | batch:        22 of        94\t|\tloss: 669.271\n",
      "Training Epoch 100  24.5% | batch:        23 of        94\t|\tloss: 836.909\n",
      "Training Epoch 100  25.5% | batch:        24 of        94\t|\tloss: 650.319\n",
      "Training Epoch 100  26.6% | batch:        25 of        94\t|\tloss: 754.167\n",
      "Training Epoch 100  27.7% | batch:        26 of        94\t|\tloss: 777.631\n",
      "Training Epoch 100  28.7% | batch:        27 of        94\t|\tloss: 847.041\n",
      "Training Epoch 100  29.8% | batch:        28 of        94\t|\tloss: 611.757\n",
      "Training Epoch 100  30.9% | batch:        29 of        94\t|\tloss: 739.428\n",
      "Training Epoch 100  31.9% | batch:        30 of        94\t|\tloss: 630.908\n",
      "Training Epoch 100  33.0% | batch:        31 of        94\t|\tloss: 928.867\n",
      "Training Epoch 100  34.0% | batch:        32 of        94\t|\tloss: 545.19\n",
      "Training Epoch 100  35.1% | batch:        33 of        94\t|\tloss: 1023.76\n",
      "Training Epoch 100  36.2% | batch:        34 of        94\t|\tloss: 752.46\n",
      "Training Epoch 100  37.2% | batch:        35 of        94\t|\tloss: 797.479\n",
      "Training Epoch 100  38.3% | batch:        36 of        94\t|\tloss: 1226.64\n",
      "Training Epoch 100  39.4% | batch:        37 of        94\t|\tloss: 853.234\n",
      "Training Epoch 100  40.4% | batch:        38 of        94\t|\tloss: 651.607\n",
      "Training Epoch 100  41.5% | batch:        39 of        94\t|\tloss: 774.541\n",
      "Training Epoch 100  42.6% | batch:        40 of        94\t|\tloss: 661.522\n",
      "Training Epoch 100  43.6% | batch:        41 of        94\t|\tloss: 964.888\n",
      "Training Epoch 100  44.7% | batch:        42 of        94\t|\tloss: 1230.68\n",
      "Training Epoch 100  45.7% | batch:        43 of        94\t|\tloss: 552.661\n",
      "Training Epoch 100  46.8% | batch:        44 of        94\t|\tloss: 1130.31\n",
      "Training Epoch 100  47.9% | batch:        45 of        94\t|\tloss: 848.782\n",
      "Training Epoch 100  48.9% | batch:        46 of        94\t|\tloss: 686.697\n",
      "Training Epoch 100  50.0% | batch:        47 of        94\t|\tloss: 729.631\n",
      "Training Epoch 100  51.1% | batch:        48 of        94\t|\tloss: 929.463\n",
      "Training Epoch 100  52.1% | batch:        49 of        94\t|\tloss: 499.958\n",
      "Training Epoch 100  53.2% | batch:        50 of        94\t|\tloss: 1034.06\n",
      "Training Epoch 100  54.3% | batch:        51 of        94\t|\tloss: 666.769\n",
      "Training Epoch 100  55.3% | batch:        52 of        94\t|\tloss: 1578.39\n",
      "Training Epoch 100  56.4% | batch:        53 of        94\t|\tloss: 1989.33\n",
      "Training Epoch 100  57.4% | batch:        54 of        94\t|\tloss: 953.934\n",
      "Training Epoch 100  58.5% | batch:        55 of        94\t|\tloss: 570.642\n",
      "Training Epoch 100  59.6% | batch:        56 of        94\t|\tloss: 770.765\n",
      "Training Epoch 100  60.6% | batch:        57 of        94\t|\tloss: 991.202\n",
      "Training Epoch 100  61.7% | batch:        58 of        94\t|\tloss: 781.468\n",
      "Training Epoch 100  62.8% | batch:        59 of        94\t|\tloss: 682.677\n",
      "Training Epoch 100  63.8% | batch:        60 of        94\t|\tloss: 609.163\n",
      "Training Epoch 100  64.9% | batch:        61 of        94\t|\tloss: 1364.65\n",
      "Training Epoch 100  66.0% | batch:        62 of        94\t|\tloss: 1045.71\n",
      "Training Epoch 100  67.0% | batch:        63 of        94\t|\tloss: 618.171\n",
      "Training Epoch 100  68.1% | batch:        64 of        94\t|\tloss: 2266.49\n",
      "Training Epoch 100  69.1% | batch:        65 of        94\t|\tloss: 653.239\n",
      "Training Epoch 100  70.2% | batch:        66 of        94\t|\tloss: 483.141\n",
      "Training Epoch 100  71.3% | batch:        67 of        94\t|\tloss: 795.59\n",
      "Training Epoch 100  72.3% | batch:        68 of        94\t|\tloss: 645.566\n",
      "Training Epoch 100  73.4% | batch:        69 of        94\t|\tloss: 830.566\n",
      "Training Epoch 100  74.5% | batch:        70 of        94\t|\tloss: 1042.33\n",
      "Training Epoch 100  75.5% | batch:        71 of        94\t|\tloss: 1534.3\n",
      "Training Epoch 100  76.6% | batch:        72 of        94\t|\tloss: 824.279\n",
      "Training Epoch 100  77.7% | batch:        73 of        94\t|\tloss: 670.279\n",
      "Training Epoch 100  78.7% | batch:        74 of        94\t|\tloss: 808.648\n",
      "Training Epoch 100  79.8% | batch:        75 of        94\t|\tloss: 884.224\n",
      "Training Epoch 100  80.9% | batch:        76 of        94\t|\tloss: 753.05\n",
      "Training Epoch 100  81.9% | batch:        77 of        94\t|\tloss: 552.212\n",
      "Training Epoch 100  83.0% | batch:        78 of        94\t|\tloss: 1124.15\n",
      "Training Epoch 100  84.0% | batch:        79 of        94\t|\tloss: 532.808\n",
      "Training Epoch 100  85.1% | batch:        80 of        94\t|\tloss: 591.001\n",
      "Training Epoch 100  86.2% | batch:        81 of        94\t|\tloss: 1323.21\n",
      "Training Epoch 100  87.2% | batch:        82 of        94\t|\tloss: 684.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:45,780 | INFO : Epoch 100 Training Summary: epoch: 100.000000 | loss: 876.077557 | \n",
      "2023-05-09 14:23:45,781 | INFO : Epoch runtime: 0.0 hours, 0.0 minutes, 1.959930658340454 seconds\n",
      "\n",
      "2023-05-09 14:23:45,781 | INFO : Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8314142990112305 seconds\n",
      "2023-05-09 14:23:45,782 | INFO : Avg batch train. time: 0.019483130840545006 seconds\n",
      "2023-05-09 14:23:45,782 | INFO : Avg sample train. time: 0.00015366792238724874 seconds\n",
      "2023-05-09 14:23:45,783 | INFO : Evaluating on validation set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 100  88.3% | batch:        83 of        94\t|\tloss: 649.798\n",
      "Training Epoch 100  89.4% | batch:        84 of        94\t|\tloss: 1038.03\n",
      "Training Epoch 100  90.4% | batch:        85 of        94\t|\tloss: 1223.44\n",
      "Training Epoch 100  91.5% | batch:        86 of        94\t|\tloss: 977.008\n",
      "Training Epoch 100  92.6% | batch:        87 of        94\t|\tloss: 927.193\n",
      "Training Epoch 100  93.6% | batch:        88 of        94\t|\tloss: 533.146\n",
      "Training Epoch 100  94.7% | batch:        89 of        94\t|\tloss: 602.024\n",
      "Training Epoch 100  95.7% | batch:        90 of        94\t|\tloss: 1144.3\n",
      "Training Epoch 100  96.8% | batch:        91 of        94\t|\tloss: 1012.7\n",
      "Training Epoch 100  97.9% | batch:        92 of        94\t|\tloss: 721.34\n",
      "Training Epoch 100  98.9% | batch:        93 of        94\t|\tloss: 1062.51\n",
      "\n",
      "Evaluating Epoch 100   0.0% | batch:         0 of        40\t|\tloss: 6323.09\n",
      "Evaluating Epoch 100   2.5% | batch:         1 of        40\t|\tloss: 1268.33\n",
      "Evaluating Epoch 100   5.0% | batch:         2 of        40\t|\tloss: 3933.63\n",
      "Evaluating Epoch 100   7.5% | batch:         3 of        40\t|\tloss: 6129.68\n",
      "Evaluating Epoch 100  10.0% | batch:         4 of        40\t|\tloss: 3236.95\n",
      "Evaluating Epoch 100  12.5% | batch:         5 of        40\t|\tloss: 2465.06\n",
      "Evaluating Epoch 100  15.0% | batch:         6 of        40\t|\tloss: 8870.03\n",
      "Evaluating Epoch 100  17.5% | batch:         7 of        40\t|\tloss: 3517.52\n",
      "Evaluating Epoch 100  20.0% | batch:         8 of        40\t|\tloss: 2973.39\n",
      "Evaluating Epoch 100  22.5% | batch:         9 of        40\t|\tloss: 2562.82\n",
      "Evaluating Epoch 100  25.0% | batch:        10 of        40\t|\tloss: 4423.49\n",
      "Evaluating Epoch 100  27.5% | batch:        11 of        40\t|\tloss: 1339.12\n",
      "Evaluating Epoch 100  30.0% | batch:        12 of        40\t|\tloss: 5354.9\n",
      "Evaluating Epoch 100  32.5% | batch:        13 of        40\t|\tloss: 2708.76\n",
      "Evaluating Epoch 100  35.0% | batch:        14 of        40\t|\tloss: 2322.96\n",
      "Evaluating Epoch 100  37.5% | batch:        15 of        40\t|\tloss: 3174.28\n",
      "Evaluating Epoch 100  40.0% | batch:        16 of        40\t|\tloss: 3440.45\n",
      "Evaluating Epoch 100  42.5% | batch:        17 of        40\t|\tloss: 3455.05\n",
      "Evaluating Epoch 100  45.0% | batch:        18 of        40\t|\tloss: 2408.05\n",
      "Evaluating Epoch 100  47.5% | batch:        19 of        40\t|\tloss: 5618.88\n",
      "Evaluating Epoch 100  50.0% | batch:        20 of        40\t|\tloss: 5705.07\n",
      "Evaluating Epoch 100  52.5% | batch:        21 of        40\t|\tloss: 1192.38\n",
      "Evaluating Epoch 100  55.0% | batch:        22 of        40\t|\tloss: 3771.37\n",
      "Evaluating Epoch 100  57.5% | batch:        23 of        40\t|\tloss: 3183.22\n",
      "Evaluating Epoch 100  60.0% | batch:        24 of        40\t|\tloss: 1903.13\n",
      "Evaluating Epoch 100  62.5% | batch:        25 of        40\t|\tloss: 3386.08\n",
      "Evaluating Epoch 100  65.0% | batch:        26 of        40\t|\tloss: 8279.02\n",
      "Evaluating Epoch 100  67.5% | batch:        27 of        40\t|\tloss: 3001.52\n",
      "Evaluating Epoch 100  70.0% | batch:        28 of        40\t|\tloss: 2175.14\n",
      "Evaluating Epoch 100  72.5% | batch:        29 of        40\t|\tloss: 9215.76\n",
      "Evaluating Epoch 100  75.0% | batch:        30 of        40\t|\tloss: 2185.95\n",
      "Evaluating Epoch 100  77.5% | batch:        31 of        40\t|\tloss: 1858.74\n",
      "Evaluating Epoch 100  80.0% | batch:        32 of        40\t|\tloss: 7736.17\n",
      "Evaluating Epoch 100  82.5% | batch:        33 of        40\t|\tloss: 5954.31\n",
      "Evaluating Epoch 100  85.0% | batch:        34 of        40\t|\tloss: 1102.47\n",
      "Evaluating Epoch 100  87.5% | batch:        35 of        40\t|\tloss: 5052.45\n",
      "Evaluating Epoch 100  90.0% | batch:        36 of        40\t|\tloss: 5368.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:46,242 | INFO : Validation runtime: 0.0 hours, 0.0 minutes, 0.45929789543151855 seconds\n",
      "\n",
      "2023-05-09 14:23:46,243 | INFO : Avg val. time: 0.0 hours, 0.0 minutes, 0.4710160127052894 seconds\n",
      "2023-05-09 14:23:46,243 | INFO : Avg batch val. time: 0.011775400317632235 seconds\n",
      "2023-05-09 14:23:46,243 | INFO : Avg sample val. time: 9.330745101134893e-05 seconds\n",
      "2023-05-09 14:23:46,244 | INFO : Epoch 100 Validation Summary: epoch: 100.000000 | loss: 3958.755141 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 100  92.5% | batch:        37 of        40\t|\tloss: 2843.01\n",
      "Evaluating Epoch 100  95.0% | batch:        38 of        40\t|\tloss: 2993.59\n",
      "Evaluating Epoch 100  97.5% | batch:        39 of        40\t|\tloss: 8432.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info('Starting training...')\n",
    "for epoch in tqdm(range(start_epoch + 1, config[\"epochs\"] + 1), desc='Training Epoch', leave=False):\n",
    "    mark = epoch if config['save_all'] else 'last'\n",
    "    epoch_start_time = time.time()\n",
    "    aggr_metrics_train = trainer.train_epoch(epoch)  # dictionary of aggregate epoch metrics\n",
    "    epoch_runtime = time.time() - epoch_start_time\n",
    "    print()\n",
    "    print_str = 'Epoch {} Training Summary: '.format(epoch)\n",
    "    for k, v in aggr_metrics_train.items():\n",
    "        tensorboard_writer.add_scalar('{}/train'.format(k), v, epoch)\n",
    "        print_str += '{}: {:8f} | '.format(k, v)\n",
    "    logger.info(print_str)\n",
    "    logger.info(\"Epoch runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(epoch_runtime)))\n",
    "    total_epoch_time += epoch_runtime\n",
    "    avg_epoch_time = total_epoch_time / (epoch - start_epoch)\n",
    "    avg_batch_time = avg_epoch_time / len(train_loader)\n",
    "    avg_sample_time = avg_epoch_time / len(train_dataset)\n",
    "    logger.info(\"Avg epoch train. time: {} hours, {} minutes, {} seconds\".format(*utils.readable_time(avg_epoch_time)))\n",
    "    logger.info(\"Avg batch train. time: {} seconds\".format(avg_batch_time))\n",
    "    logger.info(\"Avg sample train. time: {} seconds\".format(avg_sample_time))\n",
    "\n",
    "    # evaluate if first or last epoch or at specified interval\n",
    "    if (epoch == config[\"epochs\"]) or (epoch == start_epoch + 1) or (epoch % config['val_interval'] == 0):\n",
    "        aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config,\n",
    "                                                              best_metrics, best_value, epoch)\n",
    "        metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "        metrics.append(list(metrics_values))\n",
    "\n",
    "    utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(mark)), epoch, model, optimizer)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    if epoch == config['lr_step'][lr_step]:\n",
    "        utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(epoch)), epoch, model, optimizer)\n",
    "        lr = lr * config['lr_factor'][lr_step]\n",
    "        if lr_step < len(config['lr_step']) - 1:  # so that this index does not get out of bounds\n",
    "            lr_step += 1\n",
    "        logger.info('Learning rate updated to: ', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    # Difficulty scheduling\n",
    "    if config['harden'] and check_progress(epoch):\n",
    "        train_loader.dataset.update()\n",
    "        val_loader.dataset.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb0f3183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 14:23:46,274 | INFO : Exported per epoch performance metrics in '../experiments/BeijingPM25Quality_finetuned_2023-05-09_14-15-00_aHA/metrics_BeijingPM25Quality_finetuned.xls'\n",
      "2023-05-09 14:23:46,276 | INFO : Exported performance record to 'Regression_records.xls'\n",
      "2023-05-09 14:23:46,277 | INFO : Best loss was 3337.196120369453. Other metrics: OrderedDict([('epoch', 28), ('loss', 3337.196120369453)])\n",
      "2023-05-09 14:23:46,277 | INFO : All Done!\n",
      "2023-05-09 14:23:46,278 | INFO : Total runtime: 0.0 hours, 8.0 minutes, 45.47783803939819 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3337.196120369453\n"
     ]
    }
   ],
   "source": [
    "# Export evolution of metrics over epochs\n",
    "header = metrics_names\n",
    "metrics_filepath = os.path.join(config[\"output_dir\"], \"metrics_\" + config[\"experiment_name\"] + \".xls\")\n",
    "book = utils.export_performance_metrics(metrics_filepath, metrics, header, sheet_name=\"metrics\")\n",
    "\n",
    "# Export record metrics to a file accumulating records from all experiments\n",
    "utils.register_record(config[\"records_file\"], config[\"initial_timestamp\"], config[\"experiment_name\"],\n",
    "                      best_metrics, aggr_metrics_val, comment=config['comment'])\n",
    "\n",
    "logger.info('Best {} was {}. Other metrics: {}'.format(config['key_metric'], best_value, best_metrics))\n",
    "logger.info('All Done!')\n",
    "\n",
    "total_runtime = time.time() - total_start_time\n",
    "logger.info(\"Total runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(total_runtime)))\n",
    "\n",
    "#return best_value\n",
    "print(best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9c15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f9776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(config):\n",
    "\n",
    "    total_epoch_time = 0\n",
    "    total_eval_time = 0\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Add file logging besides stdout\n",
    "    file_handler = logging.FileHandler(os.path.join(config['output_dir'], 'output.log'))\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    logger.info('Running:\\n{}\\n'.format(' '.join(sys.argv)))  # command used to run\n",
    "\n",
    "    if config['seed'] is not None:\n",
    "        torch.manual_seed(config['seed'])\n",
    "\n",
    "    device = torch.device('cuda' if (torch.cuda.is_available() and config['gpu'] != '-1') else 'cpu')\n",
    "    logger.info(\"Using device: {}\".format(device))\n",
    "    if device == 'cuda':\n",
    "        logger.info(\"Device index: {}\".format(torch.cuda.current_device()))\n",
    "\n",
    "    # Build data\n",
    "    logger.info(\"Loading and preprocessing data ...\")\n",
    "    data_class = data_factory[config['data_class']]\n",
    "    my_data = data_class(config['data_dir'], pattern=config['pattern'], n_proc=config['n_proc'], limit_size=config['limit_size'], config=config)\n",
    "    feat_dim = my_data.feature_df.shape[1]  # dimensionality of data features\n",
    "    if config['task'] == 'classification':\n",
    "        validation_method = 'StratifiedShuffleSplit'\n",
    "        labels = my_data.labels_df.values.flatten()\n",
    "    else:\n",
    "        validation_method = 'ShuffleSplit'\n",
    "        labels = None\n",
    "\n",
    "    # Split dataset\n",
    "    test_data = my_data\n",
    "    test_indices = None  # will be converted to empty list in `split_dataset`, if also test_set_ratio == 0\n",
    "    val_data = my_data\n",
    "    val_indices = []\n",
    "    if config['test_pattern']:  # used if test data come from different files / file patterns\n",
    "        test_data = data_class(config['data_dir'], pattern=config['test_pattern'], n_proc=-1, config=config)\n",
    "        test_indices = test_data.all_IDs\n",
    "    if config['test_from']:  # load test IDs directly from file, if available, otherwise use `test_set_ratio`. Can work together with `test_pattern`\n",
    "        test_indices = list(set([line.rstrip() for line in open(config['test_from']).readlines()]))\n",
    "        try:\n",
    "            test_indices = [int(ind) for ind in test_indices]  # integer indices\n",
    "        except ValueError:\n",
    "            pass  # in case indices are non-integers\n",
    "        logger.info(\"Loaded {} test IDs from file: '{}'\".format(len(test_indices), config['test_from']))\n",
    "    if config['val_pattern']:  # used if val data come from different files / file patterns\n",
    "        val_data = data_class(config['data_dir'], pattern=config['val_pattern'], n_proc=-1, config=config)\n",
    "        val_indices = val_data.all_IDs\n",
    "\n",
    "    # Note: currently a validation set must exist, either with `val_pattern` or `val_ratio`\n",
    "    # Using a `val_pattern` means that `val_ratio` == 0 and `test_ratio` == 0\n",
    "    if config['val_ratio'] > 0:\n",
    "        train_indices, val_indices, test_indices = split_dataset(data_indices=my_data.all_IDs,\n",
    "                                                                 validation_method=validation_method,\n",
    "                                                                 n_splits=1,\n",
    "                                                                 validation_ratio=config['val_ratio'],\n",
    "                                                                 test_set_ratio=config['test_ratio'],  # used only if test_indices not explicitly specified\n",
    "                                                                 test_indices=test_indices,\n",
    "                                                                 random_seed=1337,\n",
    "                                                                 labels=labels)\n",
    "        train_indices = train_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "        val_indices = val_indices[0]  # `split_dataset` returns a list of indices *per fold/split*\n",
    "    else:\n",
    "        train_indices = my_data.all_IDs\n",
    "        if test_indices is None:\n",
    "            test_indices = []\n",
    "\n",
    "    logger.info(\"{} samples may be used for training\".format(len(train_indices)))\n",
    "    logger.info(\"{} samples will be used for validation\".format(len(val_indices)))\n",
    "    logger.info(\"{} samples will be used for testing\".format(len(test_indices)))\n",
    "\n",
    "    with open(os.path.join(config['output_dir'], 'data_indices.json'), 'w') as f:\n",
    "        try:\n",
    "            json.dump({'train_indices': list(map(int, train_indices)),\n",
    "                       'val_indices': list(map(int, val_indices)),\n",
    "                       'test_indices': list(map(int, test_indices))}, f, indent=4)\n",
    "        except ValueError:  # in case indices are non-integers\n",
    "            json.dump({'train_indices': list(train_indices),\n",
    "                       'val_indices': list(val_indices),\n",
    "                       'test_indices': list(test_indices)}, f, indent=4)\n",
    "\n",
    "    # Pre-process features\n",
    "    normalizer = None\n",
    "    if config['norm_from']:\n",
    "        with open(config['norm_from'], 'rb') as f:\n",
    "            norm_dict = pickle.load(f)\n",
    "        normalizer = Normalizer(**norm_dict)\n",
    "    elif config['normalization'] is not None:\n",
    "        normalizer = Normalizer(config['normalization'])\n",
    "        my_data.feature_df.loc[train_indices] = normalizer.normalize(my_data.feature_df.loc[train_indices])\n",
    "        if not config['normalization'].startswith('per_sample'):\n",
    "            # get normalizing values from training set and store for future use\n",
    "            norm_dict = normalizer.__dict__\n",
    "            with open(os.path.join(config['output_dir'], 'normalization.pickle'), 'wb') as f:\n",
    "                pickle.dump(norm_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "    if normalizer is not None:\n",
    "        if len(val_indices):\n",
    "            val_data.feature_df.loc[val_indices] = normalizer.normalize(val_data.feature_df.loc[val_indices])\n",
    "        if len(test_indices):\n",
    "            test_data.feature_df.loc[test_indices] = normalizer.normalize(test_data.feature_df.loc[test_indices])\n",
    "\n",
    "    # Create model\n",
    "    logger.info(\"Creating model ...\")\n",
    "    model = model_factory(config, my_data)\n",
    "\n",
    "    if config['freeze']:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith('output_layer'):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    logger.info(\"Model:\\n{}\".format(model))\n",
    "    logger.info(\"Total number of parameters: {}\".format(utils.count_parameters(model)))\n",
    "    logger.info(\"Trainable parameters: {}\".format(utils.count_parameters(model, trainable=True)))\n",
    "\n",
    "\n",
    "    # Initialize optimizer\n",
    "\n",
    "    if config['global_reg']:\n",
    "        weight_decay = config['l2_reg']\n",
    "        output_reg = None\n",
    "    else:\n",
    "        weight_decay = 0\n",
    "        output_reg = config['l2_reg']\n",
    "\n",
    "    optim_class = get_optimizer(config['optimizer'])\n",
    "    optimizer = optim_class(model.parameters(), lr=config['lr'], weight_decay=weight_decay)\n",
    "\n",
    "    start_epoch = 0\n",
    "    lr_step = 0  # current step index of `lr_step`\n",
    "    lr = config['lr']  # current learning step\n",
    "    # Load model and optimizer state\n",
    "    if args.load_model:\n",
    "        model, optimizer, start_epoch = utils.load_model(model, config['load_model'], optimizer, config['resume'],\n",
    "                                                         config['change_output'],\n",
    "                                                         config['lr'],\n",
    "                                                         config['lr_step'],\n",
    "                                                         config['lr_factor'])\n",
    "    model.to(device)\n",
    "\n",
    "    loss_module = get_loss_module(config)\n",
    "\n",
    "    if config['test_only'] == 'testset':  # Only evaluate and skip training\n",
    "        dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "        test_dataset = dataset_class(test_data, test_indices)\n",
    "\n",
    "        test_loader = DataLoader(dataset=test_dataset,\n",
    "                                 batch_size=config['batch_size'],\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config['num_workers'],\n",
    "                                 pin_memory=True,\n",
    "                                 collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "        test_evaluator = runner_class(model, test_loader, device, loss_module,\n",
    "                                            print_interval=config['print_interval'], console=config['console'])\n",
    "        aggr_metrics_test, per_batch_test = test_evaluator.evaluate(keep_all=True)\n",
    "        print_str = 'Test Summary: '\n",
    "        for k, v in aggr_metrics_test.items():\n",
    "            print_str += '{}: {:8f} | '.format(k, v)\n",
    "        logger.info(print_str)\n",
    "        return\n",
    "    \n",
    "    # Initialize data generators\n",
    "    dataset_class, collate_fn, runner_class = pipeline_factory(config)\n",
    "    val_dataset = dataset_class(val_data, val_indices)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            shuffle=False,\n",
    "                            num_workers=config['num_workers'],\n",
    "                            pin_memory=True,\n",
    "                            collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    train_dataset = dataset_class(my_data, train_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=config['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=config['num_workers'],\n",
    "                              pin_memory=True,\n",
    "                              collate_fn=lambda x: collate_fn(x, max_len=model.max_len))\n",
    "\n",
    "    trainer = runner_class(model, train_loader, device, loss_module, optimizer, l2_reg=output_reg,\n",
    "                                 print_interval=config['print_interval'], console=config['console'])\n",
    "    val_evaluator = runner_class(model, val_loader, device, loss_module,\n",
    "                                       print_interval=config['print_interval'], console=config['console'])\n",
    "\n",
    "    tensorboard_writer = SummaryWriter(config['tensorboard_dir'])\n",
    "\n",
    "    best_value = 1e16 if config['key_metric'] in NEG_METRICS else -1e16  # initialize with +inf or -inf depending on key metric\n",
    "    metrics = []  # (for validation) list of lists: for each epoch, stores metrics like loss, ...\n",
    "    best_metrics = {}\n",
    "\n",
    "    # Evaluate on validation before training\n",
    "    aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config, best_metrics,\n",
    "                                                          best_value, epoch=0)\n",
    "    metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "    metrics.append(list(metrics_values))\n",
    "\n",
    "    logger.info('Starting training...')\n",
    "    for epoch in tqdm(range(start_epoch + 1, config[\"epochs\"] + 1), desc='Training Epoch', leave=False):\n",
    "        mark = epoch if config['save_all'] else 'last'\n",
    "        epoch_start_time = time.time()\n",
    "        aggr_metrics_train = trainer.train_epoch(epoch)  # dictionary of aggregate epoch metrics\n",
    "        epoch_runtime = time.time() - epoch_start_time\n",
    "        print()\n",
    "        print_str = 'Epoch {} Training Summary: '.format(epoch)\n",
    "        for k, v in aggr_metrics_train.items():\n",
    "            tensorboard_writer.add_scalar('{}/train'.format(k), v, epoch)\n",
    "            print_str += '{}: {:8f} | '.format(k, v)\n",
    "        logger.info(print_str)\n",
    "        logger.info(\"Epoch runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(epoch_runtime)))\n",
    "        total_epoch_time += epoch_runtime\n",
    "        avg_epoch_time = total_epoch_time / (epoch - start_epoch)\n",
    "        avg_batch_time = avg_epoch_time / len(train_loader)\n",
    "        avg_sample_time = avg_epoch_time / len(train_dataset)\n",
    "        logger.info(\"Avg epoch train. time: {} hours, {} minutes, {} seconds\".format(*utils.readable_time(avg_epoch_time)))\n",
    "        logger.info(\"Avg batch train. time: {} seconds\".format(avg_batch_time))\n",
    "        logger.info(\"Avg sample train. time: {} seconds\".format(avg_sample_time))\n",
    "\n",
    "        # evaluate if first or last epoch or at specified interval\n",
    "        if (epoch == config[\"epochs\"]) or (epoch == start_epoch + 1) or (epoch % config['val_interval'] == 0):\n",
    "            aggr_metrics_val, best_metrics, best_value = validate(val_evaluator, tensorboard_writer, config,\n",
    "                                                                  best_metrics, best_value, epoch)\n",
    "            metrics_names, metrics_values = zip(*aggr_metrics_val.items())\n",
    "            metrics.append(list(metrics_values))\n",
    "\n",
    "        utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(mark)), epoch, model, optimizer)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        if epoch == config['lr_step'][lr_step]:\n",
    "            utils.save_model(os.path.join(config['save_dir'], 'model_{}.pth'.format(epoch)), epoch, model, optimizer)\n",
    "            lr = lr * config['lr_factor'][lr_step]\n",
    "            if lr_step < len(config['lr_step']) - 1:  # so that this index does not get out of bounds\n",
    "                lr_step += 1\n",
    "            logger.info('Learning rate updated to: ', lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "        # Difficulty scheduling\n",
    "        if config['harden'] and check_progress(epoch):\n",
    "            train_loader.dataset.update()\n",
    "            val_loader.dataset.update()\n",
    "\n",
    "    # Export evolution of metrics over epochs\n",
    "    header = metrics_names\n",
    "    metrics_filepath = os.path.join(config[\"output_dir\"], \"metrics_\" + config[\"experiment_name\"] + \".xls\")\n",
    "    book = utils.export_performance_metrics(metrics_filepath, metrics, header, sheet_name=\"metrics\")\n",
    "\n",
    "    # Export record metrics to a file accumulating records from all experiments\n",
    "    utils.register_record(config[\"records_file\"], config[\"initial_timestamp\"], config[\"experiment_name\"],\n",
    "                          best_metrics, aggr_metrics_val, comment=config['comment'])\n",
    "\n",
    "    logger.info('Best {} was {}. Other metrics: {}'.format(config['key_metric'], best_value, best_metrics))\n",
    "    logger.info('All Done!')\n",
    "\n",
    "    total_runtime = time.time() - total_start_time\n",
    "    logger.info(\"Total runtime: {} hours, {} minutes, {} seconds\\n\".format(*utils.readable_time(total_runtime)))\n",
    "\n",
    "    return best_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ed5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3ff63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
